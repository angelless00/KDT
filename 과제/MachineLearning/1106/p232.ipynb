{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost 적용 -위스콘신 유방암 예측\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "2                 0.05999  ...          25.53            152.5      1709.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset=load_breast_cancer()\n",
    "features=dataset.data\n",
    "labels=dataset.target\n",
    "cancer_df=pd.DataFrame(data=features,columns=dataset.feature_names)\n",
    "cancer_df['target']=labels\n",
    "cancer_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "target\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)\n",
    "print(cancer_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n",
      "(409, 30) (46, 30)\n"
     ]
    }
   ],
   "source": [
    "# cancer_df 에서 feature 용 DataFrame 과 Lable용 Series 객체 추출\n",
    "# 맨 마지막 칼럼이 Label임. Feature용 DataFrame은 cancer_df의 첫번쨰 칼럼에서 맨 마지막 두번쨰 칼럼까지를 :-1 슬라이싱으로 추출.\n",
    "X_features=cancer_df.iloc[:,:-1]\n",
    "y_label=cancer_df.iloc[:,-1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_features,y_label,test_size=0.2,random_state=156)\n",
    "\n",
    "#위에서 만든 X_train,y_train을 다시 쪼개어 90%는 학습과 10%는 검증용 데이터로 분리\n",
    "X_tr,X_val,y_tr,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=156)\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(X_tr.shape,X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습, 검증, 테스트용 DMatrix를 생성.\n",
    "dtr=xgb.DMatrix(data=X_tr,label=y_tr)\n",
    "dval=xgb.DMatrix(data=X_val,label=y_val)\n",
    "dtest=xgb.DMatrix(data=X_test,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_depth':3,'eta':0.05,'objective':'binary:logistic','eval_metric':'logloss'}\n",
    "num_rounds=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.62480\teval-logloss:0.63104\n",
      "[1]\ttrain-logloss:0.58674\teval-logloss:0.60478\n",
      "[2]\ttrain-logloss:0.55226\teval-logloss:0.58223\n",
      "[3]\ttrain-logloss:0.52086\teval-logloss:0.56184\n",
      "[4]\ttrain-logloss:0.49192\teval-logloss:0.54118\n",
      "[5]\ttrain-logloss:0.46537\teval-logloss:0.52223\n",
      "[6]\ttrain-logloss:0.44029\teval-logloss:0.50287\n",
      "[7]\ttrain-logloss:0.41666\teval-logloss:0.48620\n",
      "[8]\ttrain-logloss:0.39525\teval-logloss:0.46974\n",
      "[9]\ttrain-logloss:0.37542\teval-logloss:0.45497\n",
      "[10]\ttrain-logloss:0.35701\teval-logloss:0.44131\n",
      "[11]\ttrain-logloss:0.33982\teval-logloss:0.43134\n",
      "[12]\ttrain-logloss:0.32297\teval-logloss:0.41972\n",
      "[13]\ttrain-logloss:0.30725\teval-logloss:0.40902\n",
      "[14]\ttrain-logloss:0.29327\teval-logloss:0.39883\n",
      "[15]\ttrain-logloss:0.27946\teval-logloss:0.38968\n",
      "[16]\ttrain-logloss:0.26691\teval-logloss:0.38150\n",
      "[17]\ttrain-logloss:0.25473\teval-logloss:0.37368\n",
      "[18]\ttrain-logloss:0.24385\teval-logloss:0.36666\n",
      "[19]\ttrain-logloss:0.23338\teval-logloss:0.35994\n",
      "[20]\ttrain-logloss:0.22320\teval-logloss:0.35374\n",
      "[21]\ttrain-logloss:0.21363\teval-logloss:0.34704\n",
      "[22]\ttrain-logloss:0.20487\teval-logloss:0.34206\n",
      "[23]\ttrain-logloss:0.19634\teval-logloss:0.33621\n",
      "[24]\ttrain-logloss:0.18830\teval-logloss:0.33178\n",
      "[25]\ttrain-logloss:0.18093\teval-logloss:0.32774\n",
      "[26]\ttrain-logloss:0.17374\teval-logloss:0.32297\n",
      "[27]\ttrain-logloss:0.16695\teval-logloss:0.31855\n",
      "[28]\ttrain-logloss:0.16059\teval-logloss:0.31495\n",
      "[29]\ttrain-logloss:0.15450\teval-logloss:0.31173\n",
      "[30]\ttrain-logloss:0.14875\teval-logloss:0.30735\n",
      "[31]\ttrain-logloss:0.14329\teval-logloss:0.30463\n",
      "[32]\ttrain-logloss:0.13807\teval-logloss:0.30242\n",
      "[33]\ttrain-logloss:0.13325\teval-logloss:0.29922\n",
      "[34]\ttrain-logloss:0.12864\teval-logloss:0.29722\n",
      "[35]\ttrain-logloss:0.12429\teval-logloss:0.29540\n",
      "[36]\ttrain-logloss:0.12000\teval-logloss:0.29300\n",
      "[37]\ttrain-logloss:0.11581\teval-logloss:0.29010\n",
      "[38]\ttrain-logloss:0.11210\teval-logloss:0.28883\n",
      "[39]\ttrain-logloss:0.10838\teval-logloss:0.28769\n",
      "[40]\ttrain-logloss:0.10481\teval-logloss:0.28574\n",
      "[41]\ttrain-logloss:0.10160\teval-logloss:0.28434\n",
      "[42]\ttrain-logloss:0.09832\teval-logloss:0.28226\n",
      "[43]\ttrain-logloss:0.09534\teval-logloss:0.28006\n",
      "[44]\ttrain-logloss:0.09249\teval-logloss:0.27854\n",
      "[45]\ttrain-logloss:0.08972\teval-logloss:0.27747\n",
      "[46]\ttrain-logloss:0.08700\teval-logloss:0.27654\n",
      "[47]\ttrain-logloss:0.08461\teval-logloss:0.27598\n",
      "[48]\ttrain-logloss:0.08225\teval-logloss:0.27415\n",
      "[49]\ttrain-logloss:0.08001\teval-logloss:0.27245\n",
      "[50]\ttrain-logloss:0.07784\teval-logloss:0.27104\n",
      "[51]\ttrain-logloss:0.07578\teval-logloss:0.26958\n",
      "[52]\ttrain-logloss:0.07384\teval-logloss:0.26869\n",
      "[53]\ttrain-logloss:0.07196\teval-logloss:0.26760\n",
      "[54]\ttrain-logloss:0.07021\teval-logloss:0.26661\n",
      "[55]\ttrain-logloss:0.06833\teval-logloss:0.26680\n",
      "[56]\ttrain-logloss:0.06671\teval-logloss:0.26517\n",
      "[57]\ttrain-logloss:0.06519\teval-logloss:0.26412\n",
      "[58]\ttrain-logloss:0.06368\teval-logloss:0.26444\n",
      "[59]\ttrain-logloss:0.06202\teval-logloss:0.26434\n",
      "[60]\ttrain-logloss:0.06048\teval-logloss:0.26208\n",
      "[61]\ttrain-logloss:0.05898\teval-logloss:0.26139\n",
      "[62]\ttrain-logloss:0.05756\teval-logloss:0.26155\n",
      "[63]\ttrain-logloss:0.05614\teval-logloss:0.26114\n",
      "[64]\ttrain-logloss:0.05486\teval-logloss:0.25973\n",
      "[65]\ttrain-logloss:0.05372\teval-logloss:0.25878\n",
      "[66]\ttrain-logloss:0.05263\teval-logloss:0.25758\n",
      "[67]\ttrain-logloss:0.05140\teval-logloss:0.25664\n",
      "[68]\ttrain-logloss:0.05019\teval-logloss:0.25625\n",
      "[69]\ttrain-logloss:0.04910\teval-logloss:0.25593\n",
      "[70]\ttrain-logloss:0.04806\teval-logloss:0.25438\n",
      "[71]\ttrain-logloss:0.04704\teval-logloss:0.25373\n",
      "[72]\ttrain-logloss:0.04606\teval-logloss:0.25411\n",
      "[73]\ttrain-logloss:0.04514\teval-logloss:0.25316\n",
      "[74]\ttrain-logloss:0.04435\teval-logloss:0.25248\n",
      "[75]\ttrain-logloss:0.04347\teval-logloss:0.25271\n",
      "[76]\ttrain-logloss:0.04260\teval-logloss:0.25282\n",
      "[77]\ttrain-logloss:0.04178\teval-logloss:0.25165\n",
      "[78]\ttrain-logloss:0.04099\teval-logloss:0.25181\n",
      "[79]\ttrain-logloss:0.04022\teval-logloss:0.25210\n",
      "[80]\ttrain-logloss:0.03942\teval-logloss:0.25194\n",
      "[81]\ttrain-logloss:0.03875\teval-logloss:0.25254\n",
      "[82]\ttrain-logloss:0.03799\teval-logloss:0.25264\n",
      "[83]\ttrain-logloss:0.03727\teval-logloss:0.25280\n",
      "[84]\ttrain-logloss:0.03657\teval-logloss:0.25281\n",
      "[85]\ttrain-logloss:0.03586\teval-logloss:0.25219\n",
      "[86]\ttrain-logloss:0.03530\teval-logloss:0.25288\n",
      "[87]\ttrain-logloss:0.03464\teval-logloss:0.25226\n",
      "[88]\ttrain-logloss:0.03401\teval-logloss:0.25167\n",
      "[89]\ttrain-logloss:0.03347\teval-logloss:0.25258\n",
      "[90]\ttrain-logloss:0.03297\teval-logloss:0.25331\n",
      "[91]\ttrain-logloss:0.03240\teval-logloss:0.25373\n",
      "[92]\ttrain-logloss:0.03184\teval-logloss:0.25323\n",
      "[93]\ttrain-logloss:0.03136\teval-logloss:0.25240\n",
      "[94]\ttrain-logloss:0.03086\teval-logloss:0.25324\n",
      "[95]\ttrain-logloss:0.03035\teval-logloss:0.25280\n",
      "[96]\ttrain-logloss:0.02985\teval-logloss:0.25215\n",
      "[97]\ttrain-logloss:0.02937\teval-logloss:0.25179\n",
      "[98]\ttrain-logloss:0.02892\teval-logloss:0.25143\n",
      "[99]\ttrain-logloss:0.02853\teval-logloss:0.25180\n",
      "[100]\ttrain-logloss:0.02810\teval-logloss:0.25151\n",
      "[101]\ttrain-logloss:0.02769\teval-logloss:0.25158\n",
      "[102]\ttrain-logloss:0.02729\teval-logloss:0.25130\n",
      "[103]\ttrain-logloss:0.02689\teval-logloss:0.25094\n",
      "[104]\ttrain-logloss:0.02654\teval-logloss:0.25054\n",
      "[105]\ttrain-logloss:0.02617\teval-logloss:0.25030\n",
      "[106]\ttrain-logloss:0.02580\teval-logloss:0.24850\n",
      "[107]\ttrain-logloss:0.02545\teval-logloss:0.24829\n",
      "[108]\ttrain-logloss:0.02509\teval-logloss:0.24828\n",
      "[109]\ttrain-logloss:0.02475\teval-logloss:0.24881\n",
      "[110]\ttrain-logloss:0.02443\teval-logloss:0.24912\n",
      "[111]\ttrain-logloss:0.02405\teval-logloss:0.24791\n",
      "[112]\ttrain-logloss:0.02374\teval-logloss:0.24846\n",
      "[113]\ttrain-logloss:0.02341\teval-logloss:0.24931\n",
      "[114]\ttrain-logloss:0.02314\teval-logloss:0.24832\n",
      "[115]\ttrain-logloss:0.02286\teval-logloss:0.24889\n",
      "[116]\ttrain-logloss:0.02255\teval-logloss:0.24866\n",
      "[117]\ttrain-logloss:0.02227\teval-logloss:0.24925\n",
      "[118]\ttrain-logloss:0.02197\teval-logloss:0.24679\n",
      "[119]\ttrain-logloss:0.02172\teval-logloss:0.24787\n",
      "[120]\ttrain-logloss:0.02141\teval-logloss:0.24846\n",
      "[121]\ttrain-logloss:0.02112\teval-logloss:0.24683\n",
      "[122]\ttrain-logloss:0.02088\teval-logloss:0.24650\n",
      "[123]\ttrain-logloss:0.02061\teval-logloss:0.24497\n",
      "[124]\ttrain-logloss:0.02037\teval-logloss:0.24529\n",
      "[125]\ttrain-logloss:0.02012\teval-logloss:0.24516\n",
      "[126]\ttrain-logloss:0.01987\teval-logloss:0.24576\n",
      "[127]\ttrain-logloss:0.01967\teval-logloss:0.24576\n",
      "[128]\ttrain-logloss:0.01943\teval-logloss:0.24563\n",
      "[129]\ttrain-logloss:0.01922\teval-logloss:0.24533\n",
      "[130]\ttrain-logloss:0.01900\teval-logloss:0.24591\n",
      "[131]\ttrain-logloss:0.01881\teval-logloss:0.24593\n",
      "[132]\ttrain-logloss:0.01858\teval-logloss:0.24582\n",
      "[133]\ttrain-logloss:0.01839\teval-logloss:0.24619\n",
      "[134]\ttrain-logloss:0.01824\teval-logloss:0.24631\n",
      "[135]\ttrain-logloss:0.01805\teval-logloss:0.24669\n",
      "[136]\ttrain-logloss:0.01785\teval-logloss:0.24660\n",
      "[137]\ttrain-logloss:0.01770\teval-logloss:0.24584\n",
      "[138]\ttrain-logloss:0.01753\teval-logloss:0.24465\n",
      "[139]\ttrain-logloss:0.01734\teval-logloss:0.24458\n",
      "[140]\ttrain-logloss:0.01720\teval-logloss:0.24385\n",
      "[141]\ttrain-logloss:0.01703\teval-logloss:0.24422\n",
      "[142]\ttrain-logloss:0.01690\teval-logloss:0.24423\n",
      "[143]\ttrain-logloss:0.01673\teval-logloss:0.24408\n",
      "[144]\ttrain-logloss:0.01655\teval-logloss:0.24381\n",
      "[145]\ttrain-logloss:0.01641\teval-logloss:0.24311\n",
      "[146]\ttrain-logloss:0.01629\teval-logloss:0.24322\n",
      "[147]\ttrain-logloss:0.01614\teval-logloss:0.24360\n",
      "[148]\ttrain-logloss:0.01597\teval-logloss:0.24328\n",
      "[149]\ttrain-logloss:0.01582\teval-logloss:0.24314\n",
      "[150]\ttrain-logloss:0.01571\teval-logloss:0.24315\n",
      "[151]\ttrain-logloss:0.01556\teval-logloss:0.24289\n",
      "[152]\ttrain-logloss:0.01537\teval-logloss:0.24363\n",
      "[153]\ttrain-logloss:0.01523\teval-logloss:0.24404\n",
      "[154]\ttrain-logloss:0.01510\teval-logloss:0.24383\n",
      "[155]\ttrain-logloss:0.01493\teval-logloss:0.24435\n",
      "[156]\ttrain-logloss:0.01478\teval-logloss:0.24425\n",
      "[157]\ttrain-logloss:0.01467\teval-logloss:0.24361\n",
      "[158]\ttrain-logloss:0.01455\teval-logloss:0.24294\n",
      "[159]\ttrain-logloss:0.01440\teval-logloss:0.24340\n",
      "[160]\ttrain-logloss:0.01428\teval-logloss:0.24323\n",
      "[161]\ttrain-logloss:0.01417\teval-logloss:0.24310\n",
      "[162]\ttrain-logloss:0.01409\teval-logloss:0.24247\n",
      "[163]\ttrain-logloss:0.01393\teval-logloss:0.24311\n",
      "[164]\ttrain-logloss:0.01380\teval-logloss:0.24269\n",
      "[165]\ttrain-logloss:0.01368\teval-logloss:0.24268\n",
      "[166]\ttrain-logloss:0.01360\teval-logloss:0.24242\n",
      "[167]\ttrain-logloss:0.01345\teval-logloss:0.24306\n",
      "[168]\ttrain-logloss:0.01335\teval-logloss:0.24220\n",
      "[169]\ttrain-logloss:0.01328\teval-logloss:0.24116\n",
      "[170]\ttrain-logloss:0.01317\teval-logloss:0.24117\n",
      "[171]\ttrain-logloss:0.01308\teval-logloss:0.24126\n",
      "[172]\ttrain-logloss:0.01299\teval-logloss:0.24046\n",
      "[173]\ttrain-logloss:0.01292\teval-logloss:0.23993\n",
      "[174]\ttrain-logloss:0.01284\teval-logloss:0.23985\n",
      "[175]\ttrain-logloss:0.01275\teval-logloss:0.23994\n",
      "[176]\ttrain-logloss:0.01268\teval-logloss:0.23986\n",
      "[177]\ttrain-logloss:0.01260\teval-logloss:0.23996\n",
      "[178]\ttrain-logloss:0.01253\teval-logloss:0.23943\n",
      "[179]\ttrain-logloss:0.01243\teval-logloss:0.23847\n",
      "[180]\ttrain-logloss:0.01236\teval-logloss:0.23842\n",
      "[181]\ttrain-logloss:0.01226\teval-logloss:0.23885\n",
      "[182]\ttrain-logloss:0.01220\teval-logloss:0.23828\n",
      "[183]\ttrain-logloss:0.01214\teval-logloss:0.23892\n",
      "[184]\ttrain-logloss:0.01205\teval-logloss:0.23804\n",
      "[185]\ttrain-logloss:0.01198\teval-logloss:0.23799\n",
      "[186]\ttrain-logloss:0.01191\teval-logloss:0.23809\n",
      "[187]\ttrain-logloss:0.01185\teval-logloss:0.23752\n",
      "[188]\ttrain-logloss:0.01176\teval-logloss:0.23662\n",
      "[189]\ttrain-logloss:0.01170\teval-logloss:0.23659\n",
      "[190]\ttrain-logloss:0.01163\teval-logloss:0.23668\n",
      "[191]\ttrain-logloss:0.01157\teval-logloss:0.23732\n",
      "[192]\ttrain-logloss:0.01152\teval-logloss:0.23726\n",
      "[193]\ttrain-logloss:0.01146\teval-logloss:0.23722\n",
      "[194]\ttrain-logloss:0.01141\teval-logloss:0.23715\n",
      "[195]\ttrain-logloss:0.01136\teval-logloss:0.23661\n",
      "[196]\ttrain-logloss:0.01128\teval-logloss:0.23673\n",
      "[197]\ttrain-logloss:0.01126\teval-logloss:0.23651\n",
      "[198]\ttrain-logloss:0.01120\teval-logloss:0.23628\n",
      "[199]\ttrain-logloss:0.01113\teval-logloss:0.23641\n",
      "[200]\ttrain-logloss:0.01108\teval-logloss:0.23554\n",
      "[201]\ttrain-logloss:0.01103\teval-logloss:0.23533\n",
      "[202]\ttrain-logloss:0.01097\teval-logloss:0.23543\n",
      "[203]\ttrain-logloss:0.01091\teval-logloss:0.23546\n",
      "[204]\ttrain-logloss:0.01086\teval-logloss:0.23588\n",
      "[205]\ttrain-logloss:0.01079\teval-logloss:0.23600\n",
      "[206]\ttrain-logloss:0.01074\teval-logloss:0.23578\n",
      "[207]\ttrain-logloss:0.01069\teval-logloss:0.23597\n",
      "[208]\ttrain-logloss:0.01064\teval-logloss:0.23601\n",
      "[209]\ttrain-logloss:0.01058\teval-logloss:0.23613\n",
      "[210]\ttrain-logloss:0.01054\teval-logloss:0.23592\n",
      "[211]\ttrain-logloss:0.01047\teval-logloss:0.23605\n",
      "[212]\ttrain-logloss:0.01045\teval-logloss:0.23586\n",
      "[213]\ttrain-logloss:0.01041\teval-logloss:0.23626\n",
      "[214]\ttrain-logloss:0.01036\teval-logloss:0.23646\n",
      "[215]\ttrain-logloss:0.01031\teval-logloss:0.23649\n",
      "[216]\ttrain-logloss:0.01026\teval-logloss:0.23697\n",
      "[217]\ttrain-logloss:0.01024\teval-logloss:0.23679\n",
      "[218]\ttrain-logloss:0.01019\teval-logloss:0.23689\n",
      "[219]\ttrain-logloss:0.01014\teval-logloss:0.23693\n",
      "[220]\ttrain-logloss:0.01011\teval-logloss:0.23714\n",
      "[221]\ttrain-logloss:0.01006\teval-logloss:0.23732\n",
      "[222]\ttrain-logloss:0.01004\teval-logloss:0.23714\n",
      "[223]\ttrain-logloss:0.01001\teval-logloss:0.23736\n",
      "[224]\ttrain-logloss:0.00999\teval-logloss:0.23711\n",
      "[225]\ttrain-logloss:0.00997\teval-logloss:0.23703\n",
      "[226]\ttrain-logloss:0.00994\teval-logloss:0.23757\n",
      "[227]\ttrain-logloss:0.00992\teval-logloss:0.23740\n",
      "[228]\ttrain-logloss:0.00986\teval-logloss:0.23673\n",
      "[229]\ttrain-logloss:0.00984\teval-logloss:0.23649\n",
      "[230]\ttrain-logloss:0.00981\teval-logloss:0.23670\n",
      "[231]\ttrain-logloss:0.00979\teval-logloss:0.23653\n",
      "[232]\ttrain-logloss:0.00975\teval-logloss:0.23671\n",
      "[233]\ttrain-logloss:0.00971\teval-logloss:0.23674\n",
      "[234]\ttrain-logloss:0.00968\teval-logloss:0.23696\n",
      "[235]\ttrain-logloss:0.00966\teval-logloss:0.23673\n",
      "[236]\ttrain-logloss:0.00964\teval-logloss:0.23656\n",
      "[237]\ttrain-logloss:0.00961\teval-logloss:0.23708\n",
      "[238]\ttrain-logloss:0.00957\teval-logloss:0.23764\n",
      "[239]\ttrain-logloss:0.00954\teval-logloss:0.23766\n",
      "[240]\ttrain-logloss:0.00949\teval-logloss:0.23778\n",
      "[241]\ttrain-logloss:0.00948\teval-logloss:0.23775\n",
      "[242]\ttrain-logloss:0.00945\teval-logloss:0.23796\n",
      "[243]\ttrain-logloss:0.00943\teval-logloss:0.23780\n",
      "[244]\ttrain-logloss:0.00941\teval-logloss:0.23827\n",
      "[245]\ttrain-logloss:0.00940\teval-logloss:0.23819\n",
      "[246]\ttrain-logloss:0.00937\teval-logloss:0.23840\n",
      "[247]\ttrain-logloss:0.00935\teval-logloss:0.23838\n",
      "[248]\ttrain-logloss:0.00933\teval-logloss:0.23821\n",
      "[249]\ttrain-logloss:0.00931\teval-logloss:0.23872\n",
      "[250]\ttrain-logloss:0.00925\teval-logloss:0.23805\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터셋은 'train' 또는 평가데이터셋은 'eval'로 명기합니다.\n",
    "eval_list=[(dtr,'train'),(dval,'eval')]\n",
    "\n",
    "# 하이퍼 파라미터와 early stopping 파라미터를 train() 함수의 파라미터로 전달\n",
    "xgb_model=xgb.train(params=params,dtrain=dtr,num_boost_round=num_rounds,early_stopping_rounds=50,evals=eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict()수행 결괏값을 10개만 표시, 예측 확률 값으로 표시됨\n",
      "[0.938 0.004 0.75  0.049 0.98  1.    0.999 0.999 0.998 0.001]\n",
      "예측값 10개만 표시 [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "pred_probs=xgb_model.predict(dtest)\n",
    "print('predict()수행 결괏값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5보다 크면 1, 그렇지 않으면 0으로 예측값 결정하여 List 객체인 preds에 저장\n",
    "preds=[1 if x>0.5 else 0 for x in pred_probs]\n",
    "print('예측값 10개만 표시',preds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_clf_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_clf_eval\u001b[49m(y_test,preds,pred_probs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_clf_eval' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

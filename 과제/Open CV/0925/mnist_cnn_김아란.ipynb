{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import multiCLFutils as utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH='../../../수업/TORCH_IMAGE/data/'\n",
    "TRAIN_FILE='mnist_train.csv'\n",
    "TEST_FILE='mnist_test.csv'\n",
    "trainDF=pd.read_csv(DATA_PATH+TRAIN_FILE,header=None)\n",
    "testDF=pd.read_csv(DATA_PATH+TEST_FILE,header=None)\n",
    "train=trainDF[trainDF.columns[:-1]]\n",
    "label=trainDF[trainDF.columns[[-1]]]\n",
    "\n",
    "test=testDF[testDF.columns[:-1]]\n",
    "test_label=testDF[testDF.columns[[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 1))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDS=utils.MyDataSet(train,label)\n",
    "train_loader=DataLoader(trainDS,batch_size=100)\n",
    "\n",
    "testDS=utils.MyDataSet(test,test_label)\n",
    "test_loader=DataLoader(testDS,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FasionCNN,self).__init__()\n",
    "        self.layer1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=32,kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        self.layer2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc1=nn.Linear(in_features=64*6*6,out_features=600)\n",
    "        self.drop=nn.Dropout2d(0.25)\n",
    "        self.fc2=nn.Linear(in_features=600,out_features=120)\n",
    "        self.fc3=nn.Linear(in_features=120,out_features=10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=self.layer1(x)\n",
    "        out=self.layer2(out)\n",
    "        out=out.view(out.size(0),-1)\n",
    "        out=self.fc1(out)\n",
    "        out=self.drop(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "model=FasionCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasionCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
      "  (drop): Dropout2d(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-30\\anaconda3\\envs\\TORCH_38\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 500, Loss : 0.15700212121009827, Accuracy : 1058.3399658203125%\n",
      "Iteration : 1000, Loss : 0.17212453484535217, Accuracy : 1061.1500244140625%\n",
      "Iteration : 1500, Loss : 0.049235425889492035, Accuracy : 1061.8699951171875%\n",
      "Iteration : 2000, Loss : 0.003647630801424384, Accuracy : 1062.3299560546875%\n",
      "Iteration : 2500, Loss : 0.002935508731752634, Accuracy : 1061.739990234375%\n",
      "Iteration : 3000, Loss : 0.2826916575431824, Accuracy : 1062.3599853515625%\n"
     ]
    }
   ],
   "source": [
    "new_epochs=5\n",
    "count=0\n",
    "loss_list=[]\n",
    "iteration_list=[]\n",
    "accuracy_list=[]\n",
    "\n",
    "predictions_list=[]\n",
    "labels_list=[]\n",
    "\n",
    "for epoch in range(new_epochs):\n",
    "    for images,labels in train_loader:\n",
    "\n",
    "        train=Variable(images.view(100,1,28,28))\n",
    "        labels=Variable(labels)\n",
    "\n",
    "        outputs=model(train)\n",
    "        loss=criterion(outputs,labels.reshape(-1).long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count+=1\n",
    "\n",
    "        if not (count % 50):\n",
    "            total=0\n",
    "            correct=0\n",
    "            for images,labels in test_loader:\n",
    "                labels_list.append(labels)\n",
    "                test=Variable(images.view(100,1,28,28))\n",
    "                outputs=model(test)\n",
    "                predictions=torch.max(outputs,1)[1]\n",
    "                predictions_list.append(predictions)\n",
    "                correct+=(predictions==labels).sum()\n",
    "                total+=len(labels)\n",
    "\n",
    "            accuracy=correct*100/total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "\n",
    "        if not (count % 500) :\n",
    "            print(f'Iteration : {count}, Loss : {loss.data}, Accuracy : {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN 기반 다중분류 모델 구현 <hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐/속성 : 4개 Sepal_Length, Sepan_Width, Petal_ Length, Peatal_Width\n",
    "- 타겟/라벨 : 1개 variety\n",
    "- 학습방벙 : 지도학습 > 분류 > 다중 분류\n",
    "- 알고리즘 : 인공신경망 (ANN) -> MLP(Multi Layer Percetron),  심층신경망(DNN)(은닉층 多)\n",
    "- 프레임워크 : Pytorch\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비  <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로딩\n",
    "# Model 관련\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from torchinfo import summary\n",
    "\n",
    "# - Data관련\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch v.2.4.1\n",
      "Pandas v.2.0.3\n"
     ]
    }
   ],
   "source": [
    "# 활용 패키지 버전 체크 - 사용자 정의 함수로 구현할것!\n",
    "print(f'Pytorch v.{torch.__version__}')\n",
    "print(f'Pandas v.{pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 데이터로딩\n",
    "DATA_FILE='../../MachineLearning/data/iris.csv'\n",
    "\n",
    "## CSV >> DataFrame\n",
    "irisDF=pd.read_csv(DATA_FILE)\n",
    "\n",
    "## 확인\n",
    "irisDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels=> {'Setosa': 0, 'Versicolor': 1, 'Virginica': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타겟 정수화\n",
    "labels=dict(zip(irisDF['variety'].unique().tolist(),range(3)))\n",
    "print(f'labels=> {labels}')\n",
    "# 라벨인코딩<<\n",
    "irisDF['variety']=irisDF['variety'].replace(labels)\n",
    "irisDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 모델 클래스 설계 및 정의 <hr>\n",
    "- 클래스목적 : iris 데이터를 학습 및 추론 목적\n",
    "- 클래스이름 : IrisBCFModel\n",
    "- 부모클래스 : nn.Module\n",
    "- 매개변수 : 층별 입출력 갯수 고정하므로 필요 없음\n",
    "- 속성/필드 : featruesDF, targetDF, n_rows, n_features\n",
    "- 기능/역할 <필수 >\n",
    "    -  __ init __() : 모델 구조 설정 \n",
    "    - forward() : 순방향 학습 <- 오버라이딩(overriding)\n",
    "- 클래스구조\n",
    "    - 입력층 : 입력 4개 / 출력 10개 (퍼셉트론/뉴런 10개 존재)\n",
    "    - 은닉층 : 입력 10개 / 출력 5개 (퍼셉트론/뉴런 30개 존재) \n",
    "    - 출력층 : 입력 5개 / 출력 1개 (다중분류)\n",
    "- 손실함수/ 활성화함수 \n",
    "    - 클래스형태 => nn. 아래  \n",
    "        - ex) nn.ReLu << __init__() 에 사용\n",
    "    - 함수 형태 => torch.nn.functional 아래\n",
    "        - ex) F.relu << def forward() 에 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisMCFModel(nn.Module):\n",
    "\n",
    "    # 모델 구조 구성 및 인스턴스 생성 메서드\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer=nn.Linear(4,10)\n",
    "        self.hd_layer=nn.Linear(10,5)\n",
    "        self.out_layer=nn.Linear(5,3)   # 다중분류\n",
    "\n",
    "    # 순방향 학습 진행 메서드\n",
    "    def forward(self,x):\n",
    "        # - 입력층\n",
    "        y=self.in_layer(x)        # f1_1w1_1+f1_2w1_2+f1_3w1_3+b << 이런식 10개\n",
    "        y=F.relu(y)\n",
    "\n",
    "        # - 은닉층 : 10개의 숫자값 (>=0)\n",
    "        y=self.hd_layer(y)        # f2_1w2_1+f2_2w2_2+....f2_10w2_10 +b << 이런식 5개\n",
    "        y=F.relu(y)\n",
    "\n",
    "        # - 출력층 : 5개의 숫자값 (>=0) - 다중분류 : 손실함수 crossentroploss 가 내부에서 softmax진행\n",
    "        return self.out_layer(y)        # f3_1w3_1+.....f3_30w3_30+b << 1 개\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IrisMCFModel(\n",
      "  (in_layer): Linear(in_features=4, out_features=10, bias=True)\n",
      "  (hd_layer): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (out_layer): Linear(in_features=5, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### [테스트] 모델 인스턴스 생성\n",
    "model=IrisMCFModel()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "IrisMCFModel                             [17, 3]                   --\n",
       "├─Linear: 1-1                            [17, 10]                  50\n",
       "├─Linear: 1-2                            [17, 5]                   55\n",
       "├─Linear: 1-3                            [17, 3]                   18\n",
       "==========================================================================================\n",
       "Total params: 123\n",
       "Trainable params: 123\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### [테스트] 모델 확인\n",
    "summary(model,input_size=(17,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 데이터셋 클래스 설계 및 정의 <hr>\n",
    "- 데이터셋 : iris.csv\n",
    "- 피쳐개수 : 4개\n",
    "- 타겟개수 : 1개\n",
    "- 클래스이름 : IrisDataset\n",
    "- 부모클래스 : utils.data.Dataset\n",
    "- 속성필드 : featureDF, targetDF, n_rows, n_features\n",
    "- 필수메서드 \n",
    "    - __ init __(self) : 데이터셋 저장 및 전처리, 개발자가 필요한 속성 설정\n",
    "    - __ len __(self) : 데이터의 개수 반환\n",
    "    - __ getitem __(self,index) : 특정 인덱스의 피쳐와 타겟 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "\n",
    "    def __init__(self,featureDF,targetDF):\n",
    "        self.featureDF=featureDF\n",
    "        self.targetDF=targetDF\n",
    "        self.n_rows=featureDF.shape[0]      # 필수아님\n",
    "        self.n_features=featureDF.shape[1]  # 필수아님\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # 텐서화\n",
    "        featureTS=torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS=torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "        \n",
    "        # 피쳐와 타겟 반환\n",
    "        return featureTS, targetTS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.1000, 3.5000, 1.4000, 0.2000]]) tensor([[0.]])\n"
     ]
    }
   ],
   "source": [
    "## [테스트] 데이터셋 인스턴스 생성\n",
    "\n",
    "featureDF=irisDF[irisDF.columns[:4]]        # 2D (150,3)\n",
    "targetDF=irisDF[irisDF.columns[[4]]]        # 2D (150,1)\n",
    "\n",
    "# - 커스템데이터셋 인스턴스 생성\n",
    "irisDS=IrisDataset(featureDF,targetDF)\n",
    "\n",
    "# 데이터 로드 인스턴스 생성\n",
    "irisDL=DataLoader(irisDS)\n",
    "for feature,target in irisDL:\n",
    "    print(feature,target)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 학습 준비\n",
    "- 학습횟수 : EPOCH <- 처음부터 끝까지 공부하는 횟수\n",
    "- 배치크기 : BATCH_SIZE <- 한번에 학습할 데이터셋 양\n",
    "- 위치지정 : DEVICE <- 텐서 저장 및 실행 위치 (GPU/CPU)\n",
    "- 학습률(LR, learning Rate) : 가중치와 절편 업데이트 시 경사하강법으로 업데이트 간격 설정 0.001~0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 학습 진행 관련 설정 값 \n",
    "EPOCH = 100\n",
    "BATCH_SIZE= 10\n",
    "DEVICE ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스/객체 : 모델, 데이터셋, 최적화, 손실함수 (, 성능지표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X_train : (84, 4), X_val : (28, 4) , X_test : (38, 4)\n",
      " y_train : (84, 1), y_val : (28, 1) , y_test : (38, 1)\n"
     ]
    }
   ],
   "source": [
    "# 모델 인스턴스\n",
    "model= IrisMCFModel()\n",
    "\n",
    "# 데이터셋 인스턴스\n",
    "# # 학습,검증,테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test=train_test_split(featureDF,targetDF,random_state=1)\n",
    "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,random_state=1)\n",
    "print(f' X_train : {X_train.shape}, X_val : {X_val.shape} , X_test : {X_test.shape}')\n",
    "print(f' y_train : {y_train.shape}, y_val : {y_val.shape} , y_test : {y_test.shape}')\n",
    "\n",
    "\n",
    "\n",
    "trainDS=IrisDataset(X_train,y_train)\n",
    "valDS=IrisDataset(X_val,y_val)\n",
    "testDS=IrisDataset(X_test,y_test)\n",
    "\n",
    "# 데이터로더 인스턴스\n",
    "trainDL=DataLoader(trainDS,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최적화 , 손실함수 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 인스턴스 => W,b 텐서 즉, model.parameters() 전달\n",
    "optimizer=optim.Adam(model.parameters(),lr=LR)\n",
    "\n",
    "# 손실함수 인스턴스 => 분류 => 다중분류 CrossEntropyLoss \n",
    "#                            예측값은 선형식 결과값값으로 전달 => sigmoid() AF처리후 전달\n",
    "crossLoss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 학습진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100]\n",
      "trainloss=1.1592046287324693 trainscore=0.14590594917535782\n",
      "valloss=1.0728389024734497 trainscore=0.20000000298023224\n",
      "[1/100]\n",
      "trainloss=1.1277272038989596 trainscore=0.14590594917535782\n",
      "valloss=1.059334397315979 trainscore=0.20000000298023224\n",
      "[2/100]\n",
      "trainloss=1.1177448564105563 trainscore=0.14590594917535782\n",
      "valloss=1.0545114278793335 trainscore=0.20000000298023224\n",
      "[3/100]\n",
      "trainloss=1.1071663035286798 trainscore=0.14590594917535782\n",
      "valloss=1.0483423471450806 trainscore=0.20000000298023224\n",
      "[4/100]\n",
      "trainloss=1.0976316531499226 trainscore=0.19056746115287146\n",
      "valloss=1.0442503690719604 trainscore=0.35555556416511536\n",
      "[5/100]\n",
      "trainloss=1.088997695181105 trainscore=0.34080734352270764\n",
      "valloss=1.0430845022201538 trainscore=0.498964786529541\n",
      "[6/100]\n",
      "trainloss=1.080044772889879 trainscore=0.38403140505154926\n",
      "valloss=1.0404247045516968 trainscore=0.37037038803100586\n",
      "[7/100]\n",
      "trainloss=1.0726797978083293 trainscore=0.3095170342259937\n",
      "valloss=1.0409098863601685 trainscore=0.19298245012760162\n",
      "[8/100]\n",
      "trainloss=1.0654027594460382 trainscore=0.24036314007308748\n",
      "valloss=1.0403403043746948 trainscore=0.18803419172763824\n",
      "[9/100]\n",
      "trainloss=1.0585846768485174 trainscore=0.18974174310763678\n",
      "valloss=1.0389950275421143 trainscore=0.18803419172763824\n",
      "[10/100]\n",
      "trainloss=1.0530311399035983 trainscore=0.173298925989204\n",
      "valloss=1.0397101640701294 trainscore=0.18803419172763824\n",
      "[11/100]\n",
      "trainloss=1.0472087727652655 trainscore=0.173298925989204\n",
      "valloss=1.0393086671829224 trainscore=0.18803419172763824\n",
      "[12/100]\n",
      "trainloss=1.0416152477264404 trainscore=0.173298925989204\n",
      "valloss=1.0373207330703735 trainscore=0.18803419172763824\n",
      "[13/100]\n",
      "trainloss=1.0365200969907973 trainscore=0.173298925989204\n",
      "valloss=1.0360089540481567 trainscore=0.18803419172763824\n",
      "[14/100]\n",
      "trainloss=1.0310053428014119 trainscore=0.173298925989204\n",
      "valloss=1.0330477952957153 trainscore=0.18803419172763824\n",
      "[15/100]\n",
      "trainloss=1.0258649521403842 trainscore=0.173298925989204\n",
      "valloss=1.0300770998001099 trainscore=0.18803419172763824\n",
      "[16/100]\n",
      "trainloss=1.0200932886865404 trainscore=0.173298925989204\n",
      "valloss=1.024860143661499 trainscore=0.18803419172763824\n",
      "[17/100]\n",
      "trainloss=1.0148063235812717 trainscore=0.173298925989204\n",
      "valloss=1.020568609237671 trainscore=0.18803419172763824\n",
      "[18/100]\n",
      "trainloss=1.0088952912224665 trainscore=0.173298925989204\n",
      "valloss=1.0156859159469604 trainscore=0.18803419172763824\n",
      "[19/100]\n",
      "trainloss=1.0023703177769978 trainscore=0.173298925989204\n",
      "valloss=1.008582353591919 trainscore=0.18803419172763824\n",
      "[20/100]\n",
      "trainloss=0.9958759480052524 trainscore=0.173298925989204\n",
      "valloss=1.001177191734314 trainscore=0.18803419172763824\n",
      "[21/100]\n",
      "trainloss=0.9889903532134162 trainscore=0.173298925989204\n",
      "valloss=0.9930455088615417 trainscore=0.18803419172763824\n",
      "[22/100]\n",
      "trainloss=0.9816705915662978 trainscore=0.173298925989204\n",
      "valloss=0.9844149351119995 trainscore=0.18803419172763824\n",
      "[23/100]\n",
      "trainloss=0.97402423620224 trainscore=0.173298925989204\n",
      "valloss=0.9756814241409302 trainscore=0.18803419172763824\n",
      "[24/100]\n",
      "trainloss=0.965962290763855 trainscore=0.173298925989204\n",
      "valloss=0.9667174220085144 trainscore=0.18803419172763824\n",
      "[25/100]\n",
      "trainloss=0.9574310315979851 trainscore=0.18974174310763678\n",
      "valloss=0.9571417570114136 trainscore=0.18803419172763824\n",
      "[26/100]\n",
      "trainloss=0.9482430087195503 trainscore=0.20618456022606957\n",
      "valloss=0.9462176561355591 trainscore=0.3040935695171356\n",
      "[27/100]\n",
      "trainloss=0.9386884901258681 trainscore=0.22015824168920517\n",
      "valloss=0.9343577027320862 trainscore=0.3605913519859314\n",
      "[28/100]\n",
      "trainloss=0.9287227855788337 trainscore=0.255589479373561\n",
      "valloss=0.9220147132873535 trainscore=0.4100528955459595\n",
      "[29/100]\n",
      "trainloss=0.9184110760688782 trainscore=0.3103347321351369\n",
      "valloss=0.9095569252967834 trainscore=0.4539682865142822\n",
      "[30/100]\n",
      "trainloss=0.9071890248192681 trainscore=0.37293365597724915\n",
      "valloss=0.8957762122154236 trainscore=0.529411792755127\n",
      "[31/100]\n",
      "trainloss=0.8958917061487833 trainscore=0.4666111750735177\n",
      "valloss=0.8822093605995178 trainscore=0.6222222447395325\n",
      "[32/100]\n",
      "trainloss=0.8835926916864183 trainscore=0.5266834133201175\n",
      "valloss=0.8670269846916199 trainscore=0.7015566229820251\n",
      "[33/100]\n",
      "trainloss=0.8712117208374871 trainscore=0.5529801646868387\n",
      "valloss=0.8519635200500488 trainscore=0.7264957427978516\n",
      "[34/100]\n",
      "trainloss=0.8579884833759732 trainscore=0.6238021420107948\n",
      "valloss=0.8365725874900818 trainscore=0.8171428442001343\n",
      "[35/100]\n",
      "trainloss=0.8437961869769626 trainscore=0.6600930094718933\n",
      "valloss=0.8196361660957336 trainscore=0.8171428442001343\n",
      "[36/100]\n",
      "trainloss=0.8277979426913791 trainscore=0.7298941943380568\n",
      "valloss=0.8004475235939026 trainscore=0.8171428442001343\n",
      "[37/100]\n",
      "trainloss=0.8078922231992086 trainscore=0.7595238222016228\n",
      "valloss=0.7799124717712402 trainscore=0.888888955116272\n",
      "[38/100]\n",
      "trainloss=0.782810197936164 trainscore=0.8254262341393365\n",
      "valloss=0.7357743382453918 trainscore=0.888888955116272\n",
      "[39/100]\n",
      "trainloss=0.743393149640825 trainscore=0.8254262341393365\n",
      "valloss=0.6789284348487854 trainscore=0.888888955116272\n",
      "[40/100]\n",
      "trainloss=0.7131592300203111 trainscore=0.7974426945050558\n",
      "valloss=0.6332362294197083 trainscore=0.888888955116272\n",
      "[41/100]\n",
      "trainloss=0.682236115137736 trainscore=0.7974426945050558\n",
      "valloss=0.5944331288337708 trainscore=0.888888955116272\n",
      "[42/100]\n",
      "trainloss=0.6496556136343214 trainscore=0.8254262341393365\n",
      "valloss=0.5574802160263062 trainscore=0.888888955116272\n",
      "[43/100]\n",
      "trainloss=0.6166947020424737 trainscore=0.8618459833992852\n",
      "valloss=0.5185558199882507 trainscore=0.888888955116272\n",
      "[44/100]\n",
      "trainloss=0.5844515032238431 trainscore=0.8753990994559394\n",
      "valloss=0.47914910316467285 trainscore=0.888888955116272\n",
      "[45/100]\n",
      "trainloss=0.5546508000956641 trainscore=0.8618459833992852\n",
      "valloss=0.4443352520465851 trainscore=0.888888955116272\n",
      "[46/100]\n",
      "trainloss=0.5272079871760474 trainscore=0.8918600016170077\n",
      "valloss=0.4145229756832123 trainscore=0.888888955116272\n",
      "[47/100]\n",
      "trainloss=0.501801437801785 trainscore=0.9020732376310561\n",
      "valloss=0.3892301917076111 trainscore=0.888888955116272\n",
      "[48/100]\n",
      "trainloss=0.4775303403536479 trainscore=0.9020732376310561\n",
      "valloss=0.36446598172187805 trainscore=0.888888955116272\n",
      "[49/100]\n",
      "trainloss=0.45686840017636615 trainscore=0.9020732376310561\n",
      "valloss=0.3435085117816925 trainscore=0.888888955116272\n",
      "[50/100]\n",
      "trainloss=0.43729029099146527 trainscore=0.9020732376310561\n",
      "valloss=0.32427066564559937 trainscore=0.888888955116272\n",
      "[51/100]\n",
      "trainloss=0.4198947052160899 trainscore=0.9020732376310561\n",
      "valloss=0.30802494287490845 trainscore=0.888888955116272\n",
      "[52/100]\n",
      "trainloss=0.40393679671817356 trainscore=0.9103036920229594\n",
      "valloss=0.2936590611934662 trainscore=0.888888955116272\n",
      "[53/100]\n",
      "trainloss=0.38940544923146564 trainscore=0.9103036920229594\n",
      "valloss=0.28094929456710815 trainscore=0.888888955116272\n",
      "[54/100]\n",
      "trainloss=0.3760405547089047 trainscore=0.9230021039644877\n",
      "valloss=0.2695538401603699 trainscore=0.888888955116272\n",
      "[55/100]\n",
      "trainloss=0.36351685722668964 trainscore=0.9387147890196906\n",
      "valloss=0.25904950499534607 trainscore=0.888888955116272\n",
      "[56/100]\n",
      "trainloss=0.35207025541199577 trainscore=0.9490616454018487\n",
      "valloss=0.24961566925048828 trainscore=0.888888955116272\n",
      "[57/100]\n",
      "trainloss=0.34130902422799003 trainscore=0.9490616454018487\n",
      "valloss=0.24102744460105896 trainscore=0.888888955116272\n",
      "[58/100]\n",
      "trainloss=0.33113189538319904 trainscore=0.9593180550469292\n",
      "valloss=0.23307062685489655 trainscore=0.888888955116272\n",
      "[59/100]\n",
      "trainloss=0.32174502975410885 trainscore=0.9593180550469292\n",
      "valloss=0.22585058212280273 trainscore=0.888888955116272\n",
      "[60/100]\n",
      "trainloss=0.312807141078843 trainscore=0.9593180550469292\n",
      "valloss=0.21913111209869385 trainscore=0.888888955116272\n",
      "[61/100]\n",
      "trainloss=0.3043083714114295 trainscore=0.9593180550469292\n",
      "valloss=0.2127947062253952 trainscore=0.9484702348709106\n",
      "[62/100]\n",
      "trainloss=0.29634071720971 trainscore=0.9593180550469292\n",
      "valloss=0.20692875981330872 trainscore=0.9484702348709106\n",
      "[63/100]\n",
      "trainloss=0.2888927807410558 trainscore=0.9593180550469292\n",
      "valloss=0.2017149180173874 trainscore=0.9484702348709106\n",
      "[64/100]\n",
      "trainloss=0.2812345110707813 trainscore=0.9593180550469292\n",
      "valloss=0.19607165455818176 trainscore=0.9484702348709106\n",
      "[65/100]\n",
      "trainloss=0.27464424239264595 trainscore=0.9593180550469292\n",
      "valloss=0.19130490720272064 trainscore=0.9484702348709106\n",
      "[66/100]\n",
      "trainloss=0.26797424256801605 trainscore=0.9593180550469292\n",
      "valloss=0.1866791993379593 trainscore=0.9484702348709106\n",
      "[67/100]\n",
      "trainloss=0.26135974129041034 trainscore=0.9593180550469292\n",
      "valloss=0.1818208247423172 trainscore=0.9484702348709106\n",
      "[68/100]\n",
      "trainloss=0.2557004044453303 trainscore=0.9593180550469292\n",
      "valloss=0.1777985394001007 trainscore=0.9484702348709106\n",
      "[69/100]\n",
      "trainloss=0.24977047906981575 trainscore=0.9593180550469292\n",
      "valloss=0.17376533150672913 trainscore=0.9484702348709106\n",
      "[70/100]\n",
      "trainloss=0.24407589270008934 trainscore=0.9593180550469292\n",
      "valloss=0.1697506606578827 trainscore=0.9484702348709106\n",
      "[71/100]\n",
      "trainloss=0.23881016174952188 trainscore=0.9593180550469292\n",
      "valloss=0.16603872179985046 trainscore=0.9484702348709106\n",
      "[72/100]\n",
      "trainloss=0.2335903826687071 trainscore=0.9593180550469292\n",
      "valloss=0.1623329073190689 trainscore=0.9484702348709106\n",
      "[73/100]\n",
      "trainloss=0.22895284328195784 trainscore=0.9593180550469292\n",
      "valloss=0.15907661616802216 trainscore=0.9484702348709106\n",
      "[74/100]\n",
      "trainloss=0.22404933306905958 trainscore=0.9593180550469292\n",
      "valloss=0.15578821301460266 trainscore=0.9484702348709106\n",
      "[75/100]\n",
      "trainloss=0.21943426297770607 trainscore=0.9593180550469292\n",
      "valloss=0.15257230401039124 trainscore=0.9484702348709106\n",
      "[76/100]\n",
      "trainloss=0.21515053179528978 trainscore=0.9593180550469292\n",
      "valloss=0.14955809712409973 trainscore=0.9484702348709106\n",
      "[77/100]\n",
      "trainloss=0.2109671582778295 trainscore=0.9593180550469292\n",
      "valloss=0.14667363464832306 trainscore=0.9484702348709106\n",
      "[78/100]\n",
      "trainloss=0.20685427635908127 trainscore=0.9593180550469292\n",
      "valloss=0.14384546875953674 trainscore=0.9484702348709106\n",
      "[79/100]\n",
      "trainloss=0.20295600593090057 trainscore=0.9593180550469292\n",
      "valloss=0.14113324880599976 trainscore=0.9484702348709106\n",
      "[80/100]\n",
      "trainloss=0.19925888048277962 trainscore=0.9593180550469292\n",
      "valloss=0.13848809897899628 trainscore=0.9484702348709106\n",
      "[81/100]\n",
      "trainloss=0.1955918421347936 trainscore=0.9593180550469292\n",
      "valloss=0.13595834374427795 trainscore=0.9484702348709106\n",
      "[82/100]\n",
      "trainloss=0.19192763252390754 trainscore=0.9593180550469292\n",
      "valloss=0.13345302641391754 trainscore=0.9484702348709106\n",
      "[83/100]\n",
      "trainloss=0.18858596351411608 trainscore=0.9593180550469292\n",
      "valloss=0.1311062127351761 trainscore=0.9484702348709106\n",
      "[84/100]\n",
      "trainloss=0.18523507730828392 trainscore=0.9593180550469292\n",
      "valloss=0.12884381413459778 trainscore=0.9484702348709106\n",
      "[85/100]\n",
      "trainloss=0.18184259368313682 trainscore=0.9593180550469292\n",
      "valloss=0.12660302221775055 trainscore=0.9484702348709106\n",
      "[86/100]\n",
      "trainloss=0.17850908637046814 trainscore=0.9593180550469292\n",
      "valloss=0.12433502823114395 trainscore=0.9484702348709106\n",
      "[87/100]\n",
      "trainloss=0.1750987039672004 trainscore=0.9593180550469292\n",
      "valloss=0.12204917520284653 trainscore=0.9484702348709106\n",
      "[88/100]\n",
      "trainloss=0.17166664203008017 trainscore=0.9593180550469292\n",
      "valloss=0.1197633221745491 trainscore=0.9484702348709106\n",
      "[89/100]\n",
      "trainloss=0.16809304969178307 trainscore=0.9593180550469292\n",
      "valloss=0.11744929105043411 trainscore=0.9484702348709106\n",
      "[90/100]\n",
      "trainloss=0.16463978588581085 trainscore=0.9593180550469292\n",
      "valloss=0.1148301362991333 trainscore=0.9484702348709106\n",
      "[91/100]\n",
      "trainloss=0.16105584551890692 trainscore=0.9593180550469292\n",
      "valloss=0.11230040341615677 trainscore=0.9484702348709106\n",
      "[92/100]\n",
      "trainloss=0.157778552836842 trainscore=0.9593180550469292\n",
      "valloss=0.10989106446504593 trainscore=0.9484702348709106\n",
      "[93/100]\n",
      "trainloss=0.15472490506039727 trainscore=0.9593180550469292\n",
      "valloss=0.10749424248933792 trainscore=0.9484702348709106\n",
      "[94/100]\n",
      "trainloss=0.1514643140965038 trainscore=0.9593180550469292\n",
      "valloss=0.10524534434080124 trainscore=0.9484702348709106\n",
      "[95/100]\n",
      "trainloss=0.1485825934343868 trainscore=0.9593180550469292\n",
      "valloss=0.10310274362564087 trainscore=0.9484702348709106\n",
      "[96/100]\n",
      "trainloss=0.14576142612430784 trainscore=0.9593180550469292\n",
      "valloss=0.10123074799776077 trainscore=0.9484702348709106\n",
      "[97/100]\n",
      "trainloss=0.14322608709335327 trainscore=0.9593180550469292\n",
      "valloss=0.09955848753452301 trainscore=0.9484702348709106\n",
      "[98/100]\n",
      "trainloss=0.1410172801050875 trainscore=0.9593180550469292\n",
      "valloss=0.09797144681215286 trainscore=0.9484702348709106\n",
      "[99/100]\n",
      "trainloss=0.13875889364216062 trainscore=0.9593180550469292\n",
      "valloss=0.09656255692243576 trainscore=0.9484702348709106\n"
     ]
    }
   ],
   "source": [
    "## 학습의 효과 확인 손실값과 성능 평가값 저장 필요\n",
    "LOSS_HISTORY,SCORE_HISTORY=[[],[]],[[],[]]\n",
    "\n",
    "# 학습 모드로 모델 설정\n",
    " \n",
    "for epoch in range(EPOCH):\n",
    "    model.train()  ## 학습모드 켜기! 에포크 단위로 학습과 검증 진행시 for문안에서 껐다 켯다 해야함! \n",
    "\n",
    "    # 배치 크기 만큼 데이터 로딩해서 학습 진행\n",
    "    loss_total=0\n",
    "    score_total=0\n",
    "    for featureTS,targetTS in trainDL:\n",
    "\n",
    "        # 학습 진행\n",
    "        pre_y=model(featureTS)\n",
    "\n",
    "        # 손실 계산 # nn.CrossEntropyLoss 요구사항 : 정답/타겟 0D or1D 타입은 long\n",
    "        loss=crossLoss(pre_y,targetTS.reshape(-1).long())\n",
    "        loss_total+=loss.item()\n",
    "\n",
    "        # 성능평가 계산\n",
    "        score=MulticlassF1Score(num_classes=3)(pre_y,targetTS.reshape(-1))\n",
    "        score_total+=score.item()\n",
    "\n",
    "        # 최적화 진행\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval() # 검증모드 켜기!\n",
    "    with torch.no_grad():\n",
    "        # 검증데이터셋\n",
    "        val_featureTS=torch.FloatTensor(valDS.featureDF.values)\n",
    "        val_targetTS=torch.FloatTensor(valDS.targetDF.values)\n",
    "\n",
    "        # 평가\n",
    "        pre_val = model(val_featureTS)\n",
    "        #손실\n",
    "        val_loss=crossLoss(pre_val,val_targetTS.reshape(-1).long())\n",
    "        # 성능평가\n",
    "        val_score=MulticlassF1Score(num_classes=3)(pre_val,val_targetTS.reshape(-1))\n",
    "    \n",
    "    # 손실값과 성능 평가값 저장\n",
    "    LOSS_HISTORY[0].append(loss_total/len(trainDL))\n",
    "    SCORE_HISTORY[0].append(score_total/len(trainDL))\n",
    "\n",
    "    LOSS_HISTORY[1].append(val_loss)\n",
    "    SCORE_HISTORY[1].append(val_score)\n",
    "\n",
    "    print(f'[{epoch}/{EPOCH}]')\n",
    "    print(f'trainloss={loss_total/len(trainDL)} trainscore={score_total/len(trainDL)}')\n",
    "    print(f'valloss={val_loss} trainscore={val_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1804) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "model.eval() # 검증모드 켜기!\n",
    "with torch.no_grad():\n",
    "    # 검증데이터셋\n",
    "    test_featureTS=torch.FloatTensor(testDS.featureDF.values)\n",
    "    test_targetTS=torch.FloatTensor(testDS.targetDF.values)\n",
    "\n",
    "    # 평가\n",
    "    pre_test = model(test_featureTS)\n",
    "    #손실\n",
    "    test_loss=crossLoss(pre_test,test_targetTS.reshape(-1).long())\n",
    "    # 성능평가\n",
    "    test_score=MulticlassF1Score(num_classes=3)(pre_test,test_targetTS.reshape(-1))\n",
    "\n",
    "print(test_loss,test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 이미지 분류 모델\n",
    "- 이미지 데이터셋 준비\n",
    "    - torhchvision의 내장 데이터셋 활용 CIFIA10\n",
    "- 이미지 분류 모델\n",
    "    - 커스텀 CNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "from torchvision.datasets import CIFAR10        # torchvison 내장데이터셋\n",
    "from torchvision.transforms import ToTensor     # torchvision 데이터 변환 관련 모듈\n",
    "from torch.utils.data import DataLoader         # 데이터셋 관련 모듈 로딩\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 로딩\n",
    "DIR_PATH='../data/'\n",
    "\n",
    "# Pytorch의 Dataset 형태 로딩\n",
    "cifarDS=CIFAR10(DIR_PATH,\n",
    "                train=True,\n",
    "                download=False,\n",
    "                transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifarDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes : ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      " class to idx : {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      " shape : (50000, 32, 32, 3)\n",
      " targets length : 50000\n"
     ]
    }
   ],
   "source": [
    "# Dataset의 속성 확인\n",
    "print(f'classes : {cifarDS.classes}')\n",
    "print(F' class to idx : {cifarDS.class_to_idx}')\n",
    "print(F' shape : {cifarDS.data.shape}')\n",
    "print(F' targets length : {len(cifarDS.targets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 데이터 로더 <hr>\n",
    "- 학습시 배치크기만큼 데이터와 라벨/타겟을 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=50\n",
    "\n",
    "cifar10DL=DataLoader(cifarDS,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 32, 32])\n",
      "tensor([6, 9, 9, 4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n데이터 로더 사용시 채널이 앞으로 옴!\\ndata. numpy() < array로 바꾸고\\n그림을 그리고 싶다면 젤 앞에 있는 1을 지우고(squeeze)\\n채널을 뒤로 밀어야함 (data.T)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data,target in cifar10DL:\n",
    "    print(data.shape)\n",
    "    print(target)\n",
    "    #print(data.numpy())\n",
    "    # plt.imshow(data.squeeze().transpose(0,2))\n",
    "    # plt.title(cifarDS.classes[target.item()])\n",
    "    break\n",
    "\n",
    "\"\"\" \n",
    "데이터 로더 사용시 채널이 앞으로 옴!\n",
    "data. numpy() < array로 바꾸고\n",
    "그림을 그리고 싶다면 젤 앞에 있는 1을 지우고(squeeze)\n",
    "채널을 뒤로 밀어야함 (data.T)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 커스텀 모델 설계 및 정의 <hr>\n",
    "- 모델목적 : 이미지 분류 모델\n",
    "- 학습방법 : 지도학습 > 분류 > 다중분류 (10개)\n",
    "- 클래스이름 : ImageMCF\n",
    "- 클래스구조 : 특징추출부분 => CNN + 학습부분 FC\n",
    "- 부모클래스 : nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMCF(nn.Module):\n",
    "    # 모델구조 설계 즉, 생성자 메서드\n",
    "    def __init__(self):\n",
    "        # 부모 생성\n",
    "        super().__init__()\n",
    "        # 모델 층 구성\n",
    "        # 특징 추출 층\n",
    "        self.cnn_layer=nn.Sequential(\n",
    "            nn.Conv2d(3,10,kernel_size=3),\n",
    "            nn.BatchNorm2d(10),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "\n",
    "        # [1, 3, 32, 32] : input\n",
    "        self.in_layer=nn.Conv2d(3,10,3)\n",
    "        # [1, 10, 30, 30]\n",
    "        self.p_layer=nn.MaxPool2d(2)\n",
    "        # [1, 10, 15, 15]\n",
    "\n",
    "        # 학습 관련 층\n",
    "        self.hd_layer=nn.Linear(10*15*15 ,20)\n",
    "        self.out_layer=nn.Linear(20 ,10)\n",
    "\n",
    "    # 전방향/순방향 학습 메서드\n",
    "    def forward(self,input):\n",
    "        # 이미지 틍징 맵 추출\n",
    "        output=self.in_layer(input)\n",
    "        print(f'[output1] {output.shape}')\n",
    "\n",
    "        output=F.relu(output)\n",
    "        print(f'[output2] {output.shape}')\n",
    "\n",
    "        output=self.p_layer(output)\n",
    "        print(f'[output3] {output.shape}')\n",
    "\n",
    "        # 4D -> 2D (샘플수, 피처수)\n",
    "        output=output.view(output.shape[0],-1)\n",
    "        print(f'[output4] {output.shape}')\n",
    "\n",
    "        output=F.relu(self.hd_layer(output))\n",
    "        print(f'[output5] {output.shape}')\n",
    "\n",
    "        output=self.out_layer(output)\n",
    "        print(f'[output6] {output.shape}')\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMCF(nn.Module):\n",
    "    # 모델구조 설계 즉, 생성자 메서드\n",
    "    def __init__(self):\n",
    "        # 부모 생성\n",
    "        super().__init__()\n",
    "        # 모델 층 구성\n",
    "        # 특징 추출 층\n",
    "        self.cnn_layer=nn.Sequential(\n",
    "            nn.Conv2d(3,10,kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.cnn_layer=nn.Sequential(\n",
    "            nn.Conv2d(10,30,kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        \n",
    "\n",
    "        # 학습 관련 층\n",
    "        self.hd_layer=nn.Linear(30*7,7 ,20)\n",
    "        self.out_layer=nn.Linear(20 ,10)\n",
    "\n",
    "    # 전방향/순방향 학습 메서드\n",
    "    def forward(self,input):\n",
    "        # 이미지 틍징 맵 추출\n",
    "        output=self.cnn_layer(input)\n",
    "\n",
    "        # 4D -> 2D (샘플수, 피처수)\n",
    "        output=output.view(output.shape[0],-1)\n",
    "        print(f'[output4] {output.shape}')\n",
    "\n",
    "        output=F.relu(self.hd_layer(output))\n",
    "        print(f'[output5] {output.shape}')\n",
    "\n",
    "        output=self.out_layer(output)\n",
    "        print(f'[output6] {output.shape}')\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "ImageMCF                                 --\n",
       "├─Conv2d: 1-1                            280\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Linear: 1-3                            45,020\n",
       "├─Linear: 1-4                            210\n",
       "=================================================================\n",
       "Total params: 45,510\n",
       "Trainable params: 45,510\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "m=ImageMCF()\n",
    "summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[target]==> tensor([6, 9, 9, 4, 1])\n",
      "torch.Size([5, 3, 32, 32])\n",
      "[output1] torch.Size([5, 10, 30, 30])\n",
      "[output2] torch.Size([5, 10, 30, 30])\n",
      "[output3] torch.Size([5, 10, 15, 15])\n",
      "[output4] torch.Size([5, 2250])\n",
      "[output5] torch.Size([5, 20])\n",
      "[output6] torch.Size([5, 10])\n",
      "tensor([[-0.0138,  0.1802, -0.2684,  0.0279, -0.2125, -0.2013, -0.2125, -0.0253,\n",
      "         -0.1226, -0.0478],\n",
      "        [ 0.0119,  0.1710, -0.3109,  0.0423, -0.2316, -0.2336, -0.2374, -0.0209,\n",
      "         -0.1320, -0.0563],\n",
      "        [-0.0461,  0.1574, -0.2655, -0.0013, -0.2279, -0.1385, -0.1259, -0.0393,\n",
      "         -0.1756, -0.0223],\n",
      "        [-0.0240,  0.1733, -0.2430,  0.0173, -0.2228, -0.1888, -0.1855, -0.0224,\n",
      "         -0.1417, -0.0553],\n",
      "        [-0.0453,  0.1876, -0.2549,  0.0383, -0.2034, -0.1832, -0.1964, -0.0251,\n",
      "         -0.1398, -0.0417]], grad_fn=<AddmmBackward0>)\n",
      "pre => tensor([1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for data,target in cifar10DL:\n",
    "    print(f'[target]==> {target}')\n",
    "    print(data.shape)\n",
    "    # 학습\n",
    "    pre=m(data)\n",
    "    print(pre)\n",
    "    print(f'pre => {pre.argmax(dim=1)}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[in_layer.weight]-------- \n",
      "torch.Size([10, 3, 3, 3])\n",
      "[in_layer.bias]-------- \n",
      "torch.Size([10])\n",
      "[hd_layer.weight]-------- \n",
      "torch.Size([20, 2250])\n",
      "[hd_layer.bias]-------- \n",
      "torch.Size([20])\n",
      "[out_layer.weight]-------- \n",
      "torch.Size([10, 20])\n",
      "[out_layer.bias]-------- \n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,param in m.named_parameters():\n",
    "    print(f'[{name}]-------- \\n{param.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_CV_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

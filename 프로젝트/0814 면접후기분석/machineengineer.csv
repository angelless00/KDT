,주소,제목,내용
0,https://day-to-day.tistory.com/52,신입 머신러닝 엔지니어 / AI 리서처 면접 후기,"본문 바로가기Day to_day카테고리검색하기검색하기블로그 내 검색Day to_daym_inglet Tech blog (66)  Python (4)  SQL (7)  Project (12)  Machine Learning (16)  머신러닝 기초 (6)  지도 학습 (8)  비지도 학습 (0)  Deep Learning (9)  영상처리 (2)  논문 리뷰 (6)  In my mind (5)  책빵! (3) GuestbookNoticeRecent PostsLoRA(Low-Rank Adaptation)를 ⋯Docker 최소한의 개념과 기본 사용법 알아보기AutoRAG 실험해보기 (+ 사용 후기)ResNet 핵심만 빠르게!Recent Comments제 블로그를 참고해주셔서 감사합니다!!공부 잘 하고 갑니당 !포스팅 잘 보고 갑니다! 좋은 정보 감사해요 ㅎㅎ항상 잘 보고 있습니다 좋은 하루 되세요 :)Linkminglet githubprofile«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags평가 지표NVL오차 행렬beautifulsoup데이터 분석Batch Normalizationifnull결정트리정밀도데이터 프로젝트SQL웹서비스 기획감정은 습관이다LAG강화학습Normalization지도학습layer normalizationDecisionTreeNULLIF백엔드데이터 전처리CASE WHENsortednvl2five lines challenge재현율빠르게 실패하기비지도학습recallmoreArchives2024/08 (2)2024/07 (1)2024/04 (3)2024/03 (4)2024/02 (8)Today92Total13,461닫기관리 메뉴글쓰기방명록RSS관리Day to_day신입 머신러닝 엔지니어 / AI 리서처 면접 후기 본문In my mind신입 머신러닝 엔지니어 / AI 리서처 면접 후기m_inglet                           2024. 2. 3. 17:23     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90반응형(adsbygoogle = window.adsbygoogle || []).push({}); '머신러닝 공부하는 학생의 구직'을 이미지 생성 AI에 요청한 이미지 첫 구직활동의 후기를 기록해 두고 혹시나 나의 경험이 도움이 되는 사람이 있을까 하고 남겨두려고 한다. 일단 나의 상황을 설명하자면 인턴 계약이 끝나고 한 달 정도의 집 계약이 남은 상태였다. 나는 타 지역에서 서울에 올라왔기 때문에 남은 한 달 동안 열심히 구직활동을 해서 일단 취업을 하자는 목표가 컸다. 왜냐면.. 서울에서 생활을 유지해야 했기 때문이다. 특히 타 지역에서 서울로 면접 한번 보기 위해서는 그 하루의 차비, 식비를 계산하면 한 달에 면접 5번만 봐도 서울에서 생활하는 게 더 유리했다.  아무튼 완벽하게 준비된 건 없었다. 이력서를 부랴부랴 완성시키고, 포트폴리오 PPT는 없었다. (마음 급하게 구직을 했는데 이런 상태에서는 지혜로운 선택을 할 수 없어서 사실 추천하진 않음) 하지만 일단은 시작해버린걸. 과거의 나를 탓하기엔 너무 늦었다.  내 면접 후기를 결론부터 말하자면면접은 많이 보면 볼 수록 좋다. 계속해서 실패하더라도 그 실패로 인해서 내 지금의 위치를 깨닫게 된다.내가 가진 구멍이 무엇인지 보이고 그 구멍을 채우기 위해 자연스레 노력하게 될 것이다. 별로 원하지 않는 기업이더라도 나라는 제품이 시장에서 어떻게 팔리는지 고객의 피드백은 어떤지를 듣고 싶다면 안 가는 것보다 가는 게 훨씬 얻는 게 많다.  실제로 나는 직전에 인턴을 했던 경험이 있는데 AI 직무가 아니었는데도 불구하고 그것에 대해서 어떤 업무를 했는지에 대한 질문이 항상 있었다. (코딩을 하는 직군이긴 했음) 그래서 나는 어필할 수 없는 부분이라 생각했는데 면접관의 입장에서는 어필이 되는 거구나 하고 깨달았다.  결과는..?일단 한 달 반의 여정동안 내가 받은 결과는 다음과 같다. 기간: 2023.05.31 - 2023.7.17서류 제출: 약 50개면접: 9개최종 합격: 2개최종 탈락: 5개무응답: 2건 과제 전형서류 합격 후 이후에 진행했던 과정들은 회사마다 다 달랐다. 경험해 본 것을 정리하자면 다음과 같다. 1. 과제 전형 (실제 프로젝트를 진행하는 전형. 약 일주일 소요)2. 논문 리뷰3. 손코딩4. 코딩테스트5. 질문에 대한 해결 방법 제출 회사마다 원하는 인재에 따라 다르게 검증을 하는데 확실히 과제 전형이 전체 면접 프로세스 과정이 가장 오래 걸리긴 했다. 나머지 사전 과제들에 대해선 크게 어려움을 느끼진 않았다. 하지만 여기서 느낀 게 한 가지 있었다.  한 회사에서 내가 AI 리서처가 되고 싶은지, AI 엔지니어가 되고 싶은지에 대해 확실히 하는 게 좋을 것 같다는 피드백이 있었다. 정말 면접에서 느끼는 부끄러움은 다시는 느끼고 싶지 않지만 지나고 나면 다 값진 피드백들이다. 물론 둘 다 리서처 능력과 코딩 능력 모두 요구하는 직무이다. 그렇지만 내가 가진 강점이 어느 쪽에 더 가까운지를 생각해봐야 한다. 실제 구현을 빠르게 해 보고 서비스에 적용시키는 것에 더 흥미와 관심을 느낀다면 엔지니어 쪽에, 논문을 읽고 구현해 보고 더 나은 모델 구조에 대해 연구하는 것에 더 재미가 있다면 리서처에 가까울 것이다. 여기서 내가 했던 실수로는 AI 리서처를 뽑는 자리에서 내 강점으로 빠르게 서비스에 적용하고 피드백을 통해 개선해 나아간다는 소리를 했다..ㅎ   포트폴리오 질문포트폴리오에 관한 질문은 크게 두 가지로 나눌 수 있었다. 첫 번째는 질문을 통해 포트폴리오 내용을 검증하는 방법.두 번째는 내가 제출했던 노션이나 PPT를 보며 프로젝트를 설명하고 질문을 받는 방법. 두 가지 방법 모두 내가 작성한 포트폴리오에 대한 내용을 모두 구체적으로 알고 있고, 자주 물어보는 '어려웠던 점'과 '해결했던 방법'에 대해 확실히 정리하고 가면 어려울 것 없는 질문이다. 기술 영역 질문기술 영역의 핵심은 일단 자신이 이력서에 쓴 모델이나 기술에 대해서는 다 설명할 수 있을 정도로 알고 가야 한다. 예를 들어 내가 받은 질문 중에는 ""xgboost에 대해서 설명할 수 있나요? 위키피디아 수식을 보면서 설명해 주세요.""라는 질문도 있었다. 그 외에 머신러닝, 딥러닝, CS 기초 등등에 대한 질문은 다른 분들이 정리해 놓은 것을 참고하길 바란다. >> (Datascience-Interview-Questions) 마지막 대망의 임원 면접!임원 면접은 두 군데를 봐서 많은 데이터는 없지만 주로 인성과 컬처 핏에 대한 질문을 한다. 그래서 나는 이때 기업에 대한 조사를 많이 해갔다. 그리고 이 기업에서 내가 어떤 일을 하길 원하는지, 한 번쯤 생각해 보고 가는 것도 좋을 것 같다. 실무진 면접에서는 이 사람이 갖고 있는 업무 능력에 대해 판단했다면, 임원 면접에서는 내가 가지는 일에 대한 가치관 혹은 목표 등을 질문한다. 또 나라는 사람이 갖고 있는 장점, 단점 그리고 어떻게 스트레스를 관리하는지 등에 대해서도 고민하고 가면 좋겠다.  면접의 끝 우리한테 궁금한 점 있으세요?면접은 나와 기업이 서로 손잡는 동등한 위치에서 이야기를 나눈다고 생각해야 한다. (물론 면접을 보는 상황 자체는 너무나도 떨리는 일이지만 ㅠㅠ) 지금 이 글을 쓰는 시점에서는 이미 일을 시작하고 있기 때문에 이 점이 더욱 중요하게 느껴진다. 직원은 회사의 상황에 대해서도 이해를 해주며 회사의 성장도 신경을 써야 한다. 그와 동시에 회사도 개인의 성장과 그에 맞는 환경을 제공해 주려 노력해야 한다. 회사의 goal과 개인의 goal이 완벽히 같을 순 없겠지만 최대한 서로에게 필요한 존재가 되기위해서 기업과 직원이 양쪽에서 노력해야 한다.  그런 의미에서 면접에서 마지막 질문은 내가 이 회사에서 얼마나 성장을 할 수 있을지를 엿볼 수 있는 기회이기도 하다. 그러니 궁금한 점 없다고 넘겨버리지 말기! 나 같은 경우엔 Computer Vision에 관심이 있었고 이 분야에서도 성장을 할 수 있는지를 보려고 했다. 직접적으로 저는 CV분야 아니면 안 합니다!라는 뉘앙스가 아니라 진행하는 프로젝트 등의 설명을 들으며 파악해 보라는 것! 질문 예시1. 팀의 규모와 구성은 어떻게 되어있나요?2. 현재 어떤 프로젝트들을 하고 계신가요? 혹은 앞으로 계획된 프로젝트는 어떤 것이 있나요?3. 프로젝트에 대해 궁금한 점이 있다면 더 여쭤보기4. 개발 환경은 어떻게 이루어져 있나요? (gpu 등..) 마치며참.. 구직활동을 하며 다시 한번 일자리 구하기 어렵구나 하는 생각이 많이 든다. 그래도 생각하는 시각을 약간 바꾸어 꾸준히 공부와 동시에 지원서를 제출함으로써 '내가 얼마나 성장했는지'를 지속적으로 평가해 보는 것도 취업 준비를 하는 여정에 지치지 않는 나만의 팁 같다. 가끔은 지원서를 내고 그 결과를 기다리는 기간 동안 복권을 사고 기다리는 것과 비슷하는 감정이 든다. 합격할 확률보다 불합격할 확률이 많더라도 어떤 기대감에 사로잡혀 그 주를 더 열심히 살기도 한다.신입의 입장에서는 내 이력서가 매력적일까?라는 고민이 가장 클 텐데 계속해서 발전해 가며 모두들 원하는 곳에 다 합격하셨으면 좋겠다! 728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//day-to-day.tistory.com/reaction';window.ReactionReqBody = {    entryId: 52}공유하기게시글 관리Day to_day저작자표시 비영리 변경금지 'In my mind' 카테고리의 다른 글글또 8기를 마무리하며..  (0)2023.07.15글또 8기를 시작하기 전에..  (0)2023.02.0226년간의 회고  (0)2023.01.14Enter ↵  (0)2022.07.18'In my mind' Related Articles글또 8기를 마무리하며..2023.07.15글또 8기를 시작하기 전에..2023.02.0226년간의 회고2023.01.14Enter ↵2022.07.18more0  Comments댓글쓰기 폼이름비밀번호                                              Secret                                          댓글SendloadedComments[52]=true;findFragmentAndHighlight(52);Blog is powered bykakao / Designed byTistory티스토리툴바Day to_day구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""5467601-52"",""customProps"":{""userId"":""0"",""blogId"":""5467601"",""entryId"":""52"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""52"",""entryTitle"":""신입 머신러닝 엔지니어 / AI 리서처 면접 후기"",""entryType"":""POST"",""categoryName"":""In my mind"",""categoryId"":""1021328"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""5468083"",""authorNickname"":""m_inglet"",""blogNmae"":""Day to_day"",""image"":""kage@7M37e/btsFv0L06Ux/S3rRxOXv1yAhz97E0kS52K"",""plink"":""/52"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
1,https://dailyheumsi.tistory.com/207,1) 직장을 고를 때 나의 우선순위,"일상, 생각, 경험/그냥 얘기신입 데이터 엔지니어로 취업했다. 흠시2020. 3. 8. 17:19취업했다.저번 주 초에 최종 합격 연락을 받았고, 다음 주 월요일부터 출근하게 되었다.쏘카라는 회사에서 데이터팀의 데이터 엔지니어로 일하게 되었다.가고 싶던 곳이라 매우 기쁘다 :)여러모로 화두의 기업이 된 쏘카. 그곳 맞다.여기에는 입사하게 된 과정과 짧지만 내가 생각해본 것들을 적어보려 한다.1. 과정작년 12월, '프로그래머스 머신러닝 잡페어' 에서 공고를 처음 보았다.쏘카는 '데이터 분석가' / '데이터 사이언티스트' 직군을 채용하고 있던 걸로 기억한다.이후 최종 면접까지의 과정은 다음과 같았다. (위부터 순서대로)프로그래머스 과제(대회)전화 면접실무 면접임원 면접12월 시작부터 했고 채용은 2월 말에 됐으니 대략 3개월 좀 안 되는 프로세스였다.나는 사실 중간에 연락이 안 와서 떨어진 줄 알았다.그런데 기다리니까 하나씩 연락이 오더니, 면접 일정을 협의하고.. 쩌다 보니 최종 면접까지 가게 되었다.처음에는 데이터 분석으로 직군을 생각했으나, 전화면접 때 면접관님이 데이터 엔지니어 직군도 있다고 소개해주셨고, 해당 직군도 내게 가능성이 있으니 고려해보라고 하셨다. 마침 엔지니어로 갈 생각이 있었으므로 나는 고심 끝에 데이터 엔지니어로 지원하였다.참고로 해당 팀은 엔지니어가 더 소수이고, 내게는 데이터 엔지니어 관련한 이력이 없다. 당연히 떨어지겠지만, 그래도 도전이나 해본다는 생각으로 지원한 거다. 면접에 가면 데이터 엔지니어 채용에는 어떤 질문들이 들어오나 알아야겠다는 생각이었다. 면접관님들에겐 죄송하지만, 그래도 앞으로 내가 준비해나갈 방향을 현업에서 일하시는 분들에게 묻고 싶었다. 내가 붙을 거라곤 전혀 생각도 못했다.이외 채용 프로세스는 대외비인 경우가 많으므로, 여기다가 따로 적지는 않겠다.2. 준비한 것사실 나는 따로 준비한 게 없다. 아니 정확히 말하면 데이터 엔지니어 직군을 위해 뭔가 이력을 쌓은 게 없다.특히나 대기업이 아닌 IT 스타트업들은 이런 이력이 굉장히 중요하게 보는 경우가 많다. '배민', '야놀자'와 같이 독자적인 영역을 구축하는 이름 있는 스타트업은 더 그렇다. (애초에 신입을 잘 안 뽑기도 하고..)그래도 면접이니 뭔가를 준비해 간다면, 내가 당장 할 수 있는 것만 했다.시간도 얼마 안 남은 상태에서 그나마 내가 한건 다음과 같았다.해당 회사의 서비스 파악적어도 그 회사에서 무엇을 하고 있는지는 알고 가야 한다고 생각한다.나는 회사 공식 홈페이지와 최근 기사들을 몇 개 읽어서 정리했다.CS(Computer Science) 지식 빠르게 리뷰이전에 포스팅한 '빽 투더 기본기' 를 다시 보며 회고면접 질문에 나올만한 Q&A 형식을 나름대로 만들었다.물론 모든 내용 커버 못한다.운영체제 > 자료구조 & 알고리즘은 전반적으로 큼지막하게 다 봤다.네트워크와 DB는 면접 질문 위주로 공부했다.이력서 remind up내 이력서에 무슨 내용이 있었는지 다시 한번 훑어봤다.프로젝트 관련은 항상 기간, 목표, 내가 한 일, 결과를 중심으로 머릿속에 정리했다.프로젝트와 프로젝트 사이에 개연성이랄까? 내 행동의 근거와 당시 생각을 정리했다.사실 이런 건 평소에 글을 올리며 생각했던 거라 오래 걸리지 않았다.직장에 대한 나의 우선순위이건 아래에다 따로 적겠다.면접 기본1분 자기소개회사 지원 동기 및 하고 싶은 일(커리어)나의 장점, 단점입사 후 해보고 싶은 것 (관심, 포부)사실 면접 기본은 구글링 하면 금방 다 나온다.위에 2개, CS 지식과 이력서 remind-up 은 그냥 하면 되는 부분이다.아래 2개, 직장에 대한 나의 우선순위와 면접 기본은 좀 생각을 해봐야 하는 부분이었다.이에 대해서 좀 더 자세히 써볼까 한다.1) 직장을 고를 때 나의 우선순위직장이라는 곳은 내게 의미가 크다.일상의 많은 시간을 보내는 곳이자, 내가 자아실현하는 곳이기도 하니깐.따라서 좀 생각을 신중히 가지고 내가 원하는 직장에 가고 싶었다.그렇다면 나는 무엇을 원할까?사실 여기에는 '일'에 대한 자신의 가치관, 스타일이 담겨있다고 생각한다.나도 하나씩 고민해보았고, 나름대로의 우선순위를 매겨 정해보았다.함께 일하고 싶은 동료들과 문화가 있는가?사내 스터디, 도서비 지원, 기술 블로그 등 '함께' 공부하며 공유하는 문화이런 문화를 적극적으로 만들어나가는 동료들개인의 발전이 회사의 발전이라 믿는 회사보통 회사 멤버가 외부에 공유한 자료들, 회사 복지에 잘 드러남.새로운 가치를 창출하는 회사인가?새로운 서비스를 만들어내거나혹은 고도화된 기술을 만들어내거나.이 둘 다면 제일 좋고.산업 자체가 내가 관심 있어하는 분야여야 하는 건 당연.연봉내가 받고 싶은 최소 금액은 있었다.이력서에 희망 연봉을 올려둠.환경, 위치이건 Optional 한데, 그래도 뭐.가까우면 당연히 좋다.출퇴근 시간 정해져 있지 않았으면 좋겠다.사내 라운지가 있어서 거기서 일해도 뭐라 안 했으면 좋겠다.사내 커피포트랑 얼음 정수기가 있으면 좋겠다.이 우선순위는 회사 지원동기에 적극 활용됐다.나는 직장을 선택할 때 이러한 기준이 있는데, 이러한 기준에 이 회사가 딱 맞다고 생각하여 지원하게 되었다. 이런 식이다.2) 나의 장단점1분 자기소개나, 지원 동기는 생략하고 나의 장단점만 간추려보려 한다.장점설명 혹은 배운 걸 공유하려는 자세를 갖추고 있다. 글 쓰는 능력(블로그)내 성장과 타인의 성장 둘 다 도모하려고 함.원하는 분야가 생기면 능동적으로 끝까지 공부해보려 함.부스트 코스, 인프런 등의 인강 기록.컴퓨터 공학 기본기로 다져져서, 어떤 기술이든 빠르게 익힐 수 있다는 것.협업 시에 일이 즐거워짐. 따라서 업무효율도 올라감.내 분야 외에 근접한 분야에도 조금씩 관심이 있음.머신러닝. 분석. 그로스 해킹 분야라던가. 기획.새로운 인사이트나, 폭넓은 시야 혹은 대화를 가질 수 있다고 생각.네트워킹 자리나 술 좋아해서, 사람들이랑 쉽게 친해질 기회를 만들 수 있음.단점한 장소에서만 계속 집중을 못한다.그래서 일할 때, 장소를 옮겨 다니면서 일을 한다.장기 목표를 잘 못 세우고, 목표가 없으면 좀 게을러진다.10년 뒤에..? 이런 거에 대한 생각 잘 모르겠고.그래서 단기 목표 위주로 세우고 점검하려고 하는 편이다.당연히 장점은 최대한 근거가 있는 것 위주로 먼저 말해야 한다. 나에겐 블로그가 그 수단이 되었다.(실제로 면접장에서 블로그 실시간으로 보여드렸다...)반면 단점은 짧고 명확하되 커버 가능한 단점이어야 한다.나는 한 장소에서만 계속 집중을 못해서 카페나 라운지가 있으면 좋은데, 여기 사내에는 라운지가 있으므로 그 장소를 활용하겠다고 했다.3) 입사 후 하고 싶은 것빠르게 내가 서빙하고 있는 코드를 다 리뷰해보고 이해하는 것사내 스터디에 참여하는 것.이건 그냥 진짜 내가 하고싶은 것만 적었다.따로 정답은 없는 질문이라고 생각한다.3. 내가 준비하지 못한 것한편 내가 준비하지 못한 것도 있었다.1) 코워크의 경험이건 사실 면접 기본에 해당하는 내용인데, 내가 미처 생각하지 못하고 가게 됐다.코워크의 경험이라 하면,누군가와 함께 무언가를 해본 경험이 있는지.본인의 역할은 무엇이었는지그때 갈등이 있었다면 무엇이고, 어떻게 해결했는지.결과는 있었는지역시나 어떻게 갈등이나 조직문제를 해결했는지 등을 중심으로 보는 거 같다.나는 준비를 못한 채라 생각할 시간을 주실 수 있는지 여쭤보고, 생각했다.대학생활 때 했던 페스티벌 기획 동아리 이야기를 꺼냈다.다양한 사람들 20명을 팀의 부팀장으로서 운영했는지, 팀 내 역할을 줄 때 어떤 식으로 주었는지 등을 이야기했다.(여담이지만 나는 MBTI, DISC, 애니어그램 등 사람 파악하는 테스트를 좋아해서, 이런 걸 팀원들에게 자주 써먹고, 팀원들을 파악하려 했다.)준비 안 한 게 여지없이 드러나긴 했지만, 여차여차 말할 수는 있었다.2) 직무를 위한 준비알고는 있었다. 내 이력은 대부분 '시각화'나 '분석' 등 특정 직무에 대한 것보다는, 굉장히 러프한 느낌의 프로젝트들이었다. 그리고 엔지니어 특성상 이런 게 별로 도움 안된다는 거도 알고 있었다.그래도 여차여차해서 마지막 임원 면접까지 갔는데, 면접관님이 마지막에 나에게 다음과 같은 질문을 하셨다.데이터 엔지니어 직무를 위해 어떤 걸 준비하셨는지 말씀해주세요.난 내 이력에 있는 거 + 평소 공부하던 것 등등 잘 섞어서 말했다. 이 모든 게 데이터 엔지니어 그 자체를 위한 것은 아니지만 모두 도움이 되는 일들이었다고 생각한다고. 그러자 다음과 같은 대답이 돌아왔다.그건 지금까지 하신 일을 직무에 대한 노력으로 포장하시는 것 같습니다.허를 찌르는 답변이었다. 너무 맞는 말이었다.이래저래 나를 설명하던 모든 것들이 벌거벗겨지는 느낌이었다. 부끄러웠다.마지막으로 하신 질문이라 더 그랬다.나는 면접관님 말씀이 맞다고 밖에 할 수 없었다.다만, 하나만 말할 수 있었다.지금까지의 내 경험의 여정 끝에, 이제 나는 데이터 엔지니어로로 공부해나갈 준비를 마쳤다고.부끄럽지만 정말 이 말밖에 할 수 없었다.4. 마무리나는 전화 면접을 봤을 때도, 말을 어버버 했기 때문에 떨어졌다고 생각했다. 그런데 붙었다.실무 면접에서도, 면접관님이 거의 다 가르쳐주시듯 도와주셨기 때문에 당연히 불합격이라 생각했다. 근데 붙었다.마지막 면접에서도, 면접관님의 저 마지막 질문에 아무것도 없는 나를 보여드렸기 때문에, 나를 뽑을 이유가 없다고 생각했다. 그런데 붙었다.나는 한번도 내가 붙을거라고 생각해본적이 없다. 정말 어떻게 붙은 건지 모르겠다. 어벙벙하다. ... 감사하다.더군다나, 가고 싶던 기업이었기 때문에 더욱 그렇다.여하튼 나는 내 첫자리를 찾았고, 이제부터 여기에 몰두해볼 예정이다.블로그의 글들도 이제 사뭇 달라지겠지.이제부터가 진짜 시작인 거 같다. [2020-08-14] 쏘카의 데이터 그룹 상시 채용이 열려있습니다 ㅎㅎ관심있으신 분들은 이 페이지를 참고해보세요!window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//dailyheumsi.tistory.com/reaction';window.ReactionReqBody = {    entryId: 207}공유하기게시글 관리하나씩 점을 찍어 나가며저작자표시 '일상, 생각, 경험 > 그냥 얘기' 카테고리의 다른 글입사 후, 첫 번째 프로젝트 후기  (10)2020.06.07입사 후 4주 동안의 내 회사생활 회고  (14)2020.04.05[취준생의 데이터 분야의 커리어 고민 3] 엔지니어가 되자  (23)2020.03.01[취준생의 데이터 분야의 커리어 고민 2] 분석으로 취업은 힘들다  (13)2020.02.26[취준생의 데이터 분야의 커리어 고민 1] 해온 것과 느낀 것들  (4)2020.02.26'일상, 생각, 경험/그냥 얘기' Related Articles입사 후, 첫 번째 프로젝트 후기입사 후 4주 동안의 내 회사생활 회고[취준생의 데이터 분야의 커리어 고민 3] 엔지니어가 되자[취준생의 데이터 분야의 커리어 고민 2] 분석으로 취업은 힘들다이전 댓글 더보기    setInitialEntryComments(207, 1723623073)Secret댓글달기loadedComments[207]=true;findFragmentAndHighlight(207);"
2,https://iostream.tistory.com/167,3년만에 돌아온 회고,"머신러닝 엔지니어의 2023년 회고2023.12.31 15:39일상 이야기/회고     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }3년만에 돌아온 회고2020년 회고를 마지막으로 한동안 루틴처럼 하던 한 해 회고가 없었다. 이유야 다양하지만 안 하기 시작하니 1년, 2년 쌓여서 안 하게 된 것도 있고, 지나고 나서 보니 COVID-19 기간 특별히 성장하지 못한 느낌이 들어서 패배자 같다는 생각에 약간의 우울감에, 그것을 공개적으로 적기 싫어서였던 이유도 있었을 것 같다. 그러나 이젠 사회 초년생 때의 열정을 가진 나는 이미 없어져 버렸고, 조금 내려놓고 쉬어갈 수 있는 여유를 가질 수 있게 되어서 올해는 다시 회고를 작성해 본다. 가끔은 열정이 없어져 버린 내가 서글프게 느껴지지만, 하루하루 그리고 한 해 동안 나름 열심히 살았다면 무엇이 특별히 성장하지 않았어도 기록을 남기는 데 의의가 있다고 생각한다.회사 업무올 해가 퀄컴에서의 2년차였고, 라인 매니저와 테크 리드 모두에게 작년보다 조금 더 여러 부분 (하드 스킬, 소프트 스킬 모두) 영향력 있는 엔지니어가 되기를 바란다는 피드백을 들었었다. 돌이켜봤을 때 쿠팡이나 카카오에서도 1년차 때는 어느 정도 조직이 돌아가는 구조를 먼저 파악했었기 때문에 2년차부터 좀 더 나은 퍼포먼스를 보였었고, 그래서 퀄컴에서의 2년차도 작년보다는 좀 더 잘해야지라는 마음으로 시작했었다. 상대적으로 생소했던 Quantization과 On-device Machine Learning에 대해서 1년차 때는 공부하고 조금 작은 볼륨의 개발을 했다면, 올해는 여러 가지 케이스에 대해서 개발 및 성과를 낼 수 있었던 한 해 였다.Keras framework Quantization Analyzer 구현 (Feature Development)Quantization Aware Training 수정 (Technical Debt)On-device Generative AI를 지원하기 위한 IR 전처리기 구현 (Company-wide Task)세 번째 태스크는 전사 차원에서 강조하고 있는 영역 중 하나였고, 실제로 공개 Summit에서 데모로 나간 프로젝트(On-device LLaMA 7B, On-device GigaGAN)의 코어 컴포넌트 중 하나였다. 아무래도 AI Research 조직이다 보니 개발하고 있는 것들이 실제로 어디에 잘 쓸 수 있을까 고민했던 적이 있었는데, 해당 프로젝트를 통해 이런 고민을 상당 부분 만족시킬 수 있어서 매우 뿌듯했다.On-device LLaMA 7B올해는 특히 한국의 신규 입사자 및 미국 Sandiego, 인도 쪽 엔지니어들과 Cross-region으로 활발하게 업무를 진행할 수 있어서 굉장히 즐거웠고 대화 및 코드 리뷰를 통해 기술 내외적으로 나 역시 많은 도움을 받을 수 있었다. 영어가 모국어가 아니다 보니 의사소통 시 내가 원하는 바를 100% 전달하지 못한 부분은 역시 매년 따라오는 문제였고, 그냥 꾸준히 공부할 수밖에 없는 것 같다. 추가로 업무 범위가 늘어나다 보니 문서화할 일이 많아져서 작문 쪽도 조금 더 신경 써야겠다고 생각한 2023년이었다. 회화는 주로 아래 유튜브 채널을 짬이 되는 대로 많이 보고 연습하려고 노력했다.라이브 아카데미달씨Darcie회사에서의 대인 관계 부분도 꽤 많이 변한 한 해 였는데 라인 매니저와 본격적으로 1:1을 하면서 좋은 신뢰 자본을 쌓았다고 생각하고 (물론 라인 매니저는 그렇지 않을 수도 있다 lol), 석사를 졸업하고 입사한 아주 똑똑한 엔지니어와 같이 IR 전처리기 구현에 많은 부분을 기여했다. 아직 나도 마음만은 주니어 엔지니어인데 이제 연차가 차다 보니 이런 작은 부분에서의 피플 매니징도 회사나 조직에서는 어느 정도 요구하는 것 같아 가능하면 많은 대화를 하고 업무에 대해서 투명성을 유지하려고 했었다. 그 결과인지는 모르겠지만 입사한 지 얼마 되지 않아 아주 좋은 퍼포먼스를 내셔서 나도 괜히 뿌듯한 마음이 들었다 :)스터디회사 내에서 그리고 외부에서도 올 한 해 여러 가지 기술 관련 스터디를 진행했다. 큰 범주에서 보면1) Advanced Python2) Problem Solving3) Software Engineering세 가지로 볼 수 있겠다.1) Advanced Python아무래도 AIMET의 주 기술 스택 중 하나가 Python이기 때문에 작년에 읽어본 Python Tricks: A Buffet of Awesome Python Features 에 이어서 올해는 조금 더 분량이 있는 Python 책인 Effective Python 2nd 스터디를 통해서 진행했다. 해당 스터디는 인프런을 통해서 모집하고 진행했는데, 중간에 포기하거나 여러 사정으로 인해 스터디에 집중하지 못하는 분들이 계셔서 다소 아쉬웠지만 끝까지 완독했다는 것에 의의를 두고 싶다. 24년에는 Fluent Python 또는 C++ 서적을 보려고 계획 중이다.2) Software Engineering여러 엔지니어들이 많이 추천했던 소프트웨어 엔지니어 관련 책들 역시 스터디 또는 혼자서 챙겨보았다. The Missing ReadMe는 회사 내의 Reading Group에서 돌아가면서 읽고, 발표를 하면서 서로의 경험도 공유하고 퀄컴에서는 어떤 부분을 적용할 수 있는 지 얘기할 수 있어서 아주 좋았다. 이 책은 모든 소프트웨어 엔지니어가 연차에 관계 없이 반드시 읽어봐야한다고 말하고 싶다. 그 외에 존 소메즈의 소프트 스킬 2판을 베타 리뷰할 기회가 있어서 챙겨보았는데, 이 책 역시 회사 업무에 많은 부분을 적용해볼 수 있었고 도움을 받았다.3) Problem Solving우연히 골든래빗에서 지원하는 묘공단이라는 스터디 그룹을 알게 되어, 그동안 아주 많이 낡았던 Problem Solving 관련 자료구조/알고리즘 공부를 강제적으로 할 수 있겠다 싶어서 11월부터 진행중이다. 이직 준비하면서 또는 면접관으로 들어가기 전 벼락치기로 필요할 때 공부했었지만, 처음부터 끝까지 빈출되는 유형을 다시 정리할 수 있어서 아주 만족스럽고 거기에 더해 하루에 최소 1문제씩 문제를 풀어서 커밋하는 습관을 들여보고 있다. 학생 때 CodeForces를 참여하면서 레이팅을 올리려고 열심히 했었는데, 이번에도 스터디를 진행하면서 기회가 된다면 AtCoder 플랫폼에 참여해볼 생각이다. 마지막 CodeForces 레이팅이 Mint였기 때문에, AtCoder 역시 그에 대응하는 Green/Mint를 24년에는 목표로 해본다11월부터 꾸준히 1일 1커밋독서COVID-19 이전에 참여했던 독서 모임을 마지막으로 기술 서적 외의 독서는 아주 드물게만 했었다. 요즘 유행하는 MBTI 성향 중 극 T에 가까운 나는 공감 능력 개선을 위해서도 올해는 책을 좀 열심히 읽어야겠다고 마음먹었고, 운이 좋게도 거주하는 곳에서 꽤 오래 진행된 독서 모임이 있어서 주저 없이 신청하고 봄부터 활동했다. 오래된 모임인 만큼 그룹장님이 좋은 원칙을 가지고 열심히 운영하시는 모습에 나도 열심히 하지 않을 수 없었고, 덕분에 작년 대비 꽤 많은 책을 읽을 수 있었다. 우리 모임은 격월로 비문학, 문학을 읽고 있는데, 개인적으로 문학책을 꾸준히 읽을 수 있는 기회가 있어서 매우 만족스러웠다. 그리고 코엑스에서 열린 국제도서전도 가보게 되었는데, 생각보다 많은 사람들이 있어서 놀랍기도 하고 외적으로 동기부여도 얻을 수 있었다.2023 서울 국제 도서전올해 끝까지 읽은 책 목록은 다음과 같다미래과거시제타워공정하다는 착각핏빛 자오선스티브 잡스도둑맞은 집중력파친코볼드 표시를 한 책 중 소설인 미래과거시제와 파친코를 매우 재밌게 읽었고, SF 소설은 이번이 처음이었는데 너무 재밌게 읽어서 같은 작가의 다른 책인 타워도 읽어보고 주위 사람들에게 책을 선물하기도 했다. 비문학 책은 도둑맞은 집중력이 실체가 있는 여러 가지 조언을 제시하고 있어서 인상 깊었다. (물론 모든 독서가 그렇듯 본인의 상황에 맞게 비판적으로 수용해야 한다). 서로 다른 배경의 인원들이 모여서 책 내용에 관해서 얘기할 때 많은 것을 얻어 갈 수 있었고, 반대로 다른 그룹원들도 얻어간 것이 있었기를 희망한다. 2023년 막바지 모임은 여러 가지 불가피한 이유로 모임 참여를 못 했는데, 24년은 다시 또 열심히 참여하고 올해만큼 책을 읽어보려고 한다.조깅작년에 이어 올해도 주 2~3회 꾸준히 뛰었다. 주로 석촌 호수 근처를 많이 뛰는 데, 사람들 붐비는 게 싫어서 가능하면 오전에 또는 퇴근 시간 전에 많이 뛰었고 COVID-19 기간 간헐적으로 있었던 허리 통증이 조깅 덕분인지 많이 개선되었다. 마음 같아서는 페이스를 더 올려서 뛰어보고 싶은데, 작년에 조금 무리했더니 발생한 발바닥과 오금 부상 때문에 올해는 욕심내지 않고 꾸준히 뛰는 것에 의의를 뒀다. 조깅의 장점은 따로 강조하지 않아도 너무 많지만, 운동화 (가능하면 조깅에 도움이 되는) 한 켤레만 있으면 누구나 쉽게 접근할 수 있고, 생각보다 힘들기 때문에 업무에서 발생하는 온갖 잡념을 제거하기에는 제격이다. 요즘 유행하는 갓생 (?) 덕분인지 조깅하는 분들은 주위에서 꽤 많이 찾아볼 수 있지만, 혹시 뛰지 않는 분들을 만날 때는 적극적으로 영업하고 있다. 내년에는 5km나 10km 달리기를 도전해 보고는 싶은데, 성향상 너무 많은 사람이 모이거나 부대끼는 게 싫어서 조금 고민은 된다.2023년 마지막 날 조깅정리하면서COVID-19가 완전히 종식되어 일상으로 돌아간 첫 해. 업무 내외적으로 꽤 열심히 살았다고 생각한다. 사회 초년생 때처럼 너무 성장해야 지에 매몰되지 않고 쉬어갈 때는 적절히 능글맞게 뻗대보기도 하고, 열심히 달려야 할 때는 또 열심히 달려봤다. 업무의 하드 스킬 쪽은 Cross-region으로 작년 대비 더 영향력을 확장할 수 있었고, 그와 동시에 여전히 배울 게 많고 배울 수 있는 동료들이 많다는 것을 얻어간 한 해였다. 소프트 스킬 역시, 위로는 라인 매니저와 아래로는 신규 입사자분들과 대화 및 업무를 하면서 많은 재밌는 경험을 할 수 있었다. 내년을 위해서 뭔가 도전적인 목표를 세우고 싶지는 않다 (이제는 그렇게 하는 것이 너무 힘들다는 것을 알아버려서...). 올해보다 여러 가지 부분에서 아주 조금 더 나은 사람이 되는 것으로 2023년을 마무리하고 2024년을 기다려본다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//iostream.tistory.com/reaction';window.ReactionReqBody = {    entryId: 167}공유하기게시글 관리Make headway towards solving the problem 저작자표시 비영리 동일조건 2023년 회고, Machine Learning Engineer, 머신러닝 엔지니어댓글공유하기다른 글댓글이 댓글의 메뉴 토글방문자 정보이름암호운영자에게만 공개작성하기loadedComments[167]=true;findFragmentAndHighlight(167);이 글 공유하기구독하기구독하기카카오톡카카오톡라인라인트위터트위터FacebookFacebook카카오스토리카카오스토리밴드밴드네이버 블로그네이버 블로그PocketPocketEvernoteEvernote다른 글글또 9기 돌아보기글또 9기 돌아보기2024.05.12데이터 엔지니어의 2020년 회고데이터 엔지니어의 2020년 회고2020.12.30데이터 엔지니어의 2019년 회고데이터 엔지니어의 2019년 회고2019.12.31데이터 엔지니어의 2018년 회고데이터 엔지니어의 2018년 회고2018.12.23다른 글 더 둘러보기let generalThumb=""https://blog.kakaocdn.net/dn/oYkQ1/btsCTU8Yc1Z/uNdAqL1A0yN4TuycA5XE0K/img.png"";document.head.insertAdjacentHTML(""beforeend"",'<link rel=""stylesheet"" href=""https://cdn.jsdelivr.net/gh/highlightjs/cdn-release/build/styles/vs2015.min.css"">');let code=document.getElementById(""article"").getElementsByTagName(""pre"");for(let i=0;i<code.length;i++){codeInner=code[i].getElementsByTagName(""code"")[0];if(codeInner!==null){codeInner.closest(""pre"").setAttribute(""class"",""procode-wrap"");}};hljs.highlightAll();hljs.initLineNumbersOnLoad();"
3,https://eehoeskrap.tistory.com/772,"

				[Book Review] 인사이드 머신러닝 인터뷰
				
","Enough is not enoughHomeWriteSettingAbout Me 분류 전체보기 (700)  Book Review (60)  Career에 관한 생각 (7)  회고록 (8)  AI Research Topic (0)  Efficient AI (0)  Multimodal AI (0)  LLM (5)  Transformer (1)  Diffusion (7)  Human Pose Estimation (54)  Deep Learning (27)  Backbone (7)  Loss Function (3)  Model Optimization (3)  Motion Generation (3)  3D Pose and Shape (14)  Face Alignment (1)  Object Detection (28)  Image Classification (2)  Image Segmentation (4)  Object Tracking (14)  Action Recognition (10)  3D Reconstruction (9)  Image Processing (13)  Dataset (6)  AI Development (80)  TensorRT (35)  ONNX (9)  PyTorch (7)  TensorFlow | TFLite (17)  GPU | CUDA | PyCUDA (12)  Programming (155)  Python (27)  C | C++ (15)  OpenCV (34)  Linux (45)  Etc. (34)  Computer Science (64)  학부 및 대학원 과목 (22)  선형대수학 및 기타 수학 (9)  SQL-D (33)  삽질 기록 (56)  기타 (60)  참고자료 (39)  좋은 글 (5)  티스토리 (3)  논문 작성 관련 참고 (10)  메모 (0)  #chart-time {font-size:11px; text-align:right; color:#999; padding-right: 15px;}08-14 05:17        am4core.ready(function() {            am4core.addLicense(""CH90809262"");            var chart = am4core.create(""chartdiv"", am4charts.XYChart);            chart.data = [{""timestamp"":""2024-08-08T00:00:00+09:00"",""count"":1457},{""timestamp"":""2024-08-09T00:00:00+09:00"",""count"":1204},{""timestamp"":""2024-08-10T00:00:00+09:00"",""count"":441},{""timestamp"":""2024-08-11T00:00:00+09:00"",""count"":454},{""timestamp"":""2024-08-12T00:00:00+09:00"",""count"":1507},{""timestamp"":""2024-08-13T00:00:00+09:00"",""count"":1559},{""timestamp"":""2024-08-14T00:00:00+09:00"",""count"":73}];            var values = chart.data.map(function(value){                return value.count            });            var minValue = values.reduce(function(acc, current) {                return Math.min(acc, current);            });            var maxValue = values.reduce(function(acc, current) {                return Math.max(acc, current);            });            chart.dateFormatter.inputDateFormat = ""yyyyMMdd"";            var dateAxis = chart.xAxes.push(new am4charts.DateAxis());            var valueAxis = chart.yAxes.push(new am4charts.ValueAxis());            dateAxis.renderer.grid.template.disabled = true;            dateAxis.dateFormats.setKey(""day"", ""dd"");            dateAxis.periodChangeDateFormats.setKey(""day"", ""dd"");            dateAxis.renderer.minGridDistance = 1;            dateAxis.fontSize = ""10.5px"";            dateAxis.color = ""#ff0000"";            dateAxis.opacity = 0.5;            valueAxis.opacity = 0.5;            valueAxis.fontSize = ""10.5px"";            valueAxis.paddingBottom = 5;            valueAxis.marginLeft = -20;            valueAxis.min = minValue < 0 ? 0 : minValue;            valueAxis.max = maxValue + 10;            var series = chart.series.push(new am4charts.LineSeries());            series.dataFields.valueY = ""count"";            series.dataFields.dateX = ""timestamp"";            series.tooltipText = ""{count}""            series.strokeWidth = 1;            series.minBulletDistance = 15;            series.tooltip.background.cornerRadius = 20;            series.tooltip.background.strokeOpacity = 0;            series.tooltip.pointerOrientation = ""vertical"";            series.tooltip.label.minWidth = 40;            series.tooltip.label.minHeight = 40;            series.tooltip.label.textAlign = ""middle"";            series.tooltip.label.textValign = ""middle"";            var bullet = series.bullets.push(new am4charts.CircleBullet());            bullet.circle.strokeWidth = 2;            bullet.circle.radius = 3;            bullet.circle.fill = am4core.color(""#fff"");        });DarkBook Review[Book Review] 인사이드 머신러닝 인터뷰꾸준희|2024. 4. 28. 23:48728x90    한빛미디어에서 출간된 인사이드 머신러닝 인터뷰 책은 펑샤오라는 사람이 지었다. 펑 샤오라는 사람은 15년동안 소셜 미디어, 광고 기술 등 다양한 분야에서 ML 리더십 직책을 맡아 천 명에 가까운 지원자를 면접했다. 현재는 트위터(X)에서 스태프 ML 엔지니어로 근무하면서 추천 알고리즘과 광고 에측 및 랭킹을 위한 ML 시스템을 설계했다. 천 명에 가까운 ML 관련 지원자를 면접할 만큼 면접에 대한 다양한 경험이 쌓였으니, 이 책은 머신러닝 직무 관련 면접을 앞두고 있는 사람들에게 큰 도움이 될 수 있다.  대부분 ML 관련 직무 면접은 신입 / 경력 이렇게 두 가지로 나뉘게 된다. 신입 때 봤던 면접 질문 같은 경우 ML 관련 기초 지식을 기반으로 물어보는 질문들이 굉장히 많았고, 경력 때 경험했던 면접 질문 같은 경우에는 내가 진행했던 프로젝트와 관련하여 심도있는 질문들을 많이 받았었던 기억이 난다. 그래도 어느정도 규모가 있는 빅테크 회사 같은 경우에는 신입이나 경력직 구분 없이 테크니컬 폰 스크린 면접을 시작으로, ML 기본 지식, 코딩 면접 등을 거치게 되며, 경력직 같은 경우에는 ML 시스템 설계 면접 까지 추가로 보게 된다.  그래서 이 책에서는 폰 스크린 단계 면접 부터 시작하여, ML 기본 지식 면접, 코딩 면접, 시스템 설계 면접 까지 신입부터 경력직까지 모든 연차에 맞춰 면접에 대한 가이드를 제시해준다. 경력직인 나도 이 책의 ML 기본 지식을 훑어보다 보면 잊고 있었던 지식이나, 알고 있었던 지식에 살을 덧붙여 지식 업데이트가 되는 듯한 느낌을 받았다. 면접을 앞두고 있는 사람들이라면, 면접 전에 한번 정도 훑어보면 도움될만한 책이며, 면접을 앞두고 있지 않더라도, ML 교양서로 정도로 봐도 될 것 같다는 생각이 들었다. 여러모로 ML과 관련하여 쓸모가 많은 책이였다.   “한빛미디어 <나는 리뷰어다> 활동을 위해서 책을 제공받아 작성된 서평입니다."" 728x90     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//eehoeskrap.tistory.com/reaction';window.ReactionReqBody = {    entryId: 772}공유하기게시글 관리Enough is not enough저작자표시 비영리 변경금지 'Book Review' 카테고리의 다른 글[Book Review] 혼자 공부하는 얄팍한 코딩지식  (0)2024.06.23[Book Review] 실무로 통하는 ML 문제 해결 with 파이썬  (2)2024.05.26[Book Review] 한 권으로 끝내는 이미지 생성 AI with 미드저니  (0)2024.03.24[Book Review] 요즘 개발자  (0)2024.02.25[Book Review] 알고리즘인사이드 with 파이썬  (1)2023.11.26$(document).ready(function() {var offset = 90,scroll_top_duration = 700,$go_top = $('.top-btn'),$thedial = $('.dial'),$progress_circle = $('.progress-circle');const rootStyles = getComputedStyle(document.documentElement);const highlight = rootStyles.getPropertyValue('--highlight-color');// Initialize the progress dial$thedial.knob( {'min' : 0,'max' : 100,'width' : 30,'height' : 30,'fgColor' : highlight,'bgColor' : 'transparent','skin' : 'tron','thickness' : .1,'displayInput' : false,'displayPreview' : false,'readOnly' : true});$(window).scroll(function() {// Hide or show the progress bar($(this).scrollTop() > offset) ? $progress_circle.addClass('is-visible') : $progress_circle.removeClass('is-visible');// Get the window position and set it to a varialevar s = $(window).scrollTop(),d = $(document).height(),c = $(window).height();scrollPercent = (s / (d-c)) * 100;// Bind the window position to the progress dial$('.dial').val(scrollPercent).change();});//smooth scroll to top$go_top.on('click', function(e) {e.preventDefault();$('body,html').animate( {scrollTop: 0 ,}, scroll_top_duration);});});Comment 1 SECRET     setInitialEntryComments(772, 1723627644)loadedComments[772]=true;findFragmentAndHighlight(772);Designed By ushin20const navbarBtn = document.querySelector('.navbar-btn');const sidebar = document.querySelector('.sidebar');const sidebar_closeBtn = document.querySelector('.sidebar-closeBtn');function isMediaQueryActive() {// Replace the condition with your specific media query checkreturn window.matchMedia('(max-width: 768px)').matches;}navbarBtn.addEventListener('click', function() {if (isMediaQueryActive()) {// Media query is active, so reverse the behaviorif (sidebar.classList.contains('hidden')) {sidebar.classList.remove('hidden');localStorage.setItem('sidebar', 'close');} else {sidebar.classList.add('hidden');localStorage.setItem('sidebar', 'open');}} else {// Media query is not active, maintain the original behaviorif (sidebar.classList.contains('hidden')) {sidebar.classList.remove('hidden');localStorage.setItem('sidebar', 'open');} else {sidebar.classList.add('hidden');localStorage.setItem('sidebar', 'close');}}});sidebar_closeBtn.addEventListener('click', function() {sidebar.classList.toggle('hidden');localStorage.setItem('sidebar', 'close');});$(document).ready(function() {const sidebar = document.querySelector('.sidebar');var sidebar_state = localStorage.getItem('sidebar');if (isMediaQueryActive()) {if (sidebar_state === 'open') {// if sidebar is sidebar hidden, change it to sidebarsidebar.classList.add('hidden');} else {// if sidebar is sidebar, change it to sidebar hiddensidebar.classList.remove('hidden');}} else {if (sidebar_state === 'open') {// if sidebar is sidebar hidden, change it to sidebarsidebar.classList.remove('hidden');} else {// if sidebar is sidebar, change it to sidebar hiddensidebar.classList.add('hidden');}}});function toggleTheme() {var theme_content = document.getElementById('theme');var btn_toggle = document.getElementById('themeToggle');if (themeToggle.checked) {setTheme('dark');theme_content.innerHTML = ""dark"";} else {setTheme('light');theme_content.innerHTML = ""light"";}}function setTheme(theme) {if (theme === 'light') {document.documentElement.style.setProperty('--dark-bg-color', '#fefefe');document.documentElement.style.setProperty('--dark-bg-second-color', 'whitesmoke');document.documentElement.style.setProperty('--dark-font-color', 'rgb(30, 31, 33)');document.documentElement.style.setProperty('--sidebar-hr-color', 'rgba(0, 0, 0, 0.2)');localStorage.setItem('theme', 'light');} else {document.documentElement.style.setProperty('--dark-bg-color', 'rgb(30, 31, 33)');document.documentElement.style.setProperty('--dark-bg-second-color', 'rgb(50, 51, 53)');document.documentElement.style.setProperty('--dark-font-color', '#fefefe');document.documentElement.style.setProperty('--sidebar-hr-color', 'rgba(255, 255, 255, 0.2)');localStorage.setItem('theme', 'dark');}}$(document).ready(function() {var theme_content = document.getElementById('theme');var theme = localStorage.getItem('theme');if (theme === 'dark') {$('#themeToggle').prop('checked', true);setTheme('dark');theme_content.innerHTML = ""dark"";} else {$('#themeToggle').prop('checked', false);setTheme('light');theme_content.innerHTML = ""light"";}});var content = document.querySelector("".contents_style"");var headings = content.querySelectorAll(""h1, h2, h3, h4, h5, h6, h7"");var headingMap = {};Array.prototype.forEach.call(headings, function (heading) {var id = heading.id? heading.id: heading.textContent.trim().toLowerCase().split("" "").join(""-"").replace(/[\!\@\#\$\%\^\&\*\(\):]/gi, """");headingMap[id] = !isNaN(headingMap[id]) ? ++headingMap[id] : 0;if (headingMap[id]) {heading.id = id + ""-"" + headingMap[id];} else {heading.id = id;}});tocbot.init({tocSelector: "".toc"",contentSelector: "".contents_style"",headingSelector: ""h2, h3, h4"",hasInnerContainers: false,});$(document).ready(function () {$("".toc"").addClass(""toc-absolute"");var toc_top = $("".toc"").offset().top - 165;$(window).scroll(function () {if ($(this).scrollTop() >= toc_top) {$("".toc"").addClass(""toc-fixed"");$("".toc"").removeClass(""toc-absolute"");} else {$("".toc"").addClass(""toc-absolute"");$("".toc"").removeClass(""toc-fixed"");}});});        function removeElementByClassName(className) {var elements = document.getElementsByClassName(className);var element = elements[0];if (element) {element.parentNode.removeChild(element);}}function change_header_style() {var h3Elements = document.querySelectorAll('h3');var h4Elements = document.querySelectorAll('h4');// 선택된 h3 요소에 스타일 적용h3Elements.forEach(function(element) {element.style.color = 'black'; element.style.fontWeight = 'bold'; element.style.borderBottom = '1px solid black';element.style.paddingTop = ""0.5em"";element.style.marginBottom = '5px';});// 선택된 h4 요소에 스타일 적용h4Elements.forEach(function(element) {element.style.color = 'black'; element.style.fontWeight = 'bold'; element.style.borderBottom = '1px solid black';element.style.paddingBottom = '5px';element.style.marginBottom = '5px';});}        document.getElementById('removeButton').addEventListener('click', function() {            removeElementByClassName('navbar');            removeElementByClassName('sidebar');            removeElementByClassName('container_postbtn');            removeElementByClassName('another_category');            removeElementByClassName('tagTrail');            removeElementByClassName('tt_box_namecard');            removeElementByClassName('comment');            removeElementByClassName('btn_menu_toolbar');            removeElementByClassName('progress-circle');            removeElementByClassName('toc');            removeElementByClassName('category');change_header_style();var container = document.getElementsByClassName('container')[0];container.style.marginTop = 0;var titleWrap = document.getElementsByClassName('titleWrap')[0];titleWrap.style.marginTop = 0;var entry = document.getElementsByClassName('entry')[0];entry.style.maxWidth = ""100%"";var title = document.getElementsByClassName('titleWrap')[0];title.style.marginBottom = 0;title.style.alignItems = ""initial"";var author = document.getElementsByClassName('author')[0];author.style.color = ""black"";var article_content = document.getElementsByClassName('article_content')[0];article_content.style.padding = 0;article_content.style.marginTop = ""10px"";var titleWrapH2Element = document.querySelectorAll('.titleWrap h2')[0];titleWrapH2Element.style.textAlign = ""left"";// 모든 제거 완료        });    var footer = document.querySelector(""footer"");var copyrightText ='<a href=""https://ushin20-skin.tistory.com/entry/Youtube-%EC%9C%A0%ED%8A%9C%EB%B8%8C-%ED%85%8C%EB%A7%88-%EC%A0%9C%EC%9E%91%EC%99%84%EB%A3%8C"">uTube</a>· Designed By <a href=""https://ushin20.github.io"">ushin20</a>';if (!footer.innerHTML.includes(copyrightText)) {// If not present, add the copyright text to the footervar copyrightElement = document.createElement(""div"");copyrightElement.innerHTML = copyrightText;footer.appendChild(copyrightElement);}티스토리툴바Enough is not enough구독하기                    (function () {                         var blogTitle = 'Enough is not enough';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""1942807-772"",""customProps"":{""userId"":""0"",""blogId"":""1942807"",""entryId"":""772"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""772"",""entryTitle"":""[Book Review] 인사이드 머신러닝 인터뷰"",""entryType"":""POST"",""categoryName"":""Book Review"",""categoryId"":""736678"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""1463556"",""authorNickname"":""꾸준희"",""blogNmae"":""Enough is not enough"",""image"":""kage@pjhCb/btsG1eWsghl/QEL6wCoCTzu95WbK2jFT60"",""plink"":""/772"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
4,https://developside.tistory.com/118,Tag,"                                                  소스코드 요리사                              홈태그미디어로그위치로그방명록카테고리Review/책[책-리뷰] 인사이드 머신러닝 인터뷰 리뷰소스코드 요리사2024. 4. 30. 22:04(adsbygoogle = window.adsbygoogle || []).push({}); 최근에 한빛미디어 <나는 리뷰어다> 활동으로 제공받아 읽은 『인사이드 머신러닝 인터뷰』라는 책에 대해 소개하고자 합니다.이 책이 처음 서점에 나왔을 때에도 유심히 보고 있었는데 때마침 이렇게 기회가 되어 읽게되어 너무 좋았습니다.이 책은 빅테크 기업의 머신러닝 면접에서 실제로 다뤄지는 194가지 질문과 모범 답안을 제시하며, 면접 준비생들에게 실질적인 도움을 주는 가이드북입니다. 특히 저자 펑 샤오는 아마존, 트위터 등에서 천 명 가까이 되는 지원자들을 직접 면접한 경험을 바탕으로 책을 집필했기에 책의 내용이 매우 생생하고 구체적입니다.『인사이드 머신러닝 인터뷰』는 ML 기본 지식 면접, 코딩 면접, 시스템 설계 면접 등 면접 유형별로 나누어 핵심 개념과 기술을 체계적으로 정리하고 있습니다. 또한 각 장마다 짚고 넘어가야 할 키워드를 요약해주고, 실전에서 활용 가능한 명쾌한 답변 전략까지 제시해줍니다.책에 등장하는 질문들을 보면 로지스틱 회귀분석의 원리부터 콜드 스타트 문제 해결 방안, 대규모 추천 시스템 아키텍처 설계까지 머신러닝 실무자라면 반드시 알아야 할 개념들로 구성되어 있습니다. 저는 특히 자연어 이해와 추천 시스템을 구축할 때 고려해야 할 사항들을 이 책을 통해 도움을 받았습니다. 자연어 이해 파트에서는 문서 요약, 감성 분석, 토픽 모델링 등 다양한 태스크에 활용되는 피처 엔지니어링 기법과 모델링 노하우를 배울 수 있었습니다. 또한 추천 시스템 챕터에서는 사용자 행동 로그를 기반으로 한 암묵적 피드백의 활용 등 실무에 적용 가능한 인사이트를 얻을 수 있었습니다. 다만, 면접에 나올만한 내용들을 초점을 맞춰 정리되어 있기 때문에 실무에 그대로 이 내용을 쓰기는 부족합니다.저는 추천시스템, 자연어처리 파트에서 어떤 부분이 주요 포인트인지 키워드와 중심내용을 파악 후 다른 책이나 인터넷을 통해 내용을 깊게 파악해서 더 쉽게 실무에 도움을 받았습니다.그리고, 이 책을 끝까지 읽는데 시간이 많이 걸렸습니다. 저는 머신러닝이 주 포지션이 아닌 만큼 책을 읽는데 다소 시간이 걸렸습니다.이 책은 독자 대상이 머신러닝 기초 지식이 어느 정도 있는 사람들인 만큼, 초심자들에겐 다소 어려울 수 있습니다. 하지만 머신러닝 학습의 로드맵을 제시해주는 나침반 같은 역할을 해줄 수 있을 것이라 생각합니다.머신러닝 엔지니어를 꿈꾸는 분들이라면 이 책과 함께 차근차근 실력을 쌓아가시길 추천드립니다. 면접 준비는 물론, 실무에서의 역량 강화에도 큰 도움이 될 것입니다.  이 리뷰는 한빛미디어 <나는 리뷰어다> 활동으로 책을 제공받아 작성되었습니다. (adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//developside.tistory.com/reaction';window.ReactionReqBody = {    entryId: 118}공유하기게시글 관리소스코드 요리사저작자표시 비영리 변경금지 'Review > 책' 카테고리의 다른 글[책] 켄트 벡의 ""Tidy First?"" 리뷰  (0)2024.05.29[책] 읽기 쉬운 코드 리뷰  (0)2024.05.22[책] 효율적인 리눅스 명령어 사용의 기술 리뷰  (0)2024.02.22[책] 코딩도 하고, 사장도 합니다. 리뷰  (0)2024.02.16[책] 파이썬 라이브러리를 활용한 텍스트 분석 리뷰  (0)2023.03.31Tag인사이드머신러닝, 책, 한빛미디어'Review/책'의 다른글이전글[책] 효율적인 리눅스 명령어 사용의 기술 리뷰현재글[책-리뷰] 인사이드 머신러닝 인터뷰 리뷰다음글[책] 읽기 쉬운 코드 리뷰관련글[책] 켄트 벡의 ""Tidy First?"" 리뷰2024.05.29[책] 읽기 쉬운 코드 리뷰2024.05.22[책] 효율적인 리눅스 명령어 사용의 기술 리뷰2024.02.22[책] 코딩도 하고, 사장도 합니다. 리뷰2024.02.16댓글 0비밀글등록loadedComments[118]=true;findFragmentAndHighlight(118);모바일(안드로이드, 플러터) 개발자로 개발 관련된 주제를 주로 작성하며, 그 밖에 관심있는 프로그래밍,  책/영화/컨퍼런스 리뷰 등에 대해서 간간히 포스팅 합니다. 분류 전체보기 (113)  전산업무 (12)  Review (35)  책 (20)  영화 & 공연 (6)  제품 (2)  세미나 & 행사 (4)  강의 (2)  Toy Project (12)  Essay (8)  Tech & Programming (46)  Pattern & Design (5)  Algorithm & Data Structure (3)  모바일(Android, Flutter) (20)  파워빌더 (4)  파이썬 (2)  웹프로그래밍 (1)  서버 & 보안 (5)  기타 (6) TagFlutter,ToyProject,자바 디자인 패턴,토이프로젝트,리뷰,essay,알고리즘,에세이,Django,책리뷰,책,전산업무,프로그래밍,파워빌더,android,파이썬,안드로이드어플,안드로이드,어린이 낱말카드,영화리뷰,최근글과 인기글최근글인기글[패스트캠퍼스 베타러너 후기] 프롬프트 엔지니어링으로 시작하는 LLM 서비스 개발2024.07.13 01:38[책] 켄트 벡의 ""Tidy First?"" 리뷰2024.05.29 22:43[책] 읽기 쉬운 코드 리뷰2024.05.22 23:12android.app.RemoteServiceException: Context.startForegroundService() d⋯2019.10.01 10:01전산실(팀) 주요업무 소개2018.02.22 10:21[리뷰 - 책] 데니스 홍 상상을 현실로 만드는 법을 읽고2018.11.21 23:57최근댓글정리를 정말 잘 하시네요.구독 꾸욱 누르고 갑니다.맞구독 부탁 드려요 ^^체리그루브포스팅 잘 읽고 가요!나리카페안녕하세요. 좋은 정보 입니다.누구나 사용하기 편리한 컴퓨터 최적화 프로그램 '이지클린'⋯이지클린_ezclean공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/072024/052024/042024/02Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total313,249Today : 31Yesterday : 47Copyright © Kakao Corp. All rights reserved.관련사이트티스토리툴바hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2848052-118"",""customProps"":{""userId"":""0"",""blogId"":""2848052"",""entryId"":""118"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""118"",""entryTitle"":""[책-리뷰] 인사이드 머신러닝 인터뷰 리뷰"",""entryType"":""POST"",""categoryName"":""Review/책"",""categoryId"":""657169"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""3729880"",""authorNickname"":""소스코드 요리사"",""blogNmae"":""소스코드 요리사"",""image"":""kage@WLjM2/btsG4jxES5P/R65bHOkgTS34kL8SzzfpE1"",""plink"":""/118"",""tags"":[""인사이드머신러닝"",""책"",""한빛미디어""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
5,https://dopilog.tistory.com/6,티스토리툴바,"배움/데이터[30대 개발자] 머신러닝 엔지니어/사이언티스트 인터뷰 - 1 도피로그2023. 1. 10. 23:33     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }나는 딥러닝 엔지니어 인턴을 시작으로, 데이터 사이언티스트를 거쳐, 지금은 머신러닝 엔지니어로 일하고 있다. 나는 AI/ML 관련 직책으로 다양한 회사에 지원했었고, 그중 특히 머신러닝 엔지니어 포지션의 인터뷰는 정말 그 방식이 다양했다. 어떤 회사는 일주일이라는 시간과 회사 내부 데이터를 주고 모델을 만들고 분석해 오라는 과제를 주기도 했고, 텅 빈 Jupyter Notebook 위에 feature analysis, engineering, model training/evaluation까지 1시간 내에 마쳐보라고 하는 회사도 있었다. 또 다른 날은 팀의 매니저와 두 시간 동안 확률과 점화식 문제를 풀었어야 했을 때도 있었다. 소프트웨어 엔지니어와 달리 머신러닝 엔지니어는 인터뷰 과정에서 다양한 지식을 검증받는다. 코딩은 물론 기초 확률/통계와 머신러닝 개념에 대한 전반적인 이해도를 검증받는다. 머신러닝 엔지니어가 되기 위해선 코딩 인터뷰를 비롯해 정말 다양한 분야를 리뷰해야 했고, 나는 다음과 같은 방법으로 인터뷰를 준비했다. 1. KaggleKaggle에 올라온 수 많은 사람들이 작성한 Jupyter Notebook script 들을 참고해 보자. 짧은 시간 내에 사람들이 일반적으로 데이터 분석 및 모델링을 어떻게 하는지 파악할 수 있을 것이다. 이를 바탕으로 나만의 script를 작성해보자. 이 script를 바탕으로 차근차근 데이터를 분석하고 모델링 하면 인터뷰를 잘 마칠 수 있을 것이다. 2. 확률통계 & 머신러닝면접관은 때때로 면접 직전 warm up question으로 기초 개념들을 물어본다. 이때 간결하게 질문에 답변할 수 있기 위해선 예전에 공부했던 강의 자료를 반복 학습하고 학습한 내용을 이해하고 있는 게 중요하다. 대학에서, 혹은 독학한 공부 자료가 있다면 복습해 보자. 개인적으로 스탠퍼드 대학의 CS229 강의 자료가 인터뷰 준비하면서 정말 많은 도움이 됐고, 추가적으로 precision/recall 과 같은 evalation metrics에 대해서 깊게 학습한 게 도움이 됐다.  3. 머신러닝 시스템 디자인스탠퍼드 대학의 CS329S 강의를 정독해 보자. 현업에서 머신러닝 시스템을 어떻게 구성하는지 많은 케이스스터디와 그들의 솔루션을 배울 수 있다.반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//dopilog.tistory.com/reaction';window.ReactionReqBody = {    entryId: 6}공유하기게시글 관리도피로그 Secret댓글댓글달기loadedComments[6]=true;findFragmentAndHighlight(6);"
6,https://sysout.tistory.com/104,ABOUT ME,"홈전체 글태그방명록 TOTAL (87)  DAILY :) (12)  GRADUATE SCHOOL (9)  BIG DATA & AI (26)  NLP (8)  Machine Learning (7)  Mathematics (2)  PROGRAMMING (14)  Git (2)  Web Programming (3)  Python (4)  Algorithm (1)  BOOK (11)  COOK (5)  THINKING (3)  EXCHANGE STUDENT (7) ABOUT ME-인스타그램Today-Yesterday-Total-Emily's Tistory메뉴검색컨텐츠 검색블로그 내 검색[책 리뷰] 인사이드 머신러닝 인터뷰BOOK2024. 4. 9. 17:00     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});인사이드 머신러닝 인터뷰 / 펑 샤오 / 한빛미디어 (2024)총평알고리즘 인터뷰 책과 강의는 수도 없이 쏟아지는데, 머신러닝 엔지니어를 위한 인터뷰는 도대체 언제 나올까? → 나왔다.혼자 준비하기 답답했던 ML 엔지니어들에게 한 줄기 빛 같은 책이다. 본인도 최근 구직을 하면서 각종 구글링과 지인 네트워크를 통해 겨우겨우 정보를 얻어 준비했었고, 앞으로 머신러닝 엔지니어의 공급은 더 많아질 텐데 언제쯤 나올까 했던 책이 드디어 나왔다! 전형을 마무리한 후에 이 책을 보게 된 건 슬프지만, 인터뷰 준비 뿐만 아니라 옆에 두고 ML essential 다지기에도 너무 괜찮은 책이다.저자의 이름이 재미있게도(?) 최근에 화제가 되는 샤오미 전기차의 이름과 동일한데, 이 분 굉장히 대단한 분이다. Amazon 등 빅테크에서 ML 엔지니어로 활동했으며 중간에 Roxy Device라는 스타트업을 창업을 하고 개발팀이 트위터(현 X)에 인수되어 ML ranking, modeling, serving 등 전반적인 ML 업무를 맡으며 천 명에 가까운 지원자를 면접봤다고 한다. 얼마나 많은 경험과 노하우가 들어있을지 기대하며 책을 폈었다.고등학교 때 남들이 수학의 정석을 보는 반면 본인은 수학의 바이블을 굉장히 좋아했는데, 오랜만에 마음에 드는 전공 서적을 찾은 느낌이었다. 몇 번의 ML면접을 경험해본 바 정말 필요한 내용들이 집약적으로 담겨 있다. 해당 전형이 왜 필요한지, 무엇이 중심 내용인지부터 스토리텔링으로 이해와 암기를 자연스럽게 연결시켰다. 이 책은 사기적이다. 정말 솔직히 말하면 포트폴리오와 논문 실적이 어느정도 존재한다는 가정 하에, 이 책을 달달 외운다면 왠만한 IT기업은 다 뚫지 않을까 싶다. 개인적으로 요즘은 AI 인재 포화상태라고 생각하며 인터뷰도 기본 3-4번 보고 신중하게 뽑는 추세여서 면접 기준이 점점 더 높아지고 있는데, 주변의 ML 엔지니어 구직자에게 이 책을 강력 추천하고 싶다! 너무 찬사를 남발했는데 요즘 한국 사회 한정으로 육각형을 갖춘 이상형을 다들 원하고 찾지만 실제로는 없듯이 아쉬운 점이 있다면, 일반적인 ML 엔지니어를 대상으로 하고 있기 때문에 세부 분야인 NLP, CV, Multi-Modal 등에 대해서는 깊게 다루고 있지 않다. 최근에는 단순 ML 엔지니어 외에도 특정 분야의 전문가를 영입하기 위해 NLP 중에서도 LLM 전문가, Multilingual 전문가, Prompting 전문가 등 JD를 꽤나 구체적으로 적어서 뽑는 추세인데 분량상 이 부분까지 커버하기는 버거운 것 같다. (개인적으로 Part.2가 나왔으면 하는 바램도 있다.) 또한  비교적 최근에 출간한 도서라 LLM까지 다루고 있지만, ChatGPT의 RLHF, instruction fine-tuning까지만 담겨 있는 것도 참고 바란다.  책갈피다음 질문을 생각해 봅시다. ""분류 문제 X에 가장 유용한 피처를 어떻게 찾을 수 있나요?""질문에 답하기 위해 지원자는 전공 지식이나 업계에서 배운 경험을 활용합니다. 전공 지식이 있다면 카이제곱 검정이나 정보 이득과 같은 통계 기법을 거론할 테고 반대로 업계 경험이 있다면 피처값을 교란하거나 절제 연구를 수행하는 등의 직접적인 접근 방식을 제안할 수 있겠죠. 또한 지원자는 피처의 유효성만 고려할 것이 아니라 시스템 제약 아래 오프라인 수집이 용이한지, 프로덕션 환경의 온라인 추론을 위해 빠르고 안정적으로 수화(hydration, ML pipeline에서 피처값들이 얼마나 막힘없이 잘 '흐르는지'에 대한 개념)가 가능한지도 고려해야 한다는 점을 알 수 있습니다.- 지은이의 말 中<경사하강법 최적화>Q. 경사하강법을 어떻게 최적화하나요?A. 경사하강법의 문제를 해결하는 최적화 알고리즘은 다음과 같습니다.- 모멘텀(Momentum) : 이전 시간 스템의 가중치 업데이트량의 일부를 현재 가중치 업데이트에 추가합니다. 손실함수의 경사에 적응하는 것으로 볼 수도 있습니다. 더 빨리 수렴하도록 하지만 잘못된 방향으로 방황할 수도 있습니다.- 네스테로프 모멘텀(Nesterov Momentum) : 모멘텀 기법의 일종으로, 가중치에 모멘텀 업데이트를 적용한 후 경사를 계산합니다. 수렴 속도를 희생하지 않으면서 가중치 업데이트의 정확성을 높이기 위해 모멘텀에 수정을 가하는 것으로 볼 수 있습니다.- 그 외 에이다그래드(AdaGrad), 에이다델타(AdaDelta)와 RMSProp, 애덤(Adam) 등이 있습니다. (후략)p50: ML 기본 지식<모델 최적화>Q. 매우 짧은 지연 시간을 갖도록 학습한 모델을 최적화하는 방법에는 무엇이 있나요?A. 피처 선택, 레이어 수 감소시키기, 레이어 크기 감소시키기 등 기존 기법은 이미 적용되었다고 가정할 때 서빙을 위해 모델을 추가로 최적화하는 기법은 다음과 같습니다.- 모델 정리 : 모델의 예측 경로에 존재하는 불필요한 구성 요소를 제거합니다. 예를 들어 사용되지 않는 노드, 중복 노드, 학습에 필요했지만 예측에는 더 이상 필요하지 않은 기타 구성 요소 등이 있습니다. 또 다른 단계는 항상 상수 표현식으로 평가되는 모델 내 하위 그래프를 찾는 것입니다. 이러한 하위 그래프는 해당 상숫값으로 대체될 수 있습니다. 또한 배치 정규화의 곱셈을 이전 레이어의 가중치 곱셈에 통합시키는 것도 도움이 됩니다.- 입력 압축 : 프로덕션 랭킹 모델은 수천~수만 개의 입력 피처를 사용하는 경우가 많습니다. 다양한 소스에서 피처를 수화하고 네트워크를 통해 모델 서버로 전송해야 하므로 추론 중에 상당한 지연 시간이 발생하기도 합니다. 이 문제를 해결하기 위해 학습 중에 대상 및 후보 피처에 대한 밀집 임베딩을 저장해뒀다가 추론 시에 그 임베딩들만 가져옵니다. (중략)- 그 외 효율적 캐싱 전략, 일괄 추론, 투 타워, 양자화(quantization), 효율적인 신경망 제품군, 모델 압축 등이 있습니다. (후략)p256: ML 인프라 설계 목차1장 ML 면접에 임하기테크니컬 폰 스크린ML 기본 지식 면접ML 코딩 면접ML 시스템 설계 면접기타 면접우수한 답변의 필수 요소2장 ML 기본 지식Q2.1 데이터셋 수집 단계Q2.2 데이터 수집 시 문제Q2.3 데이터 수집 시 고려 사항Q2.4 레이블 불균형 처리Q2.5 누락된 레이블 처리Q2.6 입력 피처 유형Q2.7 피처 선택과 중요도Q2.8 피처 선택 방법Q2.9 누락된 피처값Q2.10 모델링 알고리즘Q2.11 로지스틱 회귀 작동 방식Q2.12 로지스틱 회귀 손실 함수Q2.13 경사하강법 최적화Q2.14 하이퍼파라미터 튜닝Q2.15 모델 과적합 처리Q2.16 정규화 기법Q2.17 선형 회귀와 로지스틱 회귀Q2.18 신경망 활성화 함수Q2.19 의사 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 결정 트리Q2.20 부스팅과 배깅Q2.21 비지도 학습 기법Q2.22 k-평균 작동 방식Q2.23 준지도 학습 기법Q2.24 손실 함수 유형Q2.25 손실 함수 볼록성Q2.26 분류 모델 평가 지표Q2.27 회귀 모델 평가 지표Q2.28 모델 최적화Q2.29 모델 성능 개선3장 ML 코딩Q3.1 k-평균Q3.2 k-최근접 이웃Q3.3 의사 결정 트리Q3.4 선형 회귀Q3.5 평가 지표Q3.6 저수지 샘플링Q3.7 확률 문제Q3.8 해시 테이블과 분산 프로그래밍 문제Q3.9 그래프 문제Q3.10 문자열 문제Q3.11 배열 문제4장 ML 시스템 설계 1 - 추천 시스템Q4.1 시스템 목적Q4.2 시스템 지표Q4.3 추천 콘텐츠 유형Q4.4 추천 콘텐츠 혼합Q4.5 시스템 운영 매개변수Q4.6 시스템 구성 요소Q4.7 콜드 스타트 문제Q4.8 데이터셋 유형Q4.9 데이터셋 수집 기법Q4.10 데이터셋 편향Q4.11 서빙 편향 완화Q4.12 위치 편향 완화Q4.13 추천 후보 출처Q4.14 추천 후보 생성 단계Q4.15 추천 후보 생성 알고리즘Q4.16 임베딩 기술Q4.17 대규모 추천 시스템의 후보 스코어링Q4.18 신규 콘텐츠 색인화Q4.19 추천 후보 병합 및 정리Q4.20 사전 랭킹 모델 학습Q4.21 사전 랭킹 모델 평가 지표Q4.22 사전 랭킹 모델 알고리즘Q4.23 사전 랭킹 모델 최적화Q4.24 랭킹 모델 주요 피처Q4.25 텍스트 또는 ID 기반 피처Q4.26 횟수 기반 피처Q4.27 헤비 랭킹 모델 학습Q4.28 헤비 랭킹 모델 알고리즘Q4.29 랭킹 모델 아키텍처Q4.30 랭킹 모델 예측값 보정Q4.31 랭킹 모델 평가 지표Q4.32 다중 작업 모델과 개별 모델Q4.33 모델 서빙 시스템Q4.34 캐싱Q4.35 모델 업데이트Q4.36 온라인 실험Q4.37 모델 로드Q4.38 모델 실험 고려 사항Q4.39 오프라인 평가 지표Q4.40 온라인 성능 저하5장 ML 시스템 설계 2 - 응용Q5.1 문서 파싱Q5.2 감성 분석Q5.3 토픽 모델링 기법Q5.4 문서 요약Q5.5 자연어 이해Q5.6 지도 학습 레이블Q5.7 비지도 학습 피처Q5.8 판별적 문제 피처Q5.9 생성 모델 피처Q5.10 정보 추출 모델 구축Q5.11 정보 추출 평가 지표Q5.12 분류 모델 구축Q5.13 회귀 모델 구축Q5.14 토픽 할당Q5.15 토픽 모델링 평가 지표Q5.16 문서 클러스터링 모델 구축Q5.17 클러스터링 평가 지표Q5.18 텍스트 생성 모델 구축Q5.19 텍스트 생성 평가 지표Q5.20 모델링 워크플로Q5.21 오프라인 예측6장 ML 인프라 설계Q6.1 모델 개발 가속화Q6.2 모델 학습 가속화Q6.3 모델 학습 분산Q6.4 모델 학습 파이프라인 평가Q6.5 분산 학습 오류Q6.6 모델 업데이트Q6.7 모델 최적화Q6.8 서빙 시스템 구성 요소Q6.9 서빙 시 문제Q6.10 피처 수화 개선Q6.11 지연 시간 개선Q6.12 많은 요청 처리하기Q6.13 서빙 시 모델 업데이트Q6.14 모델 배포와 롤백Q6.15 서버 모니터링Q6.16 서빙 시 성능 저하7장 고급 ML 문제Q7.1 지연된 레이블Q7.2 레이블 없이 학습하기Q7.3 가격 모델부록 A 생성 모델: 노이지 채널 모델에서 LLM까지A.1 기계 번역(MT)A.2 자동 음성 인식(ASR)A.3 트랜스포머로의 수렴A.4 현실의 과제를 위한 미세 조정 한빛미디어 서평단 <나는리뷰어다> 활동을 위해서 책을 제공 받아 작성된 서평입니다.반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//sysout.tistory.com/reaction';window.ReactionReqBody = {    entryId: 104}공유하기게시글 관리Emily's Tistory 저작자표시 비영리 동일조건 'BOOK' 카테고리의 다른 글[책 리뷰] 개발자를 위한 커리어 관리 핸드북  (0)2024.05.26[책 리뷰] GPT-4를 활용한 인공지능 앱 개발  (2)2024.02.20[책 리뷰] 파이썬과 엑셀로 시작하는 딥러닝  (2)2023.07.27[책 리뷰] 클린 코드의 기술  (0)2023.05.09[책 리뷰] 핸즈온 데이터 시각화 (Hands-On Data Visualization)  (0)2022.07.10TAGai, MachineLearning, ML, 도서, 리뷰, 머신러닝, 인공지능, 책, 한빛미디어관련글 관련글 더보기[책 리뷰] 개발자를 위한 커리어 관리 핸드북[책 리뷰] GPT-4를 활용한 인공지능 앱 개발[책 리뷰] 파이썬과 엑셀로 시작하는 딥러닝[책 리뷰] 클린 코드의 기술댓글 2댓글                                                    접기댓글 펼치기이전 댓글 더보기    setInitialEntryComments(104, 1723627645)댓글                                                            비밀글등록loadedComments[104]=true;findFragmentAndHighlight(104);인기포스트코딩용, 프로그래밍용 폰트(글꼴) 추천 / The Be⋯AI대학원 야간 석사 1기 회고 (한양대학교 인공지능융⋯대학원생 1주차 후기 (특수대학원/한양대 인공지능융합대⋯한양대학교 인공지능융합대학원 면접 합격 후기 (2021⋯ABOUT MEAI, Big Data, Web Programming 에 관심이 많은 데이터 사이언티스트입니다.LINKADMINadmin글쓰기163,96886129                    Written by Emily.                티스토리툴바                    (function () {                         var blogTitle = 'Emily\'s Tistory';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2557266-104"",""customProps"":{""userId"":""0"",""blogId"":""2557266"",""entryId"":""104"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""104"",""entryTitle"":""[책 리뷰] 인사이드 머신러닝 인터뷰"",""entryType"":""POST"",""categoryName"":""BOOK"",""categoryId"":""951390"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""3508947"",""authorNickname"":""emily_ju"",""blogNmae"":""Emily's Tistory"",""image"":""kage@AqpW7/btsGpHsuXDM/L2dgiklYdDX7mrTSkqBQbk"",""plink"":""/104"",""tags"":[""ai"",""MachineLearning"",""ML"",""도서"",""리뷰"",""머신러닝"",""인공지능"",""책"",""한빛미디어""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
7,https://jonhyuk0922.tistory.com/218,후기는 개인적인 회고에 가깝습니다!,"진로 탐색 log/과제 기록[진로탐색] ML/DL 분야 과제테스트 및 코딩테스트 후기 1탄 조녁2022. 4. 7. 00:49반응형(adsbygoogle = window.adsbygoogle || []).push({});   안녕하세요~!28년차 진로탐색꾼 조녁입니다! 일전에는 계속해서 진행했던 면접과 관련하여 기록하였는데, 이번에 진로탐색하면서 과제테스트를 많이 진행하다보니 제 스스로 제가 본 과제들에 대한 회고를 적고 싶어서,  과제테스트와 AI분야 코딩테스트에 대한 진로탐색 일기를 적어볼까합니다! (반성일기입니다 흑흑) 받은 과제 : 리플에이아이(코딩테스트, 복합어 추출 과제, 당뇨예측 과제), 보이스루(코테), 클래스101(코테), 원티드랩(사전면접)  후기는 개인적인 회고에 가깝습니다!1. 리플에이아이 머신러닝 엔지니어 : 코딩테스트와 과제테스트를 동시에 보내준다(프로그래머스 진행). 최근에 딥러닝을 쓰지 않아도 되면 안쓰는게 낫다는 생각이 있어서 안쓰고 풀었더니 다시 딥러닝으로 풀라고 과제테스트를 다시 보내주셨다. - 느낀점 : 복합어 추출 과제를 풀면서, 한국어와는 다른 영어의 특징을 고민해볼 수 있었다. 그리고 당뇨예측 과제를 풀면서, 내가 NLP쪽만 해서 이런 데이터는 오히려 낯설구나 .. 다양한 도메인에 익숙해져야겠다는 생각을 했다. 코딩테스트는 무난한 난이도였는데 너무 오랜만에 풀어서 버벅이다가 제대로 못푼 느낌이 있었다. 근데도 과제테스트를 다시하라고 보내주신거 보면, 이 회사에는 코딩테스트는 중요하지 않은 것 같다. - 배운점1. Pytorch로 시계열이나 이미지, 추천시스템 등 익숙치 않은 분야에 대해서 튜토리얼 정도 돌려봐도 좋을 것 같다는 생각이 들었다.2. 영어에서 복합명사를 나누는 모듈들을 사용해봤고, 룰베이스 기반으로 점수를 올려볼 수 있었다. 3. (자아성찰) 이번 시즌 첫 코딩테스트를 보며, 코딩테스트 준비가 필요하다는 사실을 꺠달았다.  2. 보이스루 DL Researcher : 코딩테스트 3문제 & 150분(프로그래머스 진행), 일주일의 시간을 주셨는데 다른 과제와 겹쳐서 1회 기간 연장함(1회까지 가능) - 느낀점 : 이메일에 '간단한 실력확인을 위함'이라고 쓰여있긴 했는데 진짜 근래 본 코딩테스트 중에 가장 쉬웠다. 다만 시간 조절을 잘 못해서 마감 25분전에 코테를 시작해서 3문제 중에 1문제는 끝까지 풀진 못했다.. 그런데 왠지 모르지만 붙었다. 정말 아예 못풀지만 않으면 보이스루는 면접에서 터실(?) 예정이신 것 같다 ㅎㅎ.. - 배운점1. NLP를 주로 하는 AI회사들은 코딩테스트가 대체로 쉽고, 텍스트 및 스트링 처리 관련된 게 많은 것 같다.2. (자아칭찬) 내가 코딩테스트를 아예 손도 못대지는 않는구나!!   3. 클래스101 Data Scientist : 코딩테스트 2문제 & 8분(코딜리티 진행) , 데싸와 관련된 코딩테스트 였다. 전부 영어임 - 느낀점 : 첫번째 문제는 몇개의 점들이 주어지고 ROC 커브의 AUPRC를 오차범위 내에서 계산해내는 식이었고 코딩보단 수식 작성에 가까웠다. 첫번째 문제 풀고 얕잡아보고 설렁설렁 했는데 두번째 문제는 precision , recall, f1-score, weighted f1 을 numpy, pandas , sklearn을 활용해서 구현하는 문제였다. 이것도 평가지표들의 수식을 먼저 이해하고 구현하면되는 문제였는데 설렁설렁(중간에 밥먹고옴..) 풀다가 시간 부족해서 다 못풀고 냈다. 사실 문제들이 쉽게 나와서 다 못풀면 끝이구나 싶었는데 진짜 끝이었다는 이야기로 끝. - 배운점1. 코딩테스트 시간에는 집중할 수 있는 환경을 만들고 코딩테스트에 집중하자! 그래야 아쉬움이 남지 않는다.2. sklearn, numpy , pandas에 더 친숙해질 필요가 있다. (이번에 조금 더 친해졌을 지도? ..)  4. 원티드랩 AI Researcher : 사전면접 질문 7가지 & 30분 (Interview Me 진행) , 조금.. 음.. 민망하다! (AI면접 기술면접 버전임) - 느낀점 : 원티드랩에서 서비스하는 인터뷰 미라는 툴은 면접을 연습하기 위한 도구고, 언제든 사용할 수 있는 것 처럼 보였다. 30분안에 한큐로 촬영해야하지만, 하다가 말고 다시 촬영해도 된다. 즉, 질문 7개는 오픈되어있기 때문에 다 검색해보고 공부해서 봐도 된다. 다만, 한큐에 촬영해야한다는게 포인트다. 중간에 틀렸다면 처음부터 다시해야한다 ㅎㅎ.. 그래서 나는 그냥 한번에 찍고 끝냈다. 질문들은 아래와 같고 그렇게 어려운 질문은 없으나 한번에 술술 이야기하는 게 쉽지않은.. 마치 AI면접 기술면접 버전처럼 느껴졌다. 그래도 좋은 서비스 알게되서 앞으로 면접전에 이걸로 연습해봐야겠다!  - 배운점1. 좋은 면접 연습 도구인 ""Interview Me""를 알게 되었다. (광고 아님)2. 비지도 학습은 패턴이나 군집을 학습하는 구나. 내가 했던 공부들이 이 질문에 답이 되는 것들이었구나! - 질문 목록 1. Supervised learning과 Unsupervised learning의 Objective fuction과 그 차이를 딥러닝 모델 중심으로 설명해 주세요2. 딥러닝 모델의 과적합을 방지하기 위해서 어떤 방법들을 사용하는지 설명해 주세요3. RNN 기반의 LM과 Transformer 계열의 LM의 가장 큰 차이점은?4. 분포가 불균형한 비정형 데이터를 분류 할 때 발생하는 문제는 무엇인가요? 해결법은?5. Domain Knowledge가 머신 러닝 모델에 미치는 영향에 대해 프로젝트 경험을 중심으로 설명해주세요6. 머신러닝 모델을 활용해서 문제를 해결하려고 할 때 가장 중요하게 생각하는 것은 어떤 것인가요?7. 최근 가장 인상적으로 읽은 논문은 무엇인가요? https://link.coupang.com/a/rGNhA [한빛미디어]이것이 취업을 위한 코딩 테스트다 with 파이썬COUPANGwww.coupang.com""이 포스팅은 쿠팡 파트너스 활동의 일환으로, 이에 따른 일정액의 수수료를 제공받습니다.""반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jonhyuk0922.tistory.com/reaction';window.ReactionReqBody = {    entryId: 218}공유하기게시글 관리조녁 코딩일기저작자표시 태그과제테스트, 리플에이아이, 보이스루, 원티드랩, 코딩테스트, 클래스101, 후기    setInitialEntryComments(218, 1723620979)Secret댓글달기loadedComments[218]=true;findFragmentAndHighlight(218);"
8,https://ariz1623.tistory.com/341,이력서,"코딩의 숲홈태그방명록메뉴 닫기글작성방명록환경설정 분류 전체보기 (317)  딥러닝 (39)  NLP (18)  Vision (10)  딥러닝 기초 (3)  LLM (8)  머신러닝 (27)  데이터 분석 (21)  토이프로젝트 (5)  코딩야학 (7)  데이터 분석 기초 (9)  파이썬 (47)  프로그래머스 (31)  백준 (14)  PyTorch (2)  MySQL (26)  c++ (128)  알고리즘 공부 (10)  프로그래머스 (21)  백준 (95)  SWEA (1)  기타 (24)  깃허브 (7)  AWS (7)  일상 (4) 홈태그방명록기타/일상 / ariz1623 / 2023. 11. 19. 14:08주니어 머신러닝 엔지니어의 이직기 (2)이번글을 포함해서 많으면 3편에 걸쳐 이직과 관련된 이야기를 해보고자 한다. 글은 아마도 이력서 - 포트폴리오 - 지원 - 테스트 - 면접 순이 될꺼같은데, 중간에 바뀔 수도 있을 것 같다.  어디까지나 내 경험을 바탕으로 쓰는 글이라 정답은 절. 대. 아니며 이렇게도 할 수 있구나~ 정도로 가볍게 보면 좋을 것 같다. 또한 나는 최근 경력직으로 이직을 한 것이기 때문에, 경력직을 위주로 글을 쓸 예정이다.   이력서 이력서는 notion으로 썼으며 아래 블로그를 참고해 템플릿을 만들었다. 블로그 링크나의 이력서는 대략적으로 아래와 같이 구성되어 있다. 그리고 글을 최대한 적게 쓰려고 노력했다. 이력서를 읽는 담당자들이 글이 너무 많으면 부담스러워할 것 같았고, 애써 작성한 이력서를 제대로 읽지 않을 수 도 있다고 생각했기 때문이다.  이력서 구성 Introduct - 내 소개Work Experience - 경력과 관련된 프로젝트Personal Experience - 개인 프로젝트 및 공모전SKill - 기술 스택 그럼 이력서를 작성해 보기전에 앞서 우선 본인이 한 모든 것을 정리해 두는 게 중요하다. 신입으로 지원하는 거라면 학교에서 공부한 내용, 수료한 교육, 프로젝트, 참가한 공모전  등등 했던 모든 것을 다 정리하는 게 우선이 되어야 한다. 정리를 할 때는, 생각나는 것 위주로 하지 말고 대학교 1학년부터 지금 까지 시간 순서대로 하는 것을 추천한다. 그래야 안 빼먹는다.  경력의 경우에도 신입이랑 크게 다르지 않을 것이다. 다만 너무 기본적인 것들은 빼고(ex. 학교에서 공부한 내용) 정리하는 것이 좋다. 나는 우선 신입으로 지원할 때 썼던 이력서에서 아래에 쓴 것들만 가져왔다. 부스트 캠프 수강공모전 수상알고리즘 문제 풀이 우선 1번과 2번은 경력직이라도 충분히 강점으로 작용할 것이라 생각했고, 3번 같은 경우에는 지금도 계속 풀고 있는 것이라 적었다. 근데 알고리즘 문제 풀이는 딱히 적을 위치가 마땅하지 않아서 이후에는 빼버렸다.  머신러닝 엔지니어인데 왜 알고리즘을 푸냐고 궁금해하는 사람들이 있을 수 있는데, 알고리즘 문제를 푸는 것이 크게 보면 어떤 문제를 코드로 옮겨 해결하는 것이다. 나는 내 생각을 코드로 잘 구현해 내는 능력을 기르는 것은 꾸준할 필요가 있다고 생각해서 계속 알고리즘 문제를 풀고 있다.  정리가 끝났다면 본격적으로 이력서를 작성해 보자.  Introduct - 내 소개 내 소개는 크게 1번째 회사에서 한일 - 느낀 점 - 2번째 회사에서 한일 - 느낀 점 - 머신러닝 엔지니어 직무로서의 목표 순으로 작성했다.내가 어떤 경험을 했고, 이 직무를 어떻게 생각하는지를 알려주고 싶었다. 그리고 담당자들이 내 이력서를 읽으며 피로감을 덜 느꼈으면 하는 바람으로 글자수를 500자 내외로 작성했다. 아래 내용은 내 이야기는 아니고 뤼튼(chat gpt 같은 사이트)을 이용해서 작성했다. (뤼튼 바로가기) 뤼튼(왼쪽)으로 초안을 작성해서 노션(오른쪽)으로 옮겨 적었다.  Work Experience - 경력과 관련된 프로젝트 다음으로는 회사에서 진행한 프로젝트들을 아래와 같이 정리했다. 해당 서비스가 어떤 서비스이고 이런 것을 설명하기보다는 내가 한 일을 위주로 작성했다. 그리고 개선된 성능들에 대해서는 최대한 수치로 표현하려고 했다.  처음에는 해당 서비스에 대한 설명을 적어두었는데, 생각해 보니 채용하는 사람 입장에서 너무 많은 글을 읽게 되면 피로감을 느낄 수 있을 것이라 생각해 지워버렸다. 그리고 서비스에 대한 자세한 설명은 포트폴리오에 작성을 했다.   Personal Experience - 개인 프로젝트 및 공모전 개인 프로젝트는 공모전이나 사이드 프로젝트로 진행한 것들을 위주로 작성했다. 공모전은 참가했던 모든 공모전을 적기보다는, 수상한 것들만 적었다. 만약 수상 내역이 없다면 정말 열심히 참가한 내용이라도 적는 것이 좋다고 생각한다.  사이드 프로젝트의 경우에도 결과물을 보여줄 수 있는 것만 적는 것을 추천한다. 사실 결과물이 없으면 아무 의미가 없다고 해도 무방하다. 오히려 시작한 프로젝트를 끝맺음 맺지 못했다는 인식을 줄 수 있어 오히려 역효과를 줄 수 있다.  나 같은 경우에는 NLP관련된 모델들을 직접 구현해 한-영 번역 모델을 만들었었는데, 면접 시 한 번씩은 질문을 받았었다. 가장 많은 질문은 해당 프로젝트를 왜 한 건지? 를 궁금해했다.  어떤 사이드 프로젝트든 하려고 하는 타당한 이유가 중요한 것 같다. 아무 이유 없이 이력서에 한 줄 더 추가하기 위한 프로젝트는 큰 의미가 없을 수 있다는 것이다.  내가 해당 프로젝트를 진행한 이유는 요즘 라이브러리들이 워낙 잘 구현되어 있어, 코드 몇 줄이면 쓸만한 머신러닝 모델을 구현할 수 있다. 그러나 정말 필요한 모델이 있는데, 구현된 라이브러리가 없다면 쓰지 못하게 될 것이다. 나는 그건 잘못되었다고 생각했고, 내가 원할 때 원하는 모델을 쓸 수 있도록 모델을 구현하는 역량을 기르기 위해 진행했던 것이 한-영 번역 모델 개발 프로젝트이다.  사이드 프로젝트나 공모전 같은 경우 본인이 의지를 가져야만 진행할 수 있는 것이기 때문에 꾸준히 해당 직무에서 역량을 강화하고 있는지 판단할 수 있는 근거가 된다고 생각한다. 그래서 나도 수상하진 못하더라도 공모전에 꾸준히 참가하려고 하고, 기회가 된다면 사이드 프로젝트도 진행하려고 한다.  실제로 공모전 같은 경우에는 공모전이 진행되는 시점에서 가장 최신의 기술과 모델들을 많이 활용하려고 하기 때문에 내가 관심 있는 기술의 트렌드를 파악하는 것에도 도움이 많이 된다.  노션으로 이력서 작성할 때 팁 이력서를 작성할때 나처럼 노션으로 많이 작성하는데, 보통 pdf파일로 변환하여 제출하는 경우가 많다. 그럴 때노션에서 바로 pdf로 내보내기 기능을 활용하는데, 아래처럼 크기 비율을 100%로 하는 것보다는 65~75% 정도가 적당하다.확대를 100%로 하면 너무 글자가 커서 한 페이지에 담기는 내용도 적고, 이력서가 조금 조잡해 보인다.(내 생각) 노션 - 내보내기 - pdf   포트폴리오 앞에서 잠깐 말했지만 포트폴리오에는 내가 이력서에 기입한 프로젝트에 대한 상세 설명이 주를 이룬다.예를 들어 유저 리뷰 분석을 통한 긍/부정 분류라는 프로젝트를 진행했다고 하자. 그럼 포트폴리오에는 아래 내용을 주로 적는다 해당 프로젝트 1줄 소개ex. 유저 리뷰 분석을 통한 긍/부정 분류 프로젝트는 유저의 리뷰를 분석해 상품에 대한 선호도를 평가하기 위해 진행한 프로젝트입니다.프로젝트 기간주요 사용 기술ex. 감성 분석, 텍스트 전처리, python, pytorch, NLP..수행 업무ex. 모델 학습을 위한 데이터 구축프로젝트 결과물프로젝트 결과물의 경우 실제 서비스 하고 있는 회사가 아니라면 첨부하기 어려울 수 있는데, 그런 경우에는 아래처럼 대략적인 형태를 그려서 프로젝트에 대한 이해도를 높이려고 하였다.예시  지원이력서와 포트폴리오 작성이 끝났다면 이제 지원을 해보자. 나는 주로 원티드, 프로그래머스에서 회사를 찾아보고 지원했고, 나중에는 사람인, 잡코리아에서도 검색을 해보았다. 다른 개발 포지션의 구직자들은 랠리에서 많이 구직을 하는 거 같았다.아래는 각 채용 플랫폼 별 특징을 간략히 정리해 보았다. 원티드모집 공고 개수 많음기존 작성한 이력서를 업로드하면 되는 형태대부분 모집 공고에 합격보상금 50만 원Wanted AI 합격예측이 있는데 사실상 무의미응답률 빠름 프로그래머스모집 공고 개수 보통이력서를 업로드하는 게 아니라 해당 플랫폼에 맞게 직접 작성해야 함깃허브 연동 및 자체 플랫폼 코딩테스트 결과 반영 가능응답률 보통프로그래머스 사이트 점핏모집 공고 개수 적음, 다만 원티드나 프로그래머스랑 잘 겹치지 않음.기존 작성한 이력서를 업로드하는 형태대부분 모집 공고에 합격보상금 70만 원응답률 느림점핏 사이트 사람인 & 잡코리아모집 공고 매우 많음기존 작성한 이력서를 업로드하면 되는 형태대부분 모집 공고에 합격 보상금 x응답률 빠름위 3개는 개발자를 위한 채용 플랫폼인 반면 사람인과 잡코리아는 모든 직군에 대한 채용 플랫폼  어쨌든 위에 기술한 채용플랫폼을 위주로 구직활동을 하였고, 구직활동을 하면서 잡플래닛과 블라인드를 자주 들락거렸다. 요즘 취준생들이 잡플래닛 평점을 많이 보는데, 내가 느낀 바로는 잡플래닛 평점은 아래처럼 해석할 수 있다. 2.3 이하 : 좋지 않음2.3 ~ 3.3 : 보통3.3 ~ 3.6 : 좋음3.7 ~ : 매우 좋음 그리고 보통의 회사들이 2.3과 3.3 사이에 있는데, 이 구간은 큰 차이가 없다는 것이 내 결론이다. 또한 요즘 잡플래닛 평점을 조작하는 회사들도 있다고 해서 100% 신뢰하지는 않지만 3.3이 넘어가는 회사는 일단 다닐만하다고 생각해도 될 것 같다.  그리고 나는 한 가지 더 확인하는 게 있는데, 기업의 매출정보나 실적, 부채 비율등을 확인해 본다.사실 요즘 워낙 불활이다보니, 내가 다니려고 하는 회사가 안정적인지는 꼭 확인할 필요가 있다고 생각한다.위 정보는 링크에서 확인할 수 있다.  여기까지 이력서와 포트폴리오 작성 그리고 구직 플랫폼에 대한 소개를 마무리하고 다음 글에서는 코딩테스트나 과제테스트에 관한 이야기를 해보려고 한다.    궁금한 내용은 댓글로 달아주시면 감사하겠습니다 : )  Reference이력서 템플릿 참고프로젝트 개요 참고window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//ariz1623.tistory.com/reaction';window.ReactionReqBody = {    entryId: 341}공유하기게시글 관리코딩의 숲 '기타 > 일상' 카테고리의 다른 글주어니 머신러닝 엔지니어의 이직기 (4)  (0)2023.12.24주니어 머신러닝 엔지니어의 이직기 (3)  (0)2023.12.23주니어 머신러닝 엔지니어의 이직기 (1)  (2)2023.09.24태그노션, 원티드, 이력서, 이직, 잡플래닛, 점핏, 포트폴리오, 프로그래머스기타/일상 관련 글주어니 머신러닝 엔지니어의 이직기 (4)2023.12.24주니어 머신러닝 엔지니어의 이직기 (3)2023.12.23주니어 머신러닝 엔지니어의 이직기 (1)2023.09.24글 더보기 0댓글을 달아 주세요비공개댓글을 남겨주세요TistoryWhaleSkin3.4"">댓글 등록loadedComments[341]=true;findFragmentAndHighlight(341);전체 카테고리 분류 전체보기 (317)  딥러닝 (39)  NLP (18)  Vision (10)  딥러닝 기초 (3)  LLM (8)  머신러닝 (27)  데이터 분석 (21)  토이프로젝트 (5)  코딩야학 (7)  데이터 분석 기초 (9)  파이썬 (47)  프로그래머스 (31)  백준 (14)  PyTorch (2)  MySQL (26)  c++ (128)  알고리즘 공부 (10)  프로그래머스 (21)  백준 (95)  SWEA (1)  기타 (24)  깃허브 (7)  AWS (7)  일상 (4) 블로그 인기글ROUGE 이해하기군집 평가 - 실루엣 분석평균이동(Mean Shift)Gemma 2 (9B & 27B) Evaluation  vs. Open/⋯transformer를 활용한 한-영 번역 모델(pytorch)Truncated SVD코딩야학 - 보스턴 집값 예측CNNDBSCAN데이콘 - 도배 하자 질의 응답 처리 후기최근 글최근 댓글최근 글[논문리뷰] How Does Quantization Affect Mult⋯ LLM의 다양한 SFT 기법: Full Fine-Tuning, PEFT ⋯ Supervised Fine-tuning: customizing LLMs Gemma 2 (9B & 27B) Evaluation  vs. Open/⋯ Pretraining LLMs 데이콘 - 도배 하자 질의 응답 처리 후기 주어니 머신러닝 엔지니어의 이직기 (4) 주니어 머신러닝 엔지니어의 이직기 (3) 주니어 머신러닝 엔지니어의 이직기 (2) Kaggle - LLM Science Exam 후기 1최근댓글ariz1623 02.21감사합니다 :)최준홍 01.31저는 1년차 주니어 개발자입니다!! 저도 님 처럼 얼른 이직해서 성공하고⋯get_time 2023포스팅 잘 보고 갑니다!get_time 2023좋은 글 잘 읽었습니다!!get_time 2023좋은 글 잘 읽었습니다!!ariz1623 2023https://aihub.or.kr/aihubdata/data/view.⋯영식 2022xlsx 파일이 어떤 형태로 되어있는지 알 수 있을까요?baundy 2022글 솜씨가 뛰어나시네요! 좋은 글 잘 보고 갑니다 다음에도 놀러올게요 :⋯baundy 2022글 솜씨가 뛰어나시네요! 좋은 글 잘 보고 갑니다 다음에도 놀러올게요 :⋯소마신군 2022안녕하세요. frm torchtext.legacy.data to Tab⋯태그#판다스#transformer#pytorch#파이썬#머신러닝#추천시스템#C++#python#크롤링#bert#텐서플로우#AWS#데이터 전처리#토이프로젝트#pandas#회귀분석#워드클라우드#회귀#백준#stable diffusion#사이킷런#데이터분석#코딩야학#Torch#프로그래머스#llm#딥러닝#군집화#차원축소#mysqlMORE전체 방문자오늘37어제59전체102,672Powered by Privatenote Copyright © 코딩의 숲 All rights reserved.TistoryWhaleSkin3.4/* 메뉴  */(function($) {function commonControl(){var sc = $(""#sidebar .c_cnt"");sc.length > 0 && sc.each(function() {$(this).html($(this).html().replace(/[()]/g, """"))});$(document).on('click', '.btn_topMenu', function(){if ($("".dropdown-content"").hasClass(""dropdown-content-toggle"")){$("".dropdown-content"").removeClass(""dropdown-content-toggle"");}else{$("".dropdown-content"").addClass(""dropdown-content-toggle"");}});$(document).on('click', '.btn_close' ,function(){$("".dropdown-content"").removeClass(""dropdown-content-toggle"");});/* 사이드바 탭 분류 */$(document).on('click', '#recent-tab li',function(){$(""#recent-tab > li"").removeClass(""active"");$(this).addClass(""active"");$("".tab-content .tab-pane"").removeClass(""active"");$($(this).attr(""id"")).addClass(""active"");});/* 복사 방지, 개발자 도구 방지 */$(document).keydown(function(event) {if (event.keyCode == 123) { // Prevent F12return false;} else if (event.ctrlKey && event.shiftKey && event.keyCode == 73) { // Prevent Ctrl+Shift+I        return false;} else if (event.ctrlKey &&(event.keyCode === 67 ||event.keyCode === 86 ||event.keyCode === 85 ||event.keyCode === 117)) {return false;}});}commonControl();})(jQuery);티스토리툴바hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""3433294-341"",""customProps"":{""userId"":""0"",""blogId"":""3433294"",""entryId"":""341"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""341"",""entryTitle"":""주니어 머신러닝 엔지니어의 이직기 (2)"",""entryType"":""POST"",""categoryName"":""기타/일상"",""categoryId"":""1076617"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""4082707"",""authorNickname"":""ariz1623"",""blogNmae"":""코딩의 숲"",""image"":""kage@oPdIr/btsCzGXzFBB/eoab3bNboAymoPqEf8lfXk"",""plink"":""/341"",""tags"":[""노션"",""원티드"",""이력서"",""이직"",""잡플래닛"",""점핏"",""포트폴리오"",""프로그래머스""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
9,https://lifeofdori.tistory.com/14,데이터 분석가 면접 질문 리스트 정리,"본문 바로가기도리의 블로그카테고리검색하기검색하기블로그 내 검색도리의 블로그도리 DoRi 분류 전체보기 (34)  후기 (10)  정보 (19)  데이터 과학 (5) GuestbookNoticeRecent Posts해외백신 접종자 7월 1일부터 국내 입국시 자가격⋯토플 시험 전 날 반드시 알아야 할 것!! (토플⋯헬로톡(HelloTalk) 친구와 6개월 간 연락⋯턱관절 통증 예방을 위해 일상생활에서 지켜야 할 ⋯Recent Comments감사합니다 :)후기 감사합니다~ 덕분에 편하게 작업했습니다^^!도움이 되었다니 기쁘네요 ^^ 큰 도움 됐어요 감사합니다.Link«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags호텔연남장데이터분석강의외국인친구헬로톡친구맥북이중눌림토플사이트개구장애무료강의토플결제헬로톡후기데이터분석해외백신접종자토플무료모의고사헬로톡토플토플시험전날자가격리면제해외백신은둔형외톨이취업커리어계발여성1인점포토플점수캔슬안심홈세트서울시여성해피캠퍼스부수입정원분식턱관절장애쯔양턱관절통증미국백신접종자moreArchives2021/06                                  (4)2021/05                                  (16)2021/04                                  (1)2021/03                                  (4)2021/02                                  (3)Today13Total52,820닫기관리 메뉴글쓰기방명록RSS관리도리의 블로그데이터 분석가 면접 질문 리스트 정리 본문데이터 과학데이터 분석가 면접 질문 리스트 정리도리 DoRi        2021. 3. 20. 21:02                   (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }   데이터 분석가 직무에서 나올 수 있는 면접 질문을 다룬 포스트들을 정리해보았습니다.데이터 분석 직무 특성 상 기술적인 질문을 받을 수 있는데, 어디서 부터 준비를 해야 할 지 막막하기도 하더라구요.구글링으로 다양한 소스들을 찾아 준비를 했었는데, 제가 도움을 받은 포스팅 링크를 정리하여 공유합니다. 부디 많은 분들에게 도움이 되길 바랍니다 :)    1. 데이터 분석 관련 개념들을 정리한 포스팅머신러닝과 관련된 개념들을 한 번 간단히 정리하고 싶을 때 유용한 포스팅입니다.stellarway.tistory.com/8 데이터 관련 직무 면접 대비용 개념 한 줄 정리※무단 사용 및 펌을 절대 금지합니다 이 페이지에서만 봐주세요※ 하나 하나 손으로 기입한 것이어서 잘못된 내용이나 오타가 있을 수 있습니다 댓글로 제보해주세요 분야 용어 용어 풀이 머stellarway.tistory.com   2. 데이터 사이언티스트 면접 시 받은 질문들과 면접 대비용으로 공부할 수 있는 소스 포함실제 데이터 사이언티스트 면접을 준비하고, 보신 분의 후기글입니다.sql, python 등을 공부하신 소스 링크도 포함되어 있어 유용합니다. new-blue.tistory.com/9 3. '30일 만에 데이터 사이언티스트 되기' 성공?! - 데이터 사이언티스트 면접 후기'360시간 만에 개발자 되기 프로젝트'의 세번째 글- '30일 만에 데이터 사이언티스트 되기' 성공?! - 데이터 사이언티스트 면접 후기입니다. '개발자 구직 과정'에 익숙하지 않은 분이시면 0. 개발자new-blue.tistory.com   3. 데이터 분석가 / 데이터 사이언티스트 / 데이터 엔지니어 직무에서 나올 수 있는 질문 정리아마 가장 유명한 질문 리스트일 것 같습니다 :)다만 질문은 있으나 답은 없다는 것!하지만 중요한 질문들이 많아서 한 번 볼 필요가 있을 것 같습니다. zzsza.github.io/data/2018/02/17/datascience-interivew-questions/#contents 데이터 사이언스 인터뷰 질문 모음집데이터 사이언스 분야의 인터뷰 질문을 모아봤습니다. (데이터 분석가 / 데이터 사이언티스트 / 데이터 엔지니어) 구직자에겐 예상 질문을 통해 면접 합격을 할 수 있도록, 면접관에겐 좋은 면접zzsza.github.io   4. 통계 개념을 정리한 포스팅이 포스팅은 머신러닝 보다는 전통적인 통계에 대한 내용에 대한 포스팅입니다.p-value, 우도 등 통계학 기본 개념을 다루고 있습니다. shelling203.tistory.com/35 통계 관련 기술면접 대비1. 베이지안은 무엇인가요? : 실제로 관측된 데이터를 사용하여 확률 분포를 고려합니다. 2. 빈도주의자는 무엇인가요? : 선택의 가설을 조건으로 하며 관찰 여부에 관계없이(표본에 대한) 경험적shelling203.tistory.com   5. 자주 묻는 머신러닝 인터뷰 질문 및 답변 50선머신러닝에 대한 질문을 다루고 있습니다.다만 번역본이어서 문장이 약간 어색합니다. 머신러닝에 대한 기본적인 지식을 다루는 질문이니, 자신만의 언어로 답변을 정리하면 도움이 될 것 입니다!insightcampus.co.kr/insightcommunity/?mod=document&uid=12897 https://insightcampus.co.kr/insightcommunity/?mod=document&uid=12897 insightcampus.co.kr   6. Top 50 Frequently asked machine learning interview questions and answers머신러닝에 관한 인터뷰 질문 50개가 있습니다. 하지만 모두 영어로 쓰여있습니다 ㅎㅎ설명에 그림들이 첨부가 되어 있어서, 차분히 읽으면 이해할 수 있을 것입니다 :)www.ubuntupit.com/frequently-asked-machine-learning-interview-questions-and-answers/ Top 50 Frequently Asked Machine Learning Interview Questions and AnswersThis article is about frequently asked machine learning interview questions and answers. It helps you to prepare yourself for your upcoming interview.www.ubuntupit.com   이렇게 제가 찾은 유용한 포스팅들을 정리해보았습니다. 여기 있는 자료만 잘 숙지해도, 답변하지 못할 질문이 없을 것 같습니다 :) 그럼 모두 인터뷰 준비 잘 하시기 바랍니다!!! window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//lifeofdori.tistory.com/reaction';window.ReactionReqBody = {    entryId: 14}공유하기게시글 관리도리의 블로그 '데이터 과학' 카테고리의 다른 글[도서] 이것이 데이터 분석이다 with 파이썬  (0)2021.05.04[파이썬] csv 파일 한글 깨질 때 인코딩 설정  (0)2021.04.09[도서] 혼자 공부하는 첫 프로그래밍 with 파이썬  (0)2021.03.31[도서] 머신러닝을 위한 실전 데이터셋  (0)2021.02.20Tag데이터분석가, 데이터분석면접, 데이터분석면접질문, 데이터분석직무면접, 데이터분석직무인터뷰, 데이터사이언티스트, 데이터사이언티스트면접질문'데이터 과학' Related Articles[도서] 이것이 데이터 분석이다 with 파이썬2021.05.04[파이썬] csv 파일 한글 깨질 때 인코딩 설정2021.04.09[도서] 혼자 공부하는 첫 프로그래밍 with 파이썬2021.03.31[도서] 머신러닝을 위한 실전 데이터셋2021.02.20moreloadedComments[14]=true;findFragmentAndHighlight(14);          Blog is powered by          kakao / Designed by          Tistory티스토리툴바document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4448333-14"",""customProps"":{""userId"":""0"",""blogId"":""4448333"",""entryId"":""14"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""14"",""entryTitle"":""데이터 분석가 면접 질문 리스트 정리"",""entryType"":""POST"",""categoryName"":""데이터 과학"",""categoryId"":""986739"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4731955"",""authorNickname"":""도리 DoRi"",""blogNmae"":""도리의 블로그"",""image"":"""",""plink"":""/14"",""tags"":[""데이터분석가"",""데이터분석면접"",""데이터분석면접질문"",""데이터분석직무면접"",""데이터분석직무인터뷰"",""데이터사이언티스트"",""데이터사이언티스트면접질문""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
10,https://acdongpgm.tistory.com/225,블로그 메뉴,"728x90(adsbygoogle = window.adsbygoogle || []).push({});나는 광주에서 3개월 동안 머신러닝 개발자로 근무했고 7월 9일 퇴사했다. 7월 9일(퇴사일)부터 8월 26일(최종 합격일)까지의 내용을 기록해보고자 한다.먼저 퇴사하고 느낀 점을 말해보면 처음 구직할때는 ""제발 일만 시켜주십시오 뭐든지 하면 열심히 하겠습니다."" 이런 마인드였다.그리고 일을 시켜준다니까 전라도 광주까지 가서 근무했다. ( 지금 생각해보면 진짜 미친놈인가?.. )이 마인드가 처음엔 좋게 작용했지만 이게 전부가 아니라는 것을 깨달았다. 이 회사가 내 커리어 혹은 내 최종 목표에 있어서 도움이 되는 회사인가.같이 일하는 동료들이 진취적이고 열정이 있는가신입이기 때문에 배울 수 있는 상사(중간급)가 존재하는가경영자가 인공지능 및 4차 산업혁명에 대한 이해도가 높은가이런 부분을 짧은 기간(3개월)이었지만 크게 느꼈고물론 뽑는 입장인 회사가 결정권을 쥐고 있는 건 사실이지만나도 이런 부분들을 경험하고서 이직 준비를 할 때 고려하기 시작했다.  *거짓말이라고 생각할 수 있지만 연봉은 크게 중요하지 않았다.일만 잘하면 돈은 자연스럽게 따라온다고 생각함 + 신입이 무슨 높은 연봉을 바라냐 이런 생각?이력서 및 서류 전형7월 12일 이력서를 업데이트했고,내가 기존에 관심이 많았던 추천 시스템 개발자로 지원을 했다 3군데 정도?3군데 전부 기업에 맞는 이력서를 작성했다. (시간이 많이 소요됨)이게 정성이라고 생각했고 회사에 대한 관심을 어필했다.하지만 내 이력서는 어떤 기업에서도 선택받지 못했다.(회사에 대한 관심이 억지성이 많았음 ㅋㅋ)그리고 이력서 쓰는 게 너무 지쳐버렸다. 맞춤형 이력서 3개 작성 그러던 도중 나와 비슷한 시기에 퇴사했던 선임 형이 있었는데그 형은 퇴사하자마자 더 좋은 조건으로 이직했다고 했다.그래서 그 형을 붙잡고 이력서 첨삭을 부탁했다.형은 흔쾌히 수락했고 좋은 말만 하려고 하는 형의 성격을 알기에 쓴소리만 해달라고 부탁했다. 진짜 쓴소리만 해주시더라 덜 아프게 ㅎㅎ문제점을 요약하면 경력기술서가 너무 빈약하다는 것과 이력서 제목과 자기소개서가 이목을 끌기 부족하다는 것이었다.형의 이력서 제목을 보니까 ""금고의 골드바 하나 넣어두시기 바랍니다"" 이거였다.. 충격이었다.자신이 골드바라고 칭하면서 자신감을 어필했고골드를 녹여서 어떤 물건도 만들 수 있다는 특성으로 모든 일이든 빠르게 녹아들어 열심히 하겠다는 열정을 어필했다.심지어 재밌기까지 눈길이 확 당기는 이력서다. 나 같아도 뽑았을 거 같다. 그리고 경력기술서를 프로젝트별로 개조식으로 정리하라고 했다.  - 담당 역할 - 기술 스택 - 기간 - 개발 인원 - 상세 내용 그래서 난 경력기술서 형식을 형과 똑같이 작성했다.경력기술서가 전보다 훨씬 깔끔해졌고 내용도 풍부해졌다. 그리고 눈에 띄게 이력서 제목과 자기소개서 제목을 바꾸었다. 이전 이력서 제목 : 신입 머신러닝 개발자 이력서수정 이력서 제목 : 인공지능처럼 반복(Epoch)으로 다져진 신입 AI 개발자입니다. * Epoch 은 인공지능 학습시킬 때 사용하는 반복 횟수 파라미터이다.나는 반복 학습할수록 정확도가 높아지는 인공지능을 빗대어 자소서 제목을 수정했다. 이전 자기소개서 제목 : ""여러 교육과정을 통한 높은 숙련도""수정 자기소개서 제목 : ""짝퉁 말고 여러 기관에서 인증받은 정품 쓰시길 바랍니다.""나는 3개의 교육과정과 2개의 인턴과정을 거친 경험을 어필했다.이 5가지 과정 모두 서류와 면접을 통해 선발되었고 그 걸 전부 통과했으니 난 보증된 상품(정품)이라는 인식을 심어주었다. 그리고 각각의 기업의 이력서를 따로 쓰지 않고 이렇게 공통 자소서를 작성했다.지원하기 훨씬 편해짐. 무지성 지원 시작!!대략 한 20군데 이상 지원한 것 같다. ㅋㅋ 좋은 기업 구별하는 법나는 형(은인)에게서 좋은 기업을 고르는 방법에 대해서도 알 수 있었다.물론 실제 일을 해보는 것이 가장 확실하지만 대략적으로 기업에 대해서 알 수 있는 방법들. 기업의 매출을 확인한다. ( 돈을 잘 버는 기업인가 + 내 월급 밀리지 않게 주는 곳인가 )기업의 퇴사율을 확인한다. ( 퇴사율이 높다는 건 그만한 이유가 있다는 것 )기업의 리뷰를 확인한다. ( 퇴사자들의 리뷰를 보고 대략적으로 알 수 있다.) * 하지만 퇴사자라는 것을 고려하여 봐야 한다 분노 섞인 글이 너무 많더라 ㅋㅋ 두 가지 웹사이트를 통해 위 사실들을 확인할 수 있다.크레딧 잡 , 잡플래닛 ( 사용방법은 생략 ) 면접기억나는 면접 스토리 (1). 전화 하소연먼저 자소서를 수정하고 나서 지원한지 이틀 만에 ( 금요일에 지원했는데 월요일도 아닌 일요일에 전화가 옴 )면접 전화를 받았다. 하지만 그땐 아직 광주에 터를 잡고 있었던 터라 서울에서 면접을 보고다시 광주로 내려와 이사를 해야 하는 상황이어서 면접은 보지 않았다.사실 리뷰와 퇴사율도 한 몫했다. 리뷰가 좋았다면 이사 전에 면접을 보러 갔을지도 모른다.그리고 결정적으로 면접 참여 전화를 하면서 여러 가지 대화를 했는데사람들이 자꾸 도망가서 힘들다고 하셨다 ㅋㅋ (2). 우리 인공지능 기업이야이곳은 특별하게도 지원한 곳이 아닌 나에게 포지션 제안을 해준 곳이다. 전화통화로 대표님께서 면접을 봐달라고 하셨다.업무 자동화를 주로 하는 회사이고 로봇을 개발하고 로봇 안에 필요한 인공지능을 개발할 사람이 필요하다고 하셨다.그래서 관심이 있다고 하니까 그럼 교육을 들어야 한다고 하셨다. 그래서 교육을 위해 회사에 방문했다.그런데 엥? 교육하시는 분이 사무자동화 툴에 대한 교육을 해주는 것이 아닌가.. 엑셀 함수 강의 등등 그래서 여쭤보았다. 혹시이거 할 사람 뽑으시는 거냐고, 그렇다고 한다. 그럼 인공지능을 하시냐 물었더니 챗봇을 개발했다고 했다.혹시 그게 머신러닝으로 하신 거냐고 물어보니까 머신러닝을 아예 모르시더라. 예상하건대 룰 기반으로 제작된 챗봇인 거 같다.요즘 자동으로 뭔가 되면 인공지능이라고 광고하는 회사가 많다고 들었는데 진짜 내가 당할 줄은 몰랐다.교육담당자님께 잘 설명하고 ""제가 생각한 인공지능과 많이 다른 것 같아요"" 하고 바로 나왔다.담당자님도 뻘쭘해하셔서 인사드리고 바로 나왔다. (3). 다른 곳 면접 안 보면 안돼요?이곳은 면접을 비대면(Zoom)으로 보았다. 직무 자체가 추천 시스템 개발자를 뽑는 기업이라 관심이 갔고 위치도 영등포라 괜찮다고 생각했다. 리뷰를 보기 전까지.. 리뷰가 작살이 나있더라 경영진에 대한 불만, SI 기업인 만큼 업무 집중도가 많이 떨어지고 개발자가 제안서를 쓰느라 밤을 새우는 등 퇴사율도 높았다. 그래도 면접은 보기로 했고 비대면이라 편한 마음으로 진행했다. 추천 시스템 관련 질문을 많이 하셨고 추천 시스템에 관심이 있던 터라 대답을 잘했다. 근데 부사장? 님 께서 기술면접 중간에 계속 끼어드셨는데 업무와 관련 없는 질문을 계속하셨다. 고등학교는 왜 기재하지 않았냐, 대학교 성적은 왜 기제 안했냐 성적이 낮아서 기제안했냐 등등, 그래서 기술 면접에 집중할 수 없었고 기술 질문을 하시는 분도 제지하지 못하고 가만히 있더라, 이런 것들이 리뷰와 맞아떨어지고(경영자 한마디에 하루아침에 프로젝트를 갈아엎는다)등 여러 가지 안 좋은 부분이 계속 보여서 마무리를 하려고 했고 다른 곳도 면접 일정이 있어서 준비해야 한다고 하니까 갑자기 우리 회사 어떻냐고 물으셨고 대놓고 싫다고 할 수 없어서 좋은 것 같다고 대답하니까 그럼 다른 곳 면접 보지 말라고 하셨다. ㅋㅋ그 뒤 합격통보를 하셨을 때 고심 끝에 다른 곳으로 결정했다고 하니까 읽씹 하셨다 ㅋㅋ (4). 하.. 면접하기 싫어~이곳은 스타트업이라 채용공고에서 열정이 느껴져서 지원하게 되었다. 그래서 방문을 했지만 놀란 게 회사 구조가 가정집 구조로 되어있었다. 신기했다 진짜 스타트업 느낌이 들어 좋았다. 하지만 면접 보는 게 힘들었다. 그냥 계속 질문만 하시고 이력서도 면접 보는 도중에 읽어보시더라 내 깃허브는 당연히 봤을 리가 없겠지.. 내 블로그도 안 봤겠지 질문도 컴퓨터 공학 질문만 하시고 인공지능 질문은 거의 하지 않았다. 개인적인 질문이 없고 그냥 면접에 틀을 정해놓고 그 틀대로만 진행했다.그러고 물론 아침 10시 30분 이긴 했지만 계속 하품하시고 그래도 성의껏 답변했지만 내가 맘에 안 드셨나 보다 뭐 그럴 수 있지2시간을 걸쳐서 도착했지만 30분도 안돼서 끝이 났다. 결과는 불합격 하지만 위 면접들이 결과적으로는 도움이 안 된 것은 아니다.위 면접에서 대답하지 못한 부분은 따로 기억해두었다가 공부했고 이후 면접에 좋은 영향을 미쳤다. AI 기술면접 질문 모아놓은 곳https://github.com/zzsza/Datascience-Interview-Questions입사한 회사의 면접서류 합격이곳은 특별하게 잡코리아로 지원하지 않고 원티드라는 플랫폼을 통해서 지원했다. 구직활동하면서 느낀 건데 개발자라면 사람인 잡코리아로 구직하는 것보다 원티드로 하는 것이 훨씬 좋다고 생각한다. 회사 소개가 풍부하고 내용이 구체적이다. 이력서는 동일하게 지원했고 서류 합격 소식을 AI 팀장님께 받았다. 그리고 3가지 링크를 주셨는 데 앞으로 개발하려고 하는 챗봇에 관련한 링크를 주셨고 간단하게 읽어보고 오라고 하셨다. 이전 기업들과 달랐다 숙제를 내주시다니ㅠㅠ 나는 관련 자료들을 살펴보았고 신기하게도 면접 질문 대비를 위해 시작한 공부가 챗봇 개발의 흥미를 느끼게 해주었다. 그래서 숙제를 하면서 챗봇에 관심이 커졌던 건 사실이다. + 잡플래닛 퇴사자들의 리뷰도 너무 좋았다.  1차 면접회사는 강남에 위치하고 있었고 불안한 성격 탓에 40분이나 일찍 도착해버렸다.내가 가장 원했던 회사인지라 시작 전에 긴장이 너무 많이 되었다. 리더님과 1:1 면접을 진행했는 데 ""아이패드 쓰시네요?""등 일상적인 질문들을 시작 전에 계속해주셔서 긴장이 많이 풀렸다. 그리고 우리 대학교 기획교수님과 대학 동기 시더라 그래서 교수님 이야기로 긴장이 더 풀렸다.( 교수님 감사합니다 ㅠㅠ ) 면접은 그 전 기업들과 다르게 질문과 대답 형식이 아닌 자연스러운 대화 형식으로 진행되었다. 준비한 게 튀어나오는 것이 아닌 정말 자연스럽게 대답이 튀어나왔다. 대답을 자연스럽게 이끌어 주시는 능력이 있으신 것 같다. 그래서 대답도 나름 잘했던 것 같다. 그리고 내가 생각하기에 가장 직무에 필요한 기술 질문을 많이 하셨고 깊이 있는 질문도 많았다. 그중 대답을 못했던 경우도 있었는데 대답을 못하니까 이해할 수 있도록 다시 설명해주셨다. 면접 와서 개념을 다시 배우게 되는 기이한 현상 그리고 같이 식사하면서 좋은 말씀을 많이 해주셨다.합격을 크게 기대하진 않았지만 면접 경험이 너무나도 좋았다. 함께 일하고 싶었다. 2차 면접사실 2차 면접이 있다는 말은 듣지 못했는데 2차 면접이 있을 거라고 하셔서 1차 면접 합격 소식을 뒤로한 채 부랴부랴 준비를 했고기술 면접을 보았으니 2차는 인성면접을 볼 것이라고 예상했다. ( 인성면접 준비를 많이 함 , 성격의 장단점 등등 ㅋㅋ )다른 기업 최종면접에 이미 합격해서 긴장이 덜 될 줄 알았지만내가 다니고 싶은 , 내가 정말 원하는 기업이라고 생각해서 인지 긴장이 멈추지 않았다.2차는 비대면으로 진행했는데 의외로 인성면접이 아니라 포부를 듣는 질문들이 많아서 평소 실력으로 자신 있게 대답했다.인사팀장님이 면접을 진행하셨는데 열정과 스타트업 정신 그리고 장기근속 가능 여부를 확인하는 면접이었던 것 같다. 인사팀장님 입에서 ""좋아요"" , ""좋네요""라는 말이 자주 나와서 기분이 좋았다. 최종 합격최종 합격을 했고 이전에 합격한 기업보다 연봉이 조금 작았지만 나에겐 큰 문제가 되진 않았다.이직 성공!! 구직활동 합산 결과 총 지원한 기업 수 ( 서울 지역 중심 ) 25 곳(원티드 5곳 , 잡코리아 20곳)응답 없음 13곳 서류 합격8곳서류 탈락4곳면접 참여6곳(전화면접 1회 , 비대면 1회)면접 불참2곳(사전 합격 1회, 리뷰보고 1회)최종 합격3곳 느낀 점(1). 면접 실력은 많이 볼 수록 는다. 겹치는 질문 많음 + 요령이 생김(2). 면접 과정이 까다로울수록 좋은 기업이다.(3). 기업 리뷰를 확인하는 것도 좋지만 100% 신뢰하진 말자.. 참고만 : 리뷰가 안 좋았던 곳에 면접을 봤었는 데 리뷰와 다르게 정말 좋았다.(퇴사자가 원한을 품은 경우도 있음)(4). 급하게 취업해서 빨리 관두는 것보다 좀 느리더라도 오래 다닐 기업에 취업하는 게 좋다.(5). 멀티플레이어를 원하는 곳이 많다.(SI 기업들이 대부분 멀티플레이어를 원함 , 이미지 , 자연어 )(6). 하고 싶은 일을 하는 것 보다 같이 하고싶은 사람이랑 일하는 게 훨씬 좋다.(7). 공고가 너무 장기간 올라온 곳은 걸러라.(사람 뽑아도 공고를 내리지 않는다. 금방 관두니까)반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//acdongpgm.tistory.com/reaction';window.ReactionReqBody = {    entryId: 225}공유하기게시글 관리Learn by doing 저작자표시 비영리 'Self-improvement' 카테고리의 다른 글[Event]. Langcon 2023 참가후기.  (0)2023.02.25[졸업]. 했습니다  (5)2023.02.21[일]. 질문 잘하기  (1)2022.03.14[탈락] 복기  (10)2021.02.14[일상] 자위행위를 안하면 어떻게 될까? ( Nofap , 금욕 , 금딸 , 금란물 )  (3)2020.06.08"
11,https://dipndeep.tistory.com/m/15,머신러닝 엔지니어 기술면접 후기,"카테고리 없음머신러닝 엔지니어 기술면접 후기DeepinDev 2021. 7. 27. 18:31 머신러닝 응용 엔지니어 포지션으로 지원한 원티드랩과의 기술 면접이 있었다. 내가 잘 아는 것이 나왔다면 좋았겠지만 반은 그렇고 반은 그렇지 못했다. 면접에서 내가 스스로 만족했던 부분과 그렇지 못했던 부분을 정리하며 이 포스팅을 마치고자 한다. 1. 내가 좋아하는게 뭔지 확실히 전달하였다. 커리어를 포함해서 나는 어떤 방향으로 성장하고 싶은지에 대해 물어봐주셨고, 내가 가진 목표나 지향점을 확실하게 어필할 수 있었다. 개인적으로 리서치를 하는 연구원보다는 머신러닝을 전반적으로 서비스 하는 경험을 높게 보는데, 이런 점을 충분히 키워나갈 수 있는 곳에서 일하고 싶다는 의지를 표현했다.  개인적으로 프론트엔드를 좋아한다는 말도 덧붙였다. 왜냐하면 웹서비스에서 중요한 부분은 여러가지가 있지만 프론트엔드에서 대부분의 요청을 처리하고 이를 통해서 Rest API를 설계하는 방향도 있기 때문에, 그리고 개발을 시작하고 프로젝트를 완성한 경험이 Javascript를 활용한 것이었기 때문에, 그렇게 이야기 한것 같다.  2. 자연어 처리에 있어서 딥러닝에 대한 이해도가 부족하였다. 과제의 문제를 해결한 방법에서 내가 활용하지 않은 부분이 딥러닝 모델이었다. 그 이유는 데이터가 충분하지 않았고 ( 반대로 적은 데이터에서 머신러닝 모델이 유효하다고 생각하였다. ) 이런 부분을 단적으로 해결할 방법이 마땅치 않았기 때문이었다. 면접에서는 개선을 위한 방법으로 딥러닝을 활용한다고 하였는데, 충분히 고민하고 알지 못하는 상황에서 딥러닝 모델을 활용한다고 하였기 때문에 충분히 이해가 되는 답변을 내놓지 못했다.  딥러닝 자연어처리에서 Transformer는 어떤건지, RNN은 어떤건지, Attention 메커니즘은 어떤건지 에 대한 답변을 정확하게 못했다. 지금 열려있는 Edwith 강의를 충분히 활용하고 실습하면서 내가 이해하는 자연어처리를 발전시켜나가는 것이 이 면접에서 얻을 수 있는 것이라고 생각된다. 이 면접이 앞으로 다가올 면접들에 대해 충분히 생각하며 발전할 수 있는 기회가 되길! "
12,https://jpub.tistory.com/1053,태그,"출간 전 책 소식인공지능 전문가를 위한 인터뷰(면접) 가이드 제이펍2020. 6. 18. 14:16혹시 Hulu(훌루)를 들어보신 적이 있나요? 넷플릭스처럼 OTT 서비스를 제공하는 스트리밍 기업인데요. 월트 디즈니 컴퍼니, 워너미디어 등 4개 회사의 합작으로 설립하였는데, 지금은 인수 합병 등을 통해 월트 디즈니의 자회사가 되었습니다. 아직은 미국과 일본에서만 서비스하고 있어서 우리에겐 낯선 이름입니다만, 두 곳에서만 3천만 이상의 유료 회원 가입자를 확보하였고, 2021년부터는 전 세계를 대상으로 서비스를 준비 중이라니 우리도 곧 Hulu만의 재미난 콘텐츠를 만나볼 수 있을 것 같습니다. Hulu를 먼저 소개한 이유는 오늘 소개할 책이 이 Hulu의 데이터 과학팀 소속 15명의 엔지니어가 만든 책이기 때문입니다. 칭화대와 스토니브룩대, 스탠퍼드대에서 공부하고 현재 Hulu 글로벌 연구소 부사장이자 중국 연구센터의 센터장으로 있는 주거웨(Zhuge Yue)의 주도하에 14명의 인공지능, 머신러닝 전문가들이 모여 아름다운(?) 결과물을 만들었는데요. 바로, 《데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집》(부제: 100개 이상의 실전 면접 문제로 배우는 머신러닝, 딥러닝, 강화학습 알고리즘)입니다. 넣고 싶은 키워드가 많다 보니 제목이 좀 길어졌습니다. ㅎㅎ 중국어 제목은 《百面机器学习: 算法工程师带你去面试》인데, 우리말로 옮기자면 '100가지의 머신러닝: 알고리즘 엔지니어가 안내하는 인터뷰 가이드' 정도가 될까요?《데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집》이 15명의 전문가는 먼저 인공지능, 머신러닝, 데이터 과학자 인터뷰 시에 면접 문제로 나올 만한 질문을 주제별, 난이도별로 선별하였습니다. 그리고 자신의 전공에 맞는 주제를 고르고, 실생활 예제를 통한 모범 해답을 찾기 위해 밤마다 머리를 싸매며 토론을 거쳐 책을 완성했다고 합니다. 이렇게 완성된 문제들은 실제 Hulu 면접자들에게도 출제되었다고 하네요. 15인의 집필 에필로그는 아래 PDF 파일에 모두 담겨 있으니 살펴보시기 바랍니다. 그것만으로도 동기 부여가 되지 않을까 싶습니다. 데이터과학자와데이터엔지니어를위한인터뷰문답집_에필로그.pdf이 책은 독자의 필요에 따라, 그리고 역량에 따라 주제와 난이도별로 선택해서 읽을 수 있도록 구성되었습니다. 피처 엔지니어링(특성 공학), 모델 평가, 클래식 알고리즘, 차원축소, 비지도학습, 확률 그래프 모델, 최적화 알고리즘, 샘플링, 피드 포워드 신경망, 순환신경망, 강화학습, 앙상블 학습, GANs, 인공지능 응용 등 총 14개의 챕터에 100개가 넘는 질문과 답변으로 구성되어 있어서 자신의 AI 지식을 검증하기에 충분할 것입니다. 이번 책도 국내 최초의 중국 인공지능 번역서인 《단단한 머신러닝》을 번역한 김태헌 님이 맡아주셨습니다. 베타리더들 모두로부터도 좋은 평을 받을 만큼 번역을 잘 해주셨고, 데이터 과학자로서의 경험을 살려 본문 곳곳에 다양한 역주를 포함해 주셨는데, 국내 독자들이 책을 이해하는 데 많은 도움이 될 것 같습니다. 관심 있는 분들은 아래 샘플 PDF 파일을 참고해 주시고, 저희는 출간 후에 다시 인사드리겠습니다. ■ 샘플 PDF(차례, 추천사, 머리말, 옮긴이 머리말, 프롤로그, 베타리더 후기, 1_2 '범주형 피처', 1_7 '이미지 데이터가 부족할 때는 어떻게 처리해야 할까요?', 2_1 '평가 지표의 한계', 2_2 'ROC 곡선', 2_3 '코사인 거리의 응용', 2_7 '과적합과 과소적합, 5_4 '클러스터링 알고리즘 평가'', 9_2 '딥러닝의 활성화 함수', 12_4 '편향과 분산', 12_6 'XGBoost와 GBDT의 차이점, 그리고 연관성')데이터과학자와데이터엔지니어를위한인터뷰문답집_sample.pdf■ 예약구매 사이트(가나다순)(연결이 되지 않는 곳을 등록되는 대로 링크를 걸어 드리겠스빈다)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]■ 제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)네이버 책  포스트  유튜브  인스타그램  트위터  페이스북   window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1053}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기저작자표시 '출간 전 책 소식' 카테고리의 다른 글'객체지향'의 근원적 개념을 탐구해 볼까요?  (2)2020.06.25블록체인 기반의 신원 인증 기술, SIS와 DID  (2)2020.06.22119가지의 키워드를 중심으로 살펴보는 정보보안의 핵심!  (13)2020.06.13일 잘하는 직장인 따로 있나? 있습니다!  (0)2020.05.29화창한 봄날엔 역시 '스프링' 인 액션이죠!  (8)2020.05.06태그GANs, nlp, 강화학습, 기계학습, 김태헌, 데이터과학자, 데이터사이언티스트, 데이터엔지니어, 딥러닝, 랜덤포레스트, 로지스틱회귀, 머신러닝, 모델평가, 심층학습, 인공지능, 자연어처리, 적대적생성신경망, 제이펍, 중국책, 추천시스템, 특성공학, 피처엔지니어링'출간 전 책 소식' Related Articles'객체지향'의 근원적 개념을 탐구해 볼까요?블록체인 기반의 신원 인증 기술, SIS와 DID119가지의 키워드를 중심으로 살펴보는 정보보안의 핵심!일 잘하는 직장인 따로 있나? 있습니다!    setInitialEntryComments(1053, 1723621197)Secret댓글달기loadedComments[1053]=true;findFragmentAndHighlight(1053);"
13,https://programming119.tistory.com/217,---,"컴퓨터 지식/서평(독후감)[도서리뷰📖]머신 러닝을 다루는 기술 with 파이썬, 사이킷런 ✨by 서상혁2021. 1. 10.별점 : ★★★★☆출처 : http://www.yes24.com/Product/goods/90706572?art_bl=13613104  '딱딱함은 질색, 코드로 익히면서 배우는 개념'  저는 블로그 내용을 봐도 알 수 있듯이, 머신러닝에 대한 견문이 전혀 없는 상태에서 이 책을 접하게 되었습니다. 학부 수업에서 들었던 머신러닝에 대한 복잡한 수식과 머신러닝 특유의 '학습'이라는 낯선 개념들은 거부감을 엄청 주었고, 자연스레 멀리하게 되었습니다. 그런데 이번에 좋은 기회로 카카오 추천팀에서 일하게 되었습니다. 당연히 웹 쪽만 주구장창 공부했고, 머신러닝, 데이터 처리에 대한 사전지식이라고는 학부 수업때 꼴랑 한두번 해본게 다였던 저는, 발등에 불이 떨어지는 심정으로 이것저것 알아보기 시작했습니다. 그 첫 번째 시도가 이 책이었죠! 그런데 저는 이 책이 딱 저같은 부류의 사람들과 잘 맞는 책이라는 것을 단번에 느꼈습니다. 그 이유가 어떤 것인지 하나하나 살펴보죠.    첫째, 이 책은 머신러닝을 파이썬으로 구현하고 있지만, 파이썬 문법이나 언어 특성에 대한 내용은 거의 다루지 않는다는 점입니다. 사람마다 장단점으로 작용할 수 있겠지만, 저는 이 부분에 대해서 매우 좋게 느꼈습니다. '파이썬' 이라는 언어에 집중하는 것 보다, 머신러닝을 구현할 때 파이썬이 활용하는 라이브러리들에 대한 정보에 집중해, 보다 많은 내용을 담을 수 있었던 것이죠. 그리고 개인적으로 파이썬 문법에 대한 내용들은 책이나 블로그, 인터넷 등에서 무수히 많은 정보들이 있고 찾아보면 다 나오니, 이런 책에 담기는 것은 낭비라고 생각합니다.    둘째, 선 개념, 후 실습의 비율이 매우 적절합니다. 이 책을 펼쳐보면, 코드 example 이 없는 페이지를 찾기 힘들 정도로 많은 예제들이 들어 있습니다. 그래서 얼핏 보면 그냥 실습이나 코드 적용에 거의 몰두한 책이 아닌가 싶은 생각이 듭니다. 하지만 직접 읽어보면, 이는 오산이라는 것을 알 수 있습니다. 이 책은 개념 또한 example 코드로 설명합니다. 예를들어 loss function, 즉 손실에 대한 개념을 설명할 때, 그것에 대한 설명과, 수식을 잔뜩 늘어놓는 지루한 방법을 쓰지 않습니다.  def traning_loss(loss, model, training_data): '모델과 전체 학습 데이터를 이용한 학습 손실의 총합'  ~~~~~생략. 와 같이 직접 함수부터 제시해서, 이 개념이 코드에 어떻게 적용되는지 부터 보여줘서 독자로 하여금 빠른 직관적 이해를 가능하게 하는 것이죠!   셋째, 가벼운 설명입니다. 가볍게 대략적으로 설명한다는 것이 아닌, 최대한 딱딱하지 않게 설명하려고 노력하는 모습을 볼 수 있습니다. 어느정도로 이 부분에 집착하신면, 수식이 나오게되면 글쓴이께서 독자들에게 사과를합니다... 이는 독자들이 이해를 쉽게쉽게 하게끔 하려는 노력을 볼 수 있습니다. 수식 한줄 쓰시고 사과를 하시는 모습.. 앞서 말씀드린 개념을 설명할 때도 코드를 이용한다는 점도, 이런 부분에서 나온게 아닌가 생각이 듭니다. 또한, visualization 부분에도 엄청 힘을 쓰시고, 개념에 대한 마인드맵이나 그림, 실생활에서의 예제를 중간중간 삽입해서, 보다 가볍게 접할 수 있습니다.  위 세 가지는 제가 느낀 이 책의 특색, 장점들입니다. 하지만 쉽게 설명하려고 하기 때문에 때로는 그냥 받아들여야 하는 부분이 있고, 파이썬이나 기본 라이브러리들에 대한 설명은 하지 않기 때문에, 이 부분에 대해서는 직접 공부를 해야 한다는 점은 책을 구매하는 분으로 하여금 고려해보셔야 할 것 같습니다!  요즘은 CS 전공자가 아닌 사람들도 머신러닝이 뭔지는 다 알고있을 정도로, 머신러닝이 핫해지고 중요성이 높아지는 시대입니다. 그런데도 인터넷에서의 머신러닝에 대한 reference 들은 정작 CS의 다른 분야에 대한 정보에 대하면 턱없이 부족하다고 생각합니다. 웹 공부를 한 저의 입장으로서는 웹은 정말 구글에만 검색해도 쉽게쉽게 정보를 구할 수 있거든요. 이 책은 뭔가 온라인 게시글에 올려도 좋겠다, 혹은 e-book으로 적합하겠다 같은 느낌이 들더군요. 책 읽을 때의 딱딱함보다는, 온라인 블로그에서 읽는 게시글의 가볍고 좀 트렌디한 느낌? 을 받았던 것 같습니다.  아무튼 아직 읽는 중이지만, 무언가 저와 비슷한 특성을 가진 사람들에게 잘 맞을 것 같다는 생각이 듭니다. 저처럼 개념이나 수식만 보는 것보다, 직접 실습을통한 인식 이후의 직관적인 이해를 원하시는 분, 파이썬과 CS 지식은 있지만 머신러닝에 대해서는 잘 모르는분들에게 적합한 책인 것 같습니다.   저는 인턴 생활을 하는 데에 머신러닝 기초 base 지식 측면에서 도움을 많이 받았고, 앞으로도 개념서 + 실전적용서 두 가지 모두의 역할로 저에게 도움을 줄 책입니다!😃728x90     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//programming119.tistory.com/reaction';window.ReactionReqBody = {    entryId: 217}공유하기게시글 관리개발자 아저씨들 힘을모아 저작자표시 비영리 '컴퓨터 지식 > 서평(독후감)' 카테고리의 다른 글[IT 도서리뷰📘]  풀스택 서버리스  / AWS Amplify  (0)2021.08.15[독서 기록장] 2021.06 ~ 07 월  (0)2021.07.24[IT 도서리뷰📘] 도메인 주도 설계로 시작하는 마이크로서비스 개발 (DDD와 MSA)  (0)2021.06.29[도서리뷰📘] TDD - 테스트 주도 개발  (0)2021.05.29[도서리뷰📘] 함께 자라기 - 애자일로 가는 길 🍀  (2)2021.05.02태그도서리뷰, 머신러닝관련글 (adsbygoogle = window.adsbygoogle || []).push({});댓글0비밀글등록loadedComments[217]=true;findFragmentAndHighlight(217);     (adsbygoogle = window.adsbygoogle || []).push({});"
14,https://www.teamblind.com/kr/post/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4-%EA%B4%80%EB%A0%A8%ED%95%B4%EC%84%9C-%EB%A7%8E%EC%9D%B4-%EB%AC%BC%EC%96%B4%EB%B3%B4%EB%8A%94-%EA%B2%83%EB%93%A4-%EC%A0%95%EB%A6%AC%ED%95%B4%EB%B4%A4%EC%96%B4-4XJGMxUM,"
blind
","blindnotification                    Oops! Something went wrong. Please try again later.                    If the problem continues, please contact our team.US : blindapp@teamblind.comKR : support@teamblind.com"
15,https://candyz.tistory.com/5,태그,"AI 대학원 준비 후기인공지능 대학원 준비 후기 (1)by  Candy Lee2021. 1. 1.이제 2021년 입니다. 다들 새해 복 많이 시길 바랍니다! 오늘은 2020년도에 제가 준비했던 인공지능 대학원 준비 후기를 포스팅 하려 합니다.    제가 학교를 다니기 시작해서 졸업을 1년 남긴 시점부터 인공지능 대학원이 선정되었고 저는 그때 부터 일반대학원 진학을 포기하고 인공지능 대학원 입학을 목표로 계속해서 공부를 했습니다.  정말로 할게 많더라구요.. 학교 학점관리, 외부 프로그래밍 활동, 영어 성적, 개인 코딩 공부 등등..  학교를 다니면서 나름 열심히 하기 위해서 외부 활동 참여, 공모전, 프로젝트 등등을 해왔지만,  인공지능이라는 것에 무지했던 저였기에  초기에 진입장벽이 너무 높아서 애를 먹었습니다..ㅠㅠ 힘들었어요  그렇지만 제가 초기에 인공지능 입문에 있어서 코딩 측면, AI 이론 측면, 이론+수학 측면  이렇게 3가지 조건을 하나씩 갖춘 참고 도서도 알려드릴까 합니다. 저도 이 책들을 보고 공부했습니다! 많은 도움이 되었습니다.   1. 골빈해커의 3분 딥러닝 텐서플로맛요즘은 다들 TF 2.0으로 변화하는 추세여서 이 책이 시대와는 안 맞을 수 있는데요 그래도 제가 당시에 이책으로 공부할 때 가장 좋았던 점은 쉽게 코드 측면에서 이론을 접근하니깐 좀 더 직관적 이해가 가능했습니다!     2. 김성훈 교수님의 딥러닝 수업 가장 잘 알려져 있고 아마도 가장 쉽고 간략하게 AI 이론을 설명해 놓은 강의가 아닐까 생각합니다! URL : hunkim.github.io/ml/ 모두를 위한 머신러닝/딥러닝 강의 hunkim.github.io        3. 인공지능을 위한 수학 이 책은 제가 인공지능의 신경망 파트 공부할 때 어떤 수식을 기반으로 신경망이 동작하고 내부 함수들은 어떻게 구현되었는지를 공부할때 많은 도움이 되었던 책입니다. 추가적으로 인공지능을 공부하기 위해서는 선형대수 공부를 병행하는 것이 제일 좋지만,  처음으로 AI를 입문한다면 이 책을 통해서 수학을 기초부터 자연스럽게 습득해 볼 수 있을 것 같아서 추천드립니다!!   이 책 외에도 각자 개인의 노력이 더해진다면  더욱 좋을 수 밖에 없겠죠??  오늘도 감사드리며 인공지능 대학원 준비 후기 포스팅을 마치겠습니다. 감사합니다.  #위의 도서 추천관련 내용글들은 절대 광고가 아님을 말씀드립니다.#   자기소개서 작성 팁 바로가기=>candyz.tistory.com/14 핵심 연구계획서(자기소개, 지원동기) 작성법안녕하세요. Candy Lee 입니다. 오늘은 제가 대학원 입시때에 작성했던 대학원 연구계획서의 1,2번 문항인 (자기소개, 지원동기)를 바탕으로 조금 더 여러분들이 손쉽게 다가갈 수 있는 작성 가이드candyz.tistory.com  두번째 포스팅 바로가기=>candyz.tistory.com/6 인공지능 대학원 준비 후기(2)안녕하세요. 이어서 인공지능 대학원 준비 후기(2)를 포스팅 하려 합니다. 1편에서 말씀드렸던 내용처럼 많은 것들 중에서도 단연 수학(선형대수, 확률통계) 공부와 코딩 공부가 많은 비중을 차candyz.tistory.com 반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//candyz.tistory.com/reaction';window.ReactionReqBody = {    entryId: 5}공유하기게시글 관리Candy's AI Study Archive저작자표시 비영리 변경금지 'AI 대학원 준비 후기' 카테고리의 다른 글인공지능 대학원 준비 후기(2)  (31)2021.01.01태그ai, AI 대학원, AI 도서 추천, 대학원 준비, 인공지능 대학원, 인공지능 도서, 인공지능 서적관련글인공지능 대학원 준비 후기(2)댓글4    setInitialEntryComments(5, 1723627649)비밀글등록loadedComments[5]=true;findFragmentAndHighlight(5);"
16,https://gweri.tistory.com/45,태그,"취향관/취향의 날디자이너가 머신러닝을? 머신러닝야학 2일차 후기by 귀밤토리2021. 1. 5.반응형(adsbygoogle = window.adsbygoogle || []).push({});2일 차의 수업의 끝 부분에서는 '더 보면 안 됩니다. 아셨죠? 진도를 여기서 멈춰주세요. '라는 부분이 나오며 끝납니다. 이게 무슨 수업이냐? 더 듣지 말라니... 원래 듣지 말라고 하면 더 들으니까 괜히 하는 말인가요? 싶으시겠지만 아닙니다. 생산자(강의자) egoing님은 진심이 입니다. 무슨 얘기인지는 차차 알려드리겠습니다.  어제부터 시작한 머신 러닝 야학을 디자이너로서 듣기 시작한 지 이틀 차...2021/01/05 - [마스터 오브 넌] - 디자이너가 머신러닝을? 머신러닝 야학 1일 차 후기 디자이너가 머신러닝을? 머신러닝야학 1일차 후기구글과 생활코딩이 함께 하는 머신러닝 야학 1일 차를 들어봤습니다. 1월 3일 개발자 남편에게 슬쩍 건내 본 링크. 정말 어쩌다가 보게 된 링크였는지는 모르겠지만, 보자마자 바로 전송을 했습gweri.tistory.com오늘이 마지막 후기 일 수도 있을 것 같다는 생각이 듭니다. '아니, 벌써요?', '벌써 포기를 하다니 작심 3일도 아니구먼'이라고 하시는 분들도 계실 수 있으실 것 같습니다. 이 글을 쓰고 있는 지금, 개발자인 남편은 3일 차의 부분을 옆에서 듣고 있지만, 저는 아마도 마지막 수업일 것 같습니다. 오늘의 내용은 머신러닝으로 뭘 할 수 있는지를 더 알아보고, 어떤 문제들을 해결할 수 있을지 고민해보는 내용이 제일 주요한 내용이었습니다. 1회 차와 마찬가지로 참으로 쉽고 간단하게 가르쳐주는 수업이었습니다. 적절한 그림과 함께 깔끔한 프레젠테이션이 참 맘에 듭니다.  근데 수업 중간중간마다, 경고에 가까운 문구가 나옵니다. 그런데 소프트웨어를 만드는 여정은 처음에는 쉽지만 뒤로 갈수록 기하급수적으로 어려워집니다. 기능이 많아질수록 거기에 인생을 바쳐야 합니다.  인생을 바칠지 말지는 천천히 고민하면 됩니다. 그럼 여기서 멈춰야 할까요? 그래도 됩니다!동시에, 조금 더 나아갈 수도 있습니다.이제 여기까지 배우고 그만둬도 괜찮다는 선생님은 처음 봤습니다. 하지만 오늘 차 수업을 끝까지 다 마치고 나면 이런 말을 왜 하는지 알게 됩니다. 이미 교양인으로서의 커리큘럼은 여기 까지라는 말씀을 하고 싶었던 것 같습니다. 현명합니다. 효율이 없다는 말을 하시고 싶었던 것입니다. (사실 그저 html css로 웹사이트의 간단한 수정 정도는  할 수 있지~라는 부심을 가진 디자이너로서 코딩에 대해서 더 알고 싶어 코딩 오프 모임을 간 적이 있었습니다. 그 모임도 3회 차까지 가고는 바로 포기했던 것 같은데, 강의자 님이 말씀하신 이유 때문입니다. 이런 것들로 이러한 것들을 해결할 수가 있구나 ~ 정도만 알아도 충분할 저에게는 3회 차의 모임에서 여긴 내가 있어도 시간만 버리겠구나 싶었습니다. 그렇습니다. 그 사실을 알고 계신 분이었습니다. )  10일 차는 채우지 못하고 2차가 마지막 후기가 될 것 같은 느낌입니다만, 오랜만에 참 재밌고 흥미로운 수업 잘 들었습니다. 누구에게나 공개된 이런 수업들이 더 많아졌으면 하는 바랍니다. 특히 좋았던 것은 저같이 잘 모르는 사람들을 위해서, 오픈으로 다른 사람들의 아이디어들도 예시들로 보여주시니, 참고하고 다른 생각도 해볼 수 있는 참여형 수업이라 좋았습니다. 보통 온라인 수업이라고 하면 아무래도 상호작용이 되는 수업이 되는 것 같은 느낌이 적은데 이 수업은 그렇게 느껴져서 재밌었습니다.   반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//gweri.tistory.com/reaction';window.ReactionReqBody = {    entryId: 45}공유하기게시글 관리Master of none '취향관 > 취향의 날' 카테고리의 다른 글0310 - 남편과 만난 지 4주년기념 첫 만남 썰푼다.  (4)2021.03.10포스팅 하나가 다음 메인에 노출 그리고 소개되다.  (5)2021.01.29디자이너가 머신러닝을? 머신러닝야학 1일차 후기  (7)2021.01.05인터넷으로 로또를 살 수 있다고? (그래서 나의 2021년 첫 복권 결과는?)  (6)2021.01.03과연 내 글을 누가 읽을까?  (10)2020.12.30태그교양의끝, 구글, 머신러닝, 머신러닝야학, 생활코딩, 야학, 오픈튜토리얼, 코딩, 코딩배우기, 튜토리얼관련글0310 - 남편과 만난 지 4주년기념 첫 만남 썰푼다.포스팅 하나가 다음 메인에 노출 그리고 소개되다.디자이너가 머신러닝을? 머신러닝야학 1일차 후기인터넷으로 로또를 살 수 있다고? (그래서 나의 2021년 첫 복권 결과는?)댓글2    setInitialEntryComments(45, 1723627650)비밀글등록loadedComments[45]=true;findFragmentAndHighlight(45);"
17,https://hoking.tistory.com/19,Tag,"                                                  IT를 여행하는 히치하이커를 위한 안내서                              홈태그방명록카테고리 없음[서평] 나는 리뷰어다 - 인사이드 머신러닝 인터뷰H.Hoper2024. 4. 28. 23:22올해 꼭 책을 한달에 한권은 읽겠다는 다짐으로 한빛미디어의 서평단 활동을 하게 되면서 읽게 된 3번째 책은 '인사이드 머신러닝 인터뷰'이다.  [ 인사이드 머신러닝 인터뷰 ]- 부제: 빅테크에서 자주 묻는 194가지 문제로 ML 면접 완벽 대비하기 -출판: 한빛미디어저자 :펑 샤오번역 :정원창출간 :2024-03-15페이지 :332 쪽  이 책은 책 제목처럼 ML(Machin Learning) 엔지니어들이 알아야 하는 지식 전반 내용과 구체적인 각각의 개념들을 정리한 해법수학과 같은 느낌의 책이다. 물론, 이 내용들이 머신러닝 엔지니어 인터뷰시 나오는 문제들이기도 할 것이다.사실 머신러닝 엔지니어로써 인터뷰 보다는 채용매니저로써 주로 일을 해 온 입장에서 , 이 정도의 내용을 알고 이해하고 있거나 경험해 본 엔지니어라면 무조건 뽑을 것이다.  이 책은 인터뷰를 위한 책보다는 머신러닝 전반에 대한 이해와 구체적인 개념 정립을 위해서 책상앞에 꼽아두고, 수시로 찾아보고푼 책이기도 하다.  또한, 초보자보다는 이미 머신러닝을 경험해본 사용자들이 체계를 잡거나 부족한 부분을 보완하기에 최적의 책이라고 생각한다. 또한, 각 과정의 세부 내용들까지 깊이 이해하고자 하는 독자들을 위한 책으로써도 최적이다. 물론, 초보를 위한 기본적인 개념들부터 고려해야 할 사항들까지도 제시하고 있는건 사실이다. 무엇보다 머신러닝을 가볍게 접해 본 초보자인 나에게는 결코 쉽지 않았던 책이다. 책 내용이 어렵다기 보다는 제목 그대로 '인사이드'로 기본적인 개념에서 한단계 더 들어가 제대로 설명하는 내용들이 많다. 또한, 내용이 간결하고 압축적이며 체계적이다. 그렇기에 기본 개념을 제대로 가지고 있지 않은 초보자들은 다른 머신러닝 개론서를 보고서 이 책을 보기를 추천한다. 그래서, 초급에서 중급으로 가거나, 중급자로서 체계적인 정리를 하고자 하는 이들에게는 정말 너무 좋은 책이 될거라 감히 단언한다.  각 장마다 우측의 내용처럼 마치 인터뷰 질문을 하듯이 되어 있다. 예를 들어, 로지스특 회귀를 설명하는 말에는 최소한 ' 하나 이상의 입력 변수(피처)를 기반으로 이벤트가 발생할 활률을 모델링 하고, 피처들은 선형으로 결합 후 로지스틱 함스롤 사용해 변환함으로써 이벤트 확률을 모델링 한다. 다항 로지스틱 회귀는 소프트맥스 회귀라고 하기도 한다'라는 답변이 이상적인 답변임을 알려준다. 다만, 한가지 아쉬운 건 각 수식에 대한 예제도 간혹 있지만, 초기 개념 설명에서는 이미지나 그림을 추가했더라면 초보자들도 좀 더 이 책을 보는데 허들이 줄어들지 않았을까 하는 생각을 해본다. 물론, 책의 중반에서부터는 여러 이미지들과 함께 개념 설명을 보여준다. 다른 한편으로는 사실 각 하나하나가 워낙 깊이 있는 내용들이라서 이 내용들을 깔끔하게 묶었다는데 보다 의미를 둘 수 있을거 같다.  그리고, 마지막 파트에서는 LLM 관련 내용도 추가하여 최신의 트렌드한 기술들도 인터뷰시나 개념을 잡는데 도움이 될 수 있도록 하고 있다. 물론, 상세 내용은 각 파트별로 별도의 책이나 인터넷을 통해서 확인해 볼 필요는 있을 것이다. 최근에 생성형AI와 딥러닝/머신러닝 관련 읽은 책중에 가장 집중도가 필요로 했던 책이었다. 보다 AI/머신러닝 전문가가 되고 싶다고 꼭 이 책을 읽어보기를 추천한다.   * 이 글은  ""한빛미디어 <나는 리뷰어다> 활동을 위해서 책을 제공받아 작성된 서평입니다.""window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//hoking.tistory.com/reaction';window.ReactionReqBody = {    entryId: 19}공유하기게시글 관리IT를 여행하는 히치하이커를 위한 안내서저작자표시 비영리 변경금지 Tag나는리뷰어다, 머신러닝, 서평, 인사이드머신러닝인터뷰, 한빛미디어'카테고리 없음'의 다른글이전글[Wired] Apple One은 무엇이며 구독해야 하나?현재글[서평] 나는 리뷰어다 - 인사이드 머신러닝 인터뷰다음글[모두의연구소] Llama3 출시 : AI 전쟁의 서막loadedComments[19]=true;findFragmentAndHighlight(19);IT를 여행하는 히치하이커를 위한 안내서최신 IT관련 정보들IT를 여행하는 히치하이커를 위한 안내서구독하기글쓰기블로그 관리 분류 전체보기 (26)  AI (12)  IT (3)  Data (4) Tag진화적사고,ChatGPT,나는리뷰어다,네이버스마트스토어시작하기,Chatgpt4,살아남는 생각들의 비밀,생성형AI,서평,머신러닝,Ai,데이타자격증,한빛서평단,LLM,GenAI,샘데이텀,윈도우장애,한빛미디어,안종희,관찰가능성,openAI,최근글과 인기글최근글인기글[서평] 데이터로 말한다! CRM 마케팅2024.07.29 00:14마이크로소프트 서비스 장애로 인한 글로벌  임팩트2024.07.20 10:26데이터 분석 자격증 Top 92024.07.10 00:21[서평] 데이터로 말한다! CRM 마케팅2024.07.29 00:14[서평] 살아남는 생각들의 비밀2024.05.19 23:14[Wired] Apple One은 무엇이며 구독해야 하나?2024.04.01 21:44최근댓글다양한 분야가 다 다뤄져서 도움이 많이 되었습니다. 좋은 한해 시작하세요~GAI.T & a.k.a Chonkko감사합니다! ^^H.Hoper좋은 정보 잘 보고 갑니다.즐거운 주말 보내세요♥IT오이시이공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/072024/062024/052024/042024/032024/022024/012023/092023/082023/05Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total476Today : 2Yesterday : 2블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트티스토리툴바window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4755785-19"",""customProps"":{""userId"":""0"",""blogId"":""4755785"",""entryId"":""19"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""19"",""entryTitle"":""[서평] 나는 리뷰어다 - 인사이드 머신러닝 인터뷰"",""entryType"":""POST"",""categoryName"":""카테고리 없음"",""categoryId"":""0"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4920072"",""authorNickname"":""H.Hoper"",""blogNmae"":""IT를 여행하는 히치하이커를 위한 안내서"",""image"":""kage@blcXhs/btsGYZmhm6K/Cju2k61yVleIqXcn1oL050"",""plink"":""/19"",""tags"":[""나는리뷰어다"",""머신러닝"",""서평"",""인사이드머신러닝인터뷰"",""한빛미디어""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
18,https://ariz1623.tistory.com/343,댓글을 달아 주세요,"코딩의 숲홈태그방명록메뉴 닫기글작성방명록환경설정 분류 전체보기 (317)  딥러닝 (39)  NLP (18)  Vision (10)  딥러닝 기초 (3)  LLM (8)  머신러닝 (27)  데이터 분석 (21)  토이프로젝트 (5)  코딩야학 (7)  데이터 분석 기초 (9)  파이썬 (47)  프로그래머스 (31)  백준 (14)  PyTorch (2)  MySQL (26)  c++ (128)  알고리즘 공부 (10)  프로그래머스 (21)  백준 (95)  SWEA (1)  기타 (24)  깃허브 (7)  AWS (7)  일상 (4) 홈태그방명록기타/일상 / ariz1623 / 2023. 12. 24. 16:00주어니 머신러닝 엔지니어의 이직기 (4)이번에 적을 내용은 면접과 관련된 내용이고 아마도 이번글이 시리즈의 마지막 글이 될 꺼같다. 올해 안에 다 적을 수 있을지 걱정이 많았는데, 올해 안에 꼭 마무리를 하고 싶어서 연휴를 틈타 열심히 글을 적고 있다.   기술 면접 - 1차 기술 면접은 신입과 경력이 차이가 많이 나는 것 같다. 신입의 경우 이렇다 할 프로젝트를 할 경험이 많지 않기 때문에 아무래도 기본 기을 많이 물어봤던 거 같고, 경력은 진행했던 프로젝트 위주로 질문을 많이 받았던 거 같다.  요즘은 신입 지원자들도 여러 가지 프로젝트를 많이 하는데, 사실 수박 겉핥기식으로 프로젝트를 진행한 것보다는 기본기를 더 다져가는 게 도움이 될 꺼 같다. 화려한 프로젝트로 이력서를 포장해서 면접을 갔다고 한들 기본적인 내용을 제대로 답변하지 못하면 프로젝트들이 눈에 들어오지 않을 것이기 때문이다.  그리고 경력 지원자들 경우 프로젝트 위주로 답변을 준비해 가는게 보통일 텐데, ""내가 진행했으니까 내가 다 아는 내용이야. 그러니까 굳이 준비를 해야 할까?""라고 생각할 수도 있지만, 그래도 준비를 하는 게 한 200배 더 나은 거 같다. 그리고 면접 준비는 한 번만 제대로 해두면 이후에는 준비하는 시간이 급격히 줄기 때문에 한 번은 제대로 정리하는 게 좋을 것 같다.  나는 기술면접 준비를 조금 빡세게(?) 한 편인 거 같다. 프로젝트와 관련된 질문에 대한 답변과 AI와 관련된 기초적인 부분까지 추가적으로 준비해 갔다. 양은 많았지만 이게 마음이 편했다. 프로젝트와 관련된 내용을 정리할 때는 철저히 작성한 이력서를 기반으로 준비했다. 예를 들어 이력서를 아래와 같이 작성했다면  이런 질문들을 준비해 갔다. 파악한 데이터 특징은 어떤 게 있나요?데이터를 어떤 식으로 재구축했나요?추론 최적화는 어떻게 진행했나요?기존의 서비스 속도는 어느 정도였나요?서비스 평가 지표를 해당 지표로 사용한 이유가 무엇인가요?더 개선할 여지가 없었나요?프로젝트는 몇 명이서 진행한 것인가요? 사실 이렇게 준비하다 보니 공통적으로 준비할 질문이 절반정도 되었다. 그래서 모든 프로젝트별 공통적으로 물어볼 수 있는 질문을 대비하고, 해당 프로젝트에서만 물어볼 수 있는 기술적인 내용에 대한 답변을 준비해 갔다.  공통적으로 물어 볼 수 있는 질문은 다음과 같이 정리했다. 해당 프로젝트의 목적? / 프로젝트 진행 이유프로젝트를 진행한 방식특정 방식(알고리즘)을 사용한 이유프로젝트를 진행한 인원 및 다른 팀원들의 역할본인의 주 역할아쉬웠던 점 위와 같은 질문을 포함하여 한 프로젝트당 질문을 10~15개 정도 준비해 갔고, 여기에 더해 면접을 보면서 들었던 질문들은 추가하는 방식으로 기술 면접을 준비해 갔다.  그리고 AI와 관련된 기초적인 내용은 예전에 깃허브에 정리해 둔 내용을 활용했다. 해당 내용은 내가 직접 작성한 것도 있고 다른 분들이 작성한 내용을 가져온 것도 있다. AI 엔지니어 기술면접 대비  마무리 기술면접에 이어 2차 면접 - 인성면접까지 다뤄 볼까 했지만, 크게 의미는 없을 거 같아 생략했다. 인성면접은 AI 개발 직군이라고 해서 다른 직군과 크게 다르지 않고, 다른 사람들이 워낙 잘 작성한 글이 많이 있기 때문이다. 그리고 내가 경험한 2차 면접은 거의 결과가 정해저 있었다. 그래서 2차 면접을 어떻게 준비해 가든 예상했던 결과와 크게 달라지는 경우는 없었다.  무튼 이것으로 주니어 머신러닝 엔지니어의 이직 후기를 마무리하고자 한다. 누군가 이 글을 읽는 사람들에게 도움이 되었으면 좋겠다. 그리고 이 글을 쓰면서 느낀 건데 내가 참 글을 못쓰는 거 같다. 살다 보면 이렇게 긴 글을 작성할 일이 많을까 싶긴 한데, 글로써 내 경험들을 기록해 두는 건 좀 의미 있는 일인 거 같아서 꾸준하게 글을 적어 나가볼까 한다.  내년 목표에 꾸준히 블로그 쓰는 것을 넣어야겠다.  혹시나 이 글을 읽고 궁금한 내용이 있으면 댓글로 적어주시면 감사하겠습니다. 그리고 글에 대한 지적은 하셔도 되는데 안 해주시면 더 감사하겠습니다.  모두 즐거운 연말 보내세요~!2023년 연말의 서울 어딘가 window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//ariz1623.tistory.com/reaction';window.ReactionReqBody = {    entryId: 343}공유하기게시글 관리코딩의 숲 '기타 > 일상' 카테고리의 다른 글주니어 머신러닝 엔지니어의 이직기 (3)  (0)2023.12.23주니어 머신러닝 엔지니어의 이직기 (2)  (0)2023.11.19주니어 머신러닝 엔지니어의 이직기 (1)  (2)2023.09.24태그AI 기술 면접, AI 엔지니어, 기술 면접, 기술 면접 질문기타/일상 관련 글주니어 머신러닝 엔지니어의 이직기 (3)2023.12.23주니어 머신러닝 엔지니어의 이직기 (2)2023.11.19주니어 머신러닝 엔지니어의 이직기 (1)2023.09.24글 더보기 0댓글을 달아 주세요비공개댓글을 남겨주세요TistoryWhaleSkin3.4"">댓글 등록loadedComments[343]=true;findFragmentAndHighlight(343);전체 카테고리 분류 전체보기 (317)  딥러닝 (39)  NLP (18)  Vision (10)  딥러닝 기초 (3)  LLM (8)  머신러닝 (27)  데이터 분석 (21)  토이프로젝트 (5)  코딩야학 (7)  데이터 분석 기초 (9)  파이썬 (47)  프로그래머스 (31)  백준 (14)  PyTorch (2)  MySQL (26)  c++ (128)  알고리즘 공부 (10)  프로그래머스 (21)  백준 (95)  SWEA (1)  기타 (24)  깃허브 (7)  AWS (7)  일상 (4) 블로그 인기글ROUGE 이해하기군집 평가 - 실루엣 분석평균이동(Mean Shift)Gemma 2 (9B & 27B) Evaluation  vs. Open/⋯transformer를 활용한 한-영 번역 모델(pytorch)Truncated SVD코딩야학 - 보스턴 집값 예측CNNDBSCAN데이콘 - 도배 하자 질의 응답 처리 후기최근 글최근 댓글최근 글[논문리뷰] How Does Quantization Affect Mult⋯ LLM의 다양한 SFT 기법: Full Fine-Tuning, PEFT ⋯ Supervised Fine-tuning: customizing LLMs Gemma 2 (9B & 27B) Evaluation  vs. Open/⋯ Pretraining LLMs 데이콘 - 도배 하자 질의 응답 처리 후기 주어니 머신러닝 엔지니어의 이직기 (4) 주니어 머신러닝 엔지니어의 이직기 (3) 주니어 머신러닝 엔지니어의 이직기 (2) Kaggle - LLM Science Exam 후기 1최근댓글ariz1623 02.21감사합니다 :)최준홍 01.31저는 1년차 주니어 개발자입니다!! 저도 님 처럼 얼른 이직해서 성공하고⋯get_time 2023포스팅 잘 보고 갑니다!get_time 2023좋은 글 잘 읽었습니다!!get_time 2023좋은 글 잘 읽었습니다!!ariz1623 2023https://aihub.or.kr/aihubdata/data/view.⋯영식 2022xlsx 파일이 어떤 형태로 되어있는지 알 수 있을까요?baundy 2022글 솜씨가 뛰어나시네요! 좋은 글 잘 보고 갑니다 다음에도 놀러올게요 :⋯baundy 2022글 솜씨가 뛰어나시네요! 좋은 글 잘 보고 갑니다 다음에도 놀러올게요 :⋯소마신군 2022안녕하세요. frm torchtext.legacy.data to Tab⋯태그#백준#토이프로젝트#코딩야학#mysql#판다스#추천시스템#머신러닝#llm#텐서플로우#회귀분석#파이썬#사이킷런#stable diffusion#데이터분석#python#Torch#크롤링#차원축소#딥러닝#회귀#bert#워드클라우드#AWS#pandas#프로그래머스#transformer#군집화#pytorch#C++#데이터 전처리MORE전체 방문자오늘37어제59전체102,672Powered by Privatenote Copyright © 코딩의 숲 All rights reserved.TistoryWhaleSkin3.4/* 메뉴  */(function($) {function commonControl(){var sc = $(""#sidebar .c_cnt"");sc.length > 0 && sc.each(function() {$(this).html($(this).html().replace(/[()]/g, """"))});$(document).on('click', '.btn_topMenu', function(){if ($("".dropdown-content"").hasClass(""dropdown-content-toggle"")){$("".dropdown-content"").removeClass(""dropdown-content-toggle"");}else{$("".dropdown-content"").addClass(""dropdown-content-toggle"");}});$(document).on('click', '.btn_close' ,function(){$("".dropdown-content"").removeClass(""dropdown-content-toggle"");});/* 사이드바 탭 분류 */$(document).on('click', '#recent-tab li',function(){$(""#recent-tab > li"").removeClass(""active"");$(this).addClass(""active"");$("".tab-content .tab-pane"").removeClass(""active"");$($(this).attr(""id"")).addClass(""active"");});/* 복사 방지, 개발자 도구 방지 */$(document).keydown(function(event) {if (event.keyCode == 123) { // Prevent F12return false;} else if (event.ctrlKey && event.shiftKey && event.keyCode == 73) { // Prevent Ctrl+Shift+I        return false;} else if (event.ctrlKey &&(event.keyCode === 67 ||event.keyCode === 86 ||event.keyCode === 85 ||event.keyCode === 117)) {return false;}});}commonControl();})(jQuery);티스토리툴바hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""3433294-343"",""customProps"":{""userId"":""0"",""blogId"":""3433294"",""entryId"":""343"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""343"",""entryTitle"":""주어니 머신러닝 엔지니어의 이직기 (4)"",""entryType"":""POST"",""categoryName"":""기타/일상"",""categoryId"":""1076617"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""4082707"",""authorNickname"":""ariz1623"",""blogNmae"":""코딩의 숲"",""image"":""kage@tfpzO/btsCzqA3NUM/Vqfk9eNQyEUqGCqsJM4E41"",""plink"":""/343"",""tags"":[""AI 기술 면접"",""AI 엔지니어"",""기술 면접"",""기술 면접 질문""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
19,https://qkqhxla1.tistory.com/1193,'private/memo'의 다른글,"                                                  archives                              홈태그미디어로그위치로그방명록private/memo데이터 엔지니어 경력 5년 이직준비 후기qkqhxla12022. 4. 27. 12:33자소서 : http://qkqhxla1.tistory.com/797면접 후기 : http://qkqhxla1.tistory.com/799내가 한 공부들과 방법 : http://qkqhxla1.tistory.com/802취업을 위한 알고리즘 공부법 : http://qkqhxla1.tistory.com/990데이터 엔지니어 경력 5년 이직준비 후기 : https://qkqhxla1.tistory.com/1193 오랫만에 글을 쓴다. 최근 두달동안 글이 없었는데 모든걸 이직준비에 올인하느라 글이 없었다. 제목에 적었듯이 나는 데이터 엔지니어 직군인데, 데이터만 다루는 직군은 예전부터 있었지만 데이터 엔지니어라는 명칭으로 it회사들의 채용공고에 박힐정도로 정립된지는 3~4년 정도 된것 같다.(대략 19년도즈음부터 정립이 되지않았나 싶음)내 가정인데, 알파고vs이세돌이 16년에 대결했었는데 그 여파로 머신러닝 분야가 확 뜨면서 머신러닝 엔지니어 채용이 늘어났고.. 머신러닝 엔지니어를 채용해서 뭔가를 만들다보니 데이터를 앞에서 예쁘게 말아주는(지금의 mlops같은) 직군이 필요해지면서 데이터 엔지니어라는 직군의 수요가 확 늘어나면서 그즈음 정립이 된게 아닌가 싶다.(사실 해외에는 그 이전부터 있었다)그래서 현재 내 경력이면(5년 4개월) 데이터 엔지니어링을 신입부터 시작한 1세대 개발자라고 볼수 있을것같다.(2017년에 처음 회사에 들어왔을때는 데이터 엔지니어라는 직군이 공고에 없었던거로 기억한다. 지금 나와 일하는 비슷한 연차의 다른회사출신 동료들에게 물어봤는데, 그분들도 처음에는 소프트웨어 엔지니어로 들어왔다고 하셨다.) 그래서 정보가 많이 없어서 이력서나 면접을 준비하기가 참 힘들었다. 다른 글들을 보면 알수있듯이 나는 5년전(2017년)에 쿠팡 신입공채로 입사했는데, 내가 아는 동기 인맥 대부분이 스프링 백엔드 엔지니어이다. 동기 인맥을 언급한 이유는 이직한 동기들이 상당히 있는데, 면접 도움을 받으면 이직준비하기가 훨씬 수월하기 때문이다. 동기들이 전해준 백엔드 면접경험에서는 전반적인 개발자 면접의 방향성에 대해서 도움을 받았지만 다른 직군이다보니 구체적인 방향성은 면접에서 여러번 털린후 감을 잡을수 있었다.데이터 엔지니어 경력 5년을 적은 이유는 이 연차가 주니어도 시니어도 아니면서 이직을 많이 생각하는 연차중 하나이기 때문에 적당히 참고하면 좋기 때문이다.이력서 작성부터 합격까지, 실패와 성공했던 모든 필요했던 사소한 과정, 깨달은점등을 처음 이직준비하는 데이터 엔지니어들이 도움이 될수 있도록 적을 예정이다. 0. 커리어 관리시작부터 커리어 관리라고 하면 당연하지만 뜬구름 잡는 말이긴 한데 기본적으로 이직을 위해 커리어 관리가 필요하기 때문에 전제조건으로 써놨다. 내가 아무리 이력서를 잘 써도, 경력이직시에 필요로 하는 기술 경험이 없으면 힘들다.(가능은 하다.) 그래서 현재 이직생각이 있던 없던 항상 커리어 관리는 하는게 좋다. 여기서 적은 커리어 관리라는 말은 꼭 좋은 회사에 입사하라는게 아니라 내 직군에서 많이 사용하는 기술들을 서칭하고, 이력서에 쓸수 있도록 사용해보자는 말이다. 예로 백엔드 개발자는 요즘 대부분이 자바 스프링을 기반으로 개발하므로 자바 스프링 경험이 있으면 더 유리하다. 채용공고들을 보면서 생각한 데이터 엔지니어의 가장 공통적으로 요구되는 기술은 하둡, 스파크라고 생각한다. 회사에서 하둡 스파크를 쓰지 않으면 최소한 도입하려는 노력은 해보자.(도입이 안되더라도 노력 자체를 자소서에 녹일 수 있다.) 도입이 되면 나중에 내가 쓸 이력서의 이력 한줄이 방금 생긴거고, 도입이 불가능한 환경이면 현재 사용하고 있는 기술을 깊이 있게 사용해보도록 노력하자.(기술을 사용한 이유, 현재 이걸 사용하는게 가장 최고의 판단인가?? 요거 나왔다던데 바꿔보면 어떨까? 뭔가 만족스럽지 않은데 더 좋은 방법은 없을까? 등) 기술을 깊게 생각해보고 사용한 것만으로도 상당한 가산점이 붙는다고 생각한다. 데이터 엔지니어 안에서도 여러 종류가 있고 나는 세분화해서 구분하자면 데이터 파이프라인 엔지니어인데, 경력직 기준으로는 데이터 파이프라인 제작만 하는건 경쟁력이 없는것 같다. 파이프라인 제작을 주 업무로 하지만 aws, k8s같은 인프라쪽은 물론, 데이터 플랫폼도 살짝 만져보고, ml팀과 협업도 해보고, 가벼운 웹 어드민 개발도 해봐야 경쟁력이 있다. 다른 직군이 보면 정말 이것저것 다하는데 이러면 잡부 아냐? 하는데 아직까지 데이터 엔지니어링은 직군이 정립되어가는 과도기한 시기라고 생각해서 잡부적인 경험이 더 경쟁력이 있다고 생각한다.(순수 개인의견)(추가) 위에 빗금친 내용은 의견이 바뀌었다. 잡부적인 경험보다 하나라도 '제대로 깊게' 해본 경험이 더 선호되는것 같다. 정립된 직군을 데이터 플랫폼 개발을 예시로 들었는데, 데이터 엔지니어링의 많은 파트가 각자 정립이 되어가는것 같다. 그래서 여전히 스타트업을 제외하고 어느정도 이상 큰 기업에 가려면 본인의 파트에서 전문성을 갖는게 더 선호되는 방향으로 가고 있다고 생각한다. 하나의 경험에 대해 제대로 깊게, 나머지에 대해 기본적인 지식이 있는 T자인재가 역시 가장 좋은것 같다. 스타트업에서는 데엔인데 잡부인 케이스뿐 아니라 심지어 혼자서 분석과 데엔, 사이언스를 전부 하는 케이스도 많은것같다. 이 케이스는 경력이 아직 주니어로 쳐주는 5년 이하일때.. 좋은곳 잘 찾아가서 커리어를 잘 만드는게 정말 중요한것 같다. 그게 아니면 이력서 수정이 정말 많이 필요할거고 이직이 많이 힘들것 같다. 면접을 보면 세 분야 다 할줄아는 대단한 인재다! 가 아니라 대부분의 케이스에서 셋중 하나도 제대로 할줄 모르네.. 라는 반응이 나올 가능성이 높다. (나도 면접을 보면서 내가 뭘 모르고 있었는지 많이 깨달았다) 전문성에 대해 예를 몇개 들어보자면 데이터 플랫폼 개발같은 경우 데이터 크기가 작은 회사에서는 쿠버네티스 위에 helm chart로 스파크 하나 대충 올리고 사용하면 된다. 쿠버네티스도 없는 경우 가장 고전적인 방법으로 올라와있는 서버 몇대 위에 스파크 서버 구성해서 써도 돌아가긴 한다. 그리고 여기서 더는 생각해볼거리가 없다. 데이터가 작기 때문에 굳이 뭔가를 더 할 필요가 없기 때문이다. 데이터가 커져서 나가는 비용이 천, 억단위가 되면 비용과 최적화에 대해서도 생각해봐야 할거고 failover도 조금 더 잘 생각해봐야 할거다. 데이터 플랫폼 말고 DW/DM 개발에 대해서도 생각해보자. 보통 데이터가 작은 회사들은 소수(1~2명)의 데이터 엔지니어들이 모든걸 전부 처리하므로, 테이블을 설계할시에도 '적당히' 우리끼리 알아볼수 있을 정도에서 만든다. 요것도 DW/DM의 범위가 커지면 어떻게 컬럼명을 통일하고, 규칙을 만들어야 이름만보고도 데이터를 추측 가능한가, 매일 갱신되는 데이터 퀄리티를 유지하기 위해 어떻게 모니터링할것인가 등의 고민을 하게 된다. 데이터 엔지니어는 요런 것들에서 전문성이 나뉘는것 같다.현재 데이터가 작거나 소수의 데이터 엔지니어로 구성된 회사에서 일하는분들은 본인이 맡은 분야에서 어떻게 더 최적화를 할수 있을까 고민해보는게 좋을것 같다. 그런데 이건 내가봐도 이상적인 이야기인것 같고, 내가 생각하기에 현실적으로 데이터 엔지니어로써 정말 유의미한 커리어를 쌓으려면 데이터를 소중하게 잘 다루는.. 회사나 팀에 들어가는수밖에는 없는것 같다. 보통 데이터를 잘 다루는 회사의 시스템을 접하기 이전에는 이런것도 고민거리이고 시스템화해야하는구나..? 하는걸 잘 모를수밖에 없다.(내가 그랬다) 당연한 이야기겠지만 데이터를 소중하게 다루는 회사일수록 단순 돌리고 끝이아닌 팀, 조직단위에서 더 고민을 하게 되고 이러한 고민을 접하게 되는 것만으로도 성장하는 자양분이 되는것 같다. 커리어 관리가 잘 되고있다는건 이력서 작성시 내가 추가적인 양념을 뿌리지않고 한 일만 그대로 적어도 합격이 되는 이력이 커리어 관리를 잘해온거라고 생각한다. 대표적으로 종종 네이버같은곳에서 재직중이던 개발자들이 갑자기 어떤일때문에 화나서 주말동안 이력정리하고 2~3주 이내로 이직했다는 썰이 종종 들리는데 이런분들이 이력관리를 잘한 분들이라고 생각한다. 물론 네이버 재직 자체가 이미 좋은 커리어이긴 하다. 다시 정리해서 적으면 평소에 내 연차를 채용하고 있는, 가고싶은 회사들의 채용공고에서 어떤 기술적인 것들을 요구하는지 찾아보고 부족한게 있으면 사용하도록 노력해보고, 현 시스템을 개선하기 위해 노력해보자. 그리고 현 시스템이 최선일지 고민하려고 해보자. 물론 대다수가 일하느라 이런거 할 시간이 없지만 이직하려면 해야 한다.내가 현재 나아가는 방향이 맞는지 끊임없이 모니터링하기위해 내 직군들이 모여있는 커뮤니티에 들어가자. 오픈카톡방도 괜찮으며 꼭 기술적인 이야기가 아니더라도 여러가지 이야기를 들으면서 시야를 넓히거나 정보를 얻을 수도 있다. 한직군이 몇백명씩 있는 오카방의 경우에는 괜찮은 회사의 채용담당자들이 들어와 있는 경우도 많아서 채용공고 알람을 받을수도 있다. 또는 인프런같은곳에서 오픈카톡방 사람들을 대상으로 할인을 푸는 등 상당히 유용한점이 많다. 1. 준비 단계실질적으로 이직준비를 시작하는 단계이다. 가장 먼저 목표로 하는 기업들 리스트를 생각해놓는다. 나의 경우 이직의 가장 큰 목적은 연봉이었고, 연봉이 만족스러우면 워라벨은 나빠도 상관없고, 그정도가 아니면 워라벨까지 어느정도 괜찮은 회사를 목표로 삼았다. 블라인드 글들과 이직한 동기들의 이야기를 여러 방면으로 듣고 개인 취향을 반영한 결과 결론적으로 카카오뱅크, 당근마켓, 우아한형제들 요 3개 회사중 하나를 가는것을 목표로 삼았다.(사실 두나무, 몰로코도 있었으나 이 두곳은 가장 빡센곳이라서 마지막에 쓰려고 했는데 그전에 붙어버렸다. 그리고 붙었을때쯤 면접보고 이력서고치고 다시준비하는 반복 작업을 좀 하느라 정신적으로 많이 지친상태여서 이 두곳은 쓰지 않았다.) 가고싶은 회사 리스트를 정할 때에는 보통 1. 높은 연봉을 주는 곳인가2. 네카라(네이버, 카카오, 라인)처럼 네임벨류가 있는 회사인가(커리어에 도움이 되는 회사인가)3. 보통 워라벨이 괜찮은 곳인가등으로 중요도를 매긴 후 1차적으로 가고싶은 기업들을 메모장 등에 정리해놓고, 2차적으로 1차에서 추린 기업들중 내가 하고있는 업무와 관련된 공고가 열려있는지 확인후 열린 공고들을 따로 정리해놓는다. 이후 가장 가고싶은 회사순으로 정렬한 후에 가장 안갈것같은 회사부터 지원을 하면 된다. 나처럼 신중하게 준비할거면 붙어도 가지 않을 면접 연습용 회사를 뽑아놓는다.(연습용으로 지원해보는건 그 회사 담당자들에게 미안하지만 많이들 이렇게 한다.) 원티드등에서 내 직군을 검색하면 채용중인 회사가 나오는데 적당한 리스트를 뽑아놓고 초반에 넣어보자. 나는 네카라중 하나, 스타트업 n개 등을 이력서, 면접 연습용으로 지원했었는데 붙었건, 떨어졌건 연습용으로 냈었던 기업들의 이름을 적는건 그래도 예의가 아니라고 생각해서 이름을 밝히지 않는다. 나처럼 첫 이직이면 이력서 작성에 익숙하지 않아서 기업들의 면접을 보고 이력서 내용이 크게 바뀌는 경우가 많으므로 어느정도 텀을 두고 지원한다.가장 가고싶은 기업은 가장 나중에, 또는 '이정도면 어느정도 준비가 되었다'고 본인이 생각할때 쓰길 바란다. 언제 준비가 되었다고 느끼냐면 내가쓴 이력서를 기반으로 면접질문들의 범위를 구체적으로 예상할 수 있고, 면접을 볼때 예상했던 면접질문이 나오며, 그런 질문들에 대해 준비된 답변을 잘 답변할수 있을때 준비가 되었다고 생각한다. 어떤 질문이 들어올지 예상하는 능력은 면접을 보다 보면 길러지고,(이력서의 특정 구간에서 매번 비슷한 질문이 들어온다.) 더 나아가 내가 원하는 답변을 하기 위해 질문을 유도할 수도 있다. 면접도 연습이라고, 처음에는 질문 하나하나에 긴장했지만 경험이 쌓일수록 긴장감은 줄어들었다.면접을 6번정도 본것같은데 코로나라 전부 구글 미트(https://meet.google.com/)로 온라인으로 진행하였으며, 온라인 면접을 위해 마이크가 동봉된 웹캠이 필요했다. 회사 맥북이 있으면 그거로 해도 되긴 하겠지만(사실 나도 초반에는 회사 맥북으로 면접을 몇번 보긴 했다.), 회사 pc라서 찝찝하거나 그러면 웹캠을 하나 구매하는게 좋다. 나는 이 상품을 구매해서 사용했다. 코딩테스트나 이력서를 준비하는 기간이 아닌 실제로 이력서를 내고 면접 보고 하는 기간은 한달, 좀 길게는 두달까지 목표로 잡자. 3달 이상되면 정신적으로도 힘들고 집중력이 떨어지므로, 이력서와 코테 준비가 어느정도 끝나면 그때부터 붙던 떨어지던 짧은 기간 안에 집중해서 끝내버리겠다는 마인드로 빡세게 하는게 좋다. 슬슬 준비해서 가야지~ 하다가는 회사 일이라도 조금 많아서 피곤해져서 늘어지면 몇년이 걸릴지 모른다. 나는 실제로 이력서를 내고 면접 보는 기간을 거의 두달을 가졌는데, 원하는곳에 합격했을때쯤 정신력을 너무 소모해서 가고싶은 나머지 기업들에 대해 추가로 이력서를 낼 생각도 하지 않았었다.개인적으로 지원 초반시기의 면접주기는 일주일에 두번 정도 면접보는정도의 주기가 좋았다. 위에 적었듯이 면접 피드백을 보고 이력서를 더 좋게 수정하는 경우도 상당히 잦았기 때문이다.(난 거의 매번 이력서를 수정했다.)면접볼수있는 최대치의 면접을 보는게 무조건 좋은것은 아니므로 본인의 상황을 보고 판단해서 더 낼지, 덜 낼지 결정하자. 쿠팡에서는 풀재택과 유연 근무를 하고 있어서 면접시간을 잡기가 편했는데도 불구하고 정신력 소모가 컸으니 이점을 유의해서 본인에게 맞는 정도를 찾자. 대부분 회사의 재 지원주기가 6개월 이상, 보통 1년이라고 보므로 한번한번의 기회에서 집중해서 되도록 많이 얻어가자.이번에 실패하면 1년을 더 기다려야 한다. 2. 이력서 작성.이력서 작성 첫단계는 적절한 포맷을 찾는것부터 보통 시작한다. 구글에서 괜찮은 포맷을 찾아보고 꾸며보고 비교하느라 시간을 많이 날렸는데, 나온 결론은 굳이 예쁜 포맷을 찾아보지 말고 그냥 원티드에서 제공해주는 이력서 양식을 쓰자.(원티드 광고 아님.)포맷이 상당히 깔끔한 편이고(개인 의견), 내용이 중요해서 개발자 이력서 포맷이 누가누가 더 예쁜지 전혀 신경쓰지 않는다.(프론트엔드면 또 모르겠다) 난 처음에 구글에 '개발자 이력서 포맷'을 치면 내가 수정할수 있는 샘플 구글 독스 이력서 포맷이 있는데, 그걸 사용했었다가 포기했다. 구글 독스를 잘 쓰지않아서 줄맞춤이나 내가 원하는대로 커스터마이징이 힘들고 깔끔하게 정리되지 않는다고 느꼈기 때문이다. 원티드는 이력서를 출력해보면 깔끔하다는걸 바로 느낄 수 있다. 평타 이상은 한다고 생각해서 나처럼 디자인에 신경 쓰기 싫은사람은 그냥 원티드 이력서 포맷을 쓰는게 낫다. 그리고 순수 내용파트는 1~2장 정도로 요약하는게 가장 깔끔한것 같다. 내 개인적으로는 2장요약을 선호한다. 원티드에서 내용만 1장 정도 적으면 자격증이나 학교였나?때문에 두장이 나오게 되는데 내가 말한 기준은 순수 경력사항 내용파트만 1~2장 정도가 좋다고 본다.(원티드에서 뽑으면 2~3장짜리)다시 적지만 내용이 중요하지 디자인은 별로 중요하지 않다. 지원하는 직군을 면접관이 알 수 있도록 이력서에 명확하게 정립해놓는다. 데이터 엔지니어도 내부적으로 여러가지 데이터 엔지니어들로 나뉘어진다. 데이터 플랫폼 엔지니어, 데이터 파이프라인 엔지니어, DW/BI 엔지니어, 시각화 엔지니어, mlops 관련 엔지니어 등.... 5가지를 적었는데 5가지가 다 롤이 다르다. 구체적으로 이름을 나눠서 모집하는 곳도 있고, 그냥 통합적으로 데이터 엔지니어로 뽑는 곳들도 많다. 보통 개발 인력이 그리 많지 않은 스타트업에서는 모든 일을 하니 직군을 세세하게 나누지 않고 데이터 엔지니어라는 직군으로 통합적으로 뽑고 규모가 있는 기업에서는 세부적인 롤로 나눠서 뽑으며, 롤마다 jd가 다르다. 데이터 플랫폼 엔지니어는 백엔드 개발이 보통 자바 스프링인것처럼 데이터 엔지니어 중에서도 롤이 어느정도 정립이 된 직군이고, 파이프라인 엔지니어는 왠만해서 대부분이 잡부(내 케이스인데 보통 기술 스택이 사람마다 다른게 일반적이다.), DW와 시각화 엔지니어는 정립이 되어있지만 그리 수요자체가 많지는 않고, mlops는 데이터 사이언스팀에서 만들어준 모델링을 자동화하는 엔지니어를 뜻한다.(얘도 어느정도 정립이 되어있다.)직군이 세부적으로 나뉘어져서 모집공고가 있는 곳이면 하는 일을 보고 내가 하는 일이랑 매칭해서 지원할수 있을텐데, 데이터 엔지니어를 통합으로 뽑는 스타트업같은곳에 지원하면 그쪽에서도 내 이력서만 보고 내가 어떤일을 중점으로했나 판단하므로 내 롤의 특징이 확실히 드러나도록 이력서를 작성하는게 좋다. 데이터 플랫폼 엔지니어 롤을 해왔으면 데이터 플랫폼 운영 등을 중점으로, 파이프라인 제작을 많이 해왔으면 파이프라인 제작을 중점으로. 이렇게 내 롤을 확실히 드러내야 면접에서 내가 모르는 다른 데이터 엔지니어링 영역에 대해 질문받는것을 피할 수 있다.(또는 잘 몰라도 마이너스없이 그냥 넘어갈수 있다.) 지금 생각하는건데, 모르는건 모른다고 확실하게 미리 자르고 가는게 이것저것 다 할줄안다고 적었다가 면접에서 털리는것보다 1000배는 더 낫다. 나같은경우 처음에 이력서를 썼을때 내 롤을 모호하게 드러내서 내가 모르는 다른 영역에 대해서까지 질문을 받았었고 답을 못해서 마이너스가 컸다. 난 이런일 안했는데 왜 이런 질문을 했지?했는데 이력서를 모호하게 쓴 내잘못이었다.저쪽에서 a가 필요하고 a를 물어보면 그거에 대해 잘 대답해야 면접에 붙는거 아님? 할수도 있는데 내가 해온게 b이면 b에 대해 강점이 있다고 어필하는게 맞는것 같다. 어색하게 a에 대해 아는척해봐야 왠만해서는 면접에서 물어보면 그냥 털리니, 거짓말하다 들키는것보다는 나는 b전문가이고 a에 대한 지식도 약간은 있다.. 너네가 뽑아주면 그래도 도움은 될거다!는 전략이 맞는것같다.(애초에 jd에 맞게 지원하는게 가장 좋긴 하다.) 첫번째로 이력서를 냈었던 기업은 유니콘 스타트업이었다. 지금보면 이력서에 어떤 부분을 집중해서 보여줘야하는지도 몰라서 막 썼는데 사람이 급했는지 면접을 봤다. 지인들에게 보통 첫면접은 아주 탈탈 털린다는 말을 들었는데 그 말을 듣고 '난 절대로 안털려야지.' 하고 준비를 하고서도 아주 탈탈 털렸다. 이력서 파트니 이력서에 대해서 몇가지 얘기하자면 위에서 말했듯이 면접시에 대답을 깊게 잘 할 자신이 없으면 조금이라도 뭔가를 더 했다는걸 어필하기 위해 전부 적지는 말자. 내가 한 일인데 조금 한거면 지식이 짧다. 그런데 여기서 질문이 조금만 깊게 들어가도 모르는것들이 상당히 많이 나오고 이러면 나 자신에 대한 불신이 생기면서 면접 전반적으로 상당한 마이너스이다.(개인적으로 이런거 걸리면 왠만해서 떨어진다고 생각한다.) 나는 이후 이력서에서 그 내용을 아예 빼버렸다. 나도 이 이야기를 이직준비할때 동기들에게 들었음에도 '그럼 난 준비해서 뛰어난 인재가 돼야지' 하고 생각했는데 첫번째 면접을 보고 깨달았다. 나는 내가 뭘 모르는지 모르고 있었다. 그 분야에 대해 뭘 모르는지도 모르는데 이걸 이력서에 쓰는건 아니라는걸 깨달은 이후 이력서에서 해당 내용을 빼는데 주저함이 없었다.  그리고 기술보다는 비지니스 목표를 중심으로 적자. 지금보면 너무 부끄럽지만 아무것도 몰랐던 내 첫 경력이력서의 일부를 적어본다. 주 제목 : 쿠버네티스 인프라 구축내용 : aws ec2의 오토스케일링 그룹을 기반으로 팀 내에서 사용할 쿠버네티스 환경을 구축하였습니다.(m4.xlarge) 너무너무 기술 중심적인 말이다. 쓸때없이 aws ec2 타입도 적었고 나는 데이터 엔지니어이지, 인프라 담당자가 아님에도 뭔가를 더 보여주기 위해 적었다. 그런데 너무 기술 중심적으로 적으면 면접때 풀어나갈 얘기가 적다. 왜냐하면 저런 기술적인 이야기는 면접에서 할 이야기이기 때문이다.(심지어 aws타입같은건 절대 물어볼 거리가 아닌데 아주 쓸모없는 정보를 이력서에 적었다. 이불킥 각..) 아마 이 이력서를 받았던 기업은 이사람은 왜 이런걸 적었을까? 궁금했을것이다.저렇게 기술적으로 하는일을 적기보다는 비지니스 성과 중심적으로 적자. 현 이력서는 보안때문에 내용을 직접 가져오지는 못하고, 예시를 하나 만들어본다.(참고로 난 추천시스템을 만들지 않았다. 그냥 만든거) 주 제목 : 추천 시스템을 위한 데이터 파이프라인 구축내용 : 개인화 추천 시스템 개발, 사용자 찜상품 관리 프로세스 파이프라인 구축, 머신러닝 지원 파이프라인 개발 위처럼 적는거로 충분하다. 그리고 면접에 들어가서 구체적인 기술에 대해 이야기를 나눈다. 면접관 : 이력서에 찜상품 관리 프로세스 파이프라인 구축이라고 적으셨었는데 어떤 기술을 사용해서 어떻게 구현하셨나요? 요런식으로 대화식으로 이야기를 한다. 그리고 면접을 몇번 보다보면 무의식적으로 적었는데 내가 대답하기 취약한 질문들이 있는데 그런것들은 피하도록 이력서의 세부적인 내용을 계속해서 수정하자.위에서 말했듯이 절대로 기술 중심적으로 적지 말자. 어쩔수없이 기술을 써야할것 같으면 간단하게 적자. 기술 중심적으로 적지 말자는거지 무슨 기술을 사용했는지 간단하게 적는건 좋다고 생각한다. 이 영상은 개인적으로 감명받은 우아한형제들의 ceo인 분이 인터뷰한 유튜브 영상인데 여기서 개발자라면 본인을 코드를 짜는 사람이 아니라 비지니스 문제를 해결하는 사람이라고 생각했으면 좋겠다는 말이 나오는데 내가 주니어를 넘어서서 시니어로 나아갈 큰 틀을 잡는데 정말 중요하게 참고할만한 말인것 같다.이력서를 쓸 때 기술중심으로 쓰지 말고 비지니스 성과를 중심으로 이력서를 쓰자. 3. 코딩테스트코딩테스트는 백엔드 엔지니어와 데이터 엔지니어는 확실히 차이가 있다. 참고로 나는 리트코드를 취미로 풀고 있고 리트코드로만 경력 코딩테스트를 준비했다.내가 지원했던 네카라중 한곳은 직군 구분없이 개발자면 동일한 코딩 테스트를 친다. 난이도는 리트코드 이지, 미디움 하위 정도였다. 여기말고 지원했던 다른 곳들은 전부 대부분 문제의 난이도가 이지~미디움 하위정도였다. 그리고데이터 엔지니어라 그런가 코딩테스트를 본 다른곳들은 전부 sql과 관련된 코테문제가 꼭 한문제는 나왔다.(라이브 코테 포함) sql문제가 최소 한문제이상 나오는데 전부 윈도우 함수를 사용하는 문제가 포함되어있었다. 데이터 엔지니어로 경력 이직을 준비하는 사람은 반드시 윈도우 함수를 공부해야하고, 단순히 개념공부만 한다고 풀수있는 문제가 아닌 경우가 많다. 나같은경우 리트코드를 결제해서 사용하고 있다. 결제를 하면 잠긴 문제를 풀수 있는데, 리트코드의 데이터베이스, 미디움 난이도의 카테고리를 보면 대부분이 윈도우 함수 문제이다. 리트코드에서 sql 미디움만 한 20문제정도를 풀었는데 모든 sql코딩테스트에서 전혀 어려움을 겪지 않았다. 개인적으로 한달치만 결제해서 빡세게 풀어보는걸 추천하고, 그게 아니면 다른 플랫폼도 있으나 애초에 적절하게 풀어볼만한 sql문제 자체가 많지 않기 때문에 이직에 진지하다면 난 그냥 리트코드를 한달 결제하는걸 추천한다.(한달기준 35$, 한화 44000원정도. 링크) 위에 적었듯이 난 리트코트 유료 sql문제를 풀고 코테에 나왔던 sql문제는 전부 풀었다. sql을 제외한 문제들은 블로그의 알고리즘 카테고리를 보면 알수있듯이 알고리즘 문제를 많이 풀어와서 쉬웠다. 이직 준비중에 코테 준비가 가장 걱정이 없었다. 4. 면접위에 적었듯이 구글 미트(행아웃)로 면접을 보며, 1:2, 1:3, 1:4, 1:5 등 다양하게 면접을 봤고, 모든 면접이 다대일면접이었다. 면접에도 여러가지 전략이 필요하다. 면접 초반에는 면접전에 단순히 내 이력서를 한번더 읽고 내가 한 일들을 다시 정리해보고 면접때 면접관님이 질문하면 중구난방으로 그거에 대해서 연관되는 모든것을 다 말하는 방식으로 했었다. 그러니까 나에 대해 모든 정보를 다 던져놓고 판단은 니네가 해. 요런 식이었는데 당연히 이러면 안된다.면접에서 대화시에 두괄식의 대화가 필요하다. 이게 상당히 중요한 이유가 두괄식으로 대화해야 내가 한 일들을 효과적으로 전달할수 있고, 효율적인 정보전달과 더불어 의사소통이 잘 되는 사람인지도 판명되므로 정말로 중요하다고 생각한다. 위의 이력서에서 만들었던 추천 시스템 예시를 다시 가져온다.(다시 적지만 난 추천시스템 관련 일을 하지 않았고 추천 시스템을 어떻게 만드는지도 모른다.)주 제목 : 추천 시스템을 위한 데이터 파이프라인 구축내용 : 개인화 추천 시스템 개발, 사용자가 찜한 상품 프로세스 파이프라인 구축, 머신러닝 지원 파이프라인 개발 면접 초반.면접관 : 개인화 추천시스템을 만들었다 그러는데 뭘 만들었나요?나 : 개인화 추천시스템은 요걸 만들고 저걸 만들고 이렇게 만들었습니다. 그리고 이걸 하다보니 요게 너무 어려워서 요거까지 하게되어서 저것도 만들었습니다.-> 하나 물어봤는데 주제에서 벗어난 내용까지 너무 주절주절했다. 이러면 이후에 면접관이 뭔가를 더 물어보기도 애매하고 이후에 한 얘기를 또하게 된다. 불필요한 커뮤니케이션 비용이 발생하면서 기술적으로 설명을 잘해도 커뮤니케이션적으로 마이너스될 확률이 높다......면접관 : 머신러닝 지원 파이프라인은 어떤걸 개발하셨나요?나 : 아 제가 이거는 아까 말했던것중에 하나인데요~... 어쩌구 저쩌구-> 위에서 한말 비효율적으로 반복.(지양하자.)......면접관 : 요렇게 구현하셨다고 하셨는데 그렇게 구현하신 이유는 뭔가요? 저렇게 구현할수도 있었을텐데요.나 : (그냥 이방법이 더 간단해서 한건데 뭐라고 대답하지) 어.. 이 방법이 괜찮다고 생각해서 저렇게 구현하는건 고려해보지 않았었습니다.-> 질문들에 대해 준비가 되지 않음. 면접 중후반.(물론 아래 내가 적은 예시보다 더 좋은 답이 있을거다.)면접관 : 개인화 추천시스템을 만들었다 그러는데 뭘 만들었나요?나 : 개인화 추천시스템은 요걸 중점으로, 이렇게 만들었습니다. (질문에서 벗어나지 않고 과하지 않은 정제된 답을 한다.)면접관 : 아하 그러면 요걸 만들면서 요러한 문제가 발생했을수도 있을텐데 이건 어떻게 해결하셨을까요? (이 이야기를 할때 다수의 면접관이 요러한 문제가 발생할수 있다는 질문을 이미 여러번 받아서 답변 준비가 되어있다.)나 : 그 문제에 대해서는 요렇게 구현했습니다.면접관 : 요렇게 구현하셨다고 하셨는데 그렇게 구현하신 이유는 뭔가요? 저렇게 구현할수도 있었을텐데요.나 : 제가 이것저것 시도해보면서 비교를 해본 결과 요 시스템이 비해서 이 시스템은 이런 장점이 있었고 현재 시스템의 요러요러한 특성상 요런 구현의 장점을 활용하는게 더 적합하다 생각해서 이걸 하기로 정했습니다. (시스템의 특성에 대해 깊게 고민해보고 생각해봤다는 느낌을 줌. 사실은 비슷한 질문을 여러번 받아서 준비된 답변임.)나 : 그리고 요 문제를 해결하기 위해서 요 인덱스를 사용했습니다. (요 인덱스는 특수한 인덱스. 면접관에게 왜 요 인덱스를 사용했는지 질문을 유도함.)면접관 : 왜 요 인덱스를 사용했나요?나 : 들어오는 데이터가 요러조러한 특성이 있어서 요 인덱스를 사용하는게 맞다고 생각했습니다.면접관 : 그럼 조금 더 깊게 물어볼게요. 요 인덱스의 또다른 특성에 대해 아시나요? (이쯤 오면 면접관의 질문을 유도하는데 성공했고 나는 질문을 유도했던 만큼 당연히 공부를 열심히 해가서 답을 할수 있다.)나 : 네 어쩌구 저쩌구 준비했던 답을 함. 이런식으로 주고받으며 대화 티키타카가 잘 이어져야 한다. 초반에는 종종 특정 기술셋을 사용했었어야한다는 무의식적인 강박이 있어서 기술적으로 답을 많이했었다. 예로 데이터 엔지니어는 일반적으로 데이터 처리시에 스파크를 많이 사용한다. 그런데 꼭 데이터 엔지니어이지만 데이터를 반드시 스파크같이 플랫폼을 써서 해결했다!는 결론이 나오지 않아도 된다. 글로 풀어놓으니 너무나 당연한 이야기지만 스파크는 문제 해결 도구중 하나이며, 문제 해결 도구는 스파크가 아니어도 된다. 다른 문제 해결 도구에 대해 면접관들에게 논리적으로 이야기를 할 수만 있으면 된다. 아래는 예시이다. 면접관 : 스케쥴링은 왜 airflow같은걸 사용하지 않고 크론탭으로 돌렸어요?나 : airflow가 현재 존재하지 않고, 스케쥴링할만한 잡이 별로 없는데 굳이 airflow까지 설치해야할 필요성을 못 느껴서 그랬습니다. airflow를 설치하면 관리까지 해야하니 일이 늘어나는데 굳이 그만한 자원을 더 투자할만한 일이 아니었거든요. 물론 어느정도 규모 이상이 되면 고려하겠지만요.면접관 : 데이터 처리는 주로 어떤것을 사용해서 했나요?나 : 파이썬의 판다스를 많이 썼고 그냥 순수 파이썬으로도 많이 처리했습니다. 요 데이터들은 크기가 작은 경우가 많아서 스파크로 처리하는건 오버스펙이라고 생각했습니다. 그리고 유니콘 스타트업들의 모집공고를 보다 시니어 엔지니어 공고를 보았다. 경력 5년 이상으로 뽑는데, 별 생각없이 경력맞춰서 시니어로 지원했다가 낭패를 봤었다.시니어 면접은 대부분 시스템 디자인 면접을 본다. ex) ""추천 시스템을 설계해보세요."" 그냥 진짜 이것만 딱 던져주고 데이터 처리 플랫폼부터 처리 주기, 모니터링 등등 혼자서 다 설계해야하는데 정말 난감했다. 만들면서 이슈가 생길만한 파트를 물어보면 그 파트에 대해 어떻게 처리할지 설명하면 된다. 이후에 ""가상 면접 사례로 배우는 대규모 시스템 설계 기초"" 라는 책을 사서 읽고 시스템디자인을 가볍게 공부했다. 하필 이 시스템 디자인 설계를 탈탈 털린다는 첫면접에 봐서 멘붕이 두배는 더 크게왔었다. '아니 원래 경력 5년에 이직하려면 이런것도 준비해야돼?' 하고 많이 당황했었는데 이후에 다른 스타트업에서 시스템 디자인 설계 면접을 한번 봤을뿐,(첫번째와 비슷했음) 나머지 회사들에서는 시스템 디자인과 관련된 질문을 받지 않았다. 기술면접은 직접 말을 내뱉고 상대방과 의사소통하는것이기 때문에 내가 시뮬레이션했던거와는 다르다. 실전 면접에서는 말을 내뱉다가 필요한 문장을 빠트릴 수도 있고, 막히는 경우도 있다. 이를 위해 집에서 혼자 소리내어 내뱉는 연습을 해보자. 이건 내 동기가 추천해준 방법인데 효과가 괜찮은것 같다. 많은 개발자가 코로나라 재택근무하면서 말수가 줄어들었을텐데, 소리내어 연습하는 훈련은 이를 보완해준다. 솔직히 민망하긴 한데 이런 훈련이 내 연봉을 올려준다고 생각하면 민망함이 사라진다. 그리고 가장 중요한것중 하나로 면접이 끝나자마자 답을 못했거나 애매했던 면접 질문들을 정리해야한다. 하루만 지나도 많은 질문들이 기억이 나지 않는다. 난 안했던건데 면접을 온라인으로 진행할 경우 녹음기를 키고 면접을 보는것도 괜찮은것 같다. 내가 어떤부분에서 답변을 잘 못했는지, 어떤 내용을 말했었어야 하는데 말을 못했는지 등을 파악할수 있다고 한다. 나는 내목소리듣는게 민망해서 녹음은 안하고 면접후 바로 메모장에 정리해놓는 방식으로 했었다. 기술적인 부분에 관해서는 백엔드 동기들에게 들었던것들중 나와 겹치는것같은 부분들을 준비해갔었다. 예로 백엔드는 mysql index구조를 종종 물어본다고 한다. 나도 공부를 했다. mysql index구조는 b+ tree구조이고 브랜치가 어쩌고, 리프가 어쩌고, b tree와의 차이점은 어쩌고를 다 공부했는데 mysql index구조를 물어봤던 면접은 한곳도 없었다.기술적으로 세세하게 들어가는 질문보다는 내가 해왔던 업무와 내가 기술을 도입시에 여러가지 고민을 해봤는지(별생각없이 쓰지는 않았는지), 문제해결력과 관련된 질문을 받았는데, 이건 내 이력서가 잡다한 여러 일을 했다고 적어서 특정 기술을 기술적으로 깊게 물어보기보다는 개발자로써의 전반적인 역량을 파악하는게 더 좋다고들 생각해서 이랬던것같다.지금 다시 생각해보니 내가 정말 데이터 엔지니어로써 하나만 깊게 팠었으면(mlops만 한다던지, 데이터 웨어하우스 제작만 한다던지)였다면 이러한 내용들에 대해 깊게 질문했을것 같다.나는 데이터 엔지니어가 보통 스파크를 많이쓰니 스파크에 대해 깊게 공부했다. 스파크의 메모리 구조가 어떻고, dataframe이 어떻고 등등. 근데 예상했던 스파크에 관한 얕은 기술적인 질문은 들어왔지만 깊은 질문들은 들어오지 않았다. 이력서가 완성되고,(본인이 느끼기에 이정도면 잘썼다, 바꿀게 없다라고 생각하는 시점) 바뀌지 않는 이력서로 면접을 2,3번정도 보면 물어보는 질문들 리스트가 어느정도 정형화된다.(어느 타이밍에 어느 질문이 많이 나오는지도.) 대답하기 힘든 질문들이 나오고, 대답하기 힘든 질문에 대해서는 이미 다른곳에서 받은 질문이면 생각해봤던 문제지만 모르는척하고 미리 생각했던 좋은 답을 낸다던지, 일부러 내 문제해결력을 어필하기 위해 어떠한 위기가 있었다는 식으로 이야기를 풀어나가서 어떻게 해결했나요? 하는 질문을 유도한다던지. 하는 능청(?)이 필요하다.(면접을 어느정도 보다 보면 이 다음에 나올 질문이 벌써 예상되어서 물어보기도 전에 먼저 말이 나오기도 한다.) 이런 경험 때문에 다들 가장 가고싶은곳은 맨 마지막에 쓰라고 하는것같다. 내 추측인데 주변 이야기와 경험을 종합해보면 주니어 연차(보통 경력 3년까지)는 cs지식이나 기본기, 시키는 일에 대해서 1인분은 할수 있겠나, 성장성은 어떻게되나를 중점적으로 체크하는것 같은데 중니어 연차(경력 5년부터 9년정도까지)는 기본기도 보지만 좀더 나아가서 한 프로젝트에 대해 혼자서 맡아서 진행할수 있는지? 정도를 보는것 같다. 신입때는 배우겠다는 말을 하는 사람이 많은데 경력이직이면 주니어여도 이제는 프로이므로 배우겠다는 식의 표현은 하지 않는게 좋은것같다. 5. 최종결과가고싶었던 회사 3개.카카오뱅크 : 서류탈. (이력서를 쓸줄 몰랐을때 냈다. 개발자 대란이라는데 면접까지는 보겠지! 하는 무대포 자신감으로 냈는데 그냥 서류탈했다. 이때 충격먹고 이력서를 다시쓰기 시작했다. 지금 생각해도 뭔 자신감이었는지 모르겠다.)당근마켓 : 서류탈. (여러곳 면접보고 거의 마지막에 낸거라 이력서도 잘 썼고, 내부 지인에게 추천 버프도 받았는데 서류탈. 이유가 궁금해서 물어보니 사용해온 기술셋이 맞지 않는다고 한다. 면접은 볼줄 알았는데 좀 충격..)우아한형제들 : 최종합 총 최종결과.서류탈 : 유니콘 스타트업 하나, 네카라중 하나, 카카오뱅크, 당근마켓면접탈 : 작은 스타트업 하나, 유니콘 스타트업 둘최종합 : 중간 스타트업 둘, 우아한형제들 우아한형제들 입사 예정. 6. 개인적인 추가의견코테 준비는 중간에 좀 쉬더라도 꾸준히 하자. 물론 코테 안보는곳 지원해서 합격하면 되겠지만 이직을 결심하게 되고 실제 지원까지 오래걸리는 많은 경우가 코테에 대한 자신감 부족 때문이 많은것같다. 이제 이직생각이 없으면 모를까 코테는 중간에 몇달 쉬더라도 다시 조금씩 해서 감을 잡아놓자. 난 정말 코테가 안맞는다 싶으면 빨리 마음먹고 면접만 보는곳을 쓰던가 과제만 보는 곳들을 중점적으로 지원하자. 요즘은 코테 안보면서도 괜찮은 곳들이 은근히 많다.(ex) 토스는 코테를 안본다.) 같은 직군의 인맥을 되도록 많이 만들어놓자. 회사 내의 내부사정을 들을 수 있을 뿐더러, 바깥에 공개되지 않는 추천으로만 뽑는 채용공고정보등도(히든퀘스트라고들 한다..) 얻을 수 있고 같이 일했던 사람이면 내부추천의 영향력이 있다. 나도 어느정도 느낀것같고 나 외에 다른 동기들과 이야기할때도 추천의 영향력을 어느정도 느꼈다고들 한다.면접을 볼때 처음보는 사람이면 면접관들이 ??? 하면서 들어오지만 어느정도 괜찮은 지인의 추천이면 이미 면접보기 전부터 지원자에게 미세한 호감버프를 갖고 면접을 시작한다고 보면 된다. 왜냐면 기본적으로 인성이던 실력이던 어느정도 괜찮다는게 1차적으로 증명이 되었다는 거니(추천해주는 사람이 인성이던 실력이던 나를 별로라고 생각했으면 추천을 안 해줬을거니까.) 기본실력만 면접으로 어느정도 검증이 되면 나는 뽑는걸 고려해볼만한 인재가 되는거다.추천을 안 받은 곳의 면접에서 100을 증명해야 합격하는 느낌이면, 추천을 받았던 곳은 70~90(기업마다 다르다는 의미)정도만 보여줘도 되었던것 같다. 사실 내가 면접을 그렇게 많이 보지 않아서 명확하게 말하긴 힘들고 그냥 순수 내 느낌이다. 이제와서 다시 깊게 생각해보면, 내 사례말고도 동기들의 사례까지 종합해보면 특히 스타트업의 경우에 추천의 영향력이 더 큰것같았다.(실력하방을 좀더 중요시하는 느낌?)혹은 내가 추천받은곳들은 추천받고 떨어지면 민망하니까 여기저기서 미리 연습하고 거의 이직준비의 끝부분에 몰려있어서 실제 난이도는 다른곳들과 비슷했고, 추천의 영향력은 딱히 없었지만 내가 면접에 익숙해져서 더 쉽게 느꼈던걸 추천의 힘으로 생각했을수도 있다. 여러 사람들의 말을 들어보면 추천 영향력이 딱히 없었다는 사람들도 많아서 여러 케이스가 있는것 같긴 한데 내가 보기에 위에도 적었지만 스타트업의 경우에 좀더 영향력이 있었던것 같고 대기업이라도 받아서 나쁠건 당연히 없으니 받도록 노력하자.내가 받게되는 추천버프의 정도는 나를 추천해준 사람이 현재 그 회사에서 괜찮은 사람인가, 같이 직접적으로 일을 했던 사람인가, 현재 내가 지원하는 팀의 맴버인가 등등에 따라 추가되는 효과의 정도가 다른 것 같다.추가로 우형에 들어와서 직원들이 CEO나 인사팀에게 질문을 하는 시간이 있는데, 여기에 어떤분이 왜 내가 추천한 인재들은 전부 떨어지는지 질문을(가장한 하소연) 한 사람이 있는거보면 또 그렇게 추천 영향력이 생각만큼 없는것같기도 하고? 그렇다. 그리고 이건 동기들이나 아주 친한 인맥만 해당되는 이야기일것 같은데 나와 같은연차가 다른 회사에서 어느정도의 보상을 받고있는지 알수있다.(보통 친하지 않는이상 연봉얘기는 잘 안하니.) 그것을 기반으로 최종합격후 내가 제시할수 있는 연봉의 대략치를 알 수 있으니 상당히 좋은 정보이다. (물론 전직장 베이스라서 상한선은 있으나 최대한 효율을 내는게 좋으니)나같은 경우는 스타트업이나 네카라로 간 동기들 5명정도에게서 계약연봉과 원천징수를 들어서 어디 합격했을때 어느정도를 제시하면 좋을지, 그 이하면 안가는게 맞는것같은지 등의 데이터를 가지고 있었다. 이 정보가 없으면 가는곳에서 내 연봉을 후려치는 것인지, 잘 대우해주는건지 평타인지 알수있어서 좋다. 별생각없이 회사측에서 현연봉에서 500올려서 제시가 왔고 나는 그정도면 만족해서 싸인했는데.. 알고보니 내 동기들은 그 회사 들어갈때 1000씩 올리고 갔으면.? 물론 면접 결과에 따라 다르고 동기가 1000을 올렸다고 나도 1000 올릴수 있다는 보장이 있는건 아니나 이미 정보를 알고 말이라도 꺼내봤으면 후회는 안하지 않을까 싶다.보상에 대해서는 같은 경력의 나보다 더 많이 받는 사람을 보고 현타(?)를 원동력으로 이직을 준비하자. 정신적으로 스트레스를 많이 받는 경우도 많은데, 이런 경우를 잘 조절하자. 무조건 남과 비교만 하다가는 너무 불행해질수 있다. 보상을 알고 나면 현타때문에 일을 못하는 사람들도 많은데, 커리어나 보상에 욕심이 있으면 알아야 할 정보이므로 미리미리 대략적으로는 알아둬서 충격을 낮춰두자. 나같은 경우도 만약 내가 평균보다 못받는 케이스면 현타때문에 일을 잘 못하겠는 경우인데, 나는 이직생각이 없는 기간에는 다른 사람들에게 서로 보상정보는 말하지 말자고 한다. 그러다가 이번에 이직하고 싶을때 내 자신이 이직공부를 더 열심히 준비할수 있게끔 보상정보를 듣고 '이직하면 훨씬 더 받을수 있는데 이직못하면 난 바보 멍청이다'로 나 자신을 압박하면서 공부를 불태우는 수단으로 사용했다.(물론 이러다 이직실패하면 현 직장에서 현타만 커지니 알아서 잘하자..)아니면 아예 포기하고 이런 보상에 관한 정보들은 아예 모르고 나만 행복하게 만족하면서 일하는것도 괜찮은것같다. 연봉이라는게 한번 알게되면 긍정적으로는 끊임없는 자기개발의 원동력이 되지만 부정적으로는 불행의 씨앗이 될수도 있으니말이다. 그리고 지인들에게 합격한 이력서나 면접 관련 정보도 얻을수 있을테니 잘 참고하자. 글을 읽으면서 내 연봉정보나 이력서를 준다고?하고 의문을 갖는 사람들도 있을텐데 주니어 레벨에서는 특히 서로 공유하는 케이스가 은근히 많고 지금도 친한 동기와는 보상정보를 공유하면서 어디가 잘주네 저기가 잘주네 이런 이야기를 많이 한다.(물론 다른 회사 동기들)나도 처음 이직 이력서를 작성할때 어떻게 작성해야 할지 몰라서 좋은곳 합격한 동기들의 이력서를 4개정도 받아서 참고하고 첨삭받았다. 신입때는 별 정보가 없었으니 인맥 그런게 뭐가중요해. 나만 잘하면 이직 잘하고 잘먹고 잘산다~ 인 마인드였으면, 지금은 나름 이런 인맥이나 정보의 중요성을 알았다고 해야 하나.. 그렇다. 그리고 이직 경험이 없으면 지금 이직생각이 없더라도 반드시 시간을 내서 이직준비를 해보고 최종합격까지 가보자. 내가 상상했던, 들었던 이직 프로세스와 실제로 겪는것은 정말로 다르다. 난 처음에 지금 개발자 대란이고, 이직이 잘되는 연차이고, 현직장도 괜찮고, 공부도 계속 해와서 10곳 넣으면 반이상은 최종합할줄알았다. 이 근자감이 처음 넣은 기업에서 서탈, 첫 면접때에는 털리는등 바사삭 깨지면서 현실파악을 빠르게해서 다행인것 같다. 그리고 깨달은점은 최종합격까지 한번은 겪어봐야 나중에 내가 진짜로 이직하고싶을때 할수있다는거다. 지금 이직 생각이 없더라도 1,2년후에 이직 생각이 있다면 이번년에 반드시 끝까지는 가보자. 안하면 막상 실제로 이직하고싶은 년도에 실패하고 연습해둘걸.. 후회할 확률도 높다.이직 시도도 해보고, 떨어져도 봐야 내가 정말로 어떤 부분이 부족한지 깨닫고 현실파악을 할 수 있다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//qkqhxla1.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1193}공유하기게시글 관리archives 'private > memo' 카테고리의 다른 글개발자들이 개발쪽으로 가려고 하는 비전공자들에게 가지 말라고 하는 이유  (5)2021.01.10해외 스톡옵션 행사 가이드  (8)2020.11.18구글 푸바 챌린지 후기(구글 신입 엔지니어 인터뷰 준비 후기)  (0)2020.08.11가져온 링크 : 난 대기업 상무직을 내려놓고 스타트업의 개발자가 되었다  (0)2020.08.09취업을 위한 알고리즘 공부법.  (112)2019.01.10'private/memo'의 다른글이전글개발자들이 개발쪽으로 가려고 하는 비전공자들에게 가지 말라고 하는 이유현재글데이터 엔지니어 경력 5년 이직준비 후기관련글개발자들이 개발쪽으로 가려고 하는 비전공자들에게 가지 말라고 하는 이유2021.01.10해외 스톡옵션 행사 가이드2020.11.18구글 푸바 챌린지 후기(구글 신입 엔지니어 인터뷰 준비 후기)2020.08.11가져온 링크 : 난 대기업 상무직을 내려놓고 스타트업의 개발자가 되었다2020.08.09댓글 50이전 댓글 더보기    setInitialEntryComments(1193, 1723595215)비밀글등록loadedComments[1193]=true;findFragmentAndHighlight(1193);프로그래밍 좋아합니다. 자료 퍼가실때는 참조만 적어주세요.. study (973)  setting, git, shell etc (21)  machine learning, image (27)  data engineering (93)  Python (140)  2.7 information (74)  2.7 simple coding(+ c++) (42)  2.7 for fun. (24)  web (27)  back + front (22)  etc (5)  kotlin (0)  algorithm (210)  theory (51)  problem solving (159)  webhacking (180)  sql, sql injection (98)  client (28)  etc (54)  systemhacking (34)  practice (25)  background (9)  private (0)  면접 (0)  memo (56)  Vancouver diary (77)  business trip (10)  normal diary (80)  English (17) Tag최근글과 인기글최근글인기글2023-03-27 월요일2023.03.27 22:022022-12-16 금요일2022.12.16 18:502022-10-13 목요일2022.10.13 23:04데이터 엔지니어 경력 5년 이직준비 후기2022.04.27 12:33취업을 위한 알고리즘 공부법.2019.01.10 11:01json.loads 에러시 위치 찾는 방법 꿀팁2019.12.02 14:06최근댓글네 위에 메일로 보내주세요.qkqhxla1안녕하세요.qkqhxla1@naver.com으로 보내주세요.qkqhxla1안녕하세요.qkqhxla1@naver.com으로 보내주세요.qkqhxla1공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2023/032022/122022/102022/06Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total722,589Today : 8Yesterday : 104Copyright © Kakao Corp. All rights reserved.관련사이트Hide지훈현서님 (python developer)백준 온라인 저지 블로그.(매우 유용)티스토리툴바archives구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""1730919-1193"",""customProps"":{""userId"":""0"",""blogId"":""1730919"",""entryId"":""1193"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1193"",""entryTitle"":""데이터 엔지니어 경력 5년 이직준비 후기"",""entryType"":""POST"",""categoryName"":""private/memo"",""categoryId"":""557080"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""1249158"",""authorNickname"":""qkqhxla1"",""blogNmae"":""archives"",""image"":""kage@bDY2Xx/btrAFNK9TiL/Ik1kOfxaxvnKbK9gbR9uyk"",""plink"":""/1193"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
20,https://dev-coco.tistory.com/153,💡 Java의 특징을 설명해주세요.,"신입 개발자 기술면접 질문 정리 - 자바by coco3o📌ETC/Tech Interview2022.02.18반응형(adsbygoogle = window.adsbygoogle || []).push({});💡 Java의 특징을 설명해주세요.Java는 객체지향 프로그래밍 언어입니다. 기본 자료형을 제외한 모든 요소들이 객체로 표현되고, 객체 지향 개념의 특징인 캡슐화, 상속, 다형성이 잘 적용된 언어입니다.장점JVM(자바가상머신) 위에서 동작하기 때문에 운영체제에 독립적이다.GabageCollector를 통한 자동적인 메모리 관리가 가능하다.단점JVM 위에서 동작하기 때문에 실행 속도가 상대적으로 느리다.다중 상속이나 타입에 엄격하며, 제약이 많다.💡 JVM의 역할에 대해 설명해주세요.JVM은 스택 기반으로 동작하며, Java Byte Code를 OS에 맞게 해석 해주는 역할을 하고 가비지컬렉션을 통해 자동적인 메모리 관리를 해줍니다.💡 Java의 컴파일 과정에 대해 설명해주세요.개발자가 .java 파일을 생성한다.build를 한다.java compiler의 javac의 명령어를 통해 바이트코드(.class)를 생성한다.Class Loader를 통해 JVM 메모리 내로 로드한다.실행엔진을 통해 컴퓨터가 읽을 수 있는 기계어로 해석된다.(각 운영체제에 맞는 기계어)💡 Java에서 제공하는 원시 타입들에 무엇이 있고, 각각 몇 바이트를 차지하나요?정수형 byte, short, int, long 실수형 float, double 문자형 char 논리형 boolean이 있고,정수형 1, 2, 4, 8, 실수형 4, 8, 문자형 2, 논리형 1 바이트를 차지합니다.💡 오버라이딩(Overriding)과 오버로딩(Overloading)에 대해 설명해주세요.오버라이딩(Overriding)은 상위 클래스에 있는 메소드를 하위 클래스에서 재정의 하는 것을 말하고,오버로딩(Overloading)은 매개변수의 개수나 타입을 다르게 하여 같은 이름의 메소드를 여러 개 정의하는 것을 말합니다.💡 객체지향 프로그래밍(OOP)에 대해 설명해주세요.우리가 실생활에서 쓰는 모든 것을 객체라 하며, 객체 지향 프로그래밍은 프로그램 구현에 필요한 객체를 파악하고 상태와 행위를 가진 객체를 만들고 각각의 객체들의 역할이 무엇인지를 정의하여 객체들 간의 상호작용을 통해 프로그램을 만드는 것을 말합니다.즉, 기능이 아닌 객체가 중심이며 ""누가 어떤 일을 할 것인가?""가 핵심특징으로는 캡슐화, 상속, 다형성, 추상화 등이 있고, 모듈 재사용으로 확장 및 유지보수가 용이합니다.💡 try-with-resources에 대해 설명해주세요.try-with-resources는 try-catch-finally의 문제점을 보완하기 위해 나온 개념입니다.try( ... ) 안에 자원 객체를 전달하면, try블록이 끝나고 자동으로 자원 해제 해주는 기능을 말합니다.따로 finally 구문이나 모든 catch 구문에 종료 처리를 하지 않아도 되는 장점이 있습니다.try-with-resources 알아보기💡 불변 객체가 무엇인지 설명하고 대표적인 Java의 예시를 설명해주세요.불변 객체는 객체 생성 이후 내부의 상태가 변하지 않는 객체를 말합니다.Java에서는 필드가 원시 타입인 경우 final 키워드를 사용해 불변 객체를 만들 수 있고,참조 타입일 경우엔 추가적인 작업이 필요합니다.💡 참조 타입일 경우 추가적인 작업은 어떤게 있는지 설명해주세요.더보기참조 타입은 대표적으로 1.객체를 참조할 수도 있고, 2.배열이나 3.List 등을 참조할 수 있습니다. 1. 참조 변수가 일반 객체인 경우 객체를 사용하는 필드의 참조 변수도 불변 객체로 변경해야 합니다. 2. 배열일 경우 배열을 받아 copy해서 저장하고, getter를 clone으로 반환하도록 하면 됩니다.(배열을 그대로 참조하거나, 반환할 경우 외부에서 내부 값을 변경할 수 있음. 때문에 clone을 반환해 외부에서 값 변경하지 못하게 함) 3. 리스트인 경우에도 배열과 마찬가지로 생성시 새로운 List를 만들어 값을 복사하도록 해야 합니다.배열과 리스트는 내부를 복사하여 전달하는데, 이를 방어적 복사(defensive-copy)라고 합니다. 💡 불변 객체나 final을 굳이 사용해야 하는 이유가 있을까요?더보기불변 객체나 final 키워드를 사용해 얻는 이점은 다음과 같습니다. 1. Thread-Safe하여 병렬 프로그래밍에 유용하며, 동기화를 고려하지 않아도 된다.(공유 자원이 불변이기 때문에 항상 동일한 값을 반환하기 때문) 2. 실패 원자적인 메소드를 만들 수 있다.(어떠한 예외가 발생되더라도 메소드 호출 전의 상태를 유지할 수 있어 예외 발생 전과 똑같은 상태로 다음 로직 처리 가능) 3. 부수효과를 피해 오류를 최소화 할 수 있다.※ 부수효과 : 변수의 값이 바뀌거나 객체의 필드 값을 설정하거나 예외나 오류가 발생하여 실행이 중단되는 현상 4. 메소드 호출 시 파라미터 값이 변하지 않는다는 것을 보장할 수 있다. 5. 가비지 컬렉션 성능을 높일 수 있다.(가비지 컬렉터가 스캔하는 객체의 수가 줄기 때문에 Gc 수행 시 지연시간도 줄어든다.)💡 추상 클래스와 인터페이스를 설명해주시고, 차이에 대해 설명해주세요.추상 클래스는 클래스 내 추상 메소드가 하나 이상 포함되거나 abstract로 정의된 경우를 말하고,인터페이스는 모든 메소드가 추상 메소드로만 이루어져 있는 것을 말합니다.공통점new 연산자로 인스턴스 생성 불가능사용하기 위해서는 하위 클래스에서 확장/구현 해야 한다.차이점인터페이스는 그 인터페이스를 구현하는 모든 클래스에 대해 특정한 메소드가 반드시 존재하도록 강제함에 있고, 추상클래스는 상속받는 클래스들의 공통적인 로직을 추상화 시키고, 기능 확장을 위해 사용한다.추상클래스는 다중상속이 불가능하지만, 인터페이스는 다중상속이 가능하다.💡 싱글톤 패턴에 대해 설명해주세요.싱글톤 패턴은 단 하나의 인스턴스를 생성해 사용하는 디자인 패턴입니다.인스턴스가 1개만 존재해야 한다는 것을 보장하고 싶은 경우와동일한 인스턴스를 자주 생성해야 하는 경우에 주로 사용합니다. (메모리 낭비 방지)싱글톤 패턴(Singleton Pattern)알아보기💡 싱글톤 패턴의 대표적인 예시를 간단하게 설명해주세요.더보기싱글톤 패턴의 대표적인 예시는 Spring Bean 입니다.스프링의 빈 등록 방식은 기본적으로 싱글톤 스코프이고, 스프링 컨테이너는 모든 빈들을 싱글톤으로 관리합니다. 스프링은 요청할 때마다 새로운 객체를 생성해서 반환하는 기능도 제공한다. (프로토타입 빈, @Scope(""prototype""))💡 가비지 컬렉션(Garbage Collection)에 대해 설명해주세요.가비지 컬렉션은 JVM의 메모리 관리 기법 중 하나로 시스템에서 동적으로 할당됐던 메모리 영역 중에서 필요없어진 메모리 영역을 회수하여 메모리를 관리해주는 기법입니다.💡 가비지 컬렉션 과정에 대해 설명해주세요.더보기GC의 작업을 수행하기 위해 JVM이 어플리케이션의 실행을 잠시 멈추고, GC를 실행하는 쓰레드를 제외한 모든 쓰레드들의 작업을 중단 후 (Stop The World 과정) 사용하지 않는 메모리를 제거(Mark and Sweep 과정)하고 작업이 재개됩니다.++ GC의 작업은 Young 영역에 대한 Minor GC와 Old 영역에 대한 Major GC로 구분됩니다.💡 객체지향의 설계원칙에 대해 설명해주세요.SRP - 단일 책임 원칙 : 한 클래스는 하나의 책임만 가져야 한다.OCP - 개방-폐쇄 원칙 : 확장에는 열려있고, 수정에는 닫혀있어야 한다.LSP - 리스코프 치환 원칙 : 하위 타입은 항상 상위 타입을 대체 할 수 있어야 한다.ISP - 인터페이스 분리 원칙 : 인터페이스 내에 메소드는 최소한 일수록 좋다. (하나의 일반적인 인터페이스보다 여러 개의 구체적인 인터페이스가 낫다.) SRP와 같은 문제에 대한 두 가지 다른 해결책이다.DIP - 의존관계 역전 원칙 : 구체적인 클래스보다 상위 클래스, 인터페이스, 추상클래스와 같이 변하지 않을 가능성이 높은 클래스와 관계를 맺어라. DIP 원칙을 따르는 가장 인기 있는 방법은 의존성 주입(DI)이다.객체지향 설계원칙 SOLID 자세히 알아보기💡 자바의 메모리 영역에 대해 설명해주세요.자바의 메모리 공간은 크게 Method 영역, Stack 영역, Heap 영역으로 구분되고, 데이터 타입에 따라 할당됩니다.메소드(Method) 영역 : 전역변수와 static변수를 저장하며, Method영역은 프로그램의 시작부터 종료까지 메모리에 남아있다.스택(Stack) 영역 : 지역변수와 매개변수 데이터 값이 저장되는 공간이며, 메소드가 호출될 때 메모리에 할당되고 종료되면 메모리가 해제된다. LIFO(Last In First Out) 구조를 갖고 변수에 새로운 데이터가 할당되면 이전 데이터는 지워진다.힙(Heap) 영역 : new 키워드로 생성되는 객체(인스턴스), 배열 등이 Heap 영역에 저장되며, 가비지 컬렉션에 의해 메모리가 관리되어 진다.💡 각 메모리 영역이 할당되는 시점은 언제인가요?더보기Method 영역 : JVM이 동작해서 클래스가 로딩될 때 생성Stack 영역 : 메소드가 호출될 때 할당Heap 영역 : 런타임시 할당💡 클래스와 객체에 대해 설명해주세요.클래스는 객체를 만들어내기 위한 설계도 혹은 틀 이라고 할 수 있고, 객체를 생성하는데 사용합니다.객체는 설계도(클래스)를 기반으로 생성되며, 자신의 고유 이름과 상태, 행동을 갖습니다. 여기서 상태는 필드(fields), 행동은 메소드(Method)라고 표현합니다. 객체에 메모리가 할당되어 실제로 활용되는 실체는 '인스턴스'라고 부릅니다.💡 생성자(Constructor)에 대해 설명해주세요.생성자는 클래스와 같은 이름의 메소드로, 객체가 생성될 때 호출되는 메소드입니다.명시적으로 생성자를 만들지 않아도 default로 만들어지며, 생성자는 파라미터를 다르게하여 오버로딩할 수 있습니다.💡 Wrapper Class란 무엇이며, Boxing과 UnBoxing은 무엇인지 설명해주세요.기본 자료형(Primitive data type)에 대한 객체 표현을 Wrapper class라고 합니다.기본 자료형 → Wrapper class로 변환하는 것을 Boxing이라 하며,Wrapper class → 기본 자료형으로 변환하는 것을 UnBoxing이라 합니다.Wrapper클래스란? 💡 Synchronized에 대해 아는 대로 말해주세요.여러 개의 쓰레드가 한 개의 자원을 사용하고자 할 때, 현재 데이터를 사용하고 있는 쓰레드를 제외하고 나머지 쓰레드들은 데이터에 접근할 수 없게 막는 개념입니다.데이터의 thread-safe를 하기 위해 자바에서 Synchronized 키워드를 제공해 멀티 쓰레드 환경에서 쓰레드간 동기화를 시켜 데이터의 thread-safe를 보장합니다.Synchronized는 변수와 메소드에 사용해서 동기화 할 수 있으며, Synchronized 키워드를 남발하게 되면 오히려 프로그램의 성능저하를 일으킬 수 있습니다.💡 new String()과 리터럴("""")의 차이에 대해 설명해주세요.new String()은 new 키워드로 새로운 객체를 생성하기 때문에 Heap 메모리 영역에 저장되고,""""는 Heap 안에 있는 String Constant Pool 영역에 저장됩니다.https://www.journaldev.com/797/what-is-java-string-pool💡 String, StringBuffer, StringBuilder의 차이를 설명해주세요.String은 불변의 속성을 가지며, StringBuffer와 StringBuilder는 가변의 속성을 가집니다.StringBuffer는 동기화를 지원하여 멀티 쓰레드 환경에서 주로 사용하며,StringBuilder는 동기화를 지원하지 않아 싱글 쓰레드 환경에서 주로 사용합니다.String, StringBuffer, StringBuilder의 차이와 장단점 💡 String 객체가 불변인 이유에 대해 아는대로 설명해주세요.더보기1. 캐싱 기능에 의한 메모리 절약과 속도 향상- Java에서 String 객체들은 Heap의 String Pool 이라는 공간에 저장되는데, 참조하려는 문자열이 String Pool에 존재하는 경우 새로 생성하지 않고 Pool에 있는 객체를 사용하기 때문에 특정 문자열 값을 재사용하는 빈도가 높을 수록 상당한 성능 향상을 기대할 수 있다.2. thread-safe- String 객체는 불변이기 때문에 여러 쓰레드에서 동시에 특정 String 객체를 참조하더라도 안전하다.3. 보안기능- 중요한 데이터를 문자열로 다루는 경우 강제로 해당 참조에 대한 문자열 값을 바꾸는 것이 불가능하기 때문에 보안에 유리하다.💡 접근 제한자(Access Modifier)에 대해 설명해주세요.변수 또는 메소드의 접근 범위를 설정해주기 위해서 사용하는 Java의 예약어를 의미하며, 총 4 가지 종류가 있습니다.public - 접근 제한이 없다. (같은 프로젝트 내 어디서든 사용 가능)protected - 해당 패키지 내, 다른 패키지에서 상속받아 자손 클래스에서 접근 가능하다.(default) - 해당 패키지 내에서만 접근 가능private - 해당 클래스에서만 접근 가능💡 클래스 멤버 변수 초기화 순서에 대해 설명해주세요.static 변수 선언부 : 클래스가 로드 될 때 변수가 제일 먼저 초기화 된다.필드 변수 선언부 : 객체가 생성될 때 생성자 block 보다 앞서 초기화 된다.생성자 block : 객체가 생성될 때 JVM이 내부적으로 locking( thread-safe 영역 ) 💡 static에 대해 설명해주세요.static 키워드를 사용한 변수나 메소드는 클래스가 메모리에 올라갈 때 자동으로 생성되며 클래스 로딩이 끝나면 바로 사용할 수 있습니다. 즉, 인스턴스(객체) 생성 없이 바로 사용 가능합니다.모든 객체가 메모리를 공유한다는 특징이 있고, GC 관리 영역 밖에 있기 때문에 프로그램이 종료될 때까지 메모리에 값이 유지된 채로 존재하게 됩니다.static 변수와 static 메소드💡 static을 사용하는 이유에 대해 설명해주세요.더보기static은 자주 변하지 않는 값이나 공통으로 사용되는 값 같은 공용자원에 대한 접근에 있어서 매번 메모리에 로딩하거나 값을 읽어들이는 것보다 일종의 '전역변수'와 같은 개념을 통해 접근하는 것이 비용도 줄이고 효율을 높일 수 있습니다.인스턴스 생성 없이 바로 사용 가능하기 때문에 프로그램 내에서 공통으로 사용되는 데이터들을 관리할 때 이용합니다.💡 Inner Class(내부 클래스)의 장점에 대해 설명해주세요.1. 내부 클래스에서 외부 클래스의 멤버에 손쉽게 접근할 수 있다.2. 서로 관련 있는 클래스를 논리적으로 묶어서 표현함으로써, 캡슐화를 증가시키고, 코드의 복잡성을 낮출 수 있다.3. 외부에서는 내부 클래스에 접근할 수 없으므로, 코드의 보안성을 높일 수 있다.💡 리플렉션(Reflection)이란 무엇인지 설명해주세요.리플렉션이란 구체적인 클래스 타입을 알지 못해도 그 클래스의 메소드, 타입, 변수들에 접근할 수 있도록 해주는 자바 API 입니다.💡 리플렉션은 어떤 경우에 사용되는지 설명해주세요.더보기코드를 작성할 시점에는 어떤 타입의 클래스를 사용할지 모르지만, 런타임 시점에 지금 실행되고 있는 클래스를 가져와서 실행해야 하는 경우 사용됩니다.프레임워크나 IDE에서 이런 동적인 바인딩을 이용한 기능을 제공합니다. intelliJ의 자동완성 기능, 스프링의 어노테이션이 리플렉션을 이용한 기능이라 할 수 있습니다.💡 Error와 Exception의 차이를 설명해주세요.Error는 실행 중 일어날 수 있는 치명적 오류를 말합니다. 컴파일 시점에 체크할 수 없고, 오류가 발생하면 프로그램은 비정상 종료되며 예측 불가능한 UncheckedException에 속합니다.반면, Exception은 Error보다 비교적 경미한 오류이며, try-catch를 이용해 프로그램의 비정상 종료를 막을 수 있습니다.예외 처리(Exception) 알아보기💡 CheckedException과 UnCheckedException의 차이를 설명해주세요.CheckedException은 실행하기 전에 예측 가능한 예외를 말하고, 반드시 예외 처리를 해야 합니다.대표적인 Exception - IOException, ClassNotFoundException 등UncheckedException은 실행하고 난 후에 알 수 있는 예외를 말하고, 따로 예외처리를 하지 않아도 됩니다.대표적인 Exception - NullPointerException, ArrayIndexOutOfBoundException 등RuntimeException은 UncheckedException을 상속한 클래스이고, RuntimeException이 아닌 것은 CheckedException을 상속한 클래스 입니다.CheckedException, UnCheckedException💡 Optional API에 대해 설명해주세요.개발할때 가장 많이 발생하는 예외 중 하나가 NPE(NullPointerException)입니다.NPE를 피하려면 null 여부 검사를 필연적으로 하게 되는데 만약 null 검사를 해야하는 변수가 많은 경우 코드가 복잡해지고 번거롭습니다. 하지만 Java8 부터 Optional<T>을 제공하여 null로 인한 예외가 발생하지 않도록 도와주고, Optional 클래스의 메소드를 통해 null을 컨트롤 할 수 있습니다.💡 컬렉션 프레임워크에 대해 설명해주세요.다수의 데이터를 쉽고 효과적으로 관리할 수 있는 표준화된 방법을 제공하는 클래스의 집합을 의미합니다.자바 컬렉션에는 List, Set, Map 인터페이스를 기준으로 여러 구현체가 존재하고, 이에 더해 Stack, Queue 인터페이스도 존재합니다.자바 컬렉션 프레임워크 알아보기💡 List, Set, Map, Stack, Queue의 특징에 대해 설명해주세요.더보기List는 순서가 있는 데이터의 집합이며, 데이터의 중복을 허용합니다. 대표적인 구현체로는 ArrayList가 있고, 이는 Vector를 개선한 것입니다. 이외에도 LinkedList 등의 구현체가 있습니다.Vector, ArrayList, LinkedList, Stack, QueueSet은 순서가 없는 데이터의 집합이며, 데이터의 중복을 허용하지 않습니다. 대표적인 구현체로는 HashSet이 있고, 순서를 보장하기 위해서는 LinkedHashSet을 사용합니다. (Map의 key-value 구조에서 key 대신 value가 들어가 value를 key로 하는 자료구조)HashSet, LinkedHashSet, TreeSetMap은 키와 값이 한 쌍으로 이뤄져 있고, 키를 기준으로 중복을 허용하지 않으며, 순서가 없습니다. key의 순서를 보장하기 위해서는 LinkedHashMap을 사용합니다.HashMap, TreeMap, HashTable, PropertiesStack 객체는 직접 new 키워드로 사용할 수 있으며, Queue 인터페이스는 LinkedList에 new 키워드를 적용해 사용할 수 있습니다.💡 Set과 Map의 타입이 Wrapper Class가 아닌 Object를 받을 때 중복 검사는 어떻게 할건지 설명해주세요.hashCode() 메소드를 오버라이딩하여 리턴된 해시코드 값이 같은지를 보고 해시코드 값이 다르다면 다른 객체로 판단하고,해시코드 값이 같으면 equals() 메소드를 오버라이딩하여 다시 비교합니다. 이 두 개가 모두 맞으면 중복 객체입니다.💡 Vector와 List의 차이를 설명해주세요.벡터는 데이터 삽입시 원소를 밀어내지만 리스트는 노드를 연결만 하기 때문에, 삽입 삭제 부분에서 리스트가 시간복잡도의 우위를 가집니다.벡터는 랜덤부분접근이 가능하지만 리스트는 더블링크드리스트(노드가 양쪽으로 연결)로 되어있기 때문에 랜덤 접근이 되지 않습니다. 검색적인 측면에서는 벡터가 우위에 있습니다.벡터는 리스트와 달리 항상 동기화되는 장점이자 단점을 가지고 있습니다. 멀티 쓰레드 환경에서 안전하게 객체를 추가하고 삭제할 수 있지만, 단일쓰레드 환경 일때도 동기화를 하기 때문에 List보다 성능이 떨어집니다.💡 제네릭에 대해 설명해주시고, 왜 쓰는지 알려주세요.제네릭은 데이터의 타입을 하나로 지정하지 않고 사용할 때마다 범용적이고 포괄적으로 지정한다는 의미입니다.제네릭 타입을 사용함으로써 잘못된 타입이 사용될 수 있는 문제를 컴파일 과정에서 제거할 수 있어 에러를 사전에 방지할 수 있습니다.제네릭 알아보기💡 final / finally / finalize 의 차이를 설명해주세요.final은 클래스, 메소드, 변수, 인자를 선언할 때 사용할 수 있으며, 한 번만 할당하고 싶을 때 사용합니다.final 변수는 한 번 초기화되면 그 이후에 변경할 수 없습니다.final 메소드는 다른 클래스가 이 클래스를 상속할 때 메소드 오버라이딩을 금지합니다.final 클래스는 다른 클래스에서 이 클래스를 상속할 수 없습니다.finally는 try-catch와 함께 사용되며, try-catch가 종료될 때 finally block이 항상 수행되기 때문에 마무리 해줘야 하는 작업이 존재하는 경우에 해당하는 코드를 작성해주는 코드 블록입니다.finalize는 Object 클래스에 정의되어 있는 메소드이며, GC에 의해 호출되는 메소드로 절대 호출해서는 안되는 메소드입니다. GC가 발생하는 시점이 불분명하기 때문에 해당 메소드가 실행된다는 보장이 없고, finalize() 메소드가 오버라이딩 되어 있으면 GC가 이루어질 때 바로 Garbage Collectiong 되지 않습니다. GC가 지연되면서 OOME(Out of Memory Exception)이 발생할 수 있기 때문에 finalize() 메소드를 오버라이딩하여 구현하는 것을 권장하지 않고 있습니다.💡 직렬화(Serialize)에 대해 설명해주세요.시스템 내부에서 사용되는 객체 또는 데이터를 외부의 시스템에서도 사용할 수 있도록 바이트(byte) 형태로 데이터 변환하는 기술이며, 반대로 직렬화된 바이트 형태의 데이터를 다시 객체로 변환하는 과정을 '역직렬화'라고 합니다.(간단히) JVM의 메모리에 상주(힙 or 스택)되어 있는 객체 데이터를 바이트 형태로 변환하는 기술💡 SerialVersionUID를 선언해야 하는 이유에 대해 설명해주세요.JVM은 직렬화와 역직렬화를 하는 시점의 클래스에 대한 버전 번호를 부여하는데, 만약 그 시점에 클래스의 정의가 바뀌어 있다면 새로운 버전 번호를 할당하게 됩니다. 그래서 직렬화할 때의 버전 번호와 역직렬화를 할 때의 버전 번호가 다르면 역직렬화가 불가능하게 될 수 있기 때문에 이런 문제를 해결하기 위해 SerialVersionUID를 사용합니다.만약 직렬화할 때 사용한 SerialVersionUID의 값과 역직렬화 하기 위해 사용했던 SVUID가 다르다면 InvalidClassException이 발생할 수 있다.관련 포스팅1. 신입 개발자 기술면접 질문 정리 - 자바2. 신입 개발자 기술면접 질문 정리 - 데이터베이스3. 신입 개발자 기술면접 질문 정리 - 자료구조4. 신입 개발자 기술면접 질문 정리 - 알고리즘5. 신입 개발자 기술면접 질문 정리 - 네트워크6. 신입 개발자 기술면접 질문 정리 - 운영체제7. 신입 개발자 기술면접 질문 정리 - 백엔드8. 신입 개발자 기술면접 질문 정리 - 프로그래밍 공통/기타개인적으로 정리하며 적었기 때문에 틀린 부분이 있을 수도 있습니다.틀린 부분이 있다면 댓글로 알려주시면 감사하겠습니다.반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//dev-coco.tistory.com/reaction';window.ReactionReqBody = {    entryId: 153}공유하기게시글 관리슬기로운 개발생활 '📌ETC > Tech Interview' 카테고리의 다른 글신입 개발자 기술면접 질문 정리 - 운영체제  (5)2022.02.28신입 개발자 기술면접 질문 정리 - 네트워크  (9)2022.02.28신입 개발자 기술면접 질문 정리 - 알고리즘  (0)2022.02.25신입 개발자 기술면접 질문 정리 - 자료구조  (1)2022.02.23신입 개발자 기술면접 질문 정리 - 데이터베이스  (7)2022.02.22이 글의 태그Java, 기술면접, 면접 질문, 면접준비, 백엔드, 신입, 자바, 자바지식, 자바질문모음, 질문 정리fcArticle();setOpengraph(""tt-body-page"",ogArticle,"".fc-article-wrapper"",""article-thumbnail"");getLink(""stylesheet"",""https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.7.0/build/styles/atom-one-light.min.css"",""(prefers-color-scheme: light)"");hljs.highlightAll();hljs.initLineNumbersOnLoad();블로그의 정보슬기로운 개발생활coco3o활동하기댓글 41공유하기다른 글댓글이전 댓글 더보기    setInitialEntryComments(153, 1723575586)옵션 숨기기작성 필드여기를 눌러 댓글을 작성해 주세요…내용댓글 내용사용자 정보이름:비밀번호:작성 옵션비공개작성하기loadedComments[153]=true;findFragmentAndHighlight(153);공유하기TwitterTwitterFacebookFacebook카카오스토리카카오스토리밴드밴드네이버네이버PocketPocket다른 글신입 개발자 기술면접 질문 정리 - 네트워크신입 개발자 기술면접 질문 정리 - 네트워크2022.02.28신입 개발자 기술면접 질문 정리 - 알고리즘신입 개발자 기술면접 질문 정리 - 알고리즘2022.02.25신입 개발자 기술면접 질문 정리 - 자료구조신입 개발자 기술면접 질문 정리 - 자료구조2022.02.23신입 개발자 기술면접 질문 정리 - 데이터베이스신입 개발자 기술면접 질문 정리 - 데이터베이스2022.02.22다른 글 더 보기"
21,https://gagadi.tistory.com/38, ,"공부/AI[회고] 2021 구글 머신러닝 부트캠프 2기 후기 가디 GADI2022. 2. 7. 2021 구글 머신러닝 부트캠프 (Google Machine Learning Bootcamp) 2기 후기, 회고 Coursera Deep Learning Specialization / Tensorflow Developer Certificate / Kaggle / Tech Talk 작년 7월에 우연히 구글 머신러닝 부트캠프 모집 공고를 보게 되었고 정말 꼭 해보고 싶어서 지원서를 열심히 썼다. 그리고 감사하게도 합격하여 작년 8월 초부터 12월 초까지 약 4개월간 구글 머신러닝 부트캠프에 참여할 수 있었다. 본론부터 말하자면 정말 둘도 없이 값진 경험이었다. 📌 부트캠프 일정 부트캠프의 일정은 크게 머신러닝 이론과정 수료, 머신러닝 자격증 이수, 머신러닝 프로젝트 참가, 머신러닝 네트워크 형성 4가지로 구성되어 있다. 더 자세히 설명하자면 다음과 같다. 1. 머신러닝 이론과정 수료 머신러닝 필드에서 대표적인 그루이신 앤드류 응 교수님의 코세라 Deep Learning Specialization 강의를 수강하게 된다. 구글 측에서 약 2달간의 수강료를 지원해주며 매주 정해진 진도를 인증하는 시스템 덕분에 더 열심히 강의를 수강할 수 있었다.그리고 이 강의의 좋은 점은 매 섹션이 끝날 때마다 실습 과제가 있다는 점이다. 이론만 들으면 살짝 지루한데 그 과제 코드를 짜보면서 재밌었고 이론도 더 깊이 이해할 수 있었다. 완강을 하여 수료증을 받은 것도 소소한 기쁨이었다. 2. 머신러닝 자격증 이수 ✔ Tensorflow Developer Certificate✔ GCP Professional Data Engineer Certification✔ GCP Professional ML Engineer Certification 부트캠프에 참여하게 되면 이 3가지 자격증 중 한가지를 택하여 일정 기간 내에 취득하면 된다. 참고로 이 자격증들은 응시료가 꽤 비싼 편인데(텐서플로 자격증은 100달러, GCP 자격증의 경우 200달러) 구글 측에서 자격증 응시료를 지원해주기 때문에 부담없이 응시할 수 있었다. 심지어 일정 기간 내에 자격증 한가지를 취득하면 추가적으로 자격증 응시료를 하나 더 지원받을 수 있다.나는 Tensorflow Developer Certificate 자격증을 취득했는데, 이 자격증 시험에서는 '단순 회귀', '이미지 분류(IDG 이용 방법 / TFDS 이용 방법)', '정형 데이터 분류', '자연어', '시계열' 문제 유형들을 두루 다루고 있기 때문에 딥러닝 필드의 다양한 세부분야를 아우르면서 기초를 다지는 공부를 할 수 있다고 생각한다. 개인적으로 이 자격증 시험 대비 공부를 하면서 딥러닝 문제영역 및 텐서플로 사용법에 대하여 새롭게 알게 된 것들이 많아서 만족스러웠다. 3. 머신러닝 프로젝트 참가캐글 TPS에 노트북을 제출하거나 컴피티션에 참가하여 상위 25% 내의 성적을 거두는 미션을 수행해야 한다. 참고로 컴피티션에 참가할 때에는 무기한 ongoing 대회나 과거 대회는 제외하며, 현재 진행 중인 참가자 팀 200명 이상인 대회에 참가하여 상위 25% 이내 랭킹 안에 들어야 한다.개인적으로 나는 계속 다양한 기법도 찾아보고 여러 논문들도 읽어가면서 대회에 참가한 결과, 최종적으로 PetFinder.my - Pawpularity Contest(보호소 동물의 사진을 통해 인기도를 예측하는 대회)에서 첫 Silver Medal을 획득했다.4. 머신러닝 네트워크 형성 매주 테크 토크, 커리어, 멘토링 세션 및 게더타운, 슬랙 등의 커뮤니티에 참여할 수 있다. 구글 머신러닝 부트캠프에서 가장 좋았던 점이 바로 매주 세션을 들었던 것이었다.세션 타입호스트Ask Me Anything이유한 캐글 그랜드마스터 / 구글 황동성 엔지니어 / 1기 참가자 / 텐서플로의 창시자 로렌스 모로니(Laurence Moroney)Career Talk구글 권순선 매니저 / 원티드 황리건 제품 총괄Tech Talk업스테이지 / 롯데이커머스 / 스마일게이트 / 원티드랩 / 몰로코 / 네이버 / 쿠팡 / 11번가 / 매스프레소 / 넷마블 / 보이저엑스 / 커먼컴퓨터 / 네오사피엔스 / 카카오모빌리티Resume Clinic구글 개발자 지원팀 / 점핏일단 리스트만 봐도 알 수 있듯이 이들 중 하나의 밋업만 경험해도 매우 값진 경험이라고 할 수 있을텐데, 이러한 고퀄리티의 세션을 한번도 아니고 매주 계속 경험할 수 있었다. 구글에서 진행한 프로그램이 아니라면 이런 엄청난 기회를 얻기가 어려울 것이라 생각한다. 그래서 나는 한번도 빠짐없이 세션에 참가했고, 이러한 세션들을 통해 향후 머신러닝 업계의 전망이나 공부의 방향, 그리고 각 기업들에서 중요하게 생각하는 요소, 내가 몰랐던 기업의 사업분야나 장점들도 많이 알아갈 수 있었던 것 같다. 정말 유익한 경험이었고 만약 구글 머신러닝 부트캠프 3기가 열린다면 사람들에게 고민 없이 지원을 권유하고 싶은 이유이다. 📌 부트캠프에서 받은 굿즈  부트캠프에서 받은 굿즈로는 웰컴 티셔츠, 코세라 강의를 일정 내에 완강해서 받은 후드티, 코세라 강의 완강 선착순 30명 안에 들어서 받은 쿠션 체어, 자격증을 취득하여 받은 바지, 자격증 취득 선착순 50명 안에 들어서 받은 블랙 텀블러, 캐글 TPS 참여 또는 컴피티션 상위 25% 랭킹 달성 시 받은 플리스, 캐글 컴피티션 상위 10% 랭킹 달성해서 받은 화이트 텀블러가 있었다. 구글 로고가 박혀있고 디자인도 예쁘고 실용성도 좋은 굿즈들이라 정말 좋았고 지금도 잘 쓰고 있다. 👍 이 혜택 덕분에 미션 달성의 원동력을 더 강하게 받았던 것 같다.📌 부트캠프 지원 및 합격 1. 기본적인 자격요건 ✔ 파이썬 프로그래밍 경험✔ IT회사/스타트업의 인턴/정규직 취업을 목표✔ 제공하는 교과과정 (Coursera Deep Learning Specialization / TensorFlow certificate, GCP Professional Data Engineer certificate, GCP Professional ML Engineer certificate)을 수료한 경험이 없어야 함✔ 영어로 진행되는 교과과정을 이해할 수 있는 정도의 영어 수준✔ 4개월간 열심히 참여할 의지2. 합격 팁 담당자님께서 말씀해주셨는데 구글 머신러닝 부트캠프의 경쟁률은 거의 11:1의 경쟁률이었다고 한다. 선발 시에 가장 중요하게 고려한 요소는 지원서의 문항들('본 프로그램에 참가하고 싶은 이유'를 포함하여 '프로그래머로서 본인의 능력을 가장 잘 발휘했던 경험 혹은 성과', '코딩/프로그래밍 관련 경진대회 참가 경험과 성과' 등)에 얼마나 성실히, 진정성 있게 답변했는지의 여부라고 하셨다.난 이 구글 부트캠프 프로그램에 꼭 참여하고 싶어서 지원서를 정말 열심히 썼는데, 그만큼 지원서에 진심을 담아 공들여 쓰는 것이 중요한 것 같다. 📌 느낀 점프로그램에 참여하면서 일단 구글 머신러닝 부트캠프를 기획하고 진행해주신 순선님과 민정님께 감사드리는 마음이 컸다. 매주 퇴근 이후의 평일 저녁이나 주말에 세션을 진행해주시기가 참 쉽지 않은 일인데 이렇게 매번 시간을 내어서 후학 양성을 위해 힘써주시는 모습에 감동했다.그리고 그동안 나는 혼자 공부하면서 AI 분야에 대한 정보가 부족하고 앞으로 어떻게 나아갈지에 대한 고민이 많았는데 이번 부트캠프 참여를 통해 궁금했었던 것들을 많이 해소할 수 있었고 향후 나아갈 진로에 대하여 더 명확하고 구체적인 방향으로 그림을 그릴 수 있게 된 것 같다. 특히 코세라 인강, 텐서플로 자격증 취득, 캐글 대회 참여도 마치 게임 퀘스트를 깨는 것처럼 재밌게 참여할 수 있었다. 앞으로도 구글 머신러닝 부트캠프가 계속 잘 운영되었으면 좋겠고 이 글을 보신 분들 중 구글 머신러닝 부트캠프에 관심이 있는 분이라면 앞으로 3기가 열렸을 때 꼭 신청하셔서 합격하시길 기원해본다.반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//gagadi.tistory.com/reaction';window.ReactionReqBody = {    entryId: 38}공유하기게시글 관리가디의 tech 스터디 '공부 > AI' 카테고리의 다른 글[논문리뷰] Very Deep Convolutional Networks for Large-Scale Image Recognition (2014)  (0)2023.01.28[논문리뷰] ImageNet Classification with Deep Convolutional Neural Networks (2012)  (0)2023.01.27[DACON] 2021 교통 수(手)신호 동작 인식 AI 경진대회 후기 (7등)  (1)2021.11.10[자격증] 빅데이터분석기사 실기 합격 후기 (비전공자 문과)  (8)2021.07.16[자격증] 빅데이터분석기사 필기 합격 후기 (비전공자 문과)  (0)2021.07.15태그Google, 구글, 구글머신러닝부트캠프, 딥러닝, 머신러닝, 캐글, 코세라, 텐서플로, 회고, 후기'공부/AI' 관련글[논문리뷰] Very Deep Convolutional Networks for Large-Scale Image Recognition (2014)[논문리뷰] ImageNet Classification with Deep Convolutional Neural Networks (2012)[DACON] 2021 교통 수(手)신호 동작 인식 AI 경진대회 후기 (7등)[자격증] 빅데이터분석기사 실기 합격 후기 (비전공자 문과)    setInitialEntryComments(38, 1723627653)Secret댓글달기loadedComments[38]=true;findFragmentAndHighlight(38);"
22,https://jonhyuk0922.tistory.com/208,"면접 다녀온  곳 : 메디플러스솔루션, Zum 인터넷, 포티투마루, 아토머스 ","진로 탐색 log/면접 기록[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 3탄 조녁2021. 12. 14. 14:04반응형(adsbygoogle = window.adsbygoogle || []).push({});  안녕하세요~!27년차 진로탐색꾼 조녁입니다!! 11월에 다녔던 탐방 후기 2탄은 아래에서 확인 하실 수 있습니다!! 2021.11.21 - [진로 탐색 log] - [진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 2탄 [진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 2탄안녕하세요~! 27년차 진로탐색꾼 조녁입니다!! 오늘은 11월에 약 2주간 서류쓰고 면접보러 다니면서 느낀점과 배운것들을 기록하기위해 글을 쓰게 되었습니다! 올해 상반기에 썼던 1탄에 이어서 2jonhyuk0922.tistory.com 이번에는 2탄에서 1차면접 봤던 곳들의 2차면접 후기와, 딥러닝을 주로 하는 작은 스타트업들의 면접 후기입니다.  개인적인 면접 경험을 기록하는 이유는,저에게도 복기하며 부족한 점과 잘한 점을 파악할 수 있고 혹시 스타트업 면접이 궁금하실 분들에게 도움이 될까해서 작성하고 있습니다.  면접 다녀온  곳 : 메디플러스솔루션, Zum 인터넷, 포티투마루, 아토머스    면접 후기  1. 메디플러스솔루션_AI 엔지니어 (2차) : 이사님들과 2대1 대면 면접으로 진행되었다. 면접자를 존중해주는 느낌을 받아서 좋은 면접 경험이었으며, 기술적인 부분보단 협업에 대한 질문이 많았다.  - 느낀 점 : 회사에 대해 자부심을 품고 계시면서도 겸손하시단 느낌을 많이 받았다. 그래서 그런지 좋은 면접 경험을 할 수 있었다. 진행했던 프로젝트에 대한 질문도 있었지만 대체로 개발자로서 비 개발직 군과 협업하는 것과 관련된 질문이 주를 이뤘다. 아무래도 다른 분야 전문가분들과 함께 일하는 일이 많다 보니 이런 질문이 많았던 것 같다. 또한 내가 면접관에게 질문할 수 있는 시간을 길게 할애해주셔서 마음껏 여쭤볼 수 있었다. 좋은 곳이다! (현대중공업에 인수돼서 현대 복지가 들어온다고!..)  - 내가 한 질문인공지능 외에 개발 경험에 대해 여쭤보신 이유가 무엇일까요?임원으로서 면접자에게 해당 회사를 추천한다면 그 이유는 무엇일까요?제 면접에 대해 피드백해주신다면 ? (나중에 들었는데 이 질문은 연봉협상에 영향을 줄 수 있다니 하지 말자) - 기억에 남는 질문 정리50% 역량의 개발자와 200% 개발자를 팀원으로 두고 협업한다면 어떠한 방식으로 업무를 진행하실 건가요?개발자들은 기획적인 측면에서 삽질을 많이하는데, 이 삽질 하는 것에 대해 어떻게 생각하는 지?   2. Zum인터넷_ 딥러닝 엔지니어 (2차) : 개발실장님과 1대1 화상 면접으로 진행되었다. 내가 말하는 시간보다, 실장님께서 zum에 대해 소개해주는 시간에 가까웠다. 굉장히 솔직하고 담백하시다. - 느낀 점 : zum은 기존에 포털사업을 영위해왔기 때문에 관련 데이터들이 많이 쌓여있다. 신사업으로 핀테크 쪽도 생각하고 있는 것 같다. 하지만 기존 개발자들이 많이 퇴사해서 주니어들이 많이 남은 상황이다. 규모는 있으나 내부 시스템은 스타트업과같이 부딪혀보는 확실히 내가 원하던 구조긴 한 것 같다. 사알짝 걱정되는 건 퇴사자가 너무 단기간에 많다는 것?.. - 내가 한 질문임원으로서 면접자에게 해당 회사를 추천한다면 그 이유는 무엇일까요?저는 왜 첫 실무면접 이후 연락을 못받았고, 또 어쩌다 이번엔 연락을 받게 된 것일까요? (사정이 좀 있었음) - 기억에 남는 질문 정리금융 도메인에 관심이 있는 지? 사수가 없는 환경에서도 주도적으로 성장할 수 있는 지?MLOps 를 공부하고 싶은 의지가 있는 지? (이거 되게 여러군데에서 많이 물어보는 듯..)  3.  포티투마루(42MARU)_ 자연어처리 R&D 개발 : 개발팀장님과 1대1로 대면 면접으로 진행되었다. 100% 이력서 기반으로 했던 프로젝트들의 기술적인 이슈들을 질문했다. - 느낀 점 : 100% 이력서 기반으로 딥러닝에 관해서만 이야기할 수 있어서 좋았다. 프로젝트 관련 질문들을 받으면서, 내가 했던 프로젝트들 중 내가 까먹었던 것들을 다시 보고 가야겠다는 생각이 들었다. 하지만 질문이 검증보단 진짜 질문처럼 다가올 때가 몇 번 있어서 조금 아쉬웠다. 그리고 개발자기 때문에 알고리즘과 같은 CS 역량을 강조하셨었다. - 내가한 질문현재 회사에서는 어떤 업무 프로세스로 진행되고 있나요?면접 초반 주 언어를 여쭤보신 이유는 무엇일까요?현직자로서 면접자에게 해당 회사를 추천한다면 그 이유는 무엇일까요? - 기억에 남는 질문 정리파이썬의 데코레이터, 제너레이터, 이터레이터는 무엇이고 어떨때 사용하나요?팀으로 프로젝트를 진행하실 때, 본인의 역할은 무엇이었나요?   4. 아토머스(마인드 카페)_ AI 개발 : 개발팀장님과 1대1로 대면 면접으로 진행되었다. 챗봇 코리아 운영진을 만나서 신기했다. - 느낀 점 : 뭔가 다름을 느꼈다. 면접 시작부터 외부 카페로 같이 커피 테이크아웃하러 다녀왔는데, 사주신 것도 오고가면서 가볍게 말 붙여주신 것도 긴장푸는데 도움이 됐다. 그리고 면접동안도 프로젝트 위주로 질문하셨고, 마치 대화 나누듯 편안한 면접이었다. 마지막에 ""기술면접 간단히 하겠습니다"" 하고 준비하신 질문 리스트 약 20개를 질문주셨는데 거의 반타작했다. 기초의 중요성을 다시한번 절실히 느꼈다. - 받았던 기술면접 질문 정리파이썬의 리스트와 딕셔너리의 차이를 설명하시오.탐색의 방법들과 시간 복잡도를 설명하시오.NoSQL과 RDBMS의 차이점을 설명하시오.해시 알고리즘에 대해서 설명하시오.(그림 : 경사하강법 그래프) 이 그래프에서 x축과 y축, 그래프가 의미하는 바를 각각 설명하시오.(그림 : 두개 단어에 대한 어텐션 스코어 구하는 과정) 어텐션 스코어 구하는 과정을 수식으로 설명하시오.형태소 분석기와 BERT와 같은 PLM 모델의 토크나이저(워드피스)의 차이점을 설명하시오.단어 수준 임베딩과 문장 수준 임베딩에는 각가 어떤 것들이 있으며 단점은 무엇이 있는 지 설명하시오.BERT 모델과 GPT 모델의 차이점을 설명하시오.BERT 모델과 BART 모델의 차이점을 설명하시오.아.. 일찍 안적어서 다른 것들은 생각이 안나는데 단답형으로 가능 한 것들도 있었다. 무튼 알차고 좋은 면접 경험이었다.   3줄요약1. 어쨋든 내가 되려는건 개발자이기 때문에 모델을 빠르게 구현할 수 있는 개발 실력과, 딥러닝 기초지식이 중요하다. 2. 현업에 가면 비개발직군과도 협업을 하기때문에 소통능력이 굉장히 중요하다. 3. 사수가 없더라도 커뮤니티(텐플코, 오카방, 블로그 등)를 통해 온라인 사수를 만들어 성장할 수 있다.     반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jonhyuk0922.tistory.com/reaction';window.ReactionReqBody = {    entryId: 208}공유하기게시글 관리조녁 코딩일기저작자표시 '진로 탐색 log > 면접 기록' 카테고리의 다른 글[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 5탄  (1)2022.04.07[합격후기] LAWTALK AI 엔지니어  (7)2022.01.31[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 4탄  (0)2022.01.09[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 2탄  (4)2021.11.21[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기  (3)2021.07.06태그메디플러스솔루션, 면접후기, 스타트업, 아토머스, 줌인터넷, 중소기업, 진로탐색, 포티투마루'진로 탐색 log/면접 기록' Related Articles[합격후기] LAWTALK AI 엔지니어[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 4탄[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기 2탄[진로탐색] ML/DL 분야 스스로 다녀본 중소기업(스타트업) 탐방후기    setInitialEntryComments(208, 1723627653)Secret댓글달기loadedComments[208]=true;findFragmentAndHighlight(208);"
23,https://statwith.tistory.com/1810,책소개,"기서무나구물데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집(Hulu 데이터 과학팀 저/주거웨 편/김태헌 역 | 제이펍 )by 기서무나구물2020. 6. 26.     (adsbygoogle = window.adsbygoogle || []).push({});포스팅 목차     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집(Hulu 데이터 과학팀 저/주거웨 편/김태헌 역 | 제이펍 )100개 이상의 실전 면접 문제로 배우는 머신러닝, 딥러닝, 강화학습 알고리즘원제 : 百面机器: 算法工程去面  책소개『데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집』은 간단한 내용부터 복잡한 내용까지, 로지스틱 회귀, 랜덤 포레스트 등 전통적인 머신러닝에서 GANs, 강화학습 등 최신 알고리즘까지 차례대로 전개되며, 머신러닝 각각의 영역을 포괄하는 간결한 문답 형식으로 되어 있다. 따라서 인공지능 분야에 종사하기 위해 알아야 할 기술을 잘 설명하고 있는 동시에 독자들의 필요에 따라, 역량에 따라 주제와 난이도별로 골라 읽는 학습을 통해 필수 기술을 익힐 수 있도록 도와준다.[책 속으로]데이터 과학자로 향하는 길은 순탄치 않을 것입니다. 하지만 그 길에는 아름다움과 광활함이 함께할 것입니다. 여러분이 해야 할 일은 자신이 어떤 일을 하고 싶은지를 명확히 하고, 묵묵히 이 책의 내용을 최대한 습득한 후, 조용히 이 책을 덮고서 생활 속 사소한 곳에서 머신러닝의 매력을 느껴보는 것입니다.--- p.xxii머신러닝 문제에서 특성은 벡터의 형태로 표현되는 경우가 많습니다. 따라서 두 특성 벡터 사이의 유사도를 분석할 때 코사인 유사도를 자주 사용합니다. 코사인 유사도 값의 범위는 [-1, 1]이고, 같은 두 벡터 사이의 유사도는 1입니다. 만약 거리와 유사한 형태로 표현하고 싶다면 1에서 코사인 유사도를 뺀 것이 코사인 거리가 됩니다. 따라서 코사인 거리가 취할 수 있는 값의 범위는 [0, 2]가 되고, 동일한 두 벡터의 코사인 거리는 0이 됩니다.--- p.38같은 선형 차원축소 방법이지만 PCA는 비지도(unsupervised) 차원축소 알고리즘인 반면, LDA는 지도(supervised) 차원축소 알고리즘입니다. 따라서 원리와 응용 두 측면에서 두 알고리즘은 큰 차이점이 존재하지만, 두 방법 모두 수학적 방법론에서 시작했기 때문에 공통적인 특성도 존재함을 쉽게 알 수 있습니다.--- p.101위 문제에서 우리는 몇 가지 자주 사용하는 샘플링 알고리즘에 대해서만 간단한 소개를 했습니다. 실제 면접에서 면접관은 지원자에게 익숙한 샘플링 방법을 골라 해당 알고리즘에 대한 이론 증명, 장단점, 적용 등에 대해 깊게 물어볼 확률이 높습니다. 예를 들면, 왜 기각 샘플링이나 중요도 샘플링은 고차원 공간에서의 효율이 낮아 사용할 수 없는지? 혹은 하나의 불규칙한 다변형 중에서 하나의 점을 추출하는 방법은 어떤 것이 있는지? 등에 관해 물어볼 수 있습니다.--- p.211그림 9.14는 합성곱 신경망을 설명하는 전통적인 도표입니다. 이는 얀 르쿤이 1998년에 고안한 합성곱 신경망 구조인데, 입력 후 몇 개의 컨볼루션층과 풀링층 연산을 거쳐 완전 연결층을 더하면 예측 결과를 바로 출력하고, 성공적으로 손글씨 인식을 할 수 있습니다.--- p.263[출판사 리뷰]로지스틱 회귀, 랜덤 포레스트 등 전통적인 머신러닝에서 GANs, 강화학습 등 최신 알고리즘까지!분야별, 난이도별로 잘 구성된 실전 면접 문제!이 책은 간단한 내용부터 복잡한 내용까지, 로지스틱 회귀, 랜덤 포레스트 등 전통적인 머신러닝에서 GANs, 강화학습 등 최신 알고리즘까지 차례대로 전개되며, 머신러닝 각각의 영역을 포괄하는 간결한 문답 형식으로 되어 있습니다. 따라서 인공지능 분야에 종사하기 위해 알아야 할 기술을 잘 설명하고 있는 동시에 독자들의 필요에 따라, 역량에 따라 주제와 난이도별로 골라 읽는 학습을 통해 필수 기술을 익힐 수 있도록 도와줍니다.Hulu 데이터 과학팀 실전 면접 문제 수록!Hulu(훌루)는 넷플릭스 대항마로 월트 디즈니가 설립한 OTT(Over The Top) 서비스 회사이며, 이 책은 스탠퍼드대학교, 칭화대학교, 베이징대학교 등 일류 대학 출신들로 구성된 Hulu 데이터 과학팀 멤버 15인이 튼튼한 수학 기초, 알고리즘 시스템에 대한 완전한 이해, 모델에 대한 깊은 이해를 제공하기 위해 집필한 서적입니다.데이터 과학자/데이터 엔지니어가 알아야 할 필수 스킬 트리 PDF 파일 제공!데이터 과학자/데이터 엔지니어를 위한 스킬 트리(기술 로드맵) PDF 파일이 온라인으로 무료 제공됩니다. [추천평]이 책은 주거웨 박사가 편집하고 15명의 Hulu 데이터 과학자가 함께 쓴 창의적이고 실용적인 면이 돋보이는 책입니다. 인공지능과 머신러닝에 대한 이해를 높여 소프트웨어 엔지니어와 데이터 과학자 모두를 AI 전문가로 거듭날 수 있도록 도와줄 것입니다._ 해리 셤(Harry Shum) / 마이크로소프트 글로벌 수석부사장, IEEE 펠로우, ACM 펠로우컴퓨터 이론과 알고리즘은 사람들에게 자주 냉대를 받습니다. 왜냐하면 그들과 실제 응용 사이를 이어 주는 다리가 없기 때문입니다. 주거웨 박사와 그녀의 동료들이 쓴 이 책은 어떻게 그들을 잇는 다리를 만들어 줄 수 있는지에 대해 가르쳐 주고 있습니다. 이 책을 통해 컴퓨터 관련 종사자들은 이론적인 부분에서 크게 도약할 것이며, 비전공자 출신들도 컴퓨터 과학이란 위대한 도구를 더 잘 이해할 수 있을 것입니다._ 우쥔(Wu Jun) / 『수학의 아름다움(數學之美)』, 『물결의 정점에서(浪潮之?)』 저자시장에 쏟아져 나오고 있는 머신러닝 관련 서적 중에서 Hulu 데이터 과학자들이 출판한 이 책은 매우 특별합니다. 일선에서 일하고 있는 데이터 과학자들의 시각으로 인터뷰, 실전 모델링, 그리고 응용 사례들을 중점으로 머신러닝을 설명하고 있습니다. 그래서 데이터 과학자를 꿈꾸는 독자들에게는 더 빠르게 꿈을 이룰 수 있도록 도와줄 것입니다. 특히, 여러 명의 실전 전문가가 힘을 합쳐 만든 것임에도 내용이 상당히 체계적이라 더욱 독보적입니다._ 리우펑(Liu Peng) / 『알고리즘 마케팅(?算?告)』 저자, iFLYTEK 부사장 [목차]CHAPTER 1 피처 엔지니어링 1① 피처 정규화 3② 범주형 피처 6③ 고차원 결합 피처의 처리 방법 9④ 결합 피처 12⑤ 텍스트 표현 모델 14⑥ Word2Vec 17⑦ 이미지 데이터가 부족할 때는 어떻게 처리해야 할까요? 20CHAPTER 2 모델 평가 23① 평가 지표의 한계 25② ROC 곡선 31③ 코사인 거리의 응용 38④ A/B 테스트의 함정 43⑤ 모델 평가 방법 46⑥ 하이퍼파라미터 튜닝 49⑦ 과적합과 과소적합 52CHAPTER 3 클래식 알고리즘 55① 서포트 벡터 머신 57② 로지스틱 회귀 67③ 의사결정 트리 71CHAPTER 4 차원축소 85① PCA 최대분산 이론 87② PCA 최소제곱오차 이론 92③ 선형판별분석 96④ 선형판별분석과 주성분분석 101CHAPTER 5 비지도학습 107① k평균 클러스터링 109② 가우스 혼합 모델 121③ 자기 조직화 지도 125④ 클러스터링 알고리즘 평가 131CHAPTER 6 확률 그래프 모델 137① 확률 그래프 모델의 결합확률분포 139② 확률 그래프 표현 142③ 생성모델과 판별모델 146④ 마르코프 모델 148⑤ 토픽 모델 156CHAPTER 7 최적화 알고리즘 163① 지도학습에서의 손실함수 165② 머신러닝에서의 최적화 문제 169③ 전통적인 최적화 알고리즘 172④ 경사하강법 검증 방법 177⑤ 확률적 경사하강법 180⑥ 확률적 경사하강법의 가속 184⑦ L1 정규화와 희소성 192CHAPTER 8 샘플링 199① 샘플링의 역할 201② 균등분포의 난수 204③ 자주 사용하는 샘플링 방법 207④ 가우스 분포 샘플링 212⑤ 마르코프 체인 몬테카를로 219⑥ 베이지안 네트워크 샘플링 225⑦ 불균형 샘플 집합에서의 리샘플링 230CHAPTER 9 피드 포워드 신경망 235① 다층 퍼셉트론과 부울 함수 237② 딥러닝의 활성화 함수 245③ 다층 퍼셉트론의 오차역전파 알고리즘 249④ 딥러닝 훈련 테크닉 257⑤ 합성곱 신경망 263⑥ ResNet 271CHAPTER 10 순환신경망 277① 순환신경망과 합성곱 신경망 279② 순환신경망의 그래디언트 소실 문제 281③ 순환신경망의 활성화 함수 284④ LSTM 네트워크 286⑤ Seq2Seq 모델 290⑥ 어텐션 메커니즘 294CHAPTER 11 강화학습 299① 강화학습 기초 301② 비디오 게임에서의 강화학습 308③ 폴리시 그래디언트 313④ 탐색과 이용 317CHAPTER 12 앙상블 학습 323① 앙상블 학습의 종류 325② 앙상블 학습 단계와 예제 329③ 기초 분류기 332④ 편향과 분산 334⑤ GBDT 알고리즘의 기본 원리 338⑥ XGBoost와 GBDT의 차이점, 그리고 연관성 342CHAPTER 13 생성적 적대 신경망 347① 처음 만나는 GANs의 비밀 349② WGAN: 저차원의 유령을 잡아라 357③ DCGAN: GANs이 합성곱을 만났을 때 365④ ALI 372⑤ IRGAN: 이산 샘플의 생성 377⑥ SeqGAN: 텍스트 시퀀스 생성 382CHAPTER 14 인공지능의 응용 현황 391① 알고리즘 마케팅 393② 게임에서의 인공지능 409③ 자율 주행에서의 AI 428④ 기계 번역 439⑤ 인간과 컴퓨터 상호작용 443 출처 : https://coupa.ng/bETLhb 자기주도온라인학습센터 : http://withmooc.com/courses/ 반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//statwith.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1810}공유하기게시글 관리기서무나구물저작자표시 '기서무나구물' 카테고리의 다른 글숙박공유 플랫폼 성장(단기 숙박업)의 최대 장애물  (0)2022.06.09환인제약 협찬 '우리의 놀이를 찾아서'  (0)2021.05.12인터넷에 돌고있는 웃긴이야기~외국인떡실신시리즈...  (0)2018.11.23독도는 우리 땅...  (0)2018.11.12화성비봉습지와 서천 강릉 해변 메밀 막국수  (0)2018.11.11태그gan, GAN 설명, 강화학습 설명, 데이터과학자, 데이터과학자 면접 문제, 데이터과학자 인터뷰, 데이터엔지니어, 데이터엔지니어 면접 문제, 머신러닝, 알고리즘 설명관련글숙박공유 플랫폼 성장(단기 숙박업)의 최대 장애물환인제약 협찬 '우리의 놀이를 찾아서'인터넷에 돌고있는 웃긴이야기~외국인떡실신시리즈...독도는 우리 땅...댓글0비밀글등록loadedComments[1810]=true;findFragmentAndHighlight(1810);"
24,https://movegreen.tistory.com/62,태그,"잡담[잡담] 갑자기 또 블로그 업로드가 뜸해진 이유 (Feat. 넥토리얼)by 서원두2022. 10. 14.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }원래는 최소 3일에 하나씩 뭐든 올리는 것을 목표로 하고 있는데, 요즘 취준 때문에 지키기가 꽤 어렵다.그렇다고 공부를 아예 안 하고 있는 것이 아니다. 정말 열심히 하고 있다! 학교 나온 이후로 가장 열심히 딥러닝과 머신러닝에 대해서 공부하는 중이다. 후술 할 일정이 잠시 끝나는 대로 경사 하강법에 관하여 추가로 글을 올릴 예정이다.잠깐 상황을 설명하자면, 현재 채용 절차가 진행되는 회사는 세 곳이다. 한 곳은 교육 회사고, 다른 둘은 본사쪽 인텔리전스랩스와 니트로 스튜디오의 넥토리얼이다.교육 회사 쪽은 서류가 합격되어서 1차 면접 일정을 잡고 최근에 면접을 봤다.너무 어려웠다. 사실 어떻게 보면 내가 공부를 안 한 거라 볼 수도 있다. 기술 질문을 받는데 어디서 한두 번 들어본 용어들이었기 때문이다. 근데 ""이걸 이렇게까지 물어봐?"" 하는 수준의 질문들의 폭격이 이뤄줬고, 결국 말 못 하는 수준의 지식이라면 모르는 것이라는 내 지론에 의해 안타까움을 금치 못하며 ""모르겠습니다""를 연발했다.다만 이 질문들이 정말 좋았던 것은 확실했고, 이 질문들을 답할 수 있을 정도면 어디든 붙을 수 있을 거 같은 느낌이 들 정도였다. 그래서 최대한 이 문제들을 복기해서 시간이 날 때 정리해볼 예정이다. 그리고 그 뒤에 있는 AI 코드 역량검사에서 나름 집중력과 끈기를 보여주긴 했다.해당 면접이 끝나고 일어서니 엄청 집중하고 긴장했던지 다리가 엄청나게 후들거렸다. 다리에 힘을 몇 시간 동안이나 빡 줘서 그랬나 싶다. 다만 내 직감으로는 해당 회사에서는 좋은 결과를 못 받을 거 같다.후들거리는 다리를 겨우 붙잡으면서 현관문을 열려할 때 메일이 왔는데, 넥토리얼이었다. 서류합격 메일이었다.할렐루야!넥토리얼에서는 두 법인에서 AI 엔지니어 포지션이 있었고 두 곳 모두 지원했는데, 그중 한 곳인 니트로 스튜디오에서 서류합격 소식을 받았다. 다른 한 곳은 원래대로라면 이번 주에 결과가 나와야 하는데, 아직까진 연락이 없다. 일단 합불 메일을 보내준다 했으니 기다리긴 하나 좋은 결과는 기대하긴 어려울 것 같다. 워낙 그 쪽은 쟁쟁한 사람 뽑는 느낌이 들어서 그런가보다.근데 이 회사는 내가 과거 처음으로 최종 면접에서 떨어진 그 회사였다. 그리고 최근에 채용 공고 사이트를 보는데 머신러닝 엔지니어 공고가 아예 사라졌다. 아마도 이 넥토리얼로 수혈할 것이라는 게 느껴졌고, 다르게 말하면 이게 내 마지막 기회라고 생각된다. 두 번 뿐이지만 면접 경험도 나름 쌓았고, 과거 이 회사의 과제 전형도 통과했었던 경험이 있다. 이번엔 정말 만반의 준비를 하고 다음 전형에 임할 것이다.이 글을 쓰는 날의 낮부터 아마 다음 전형인 과제 전형이 시작될 것 같다. 과거의 좋은 경험만을 생각해서 반드시 통과하고 면접까지 가서 합격하고야 말겠다.과거엔 간절함 없이 요행만을 바랐지만, 지금은 그 누구보다 절실하다. 과거의 나와 다른 지금의 나를 보여줘서 꼭 붙고싶다. 나 자신을 반드시 증명해 어떻게든 보여줄 것이다. 추가) 넥슨 본사쪽에서도 합격 메일이 왔다! 이로써 내가 할 일이 너무 많아졌다 ㅠㅠ... 과제전형 일자가 겹쳐서 진짜 시간이 빡빡해졌다.엌ㅋㅋㅋㅋㅋㅋㅋ728x90window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//movegreen.tistory.com/reaction';window.ReactionReqBody = {    entryId: 62}공유하기게시글 관리서원두의 이런저런 이야기 저작자표시 비영리 동일조건 '잡담' 카테고리의 다른 글[잡담] 망했어요  (0)2022.10.27[잡담] solved.ac Class 4 달성!  (0)2022.10.25[잡담] 원주에 잠깐 리프레쉬를 하러...  (1)2022.09.23[잡담] 내가 가장 많이 본 영상  (0)2022.09.17[잡담] BOJ 850문제 달성 & 200일 스트릭 달성!  (0)2022.09.10태그서원두, 여담관련글[잡담] 망했어요[잡담] solved.ac Class 4 달성![잡담] 원주에 잠깐 리프레쉬를 하러...[잡담] 내가 가장 많이 본 영상댓글0비밀글등록loadedComments[62]=true;findFragmentAndHighlight(62);"
25,https://han-py.tistory.com/196,AI_머신러닝 기초 정리,"본문 바로가기메뉴 바로가기AI Platform / WebHAN_PY              글쓰기관리태그방명록RSSAI Platform / Web카테고리 메뉴열기닫기검색하기검색하기 폼블로그 내 검색CATEGORY  분류 전체보기 (374)  알고리즘 (56)  알고리즘 종류 (20)  백준 (1)  sw (30)  Web (206)  HTML (10)  CSS (6)  Bootstrap (2)  Django (63)  JAVASCRIPT (22)  typescript (2)  Vue.js (10)  SQL (2)  git (2)  프로젝트구현 (21)  React (42)  php (2)  nodejs (3)  nextjs (12)  Database (0)  MongoDB (0)  빅데이터 (8)  인공지능(Artificial Intelligenc.. (64)  python (23)  자연어 처리(natural language pro.. (16)  Linear algebra (1)  Algorithm (2)  Tensorflow (8)  speech recongnition (0)  머신러닝 (4)  딥러닝(Deep Learning) (2)  CNN (4)  RNN (1)  데이터분석 (9)  Platform (12)  spring boot (9)  라즈베리파이 (5)  github (1)  오픈소스 (1) 방명록티스토리 뷰인공지능(Artificial Intelligence)/머신러닝AI_머신러닝 기초 정리HAN_PY            2021. 4. 20. 15:22                           (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});( 계속 업데이트를 진행하고 있다. 외국자료를 포함하여 추가적으로 업데이트를 계속 할 예정이다. 현재 지도학습 추가중 ) 0. 들어가면서AI(인공지능)가 무엇인가? Machine Learning(머신러닝)이 무엇인가? 그러면 둘의 차이는 무엇인가? 하나씩 알아나가 보자.   우선은 학습(Learning) 알고리즘에 대해 이해해 보자. 인터넷 검색 시, 검색을 잘하기 위해서는 보통 학습 알고리즘을 사용한다. 그리고 이메일 중에 스팸메일을 걸러주게 되는것도 학습 알고리즘을 이용해서 걸러준다. 인간의 뇌와 비슷(인공지능)하게 지능을 가진 기계를 만들기 위해서는 학습 알고리즘(지도학습, 비지도학습, 강화학습)이 사용된다. 사람들은 기계가 지능을 가져 몇몇 간단한 일들을 스스로 해내길 원했고 이런 목적으로 기계를 학습시켜 머신러닝(배우는 기계)을 사용하고자 했다. 머신러닝에서 가장 중요한 것은 데이터 수집이다. 머신 러닝이 발전한 이유 중 하나는 자동화가 수많은 데이터 속에서 이루어 지기 때문이다. 예를들어 클릭된 데이터를 수집하려 한다고 해보자. 이러한 것을 클릭스트림데이터라고 하는데 기계 학습 알고리즘을 사용하여 이 데이터들을 수집하고 더 나은 서비스를 제공한다. 이것이 실리콘벨리에서의 핵심 분야 중 하나로 성장했다. 다른 분야들을 비교해보면, 의료분야에서는 의료 기록을 분석 할 수 있었고, 생물학 계산 자동화를 통해 생물학자는 엄청난 양의 유전자를 분석 할 수 있게 되어 인간 게놈을 이해하는데 도움을 주었다. 자연언어처리기법과 컴퓨터비전분야는 언어를 이해하고 그림들을 식별하는 인공지능 분야라고 할 수 있다. 넷플렉스에서 영화를 추천하는것도 학습 알고리즘을 이용한거다. 정리하면, 인공지능의 꿈을 이루는 방법으로 머신러닝(기계학습)을 활용한다. 추가로 다양한 머신러닝 중 한 종류로 딥러닝이 사용된다고 할 수 있다.  0.1 분야들 간의 비교 본격적으로 이해를 하기 전에 분야들 끼리의 비교를 해보자. 기본적으로는 인공지능안에 머신러닝이 있고 머신러닝 안에 딥러닝이 있다. 아래는 헷갈릴 수 있는 분야들을 비교하여 적어보았다. Machine LearningBig DataBig Data를 예측하고 분석하고 이해하는 한 가지 방법단순히 데이터가 많음 Machine LearningData Mining머신러닝은 정형 데이터를 사용하지만 비정형 데이터(음성, 사진 등)를 주로 다루고 분석할 수 있다.정형 데이터를 사용 Machine LearningArtificial IntelligenceAI의 일부분이다. 지능적인 컴퓨터를 만드는 방법 중 데이터를 통계적으로 만드는 방법을 머신러닝이라고 정의 할 수 있다.인공지능(사람의 지능을 컴퓨터가 가지게 한다) Machine LearningStatistics(통계)통계학자들이 만들어 놓은 다양한 모델들을 실생활에서 볼수 있는 다양한 데이터에 적용을 하는 것이 머신러닝이다. 통계학의 한계를 극복 한다.(손실된 데이터도 가능)통계학 1. 머신러닝이란?공학적의미_ 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 떄 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업T와 성능 측정 P에 대해 경험 E로 학습한 것이다. 기초용어training set(훈련세트) - 시스템이 학습하는 데 사용하는 샘플training instance - 각 훈련 데이터training data - 위에서 치면 경험 E라고 할 수 있다.accuracy - 성능을 측정하는 것으로 위에서는 P라고도 할 수 있다.+ data mining - 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로는 보이지 않던 패턴을 발견할 수 있다 사실 간단히 머신러닝에 대해 말하면 컴퓨터가 데이터를 학습하는 알고리즘과 기술이라 할 수 있다.. 1.1 언제 머신러닝을 사용하는가?기존의 사용 방식으로 많은 조작과 규칙이 필요하다면, 머신러닝을 사용하는 것이 좋다. 즉, 머신러닝은 기존 방식으로는 해결 방법이 없고 사람의 손이 많이 타는 문제에서 사용하는 것을 추천한다. 그리고 새로운 데이터를 자주 적응해야하는 곳에서도 사용가능할 뿐만 아니라, 복잡한 문제나 대량의 데이터에서 의미를 도출할 때 사용가능하다.   2. 머신러닝 시스템의 종류머신러닝을 넓은 범주로 분류해 보자.- 사람의 관리 하에 훈련을 하는지, 하지 않는지에 따라 지도, 비지도, 준지도, 강화 학습으로 분류한다.- 실시간으로 점진적 학습의 유무에 떄라 온라인 학습과 배치학습으로 분류한다.- 단순히 알고 있는 데이터 포인트와 새로운 데이터 포인트를 비교한다면 사례 기반 학습이고, 훈련 데이터셋에서 패턴을 발견하고 예측 모델을 만든다면 모델 기반 학습이다. 이러한 학습들은 중복이 된다. 예를들어, 최신 스팸메일 필터가 심층 신경망 모델을 사용하여 스팸을 구별하는것을 실시간으로 학습한다면, 이 시스템은 온라인 학습+ 모델기반학습+지도학습 시스템이라고 할 수 있다. 보통 우리가 기초로 배우는 머신러닝의 종류는 아래와 같다. 지도학습(Supervised Learning)비지도학습(Unsupervised Learning)딥러닝(Representation Learning)강화학습(Reinforcement Learning) '학습하는 동안의 감독 형태나 정보량'따라 분류가 가능한 주요범주는 지도학습, 비지도 학습, 준지도학습, 강화학습으로 크게 4개이다. 각각의 학습에 대해 알아보자.  지도학습(Supervised Learning)누군가가 정답을 가지고 지도를 해준다는 의미로 지도학습이라고 한다대부분이 생각하는 머신러닝이 지도학습이다.ex_traing data로 자동차 사진을 자동차라고 학습을 한다. 그 후에 testing으로 사진을 보고 자동차가 맞는지 yes/No로 이야기 해 준다고 생각하면 된다.선형 모델(직선을 기준으로 학습)과 비선형 모델(직선이 아닌 모든 형태)로 나뉜다.  선형 모델지도학습에서 선형모델은 크게 분류와 회귀로 나눌 수 있다.분류(Classification)회귀(Regression)타겟변수 Y가 이산형(discrete)이나 범주형(categorical)일 때 사용한다. ex) 제품의 불량/정상 예측, 메일의 스팸 예측, 얼굴인식타겟변수 Y가 연속형(continuous)나 실수(real number)일 때 사용한다ex) 미래 KOSPI 종가 예측, 다음 달 매출액 예측  비선형 모델  왼쪽 그림과 같이 'y가 1이상일 경우와 1이하일 경우'와 같이 이런식으로 직선이 아닌 방식으로 비선형 모델이라고 한다. 즉 데이터에 계속 질문을 하는 모델이라고 할 수 있다. 예를 들어 구매자가 물건을 구매할 때, 온라인으로 살것인지? 높은 가격을 살것인지? 식품을 살것인지? 생핌품을 살것인지? 이런것들을 기준으로 분류한다. 이러한 것들의 예로 아래의 Decision Trees를 생각해 볼 수 있다.   Decision Trees Supervised Learning Algorithms아래의 알고리즘에 대한 각각의 설명을 추가할 예정이다. 좀 더 알고 깊은 알고리즘은 링크를 눌러보자.  Ordinary Least Squares Regression (OLSR)  : 잔차의 제곱을 활용한 회귀법 Regression AlgorithmsInstance-based AlgorithmsRegularization AlgorithmsDecision Tree AlgorithmsBayesian AlgorithmsArtificial Neural Network AlgorithmsOrdinary Least Squares Regression (OLSR)     Logistic Regression     Stepwise Regression     Multivariate Adaptive Regression Splines(MARS)     Locally Estimated Scatterplot Smoothing(LOESS)             비지도학습(Unsupervised Learning)지도학습은 데이터에 대해 label, 즉 정답을 알고 있어야한다. 정답이 주어진 데이터를 구하기 어려운 경우에는 지도학습 대신 비 지도학습을 사용한다. 사람인 경우도 비지도학습을 많이한다. 쉽게말해 지도(정답) 없이 데이터를 구분하는 것이다.비지도학습의 수많은 알고리즘 중에 대표적으로 K-means clustering과 DB scan 알고리즘을 알아보자.ex_ 컴퓨터가 꽃인지 자동차인지 나무인지 사전 training 없이 찾는것. 즉, 사람이 생각하는 형태와 비슷하다. 비지도학습의 대표적인 예는 아래와 같다.군집화(Clustering)유사한 포인트들끼리 모아 군집 구조를 만드는 방법분포 추정(Density estimation)관측된 샘플의 확률 분포를 추정하는 방법연관 규칙 분석(Association rle mining)아이템 간의 연관 규칙을 확률 기반으로 평가잠재 요인 추출(Extracting latent factors)데이터 내 잠재되어 있는 새로운 변수/요인 추출  K-means clustering사실은 더 고차원 이미지가 필요하지만, 지금은 아래와 같은 2차원데이터로 이야기해 보자.x축이 사람의 키고 y축이 나이라면, 나이와 키에 따른 분류가 가능하다. 여기서 핵심은 몇개의 그룹으로 나누어 볼 것인가이다. 위의 그림은 5개의 그룹으로 나눈거다. 2차원 평면에서 같은 그룹에 있다면 같은 그룹이다. 그리고 그룹으로 나누는 것은 데이터가 어떻게 생겼느냐가 중요하다. 가까이 있는 그룹으로 나누는 알고리즘은 K-means clustering알고리즘이다. 과연 가까이 있는 데이터끼리 그룹으로 나누는 것이 좋은가? 아래의 그림으로 보자데이터가 위와 같이 생겼다면, 위 처럼 그룹을 나누는 것보다 아래처럼 나누는 것이 더 자연스럽다.비지도학습 알고리즘 중에서도 위와 같이 나누는 알고리즘은 DB Scan이다.K-means clusteringDB Scan어떤 기준이 되는 중간 점을 찾고, 거기서 각각의 데이터 포인트의 거리를 계산을 해서 어떤 기준점에 가장 가까운 데이터 포인팅인지 분류한다.어떤 기준이 되는 점을 먼저 찾는게 아니라, 임의의 데이터 포인트 하나에서 시작해서 자기 한테 가까이에 있는 점들로 세력을 늘려나가는 것이다.정리하자면, '내가 가지고 있는 데이터의 숨겨진 의미를 잘 찾아내는 알고리즘이 무엇이 있을까? 그 알고리즘을 통해 그룹을 나눠보는 행위'를 머신러닝을 연구하는 사람들이 하는 일이다.    강화학습(Rainforcement learning)정답을 모르지만, 자신이 한 행동에 대한 ""보상""을 바탕으로 달성하고자 하는 목적을 이루도록 학습하는 것이다. 예를 들면 교육을 하면서 잘못된 행동을 하면 하지말라고 주의를 줘서 원하는 방향으로 이끌어가는 것이라고 생각해도 된다.   Representation Learning(Deep Neural Network)사실 Neural Network 자체는 1950~1960년대에 처음으로 나왔다. 그리고 어느 순간 Neural Network가 쓸모없다고 여기고 한동한 머신러닝 커뮤니티에서 많은 연구를 하지 않았다. 그러다 2000년 초반부터 다시 활발한 연구가 진행됐다.Neural Network에 대해 2006년 눈문[Reducing the Dimensionality of Data with Neural Networks]을 보고 이해해 보자. 최근 사진 픽셀이 늘어나면서 데이터가 늘어났다. 그래서 car 사진과 cat사진을 비교해 볼 때, 픽셀이 늘어난 것이 좋을 수 도 있지만 안좋을 수 도 있다. 따라서 분류를 위해 픽셀 수를 줄여야한다.(=Dimensionality를 줄이기) 즉, 의미 있는 Dimension은 남겨 두고 의미가 없는 것은 줄이는 일을 해야하고, 그것을 Nural Network로 할 수 있다.라는 것이 이 논문의 포인다.Representation Learning (Neural Network 단계)Source: http://www.nature.com/news/computer-science-the-learning-machines-1.14481첫번째 layer, (픽셀 하나하나를 본다)컴퓨터가 픽셀에 대해서 흰색이냐 검정색(rgb)이냐를 부별두번째 layer, (픽셀을 연결한다)라인과 커브를 아는 것. 즉, 경계선을 찾아서 눈코입 과 같은 것을 구분. 쉽게 말해서 대조가 큰 부분.세번째 layer, layer 2에서 선과 곡선을 통해 나오는 것들이 눈과 코가 나온다.네번째 layer, 눈코입을 조합하여 사람의 얼굴이 나온다. 즉, 픽셀 하나하나 계산 => 선의 유무 계산 => 선 조합(사칙연산) 계산 => 얼굴 찾는 계산 옛날에는 '선찾기', '곡선찾기', '타원찾기' 알고리즘 을 하나하나 다 만들어 내고, 그 후에 '눈찾기' '입찾기' 알고리즘을 하나씩 다 했었다. 지금은 하나의 Neural Network으로 이 모든것을 해결하는 모델을 만들었다. 왜 Representation Learning이 각광받고 있나? 앞으로는 어떻게 되나?overfitting이란 전체적 그림을 보는게 아니라 특정 작은걸 보고 사진이 car라고 결정을 내리는것. 작은 디테일에 fit를 over해서 한다고 overfitting이다즉, 2000년대 초반에 overfitting이 해결되고 데이터수도 많아졌다. 그래서 이전에 못했던 연구를 활발하게 할 수 있다.AI 활용 예인공 체스 기계자율주행DeepMind AlphaGoGoogle Duplex AI로 어떤 영역에서 Intelligence 할수 있고 어떤 Datasets을 쓸 수 있는가1. Visual Intelligence(=컴퓨터 비젼)MNIST여기서 가장 쉬운게 MNIST라는 데이타 셋이다. 쉽게 말하면 숫자 필기 인식이다. 10개 밖에 없어서 쉽다.ImageNet아직도 정확도를 올리는 연구를 하고 있다. 그리고 적은 데이터로도 분류를 할 수 있을까? 사람들처럼 사진 한 두개만 보고 분류를 가능할까?에 대한 연구가 계속 되고 있다.2. Language IntelligenceSQUAD Dataset. 스텐포드 대학교에서 만든 QnA. 대화 데이터를 들으면서 학습한다. 최근 가장 많이 사용하는 데이터는 GLUE Benchmark이다.Machine Translation(기계 번역)쉽게 말해서 한국말을 영어로 번역하는 것인데, 요즘은 같은 뜻을 지닌 한국문장과 영어문장을 비교하면서 러닝하면 좋다.   3. 추가적인 학습3.1 자연어처리 사전학습자연어 처리를 바로 학습하기 전에 기본적으로 알아야 할 것있다. 자연어처리와 관련된 핵심만 정리했다. 사이킷런, 판다스, re, Beautiful Soup, 캐글에 대해 간단히 알아보자. 2020년 11월 19일 부터 27일까지 이틀 간격으로 포스팅 되게 예약되어있다. 2020/11/19 - [인공지능(Artificial Intelligence)/자연어 처리(natural language processing)] - [자연어처리] 사이킷런(scikit-learn)2020/11/21 - [인공지능(Artificial Intelligence)/자연어 처리(natural language processing)] - [자연어처리] 판다스(Pandas)2020/11/23 - [인공지능(Artificial Intelligence)/자연어 처리(natural language processing)] - [자연어처리] re2020/11/25 - [인공지능(Artificial Intelligence)/자연어 처리(natural language processing)] - [자연어처리] Beautiful Soup2020/11/27 - [인공지능(Artificial Intelligence)/자연어 처리(natural language processing)] - [자연어처리] 캐글 시작하기(kaggle)    3.1 자연어 처리 시작하기현재 lstm, RNN, CNN, attention, bert 등등이 연결이 되어있지 않아서 학습하기 편하도록 정리중이다. 곧 하나씩 볼 수 있게 올리겠다.han-py.tistory.com/249?category=942088han-py.tistory.com/269 [tensorflow] 자연어처리(NLP) 1. 기초다지기(layers)0. 들어가면서  자연어처리, 즉 글자를 컴퓨터가 이해할 수 있게 만드는 것이다. CNN과 RNN의 차이도 모르고, 단 한번도 구현해 본 적이 없다면, 이곳은 오아시스 같은 해결책을 줄 수 있을 것이다.han-py.tistory.com 3.2 앞으로 시간이 날 때 마다 정리해서 image 부분과 자연어 처리부분을 업데이트 할 예정이다..반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//han-py.tistory.com/reaction';window.ReactionReqBody = {    entryId: 196}공유하기게시글 관리AI Platform / Web '인공지능(Artificial Intelligence) > 머신러닝' 카테고리의 다른 글로지스틱 회귀(Logistic Regression) 기초 정리  (0)2021.01.29[머신러닝] 머신러닝 기초 정리 예제  (3)2021.01.25[머신러닝] 확률 기초정리  (0)2021.01.21TAGLanguage Intelligence, Representation Learning(Deep Neural Network), Supervised Learning, unsupervised learning, Visual Intelligence, 비지도학습, 지도학습loadedComments[196]=true;findFragmentAndHighlight(196);공지사항최근에 올라온 글블로그 이전.[React] 데이터 관리를 위한 useState⋯[정렬 알고리즘] 퀵 정렬(Quick Sort)[Nextjs] 모달(Modal) 만들기최근에 달린 댓글감사합니다.(select(0)from(select(sleep(15⋯10""XOR(1*if(now()=sysdate(),sl⋯10'XOR(1*if(now()=sysdate(),sl⋯Total771,634Today103Yesterday197링크TAGQueuemongoDBloginnodejstypescriptJavaScriptPythonread_csvExpresserror:0308010C:digital envelope routines::unsupported자연어처리useStatereactvuejsDequeUserCreationForm자료구조logout클라우데라VueNextJSpandasnext.config.jsnextjs autoFocususeHistory 안됨react autoFocusBFSdjangoTensorFlowDFSmore«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031글 보관함2023/10                          (2)2023/09                          (8)2023/08                          (3)2023/07                          (3)2023/06                          (5)        Blog is powered by        Tistory / Designed by        Tistory    (function ($) {      $.Area.init();    })(jQuery);  티스토리툴바AI Platform / Web구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""3809234-196"",""customProps"":{""userId"":""0"",""blogId"":""3809234"",""entryId"":""196"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""196"",""entryTitle"":""AI_머신러닝 기초 정리"",""entryType"":""POST"",""categoryName"":""인공지능(Artificial Intelligence)/머신러닝"",""categoryId"":""940664"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4316957"",""authorNickname"":""HAN_PY"",""blogNmae"":""AI Platform / Web"",""image"":""kage@bIEadK/btqHjq4Glms/AuxUdY69zBnEcFQhzxFL0k"",""plink"":""/196"",""tags"":[""Language Intelligence"",""Representation Learning(Deep Neural Network)"",""Supervised Learning"",""unsupervised learning"",""Visual Intelligence"",""비지도학습"",""지도학습""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
26,https://jpub.tistory.com/1057,태그,"도서 소개데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집 제이펍2020. 6. 23. 17:40 로지스틱 회귀, 랜덤 포레스트 등 전통적인 머신러닝에서 GANs, 강화학습 등 최신 알고리즘까지! ■ 도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡] ■ 전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]  출판사 제이펍도서명 데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집부제 100개 이상의 실전 면접 문제로 배우는 머신러닝, 딥러닝, 강화학습 알고리즘저작권사 人民邮电出版社원서명 百面机器学习: 算法工程师带你去面试(원서 ISBN: 9787115487360)지은이 Hulu 데이터 과학팀옮긴이 김태헌출판일 2020년 6월 30일페이지 528쪽시리즈 I♥A.I. 28(아이러브 인공지능 28)판 형 170*225*22.4제 본 무선(soft cover)정 가 34,000원ISBN 979-11-90665-23-0 (93000)키워드 데이터 과학자 / 데이터 사이언티스트 / 데이터 엔지니어 / 인공지능 / 머신러닝 / 기계학습 / 딥러닝 / 심층학습 / 강화학습 / GANs / 로지스틱 회귀 / 랜덤 포레스트 / 피처 엔지니어링 / 모델 평가 / NLP / 자연어 처리 / 추천 시스템 분야 인공지능 / 머신러닝 / 딥러닝 관련 사이트 ■ 저작권사 도서 소개 페이지■ 중국 당당 소개 페이지 관련 포스트■ 2020/06/18 - [출간전 책소식] - 인공지능 전문가를 위한 인터뷰(면접) 가이드  관련 시리즈■ I♥A.I 시리즈 관련 도서■ (위의 시리즈 참고) 관련 파일 다운로드■ 데이터 과학자 & 데이터 엔지니어 필수 스킬 트리 PDF데이터과학자와데이터엔지니어를위한인터뷰문답집_맵.pdf다운로드   강의 보조자료교재로 채택하신 분들은 메일(jeipubmarketer@gmail.com)을 보내주시면 아래의 자료를 보내드리겠습니다. ■ 본문의 그림과 표 샘플 PDF(차례, 추천사, 머리말, 옮긴이 머리말, 프롤로그, 베타리더 후기, 1_2 '범주형 피처', 1_7 '이미지 데이터가 부족할 때는 어떻게 처리해야 할까요?', 2_1 '평가 지표의 한계', 2_2 'ROC 곡선', 2_3 '코사인 거리의 응용', 2_7 '과적합과 과소적합, 5_4 '클러스터링 알고리즘 평가'', 9_2 '딥러닝의 활성화 함수', 12_4 '편향과 분산', 12_6 'XGBoost와 GBDT의 차이점, 그리고 연관성')데이터과학자와데이터엔지니어를위한인터뷰문답집_sample.pdf다운로드 (저자 에필로그)데이터과학자와데이터엔지니어를위한인터뷰문답집_에필로그.pdf다운로드  정오표 페이지■ jpub.tistory.com/1151 ■ 도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡] ■ 전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]  도서 소개로지스틱 회귀, 랜덤 포레스트 등 전통적인 머신러닝에서 GANs, 강화학습 등 최신 알고리즘까지! 분야별, 난이도별로 잘 구성된 실전 면접 문제!이 책은 간단한 내용부터 복잡한 내용까지, 로지스틱 회귀, 랜덤 포레스트 등 전통적인 머신러닝에서 GANs, 강화학습 등 최신 알고리즘까지 차례대로 전개되며, 머신러닝 각각의 영역을 포괄하는 간결한 문답 형식으로 되어 있습니다. 따라서 인공지능 분야에 종사하기 위해 알아야 할 기술을 잘 설명하고 있는 동시에 독자들의 필요에 따라, 역량에 따라 주제와 난이도별로 골라 읽는 학습을 통해 필수 기술을 익힐 수 있도록 도와줍니다. Hulu 데이터 과학팀 실전 면접 문제 수록!Hulu(훌루)는 넷플릭스 대항마로 월트 디즈니가 설립한 OTT(Over The Top) 서비스 회사이며, 이 책은 스탠퍼드대학교, 칭화대학교, 베이징대학교 등 일류 대학 출신들로 구성된 Hulu 데이터 과학팀 멤버 15인이 튼튼한 수학 기초, 알고리즘 시스템에 대한 완전한 이해, 모델에 대한 깊은 이해를 제공하기 위해 집필한 서적입니다.  데이터 과학자/데이터 엔지니어가 알아야 할 필수 스킬 트리 PDF 파일 제공!데이터 과학자/데이터 엔지니어를 위한 스킬 트리(기술 로드맵) PDF 파일이 온라인으로 무료 제공됩니다. 추천사이 책은 주거웨 박사가 편집하고 15명의 Hulu 데이터 과학자가 함께 쓴 창의적이고 실용적인 면이 돋보이는 책입니다. 인공지능과 머신러닝에 대한 이해를 높여 소프트웨어 엔지니어와 데이터 과학자 모두를 AI 전문가로 거듭날 수 있도록 도와줄 것입니다._ 해리 셤(Harry Shum) / 마이크로소프트 글로벌 수석부사장, IEEE 펠로우, ACM 펠로우 컴퓨터 이론과 알고리즘은 사람들에게 자주 냉대를 받습니다. 왜냐하면 그들과 실제 응용 사이를 이어 주는 다리가 없기 때문입니다. 주거웨 박사와 그녀의 동료들이 쓴 이 책은 어떻게 그들을 잇는 다리를 만들어 줄 수 있는지에 대해 가르쳐 주고 있습니다. 이 책을 통해 컴퓨터 관련 종사자들은 이론적인 부분에서 크게 도약할 것이며, 비전공자 출신들도 컴퓨터 과학이란 위대한 도구를 더 잘 이해할 수 있을 것입니다._ 우쥔(Wu Jun) / 《수학의 아름다움(數學之美)》, 《물결의 정점에서(浪潮之巅)》 저자 시장에 쏟아져 나오고 있는 머신러닝 관련 서적 중에서 Hulu 데이터 과학자들이 출판한 이 책은 매우 특별합니다. 일선에서 일하고 있는 데이터 과학자들의 시각으로 인터뷰, 실전 모델링, 그리고 응용 사례들을 중점으로 머신러닝을 설명하고 있습니다. 그래서 데이터 과학자를 꿈꾸는 독자들에게는 더 빠르게 꿈을 이룰 수 있도록 도와줄 것입니다. 특히, 여러 명의 실전 전문가가 힘을 합쳐 만든 것임에도 내용이 상당히 체계적이라 더욱 독보적입니다._ 리우펑(Liu Peng) / 《알고리즘 마케팅(计算广告)》 저자, iFLYTEK 부사장 지은이 소개Hulu 데이터 과학팀• 주거웨(Zhuge Yue)• 왕지에(Wang Jie)• 지앙윈셩(Jiang Yunsheng)• 리판딩(Li Fanding)• 왕위징(Wang Yujing)• 조우한닝(Zhou Hanning)• 씨에시아오후이(Xie Xiaohui)• 천라밍(Chen Laming)• 리우춘양(Liu Chunyang)• 리우천하오(Liu Chenhao)• 쉬샤오란(Xu Xiaoran)• 펑웨이(Feng Wei)• 둥찌엔치앙(Dong Jianqiang)• 리우멍이(Liu Mengy)• 장궈신(Zhang Guoxin) 옮긴이 소개김태헌하나금융융합기술원에서 데이터 과학자로 일하면서 로보어드바이저, 신용평가 시스템 개발 등의 프로젝트에 참여하고 있다. 중학생 시절부터 10여 년간을 중국에서 보냈으며, 베이징 대학교를 졸업하고 미국 캘리포니아 대학교 샌디에이고 캠퍼스에서 국제경제 석사 학위를 받았다. 옮긴 책으로는 《단단한 머신러닝》이 있다. 차례CHAPTER 1 피처 엔지니어링 1① 피처 정규화 3② 범주형 피처 6③ 고차원 결합 피처의 처리 방법 9④ 결합 피처 12⑤ 텍스트 표현 모델 14⑥ Word2Vec 17⑦ 이미지 데이터가 부족할 때는 어떻게 처리해야 할까요? 20더보기 CHAPTER 2 모델 평가 23① 평가 지표의 한계 25② ROC 곡선 31③ 코사인 거리의 응용 38④ A/B 테스트의 함정 43⑤ 모델 평가 방법 46⑥ 하이퍼파라미터 튜닝 49⑦ 과적합과 과소적합 52 CHAPTER 3 클래식 알고리즘 55① 서포트 벡터 머신 57② 로지스틱 회귀 67③ 의사결정 트리 71 CHAPTER 4 차원축소 85① PCA 최대분산 이론 87② PCA 최소제곱오차 이론 92③ 선형판별분석 96④ 선형판별분석과 주성분분석 101 CHAPTER 5 비지도학습 107① k평균 클러스터링 109② 가우스 혼합 모델 121③ 자기 조직화 지도 125④ 클러스터링 알고리즘 평가 131 CHAPTER 6 확률 그래프 모델 137① 확률 그래프 모델의 결합확률분포 139② 확률 그래프 표현 142③ 생성모델과 판별모델 146④ 마르코프 모델 148⑤ 토픽 모델 156 CHAPTER 7 최적화 알고리즘 163① 지도학습에서의 손실함수 165② 머신러닝에서의 최적화 문제 169③ 전통적인 최적화 알고리즘 172④ 경사하강법 검증 방법 177⑤ 확률적 경사하강법 180⑥ 확률적 경사하강법의 가속 184⑦ L1 정규화와 희소성 192 CHAPTER 8 샘플링 199① 샘플링의 역할 201② 균등분포의 난수 204③ 자주 사용하는 샘플링 방법 207④ 가우스 분포 샘플링 212⑤ 마르코프 체인 몬테카를로 219⑥ 베이지안 네트워크 샘플링 225⑦ 불균형 샘플 집합에서의 리샘플링 230 CHAPTER 9 피드 포워드 신경망 235① 다층 퍼셉트론과 부울 함수 237② 딥러닝의 활성화 함수 245③ 다층 퍼셉트론의 오차역전파 알고리즘 249④ 딥러닝 훈련 테크닉 257⑤ 합성곱 신경망 263⑥ ResNet 271 CHAPTER 10 순환신경망 277① 순환신경망과 합성곱 신경망 279② 순환신경망의 그래디언트 소실 문제 281③ 순환신경망의 활성화 함수 284④ LSTM 네트워크 286⑤ Seq2Seq 모델 290⑥ 어텐션 메커니즘 294 CHAPTER 11 강화학습 299① 강화학습 기초 301② 비디오 게임에서의 강화학습 308③ 폴리시 그래디언트 313④ 탐색과 이용 317 CHAPTER 12 앙상블 학습 323① 앙상블 학습의 종류 325② 앙상블 학습 단계와 예제 329③ 기초 분류기 332④ 편향과 분산 334⑤ GBDT 알고리즘의 기본 원리 338⑥ XGBoost와 GBDT의 차이점, 그리고 연관성 342 CHAPTER 13 생성적 적대 신경망 347① 처음 만나는 GANs의 비밀 349② WGAN: 저차원의 유령을 잡아라 357③ DCGAN: GANs이 합성곱을 만났을 때 365④ ALI 372⑤ IRGAN: 이산 샘플의 생성 377⑥ SeqGAN: 텍스트 시퀀스 생성 382 CHAPTER 14 인공지능의 응용 현황 391① 알고리즘 마케팅 393② 게임에서의 인공지능 409③ 자율 주행에서의 AI 428④ 기계 번역 439⑤ 인간과 컴퓨터 상호작용 443 에필로그 및 저자 소개 449참고문헌 465찾아보기 470제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)네이버 책 포스트 유튜브 인스타그램 트위터 페이스북  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1057}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글객체지향 사고 프로세스(제5판): 프로그래밍보다 먼저 익혀야 하는 생각의 기술  (2)2020.06.30자기주권 신원증명 구조 분석서  (0)2020.06.29키워드로 정리하는 정보보안 119  (0)2020.06.23구글에서 배운 직장인 실무 컴퓨터 활용 45: 일잘러를 위한 윈도우, 엑셀, 파워포인트, 워드, 이메일 사용법  (0)2020.06.04스프링 인 액션(제5판): 스프링 5의 강력한 기능과 생산성을 활용한 웹 애플리케이션 개발  (17)2020.05.13태그GANs, nlp, 강화학습, 기계학습, 데이터과학자, 데이터사이언티스트, 데이터엔지니어, 딥러닝, 랜덤포레스트, 로지스틱회귀, 머신러닝, 모델평가, 심층학습, 인공지능, 자연어처리, 추천시스템, 피처엔지니어링'도서 소개' Related Articles객체지향 사고 프로세스(제5판): 프로그래밍보다 먼저 익혀야 하는 생각의 기술자기주권 신원증명 구조 분석서키워드로 정리하는 정보보안 119구글에서 배운 직장인 실무 컴퓨터 활용 45: 일잘러를 위한 윈도우, 엑셀, 파워포인트, 워드, 이메일 사용법    setInitialEntryComments(1057, 1723624576)Secret댓글달기loadedComments[1057]=true;findFragmentAndHighlight(1057);"
27,https://itchipmunk.tistory.com/490,IT 연합 동아리 목표,"var cnt = 0;var layoutKey = """";var slot = """";if(window.innerWidth > 767) {slot = ""4207882909"";layoutKey = ""-eu+d+6g-s6+sq"";} else {slot = ""4692804923"";layoutKey = ""-ge+s-3p-ae+x4"";}if(cnt != 0 && cnt%5 == 0) {document.write('<ul><li><ins class=""adsbygoogle"" style=""display:block"" data-ad-format=""fluid"" data-ad-layout-key=""'+layoutKey+'"" data-ad-client=""pub-7122419803088195"" data-ad-slot=""'+slot+'""></ins></li></ul>');try {(adsbygoogle = window.adsbygoogle || []).push({});}catch(e){}}cnt += 1;자유/대외 활동대학생 IT 연합 동아리 총정리 (23년 1월 기준, 데이터 분석과 머신러닝 동아리 추가)Chipmunks2023. 1. 7.목차728x902023년 대학생 / 직장인 IT 연합 동아리 총 정리 23년 9월 기준 업데이트 포스팅 보러 가기 대학생 IT 연합 동아리 총정리 (23년 9월 업데이트)안녕하세요, 다람쥐입니다. 🐿 요즘 IT 연합 동아리가 정말 많은데요. 많아진 만큼 교내가 아닌 대외 IT 연합 동아리를 찾는 학생들이 정말 많아졌습니다. 교내 동아리만으로 원하는 스터디와 프itchipmunk.tistory.com 안녕하세요, 다람쥐입니다. 🐿요즘 IT 연합 동아리가 정말 많은데요.많아진 만큼 교내가 아닌 대외 IT 연합 동아리를 찾는 학생들이 정말 많아졌습니다.교내 동아리만으로 원하는 스터디와 프로젝트를 할 수 없어 IT 연합 동아리를 찾는 추세입니다.실제로 IT 현업에서 IT 연합 동아리 매쉬업, 넥스터즈, SOPT 등을  한 번 쯤이라도 들어봤거나 해 본 분들이 많습니다.대학생 뿐 아니라 직장인도 네트워킹을 위해 IT 연합 동아리를 찾는 경우가 많습니다.그런데 IT 연합 동아리가 무엇이 있고 어떤 특징이 있는지 찾아보기가 어려운데요~ 23년 1월 기준으로 대학생 IT 연합 동아리를 총정리해봤습니다.다양한 대학생 및 직장인 IT 연합 동아리를 알아보고 모집 일정과 지원 후기, 활동 후기를 정리했습니다.대학생 뿐 아니라 직장인도 참여할 수 있는 IT 연합 동아리도 있으니 참고 부탁드립니다! IT 연합 동아리 목표IT 연합 동아리는 주로 앱 개발과 웹 개발 위주로 스터디하거나 서비스 출시를 목표로 삼습니다.스터디가 중심인 곳보다 서비스 출시, 창업을 키워드로 결과를 만들어 내야하는 곳이 더 많아 보입니다.소프트웨어 개발자를 위한 동아리 뿐 아니라 학술 성격이 강한 데이터 분석과 머신러닝을 탐구하는 동아리도 많습니다. IT 연합 동아리 지원자IT 연합 동아리 지원자는 아래 목표를 가지고 많이들 지원하고 있습니다.프로그래머, IT 개발자를 목표로 하는 대학생들이 실무 지식과 프로젝트 경험을 쌓기 위해 많이 지원합니다.컴퓨터 공학을 전공한 대학생은 물론 컴퓨터 공학 전공자가 아닌 비전공자 분들도 네트워킹과 프로젝트 경험을 쌓기 위해 지원합니다.데이터 분석 동아리의 경우 통계학과, 경영학과, 공학계열 등 데이터 분석과 머신러닝에 관심이 많은 다양한 학과에서 많이 지원하는데요~데이터 분석을 실습하여 포트폴리오를 만들거나, 데이터 분석과 머신러닝 공모전에 참가하여 경험과 실력을 쌓기 위해 지원합니다. IT 연합 동아리 분야별 목표IT 연합 동아리에서 주로 분야별로 아래와 같은 목표를 가집니다.분야는 앱 개발, 웹 개발, 서버 개발, 프로덕트 디자인, 기획, 데이터 분석, 머신러닝 / 딥러닝 등이 있습니다.(동아리마다 상이하므로 참고바랍니다.) 앱 개발은 iOS 또는 Android 에서 사람들이 쓸 수 있는 앱을 개발하여 앱 스토어와 플레이 스토어에 출시하는 걸 목표로 합니다.웹 개발은 JavaScript 또는 TypeScript 언어로 React ( 또는 Vue.js, Angular.js ) 같은 라이브러리를 이용해 누구나 웹으로 접근할 수 있는 서비스를 개발하여 도메인을 호스팅하여 출시하는 걸 목표로 합니다.서버 개발은 앱 개발자와 웹 개발자에게 내부 데이터를 편집하고 내려받을 수 있도록 API를 개발하고 API 문서를 작성하여 전달하는 걸 목표로 합니다. 추가로 24시간 365일 내내 쾌적하게 서비스가 운영될 수 있도록 클라우드 셋팅을 한다든지 등의 목표를 가집니다. 서버 개발은 IT 동아리마다 언어와 언어에 맞는 프레임워크를 이용하는 것이 다르므로 많은 참고를 하셔야 합니다.Java 또는 Kotlin 언어를 사용하는 동아리는 Spring Framework, Spring Boot 프레임워크로 API 서버를 개발합니다.Python 언어를 사용하는 동아리는 Django, Flask, FastAPI 프레임워크로 API 서버를 개발합니다.Node 환경을 이용하는 동아리는 JavaScript 또는 TypeScript 언어로 Express, NestJS 프레임워크로 API 서버를 개발합니다. 아래 언어들을 사용하는 IT 동아리는 거의 없지만 참고차 작성합니다!기타 Ruby 언어의 경우 Ruby On Rails, Sinatra 프레임워크, Go 언어의 경우 Gin 프레임워크 등으로 개발합니다.C# 언어의 경우 ASP.Net 프레임워크로 개발합니다. 프로덕트 디자인은 Adobe XD, Figma 를 이용하여 프로덕트 컨셉을 녹이고 서비스를 사용하는 유저 플로우를 고려하여 화면을 설계 합니다. Figma 를 공유하거나 Zeplin 으로 개발자에게 애셋 이미지를 전달하고 화면 설계 사항 ( 크기, 폰트 등 ) 들을 전달합니다.앱 개발의 경우 앱 스토어와 플레이 스토어에 제출용으로 앱 이미지 또는 소개 영상을 작업합니다.추가적으로 서비스 컨셉을 소개하는 포트폴리오도 작업합니다. 기획은 시장을 조사하고 고객에게 필요한 니즈를 파악한 걸 기반으로 아이디어를 개발자와 디자이너에게 서비스 컨셉을 제안합니다.비즈니스 모델을 설정하여 수익을 어떻게 내는지, 고객 유치를 어떻게 잘 할 수 있는지 고민합니다.기획 포지션은 IT 연합 동아리에서 많이 있는 포지션은 아니라서 참고 부탁드립니다. 데이터 분석은 통계 지식과 인포그래픽을 활용하여 날 것의 데이터의 동향을 시각적으로 표현합니다. R 언어, 파이썬 언어로 데이터의 특성을 이해하고 그래프 등으로 표현해보고 포토샵과 일러스트레이터를 활용하여 어떻게 보기 좋은 인포그래픽을 만들 지 고민합니다.서비스를 개발하는 IT 연합 동아리 보다는 데이터 분석을 전문으로 하는 IT 연합 동아리에서 모집합니다. 머신러닝은 주어진 데이터를 기반으로 새로운 데이터가 들어오면 어떤 데이터인지 판단하거나, 수학적 특성으로 데이터를 분류합니다. 일반적인 데이터 특성과 다른 데이터를 인식한다든지, 기존 데이터로 새로운 콘텐츠를 추천해줄 수 있습니다.딥러닝은 인공신경망을 수학적으로 구현하여 오차를 수정해 나가는 기술이다. 날 것의 데이터를 직접 파악하기 어려운 이미지나 음성, 영상 데이터를 가지고 오차를 수정해가며 정교한 답을 예측할 수 있습니다. 이를 통해 기존에 없는 이미지나 음성, 영상을 제작할 수도 있습니다.머신러닝 / 딥러닝 분야는 데이터 분석과 같이 모집하는 경우가 많습니다. 1. 매쉬업, Mash-Up (23년 1월 11일 수요일부터 모집 예정)매쉬업 동아리 홈페이지 화면매쉬업 IT 연합 동아리는 개발, 디자인에 관심과 열정이 있는 사람들이 모인 단체로 UX/UI Design, Android, iOS, Web, Node, Spring 총 6개의 팀으로 구성되어 있습니다. 매주 팀별 스터디 진행과 함께 짝수 주에는 전체모임의 세미나 및 네트워킹을 진행하고 있으며, 이를 통하여 개인의 전문역량과 협업능력을 증대시키고자 합니다.궁극적으로 매쉬업은 활동 기간동안 프로젝트 팀을 이뤄 서비스를 출시하는 것을 목표로 하고 있는 IT 연합 동아리 입니다.홈페이지 주소 : https://www.mash-up.kr/블로그 주소 : https://mash-up.tistory.com/페이스북 주소 : https://www.facebook.com/mashupgroup/비핸스 주소 : https://www.behance.net/Mash-Up깃허브 주소 : https://github.com/mash-up-kr최근 기수 : 12기최근 기수 모집 공고 :12기 : https://recruit.mash-up.kr/ 11기 : https://www.notion.so/Mash-Up-11th-Rookie-Recruiting-2d94745cf6014adfb5e95ddc33dd32dd다음 모집 일정 : 13기 - 23년 1월 11일 수요일부터 모집 예정, 14기 - 23년 하반기 모집 예정예상 동아리 인원 : 80 ~ 100 여명활동 장소 : 서울권활동 내용 : 프로젝트 / 스터디 / 네트워킹모임 시각 : (전체 모임) 둘 째 주, 넷 째 주 토요일 오후 3시, (팀 모임) 팀별 상이모집 대상 : 대학생 / 직장인 / IT 취업준비자모집 분야디자이너Product Design 팀개발자클라이언트 개발자모바일 개발자 Android 팀iOS 팀프론트엔드 개발자Web (React) 팀서버 개발자Spring 팀Node 팀지원 후기매쉬업 10기 스프링팀 지원 후기 - https://eocoding.tistory.com/59매쉬업 10기 노드팀 지원 후기 : https://velog.io/@nari120/Mash-Up-IT-%EA%B0%9C%EB%B0%9C-%EB%8F%99%EC%95%84%EB%A6%AC-10%EA%B8%B0매쉬업 11기 스프링팀 지원 후기 : https://devlog-wjdrbs96.tistory.com/430매쉬업 12기 웹팀 지원 후기 : https://velog.io/@otterji/IT-%EB%8F%99%EC%95%84%EB%A6%AC-Mash-Up-%EC%A7%80%EC%9B%90%EC%84%9C-%EC%9E%91%EC%84%B1-%ED%9B%84%EA%B8%B0활동 후기매쉬업 iOS 팀 활동 후기 : https://onemoonstudio.tistory.com/19매쉬업 5기 ~ 12기 iOS 팀 & 스프링팀 & 노드팀 & 웹팀 후기 : https://itchipmunk.tistory.com/488매쉬업 12기 안드로이드팀 프로젝트 후기 : https://mash-up.tistory.com/entry/HMM%ED%8C%80%EC%9D%98-%EC%B7%A8%EB%AC%B8%EC%B7%A8%EB%8B%B5-%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%B9%9C%EC%B9%9C%EC%9D%84-%EC%86%8C%EA%B0%9C%ED%95%A9%EB%8B%88%EB%8B%A4%F0%9F%A5%B0매쉬업 12기 웹팀 프로젝트 후기 : https://brunch.co.kr/@swimjiy/46매쉬업 12기 디자인팀 프로젝트 후기 : https://ux-navigator-story.tistory.com/9매쉬업 12기 활동 후기 : https://velog.io/@prayme/Mash-Up-12%EA%B8%B0-%ED%9B%84%EA%B8%B0매쉬업 9기 웹팀 활동 후기 : https://medium.com/guleum/mash-up-your-ideas-a319cb364324매쉬업 10기 안드로이드팀 활동 후기 : https://jaeryo2357.tistory.com/91매쉬업 8기 안드로이드팀 활동 후기 : https://black-jin0427.tistory.com/265매쉬업 11기 스프링팀 활동 후기 : https://devlog-wjdrbs96.tistory.com/430매쉬업 11기 노드팀 활동 후기 : https://velog.io/@haron/%EB%A7%A4%EC%8B%9C%EC%97%85-11%EA%B8%B0-%ED%95%B4%EC%BB%A4%ED%86%A4-%ED%9A%8C%EA%B3%A0매쉬업 10기 해커톤 회고 : https://d2fault.github.io/2021/03/01/20210301-diary/매쉬업 7기 안드로이드팀 활동 후기 : https://black-jin0427.tistory.com/227매쉬업 11기 활동 회고 : https://brunch.co.kr/@swimjiy/382021 년 활동 회고 : https://gardeny.tistory.com/49매쉬업 8기 프로덕트 디자인팀 활동 후기 : https://flygoeun.tistory.com/42. 솝트, SOPTSOPT 동아리 로고S.O.P.T 는 Shout Our Passion Together의 약자로 대학생 IT 연합 동아리입니다.동아리는 수도권 지역 대학의 대학생들로 구성 되어있으며, IT 창업을 목적으로 하고 있습니다. 홈페이지 주소 : http://sopt.org/wp/페이스북 주소 : https://ko-kr.facebook.com/clubsopt/유투브 주소 : https://www.youtube.com/channel/UCui_xDNrVlxAuGJUV8zmN6A인스타그램 주소 : https://www.instagram.com/sopt_official/최근 기수 : 31기최근 기수 모집 공고 : https://www.youtube.com/watch?v=hKbpVnrwKnY다음 모집 일정 : 32기, 23년 3월 예상예상 모집 인원 : 약 120 명경쟁률 : 8.9 : 1 ( 31기 기준 ), 8.6  : 1 ( 29기 기준 ) 10.0 : 1 ( 28기 기준 )예상 동아리 인원 : 약 200 여명활동 장소 : 수도권활동 내용 : 세미나 강의 / 프로젝트 / 네트워킹모임 시각 : 매주 토요일 2시에 진행모집 대상 : 대학생모집 분야기획디자인개발안드로이드iOS웹서버지원 후기32기 서버파트 YB 불합격 후기 : https://itchipmunk.tistory.com/52031기 서버파트 OB 지원 후기 : https://vanillacreamdonut.tistory.com/29731기 웹파트 지원 후기 : https://velog.io/@juurom/SOPT-SOPT-31%EA%B8%B0-%EC%9B%B9%ED%8C%8C%ED%8A%B8-%EC%A7%80%EC%9B%90-%ED%9A%8C%EA%B3%A0%EB%A1%9D30기 기획파트 합격 후기 : https://sz-inspiration.tistory.com/1630기 iOS파트 합격 후기 : https://inuplace.tistory.com/114730기 iOS YB 지원 후기 : https://vanillacreamdonut.tistory.com/21729기 안드로이드파트 지원 후기 : https://heaven0713.tistory.com/5629기 웹파트 면접 후기 : https://nukw0n-dev.tistory.com/2329기 iOS파트 합격 후기 : https://hellozo0.tistory.com/35229기 디자인파트 지원 후기 : https://zeonni.tistory.com/629기 OB 지원 후기 : https://ju-hyeon.tistory.com/2028기 서버파트 지원 후기 : https://ju-hyeon.tistory.com/1928기 웹파트 지원 후기 : https://velog.io/@hojin11choi/SOPT-%EB%A9%B4%EC%A0%91-%ED%9B%84%EA%B8%B028기 iOS파트 지원 후기 : https://velog.io/@dlwns33/SOPT-28%EA%B8%B0-SOPT-YB-%EC%A7%80%EC%9B%90-%ED%9B%84%EA%B8%B028기 iOS파트 지원 후기 : https://kingwltn.tistory.com/926기 안드로이드파트 지원 후기 : https://leejieun1121.github.io/.etc/SOPT%EB%A9%B4%EC%A0%91%ED%9B%84%EA%B8%B0/27기 안드로이드파트 지원 후기 : https://wonnyhouse.tistory.com/24928기 서버파트 지원 후기 : https://expresshighway.tistory.com/5024기 안드로이드파트 지원 후기26기 디자인파트 지원 후기 : https://m.blog.naver.com/jj_bling/22196375383929기 서버파트 지원 후기 : https://yull-study-code.tistory.com/825기 서버파트, 27기 웹파트 지원 후기 : https://juhi.tistory.com/228기 서버파트 지원 후기 : https://iot624.tistory.com/13528기 iOS파트 지원 후기 : https://mini-min-dev.tistory.com/629기 웹파트 지원 후기 : https://snupi.tistory.com/16528기 iOS파트 지원 후기 : https://taekki-dev.tistory.com/3527기 iOS파트 지원 후기25기 서버파트 지원 후기 : https://kkoon9.tistory.com/4329기 iOS파트 지원 후기 : https://beansbin-develop.tistory.com/829기 웹파트 지원 후기 : https://small-j.tistory.com/3729기 서버파트 지원 후기 : https://ajh322.tistory.com/350기획파트 지원 후기 : https://hio731.wordpress.com/mine/s-o-p-t/활동 후기30기 서버파트 활동 후기 : https://woojin.tistory.com/3829기 서버파트 활동 후기 : https://blog.hyositive.com/4427기 서버파트 활동 후기 : https://overcome-the-limits.tistory.com/1128기 서버파트 활동 후기 : https://ju-hyeon.tistory.com/1422기 디자인파트 활동 후기 : https://besign35.oopy.io/aaeae1e3-f775-4833-9543-0e41ec0ad09f25기 기획파트 활동 후기 : https://plavement.tistory.com/5225기 디자인파트 활동 후기 : https://blog.naver.com/jwyandkrh/22187999424125기 서버파트 활동 후기 : https://ooeunz.tistory.com/4428기 서버파트 활동 후기 : https://iot624.tistory.com/16225기 기획파트 활동 후기 : https://everybody-yeah.tistory.com/225기 안드로이드파트 활동 후기 : https://kangmin1012.tistory.com/1325기 기획파트 활동 후기 : https://leeyeseul.tistory.com/3329기 서버파트 활동 후기 : https://yull-study-code.tistory.com/926기 기획파트 활동 후기 : https://s0ng-2-63.tistory.com/2226기 안드로이드파트 활동 후기26기 안드로이드파트 활동 후기 : https://brunch.co.kr/@danmin/529기 iOS파트 활동 후기 : https://hellozo0.tistory.com/3623. 넥스터즈, NEXTERS (23년 5월 모집 예정)넥스터즈 홈페이지 화면NEXTERS는 IT 업계를 주도하는개발자와 디자이너를 위한 모임입니다.자유롭게 협업하고 소통하며,자기역량 강화와 새로운 서비스 경험을 통해IT 인재로 발전하는 것을 목표로 합니다.수도권 중심으로 대학생과 직장인이 활동하며대학생은 실무에 준하는 협업을,직장인은 새로운 도전을 경험할 수 있습니다. 홈페이지 주소 : http://teamnexters.com/ 페이스북 주소 : https://ko-kr.facebook.com/Nexterspage/최근 기수 : 22기최근 기수 모집 공고 : http://teamnexters.com/recruitment다음 모집 일정 : 23기, 23년 5월 예상예상 모집 인원 : 30 ~ 40 명경쟁률 :(개발자) 13.4 : 1 (디자이너) 15.3 : 1 (22기 기준)(개발자) 15.0 : 1 (디자이너) 9.0 : 1 (21기 기준)(개발자) 22.0 : 1 (디자이너) 16.0 : 1 (20기 기준)활동 장소 : 수도권활동 내용 : 프로젝트모임 시각 : 매주 토요일 오후 1시~5시에 진행되는 정규 세션모집 대상 : 대학생 / 직장인모집 분야디자인안드로이드iOS웹서버지원 후기22기 iOS팀 지원 후기 : https://velog.io/@dayo2n/NEXTERS-iOS-%EA%B0%9C%EB%B0%9C%EC%9E%90-%EC%A7%80%EC%9B%90%EA%B8%B022기 서버팀 지원 후기 : https://kth990303.tistory.com/40121기 디자인팀 지원 후기 : https://juyami.tistory.com/11421기 iOS팀 지원 후기 : https://jcrescent61.tistory.com/m/4121기 지원 후기 : https://imksh.com/104 & https://imksh.com/10519기 프론트엔드팀 지원 후기 : https://minkukjo.github.io/life/2021/06/23/review/17기 안드로이드팀 지원 후기 : https://salix97.tistory.com/27018기 서버팀 지원 후기 : https://eocoding.tistory.com/59넥스터즈 면접 팁 : https://devvkkid.tistory.com/12718기 웹팀 지원 후기 : https://shiincs.medium.com/%EB%84%A5%EC%8A%A4%ED%84%B0%EC%A6%88-nexters-%EC%A7%80%EC%9B%90-%ED%95%A9%EA%B2%A9-%ED%9B%84%EA%B8%B0-2a0a655a293814기 서버팀 안드로이드팀 지원 후기 : https://pjh3749.tistory.com/22716기 서버팀 지원 후기 : https://blog.naver.com/PostView.nhn?blogId=rkdudwl&logNo=221738894361https://blog.naver.com/rkdudwl/22173582409016기 안드로이드팀 iOS팀 지원 후기 : https://se-h2.tistory.com/30활동 후기21기 서버팀 활동 후기 : https://imksh.com/10721기 PM 활동 후기 : https://enebin.medium.com/%ED%9A%8C%EA%B3%A0-%EB%84%A5%EC%8A%A4%ED%84%B0%EC%A6%88-21%EA%B8%B0-%EB%84%A4%EB%8B%88%EC%98%A4-team-vs-1-f391a84a87e621기 웹팀 활동 후기 : https://velog.io/@smjan27/nexters-21th19기 운영진 활동 후기 : https://brunch.co.kr/@gg2/1514기 서버팀 활동 후기 : https://makemethink.tistory.com/16015기 활동 후기 : https://devvkkid.tistory.com/12516기 안드로이드팀 활동 후기 : https://wlgusdn700.tistory.com/11112기 iOS팀 활동 후기 : https://hyerios.tistory.com/23517기 안드로이드팀 활동 후기 : https://flymogi.tistory.com/6816기 안드로이드팀 활동 후기 : https://s0ng-2-63.tistory.com/22 4. 디프만, DEPROMEET (23년 2월 모집 예정)디프만 홈페이지 화면그리던 프로덕트를 만들 시간디자이너와 프로그래머가 만났을 때학생, 취준생, 직장인의 동반 성장을 추구하는 IT 동아리입니다. 홈페이지 주소 : https://www.depromeet.com/페이스북 주소 : https://www.facebook.com/depromeet/ 미디엄 주소 : https://depromeet.medium.com/최근 기수 : 12기최근 기수 모집 공고다음 모집 일정 : 13기모집 인원 : 약 60 ~ 70명경쟁률 : (개발자) 8.4 : 1 (디자이너) 9.5 : 1 ( 12기 기준 )(개발자) 11.0 : 1 (디자이너) 7.0 : 1 ( 11기 기준 )(개발자) 6.0 : 1 (디자이너) 5.0 : 1 ( 10기 기준 )예상 동아리 인원 : 약 100 여명활동 장소 : 온라인활동 내용 : 프로젝트모임 시각 : 매주 토요일 오후 2시-5시에 진행되는 정규 세션모집 대상 : 대학생 / 직장인모집 분야디자이너FE 개발자WebiOSAndroidBE 개발자지원 후기11기 BE 개발자팀 지원 후기 : https://minsoolog.tistory.com/499기 BE 개발자팀 지원 후기 : https://minkukjo.github.io/life/2020/07/10/daily/9기 지원 후기 : https://ahn3330.tistory.com/96안드로이드팀 지원 후기 : https://enant.tistory.com/1310기 웹팀 지원 후기 : https://seokzin.tistory.com/entry/%ED%9A%8C%EA%B3%A0-%EB%94%94%ED%94%84%EB%A7%8C-10%EA%B8%B0-%ED%95%A9%EA%B2%A920년도 2학기 지원서 : https://alpoxdev.tistory.com/3활동 후기11기 BE 개발자팀 후기 : https://devnm.tistory.com/12 10기 & 11기 디자인팀 후기 : https://kusim.tistory.com/entry/%EB%94%94%ED%94%84%EB%A7%8C-%EB%94%94%EC%9E%90%EC%9D%B4%EB%84%88%EC%99%80-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80-%EB%A7%8C%EB%82%A0-%EB%95%8C-Depromeet-10%EA%B8%B0-11%EA%B8%B0-%ED%9A%8C%EA%B3%A011기 디자인팀 후기 : https://brunch.co.kr/@tudandilion/310기 & 11기 디자인팀 & 부회장 후기 : https://imean.tistory.com/1011기 웹팀 OB 후기 : https://danminblog.tistory.com/89 8기 웹팀 후기8기 웹팀 : https://brunch.co.kr/@danmin/56기 웹팀 해커톤 후기 : https://junekim.dev/Web_Dev/depromeet_2/ 5. AUSG (23년 6월 예정)AUSG 홈페이지 화면AUSG는 AWSKRUG University Student Group의 약자로, AWS와 Cloud, 프로그래밍에 관심있는 대학생들의 모임입니다.자유로운 분위기에서 다양한 사람을 만나 각자의 경험을 나누고 소통할 수 있습니다.AWS 한국사용자모임과 함께하고 있어요! 😎 우리는 각자의 경험을 나누고 함께 성장하는 것을 추구합니다.막히는 것이 있다면 언제든 편하게 같이 이야기합니다.각자의 자리에서 가진 고민들을 함께 나누며 발전하고 있습니다.개발 뿐만 아니라, 즐거운 네트워크 형성도 하고 있습니다! 홈페이지 주소 : https://ausg.me/페이스북 주소 : https://www.facebook.com/ausgkr/블로그 주소 : https://ausg.me/blog최근 기수 : 6기최근 기수 모집 공고다음 모집 일정 : 7기, 23년 6월 예상모집 인원 : 약 20 ~ 30 명예상 동아리 인원 : 약 40 ~ 50 여명활동 장소 : 오프라인활동 내용 : 스터디 / 세미나모임 시각 : 격주 월요일 저녁 8시 ~ 10시 오프라인 정기 모임모집 대상 : 대학생지원 후기3기 지원 후기 : https://yorr.tistory.com/85기 지원 후기 : https://devlog-wjdrbs96.tistory.com/430활동 후기4기 ~ 5기 활동 후기 : https://danminblog.tistory.com/883기 활동 후기 : https://yorr.tistory.com/92기 활동 후기 : https://medium.com/@yoonhoGo/ausg-2%EA%B8%B0%EB%A5%BC-%ED%99%9C%EB%8F%99%ED%95%98%EA%B2%8C-%EB%90%AC%EC%8A%B5%EB%8B%88%EB%8B%A4-90a8cbf4ce4a4기 오거나이저 회고https://velog.io/@coffee-con/AUSG-3%EA%B0%9C%EC%9B%94%EA%B0%84%EC%9D%98-%ED%9A%8C%EA%B3%A0%EB%A1%9D-Part.2-g6twpv4k https://velog.io/@coffee-con/AUSG-3%EA%B0%9C%EC%9B%94%EA%B0%84%EC%9D%98-%ED%9A%8C%EA%B3%A0%EB%A1%9D-Part.1 6. YAPP (23년 3월 모집 예정)YAPP은 대학생들의 다양한 아이디어와 열정 그리고 가능성을 바탕으로조그마한 변화일지라도 의미 있는 일을 추구하며기존에 없던 새로운 가치를 만들기 위해 노력하는'대학생 연합 기업형 IT 동아리' 입니다. YAPP은 기획자, 디자이너, 개발자로 팀을 구성하여 6개월간 하나의 IT 서비스(웹,앱,etc.)를 제작하는 연합 동아리입니다.프로젝트는 기업형 프로세스에 따라 진행하고 런칭하여, 팀원들의 아이디어를 실제 IT 서비스로 구체화시키는 경험을 할 수 있습니다. 홈페이지 주소 : http://yapp.co.kr/페이스북 주소 : https://www.facebook.com/yapp.co.kr최근 기수 : 21기최근 기수 모집 공고 : https://www.yapp.co.kr/recruit다음 모집 일정 : 22기, 23년 3월 예상활동 장소 : 온라인활동 내용 : 스터디 / 세미나 / 프로젝트모임 시각 : 매주 일요일 오후 2시 ~ 5시모집 대상 : 대학생 / 직장인 / 취업준비자경쟁률 : 8.4 : 1 ( 21기 기준 )모집 분야플래너 (기획, PM)디자이너엔지니어 (개발자)iOSAndroidWeb Fornt-EndBack-End지원 후기21기 서버팀 지원 후기 : https://puleugo.tistory.com/11221기 웹팀 지원 후기 : https://bba-jin.tistory.com/5720기 서버팀 합격 후기 : https://velog.io/@0_hun/IT-%EC%97%B0%ED%95%A9%EB%8F%99%EC%95%84%EB%A6%AC-YAPP-20%EA%B8%B0-%ED%95%A9%EA%B2%A9-%ED%9B%84%EA%B8%B0-BACKEND%EC%A7%81%EA%B5%B020기 웹팀 지원 후기 : https://velog.io/@taeeeeun/IT-%EC%97%B0%ED%95%A9-%EB%8F%99%EC%95%84%EB%A6%AC-YAPP-20%EA%B8%B0-%EC%9B%B9-%EC%A7%81%EA%B5%B0-%EC%84%9C%EB%A5%98-%EB%A9%B4%EC%A0%91-%ED%95%A9%EA%B2%A9-%ED%9B%84%EA%B8%B020기 안드로이드팀 지원 후기 : https://yjyoon-dev.github.io/review/2022/09/16/yapp-review/19기 백엔드팀 지원 후기 : https://jionchu.tistory.com/11516기 프론트엔드 지원 후기 : https://blog.naver.com/PostView.nhn?blogId=rkdudwl&logNo=22182818964119기 백엔드팀 지원 후기 : https://velog.io/@ksmfou98/IT-%EC%97%B0%ED%95%A9-%EB%8F%99%EC%95%84%EB%A6%AC-YAPP-19%EA%B8%B0-%EB%A9%B4%EC%A0%91-%ED%9B%84%EA%B8%B019기 백엔드팀 지원 후기 : https://doiler.tistory.com/518기 iOS 팀이동 지원 후기 : https://beenii.tistory.com/13816기 웹팀 지원 후기 : https://blog.naver.com/PostView.naver?blogId=rkdudwl&logNo=221828189641&parentCategoryNo=&categoryNo=34&viewDate=&isShowPopularPosts=false&from=postView활동 후기20기 안드로이드팀 활동 후기 : https://blog.yjyoon.dev/review/2022/09/16/yapp-review/20기 웹팀 활동 후기 : https://velog.io/@dongkyun/%ED%9A%8C%EA%B3%A0-Yapp-20%EA%B8%B0-Weekand-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%EB%A5%BC-%EB%A7%88%EC%B9%98%EB%A9%B4%EC%84%9C19기 웹팀 활동 후기 : https://doiler.tistory.com/3616기 활동 후기 : https://velog.io/@jshme/YAPP-%ED%8C%80%EC%9B%90%EC%97%90%EC%84%9C-%EB%A9%B4%EC%A0%91%EA%B4%80%EA%B9%8C%EC%A7%802019년 활동 후기 : https://k-elon.tistory.com/3513기 활동 후기 : https://u0jin.tistory.com/m/3416년 기획팀 활동 후기 : https://brunch.co.kr/@sktjdghks/4 7. DDD (23년 3월 모집 예정)DDD 동아리 로고""Dynamic Project""열정넘치고 성장하고 싶은 사람들이만나서비스를 “직접” 만들어보는 경험을 해보세요‼️DDD.는 개발자와 디자이너가 함께 사이드 프로젝트를 진행하며 서로 파트에 대한이해와 친목을 쌓을 수 있는 기회를 제공합니다. 직군세션 및 세미나를 통해서는 서로 알고있는정보와 생각들을 자유롭게 네트워킹하며 지식을 확장합니다.Side Project에 관심이 있는 열정과 재능이 넘치는 6기 멤버분들을 기다리고 있습니다.많은 개발자, 디자이너분들의 신청을 기다립니다! 페이스북 주소 : https://www.facebook.com/dddstudy미디엄 주소 : https://dddstudy.medium.com/최근 기수 : 8기최근 기수 모집 공고 : https://www.facebook.com/dddstudy/posts/pfbid029pM7vCoXR93a3Dcub4ceJocSXXG54nAnDTy3yo7JvgRLG4Bhe8aeyqZUYPfdnAVRl다음 모집 일정 : 9기, 23년 3월 예상예상 동아리 인원 : 약 40 ~ 50 여명활동 장소 : 온라인활동 내용 : 프로젝트 / 세미나 / 네트워킹모임 시각 : 격주 토요일 2시 ~ 5시모집 대상 : 대학생 / 직장인 / 취업준비자참가비 : 15만원 (7만원 운영비 + 8만원 노쇼비용 환급 예정)모집 분야디자인안드로이드iOS웹서버지원 후기6기 서버팀 지원 후기 : https://blue-boy.tistory.com/242활동 후기4기 3기 iOS 팀 회고 : https://hyesunzzang.tistory.com/1714기 안드로이드 팀 회고 : https://velog.io/@jshme/%EA%B0%9C%EB%B0%9C-%EB%8F%99%EC%95%84%EB%A6%AC-DDD-4%EA%B8%B0-%ED%9A%8C%EA%B3%A0 8. Fun.D (23년 1월 모집 예정)Fun.D 동아리 홈페이지 화면펀디(Fun.D)는 기획자, 디자이너, 개발자들이 모여 '배움과 교류'를 통해 성장하는 IT 프로젝트 커뮤니티입니다.149명의 참가자와 함께 했던 6기에 이어 2022년 7기를 진행하게 되었습니다.우선 그 동안 펀디에서 어떤 프로젝트들이 진행되었는지 확인해보세요. 네이버 카페 : https://cafe.naver.com/eofl7942유투브 주소 : https://www.youtube.com/channel/UC1BRoMHI8Ucq11l60c3b89w최근 기수 : 7기최근 기수 모집 공고 : https://fun-d.notion.site/fun-d/Fun-D-7-f3fc18c718914e2ea1d540b0244d7345다음 모집 일정 : 8기, 23년 1월 예상예상 모집 인원 : 약 80 명예상 동아리 인원 : 약 80 ~ 100 여명활동 장소 : 온라인활동 내용 : 프로젝트 / 네트워킹모집 대상 : 대학생, 취준생 / 3년차 이하 직장인 / 3년차 이상 직장인참가비 : 20만원 ( 수료 환급비 15만원 + 상금 및 운영비 5만원 )중간 발표 이후 5만원, 최종 발표 이후 10만원 환급상금 총 300만원모집 분야기획자 - 12명대학생 + 취준생 - 4명3년차 이하 직장인 - 4명3년차 이상 직장인 - 4명디자이너 - 20명대학생 + 취준생 - 6명3년차 이하 직장인 - 7명3년차 이상 직장인 - 7명프론트엔드 개발자 - 24명대학생 + 취준생 - 7명3년차 이하 직장인 - 8명3년차 이상 직장인 - 9명백엔드 개발자 - 24명대학생 + 취준생 - 7명3년차 이하 직장인 - 8명3년차 이상 직장인 - 9명활동 후기7기 활동 후기 : https://padro.tistory.com/203?category=759344 9. 프로그라피 (23년 1월 모집 예정)프로그라피 홈페이지 화면🛠 프로그라피는 가벼운 동아리가 아닙니다.프로그라피는 단순히 지식을 습득하고 프로젝트를 경험하는 것을 목적으로 하는 동아리가 아닙니다.우아한형제들, 쿠팡, 카카오, 29CM, 아이디어스 등 다양한 회사에서개발자와 디자이너로 일하고 있는 많은 운영진들과 열정과 실력을 갖춘 활동인원이 모여서비스를 직접 기획하고 개발하며 배포하는 완성도 높은 프로젝트 진행을 목표로 합니다.🌱 운영진과 활동인원의 교류와 상생을 추구합니다.운영진은 구성원의 성장과 동기부여를 위해 다양한 각도에서 노력하고 참여하며활동인원은 능동적이고 열정적으로 활동하며 모든 구성원이 보람을 느낄 수 있는 결과물을 만듭니다.운영진은 단순한 개발, 디자인 선생님이 아닌 여러분들과 함께 활동하는 구성원으로써멋진 사람들이 모여드는 즐거운 모임을 만들기 위해서 노력합니다.🌟 개발자와 디자이너의 멋진 커뮤니티를 꿈꿉니다.프로그라피는 실제로 운영할 수 있는 수준의 서비스를 개발하는 모임임과 동시에개발자와 디자이너의 커리어를 꿈꾸는 많은 멋진 사람들이 모여 교류하고 소통하는커뮤니티가 되기를 꿈꿉니다. 홈페이지 주소 : https://www.prography.org/페이스북 주소 : https://www.facebook.com/thePrography/최근 기수 : 7기최근 기수 모집 공고 : https://www.facebook.com/thePrography/posts/550401208905896다음 모집 일정 : 8기 23년 1월예상 모집 인원 : 약 30 ~ 40 명예상 동아리 인원 : 50 ~ 70 여명 ( 직장인 : 대학생 =  2 : 3 )활동 장소 : 온라인활동 내용 : 프로젝트 / 네트워킹모임 시각 : 매 주 토요일 오후 모집 대상 : 대학생 / 직장인모집 분야웹 프론트 (React)앱 프론트 (Android, iOS)백엔드 (Django, NodeJS, Spring 신설 예정)디자인 (UXUI, BX)지원 후기5기 백엔드 (Django) 지원 후기 : https://planjang.tistory.com/185활동 후기7기 NodeJS 팀 활동 후기 : https://le2ksy.tistory.com/177기 NodeJS 팀 시작 후기 : https://velog.io/@linho1150/Prography-7%EA%B8%B0%EB%A5%BC-%EC%8B%9C%EC%9E%91%ED%95%98%EB%A9%B05기 알고리즘 스터디 회고 : https://prography-tech.github.io/2020/02/19/review-algorithm-study/6기 안드로이드팀 회고 : https://harrywinks.tistory.com/1995기 운영진 회고 : https://velog.io/@xunwk/%EB%8D%94-%EB%82%98%EC%9D%80-%EB%A9%B4%EC%A0%91%EC%9D%84-%EA%B3%A0%EB%AF%BC%ED%95%98%EB%A9%B0-zxk0b76vft6기 안드로이드팀 활동 후기 : https://veritasluxmea-sh.tistory.com/266기 안드로이드팀 회고 : https://harrywinks.tistory.com/1995기 ~ 6.5기 딥러닝팀 회고 : https://breakout-theworld.tistory.com/352020년 회고 : https://paikend.medium.com/good-bye-2020-6cb53d75219a3기 - 5기 NodeJS 멘토 회고백엔드팀 5기 회고6기 백엔드팀 회고 : https://sundries-in-myidea.tistory.com/1114기 프론트엔드 멘토 회고 : https://zinee-world.tistory.com/52810. 피로그래밍 (23년 5월 모집 예정)피로그래밍 PIROGRAMMING 동아리 홈페이지 화면피로그래밍은 프로그래밍 공부를 하고 싶으나 어디서부터 시작해야 할 지 막막한 비전공자들이Python과 Django 프레임워크를 기반으로 웹 개발을 배우고자신만의 웹 서비스를 만들어내는 동아리입니다.비전공자를 기준으로 기초부터 쉽게 차근차근 공부하며 방학동안 집중적으로 코딩에 전념하여웹 프로그래밍의 기반을 확보하는 것을 목표로 합니다. 홈페이지 주소 : https://pirogramming.com/깃허브 주소 : https://github.com/pirogramming인스타그램 주소 : https://www.instagram.com/pirogramming_official/카카오톡 플러스 친구 : https://pf.kakao.com/_xdHxdXK최근 기수 : 18기최근 기수 모집 공고 : 인스타그램 참고https://www.instagram.com/p/Cd8e5RCPGY7/다음 모집 일정 : 19기, 23년 5월 ~ 6월 예정 ( 매 방학마다 진행 )예상 모집 인원 : 약 25 + @ 명경쟁률약 8.0 : 1 ( 18기 기준 )약 8.0 : 1 ( 17기 기준 )약 10.0  : 1 ( 16기 기준 )예상 동아리 인원 : 약 30 ~ 40 명활동 장소 : 온라인 & 오프라인 / 수도권모임 시각 : 방학 매주 화목토 10:00 ~ 17:00참가비 : 12 만원 ( 4만원 운영비, 8만원 보증금 )모집 대상 : 대학생 / 졸업생활동 내용 : 세미나 강의 / 프로젝트한 달간 네이버, 매스프레소, 로앤굿 등의 현업자가 강사로 오전부터 오후까지 신입 기수 대상으로 강의 진행다음 한 달 간은 5명 단위로 팀 프로젝트를 진행모집 분야Django지원 후기17기 지원 후기 : https://uiop5809.tistory.com/22816기 지원 후기 : https://velog.io/@beneficial/%ED%94%BC%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-16%EA%B8%B0-%EC%84%9C%EB%A5%98%ED%95%A9%EA%B2%A9-%EB%A9%B4%EC%A0%91%EB%B3%B5%EA%B8%B014기 지원 후기 : https://progyun.tistory.com/7114기 지원 후기 : https://nwy1996.tistory.com/4112기 지원 후기 : https://rnjsrntkd95.github.io/activity/p'irogarmming/활동 후기17기 활동 후기 : https://uiop5809.tistory.com/4017기 활동 후기 : https://velog.io/@limce21/%ED%94%BC%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-17%EA%B8%B0-%ED%99%9C%EB%8F%99-%ED%9B%84%EA%B8%B012기 활동 회고 : https://aalphaca.tistory.com/3214기 세션 활동 회고 : https://subeen.io/blog/diary/2021-05-18-pirogramming01/14기 프로젝트 회고 : https://subeen.io/blog/diary/2021-05-18-pirogramming02/12기 활동 회고 : https://leocodms.tistory.com/7 11. DnD (22년 12월 모집 예정)DnD 동아리 홈페이지 화면프로젝트에 즐거움을모두에게 기회를DND는 개발자와 디자이너라면 누구나참여할 수 있는 IT비영리단체입니다. DND는 대학생, 현직자 구분 없이 사이드프로젝트를 해보고 싶은 개발자와 디자이너가 팀을 이루어 8주 동안 웹/앱 프로젝트를 진행하고 경험해볼 수 있도록 기획된 비영리단체입니다. 홈페이지 주소 : https://dnd.ac/블로그 주소 : https://dnd.ac/blog인스타그램 주소 : https://www.instagram.com/dnd.ac/깃허브 주소 : https://github.com/DNDACADEMY/유투브 주소 : https://www.youtube.com/channel/UCLzVjG8j1m4X8TSpMF-x5yw최근 기수 : 8기최근 기수 모집 공고 : 인스타그램 참조다음 모집 일정 : 9기, 23년 6월 예정, ( 여름 방학 1회, 겨울 방학 1회 )예상 모집 인원 : 약 60 명경쟁률 : (개발자) 약 22.1 : 1 (디자이너) 약 8.7 : 1예상 동아리 인원 : 약 60 ~ 80 명활동 장소 : 온라인활동 내용 : 프로젝트 / 세미나 / 네트워킹활동비 : 무료모임 시각 : 주 1회 온라인 / 오프라인 모임모집 대상 : 대학생 / 직장인 / 취업준비자모집 분야디자이너 - 20명프론트엔드 개발자 - 20명백엔드 개발자 - 20명지원 후기7기 서버팀 합격 후기 : https://velog.io/@nikki/DND1%EC%B0%A8-%EB%AF%B8%ED%8C%857기 웹팀 지원 후기 : https://www.jongung.com/2406기 안드로이드 개발자 지원 후기 : https://itstory1592.tistory.com/584기 iOS 개발자 지원 후기 : https://beenii.tistory.com/1196기 안드로이드 개발자 합격 후기5기 합격 후기 : https://ghoon99.tistory.com/10?category=1216058활동 후기7기 서버팀 활동 후기 : https://velog.io/@ssssujini99/%ED%99%9C%EB%8F%99-%ED%9B%84%EA%B8%B0-DND-7%EA%B8%B0-%EB%B0%B1%EC%97%94%EB%93%9C7기 웹팀 활동 후기 : https://www.jongung.com/2565기 선발 후기 : https://strawberryjamsea.tistory.com/436기 서버팀 활동 후기 : https://coding-lks.tistory.com/1716기 서버팀 활동 후기 : https://pgmjun.tistory.com/m/466기 안드로이드팀 활동 후기 : https://velog.io/@dddooo9/DND-6%EA%B8%B0-%EC%95%88%EB%93%9C%EB%A1%9C%EC%9D%B4%EB%93%9C-%ED%9B%84%EA%B8%B0DnD 홈페이지 후기 : https://dnd.ac/reviews4기 서버 개발 회고 : https://dailyheumsi.tistory.com/2534기 프론트엔드 개발자 회고 : https://egg-programmer.tistory.com/295?category=8767785기 최종 발표 후기 : https://selena30.tistory.com/163DnD 리브랜딩 후기 : https://medium.com/@danadayoung/dnd-%EB%A6%AC%EB%B8%8C%EB%9E%9C%EB%94%A9-1%EB%85%84-%ED%9B%84-%ED%9A%8C%EA%B3%A0-%EB%B0%8F-%EC%84%B1%EA%B3%BC-%EC%B8%A1%EC%A0%95-%ED%95%98%EA%B8%B0-93815945a9fdDnD 5기 활동 후기DnD 5기 활동 후기 (2)DnD 5기 회고 : https://seokzin.tistory.com/entry/%ED%9A%8C%EA%B3%A0-DND-5%EA%B8%B0%EB%A5%BC-%EB%A7%88%EC%B9%98%EB%A9%B0DnD 서버 개발 회고 : https://shrewd.tistory.com/23  12. CEOS (23년 2월 모집 예정)CEOS 홈페이지 화면신촌 유일의 IT 창업 동아리Start-Up NetWork No.1CEOS; Creativity,Entrepreneurship,Openness,SustainabilityCEOS는 신촌 유일의 IT 창업동아리로,2015년 3월을 1기로 시작하여 올해 2021년에 14기를 맞이합니다.기획, 디자인, 개발 역량을 겸비한열정 있는 대학생들이 모여창업을 경험하고 실현할 수 있습니다. 홈페이지 주소 : https://www.ceos.or.kr/페이스북 주소 : https://www.facebook.com/clubceos인스타그램 주소 : https://www.instagram.com/ceos.sinchon/최근 기수 : 16기최근 기수 모집 공고 : https://www.facebook.com/clubceos/posts/3050163305214321다음 모집 일정 : 17기, 23년 2월달 예상예상 모집 인원 : 약 40 명예상 동아리 인원 : 약 50 명활동 장소 : 온라인, 신촌활동 내용 : 프로젝트 / 네트워킹모임 시각 : 오프라인의 경우 매 주 수요일 저녁 7시모집 대상 : 신촌 지역 대학 출신 ( 연세대, 서강대, 이화여대, 홍익대 )모집 분야기획 - 10 명디자인 - 10명개발자프론트 - 10명백엔드 - 10명지원 후기14기 지원 후기 : https://zaraza.tistory.com/47활동 후기15기 ~ 16기 활동 후기 : https://9yujin.tistory.com/999기 활동 회고 : https://sumini.dev/retrospective/000-sky-closet/ 13. 멋쟁이 사자처럼, LikeLion (23년 2월 모집 예정)멋쟁이 사자처럼 홈페이지멋쟁이사자처럼은 2013년 비영리법인으로 시작하여 국내 및 국외(한국, 미국, 호주, 홍콩, 일본 등) 7,000여명의 대학생에게 프로그래밍 교육을 제공해왔습니다.2018년 5월 영리법인으로 전환하여 교육 대상과 지역(베트남 등)을 확장했고, 현재는 멋쟁이사자처럼 대학생, 멋쟁이사자처럼 직장인 , 멋쟁이사자처럼 AI School , 광주 인공지능사관학교 등의 오프라인 교육과, 글로벌 온라인 코딩 교육 플랫폼  코드라이언(CODE LION)을 개발, 운영하고 있습니다.2018년 5월 영리법인으로 전환한 이후, 2019년 전년 대비 매출액 425%를 달성했고, 2020년에는 전년 대비 1,500% 이상의 성장을 달성했습니다. 이에 역량과 향후 글로벌 차원의 성장성을 인정받아 2019년 9월 미래에셋벤처투자로부터 투자를 유치한바 있습니다. 홈페이지 주소 : https://www.likelion.net/페이스북 주소 : https://www.facebook.com/likelion.net유투브 주소 : https://www.youtube.com/channel/UCYaDkwVaOhuoe_LuFr3lWkA브런치 주소 : https://brunch.co.kr/@likelion인스타그램 주소 : https://www.instagram.com/likelion.official/최근 기수 : 10기최근 기수 모집 공고 : 대학별 상이, 에브리타임 및 페이스북 참고 바람다음 모집 일정 : 11기, 23년 1월 예정, 홈페이지 참고예상 모집 인원 : 20~40여명, 대학별 상이경쟁률 : 대학별 상이예상 동아리 인원 : 20~40여명, 대학별 상이활동 장소 : 온라인, 대학별 상이활동 내용 : 스터디 / 프로젝트 / 네트워킹모임 시각 : 대학별 상이모집 대상 : 대학생모집 분야디자인Python & Django지원 후기9기 지원 후기 : https://guiyum.tistory.com/6010기 지원 후기 : https://itwithruilan.tistory.com/8510기 지원 후기 : https://acho.tistory.com/510기 지원 후기 : https://velog.io/@hamham/%EB%A9%8B%EC%9F%81%EC%9D%B4-%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC-%EB%A9%8B%EC%82%AC-10%EA%B8%B0-%EC%84%9C%EB%A5%98-%EB%A9%B4%EC%A0%91-%ED%95%A9%EA%B2%A9-%ED%9B%84%EA%B8%B09기 지원 후기 : https://blog.naver.com/gene028/2224104475059기 지원 후기 : https://guiyum.tistory.com/638기 지원 후기 : https://yumyumcoding.tistory.com/48기 면접 후기 : https://m.blog.naver.com/jwyandkrh/2218818386217기 합격 후기 : https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=spring_you1&logNo=2214961908718기 면접 후기 : https://kimdee.tistory.com/entry/%EB%A9%8B%EC%9F%81%EC%9D%B4-%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC-8%EA%B8%B0-0-%EB%8F%99%EC%95%84%EB%A6%AC-%EC%A7%80%EC%9B%90%EA%B3%BC-%EB%A9%B4%EC%A0%91-%ED%9B%84%EA%B8%B08기 합격 후기 : https://ckdgus.tistory.com/50단국대 9기 합격 후기 : https://zu-techlog.tistory.com/m/3?category=9235726기 합격 후기 : https://deepinsight.tistory.com/3활동 후기10기 해커톤 후기 : https://choi-records.tistory.com/entry/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC-%EB%A9%8B%EC%82%AC-10%EA%B8%B0-%ED%95%B4%EC%BB%A4%ED%86%A4-%ED%9B%84%EA%B8%B010기 해커톤 후기 : https://cwkim0321.tistory.com/m/810기 활동 후기 : https://velog.io/@hamham/%EB%A9%8B%EC%9F%81%EC%9D%B4%EC%82%AC%EC%9E%90%EC%B2%98%EB%9F%BC-10%EA%B8%B0-%ED%9B%84%EA%B8%B0%ED%95%B4%EC%BB%A4%ED%86%A4-%ED%9B%84%EA%B8%B07기 후기 : https://rebro.kr/424기~5기 후기 : https://itchipmunk.tistory.com/91멋사 후기 모음 : http://hufsglobal.likelion.org/board/7th_recruit_review 14. 클라우드 클럽, CLOUD CLUB ( 3기, 23년 2월 모집 예정 )CLOUD CLUB 로고CLOUD CLUB은 클라우드의, 클라우드에 의한, 클라우드를 위한 IT 연합 동아리로,클라우드에 관심있는 대학생이 모여 네트워킹 & 스터디 하는 동아리입니다.클라우드 클럽은 특정 벤더에 종속되지 않은(vendor-neutral) 폭넓은 클라우드 인프라 경험을 추구합니다.⭐️클둥이's Benefits⭐️- AWS, 컨테이너 기술, 쿠버네티스 등 가장 핫🔥한 클라우드 서비스를 함께 경험하고 공부할 수 있습니다!- 클라우드 기술에 관심있는 대학생과 네트워킹할 수 있는 CCND(Cloud Club Networking Day)가 기다리고 있습니다!- 외부 기관(기업 or 동아리)의 교육 세미나를 통해 전문적인 지식과 현업자와의 Q&A 기회를 제공받을 수 있습니다!- 또한 클라우드 클럽은 특정 벤더에 종속되지 않은(vendor-neutral) 폭넓은 클라우드 인프라 경험을 추구합니다. 클라우드 엔지니어링, 데브옵스, 마이크로서비스 아키텍처와 같은 다양한 클라우드 인프라를 경험하고 싶다면? 지금 바로 지원해 주세요! 홈페이지 주소 : https://cloudclub.oopy.io/ 최근 기수 : 2기최근 기수 모집 공고 : 2기 https://cloudclub.oopy.io/apply다음 모집 일정 : 3기, 23년 2~3월 예정활동 장소 : 온라인 / 오프라인활동 내용 : 스터디 / 세미나모임 시각 : 매 주 목요일 오프라인 강남 인근 20시 / 온라인 22시 (https://cloudclub.oopy.io/plan)모집 대상 : 대학생 / 직장인 15. 보아즈, BOAZ (21기, 23년 12월 예정)BOAZ 동아리 로고보아즈는 '데이터 분석', '데이터 시각화', '데이터 엔지니어링' 총 세 부문에서 신입 회원을 모집하고 있습니다.각 부문별 신입 회원은 기본기를 익힐 수 있는 BASE Session, 직접 문제를 정의하고 해결해보는 ADVance Session을 통해 빅데이터 전문성을 쌓게 됩니다.뿐만 아니라 멘토-멘티 스터디를 비롯한 다양한 스터디, 부문 공동세션 등을 통해 자신이 추가로 관심 있는 영역에서 역량을 키울 수 있습니다. 홈페이지 주소 : https://www.bigdataboaz.com/페이스북 주소 : https://www.facebook.com/BOAZbigdata유투브 주소 : https://www.youtube.com/@bigdataboaz4452인스타그램 주소 : https://www.instagram.com/boaz_bigdata/블로그 주소 : https://blog.naver.com/boazbigdata최근 기수 : 20기최근 기수 모집 공고 : https://www.bigdataboaz.com/recruitment다음 모집 일정 : 21기, 23년 12월 예상활동 장소 : 신촌 근방활동 내용 : 스터디 / 프로젝트 / 컨퍼런스모임 시각데이터 분석 : 매주 목요일 18시 (방학) 19시 (학기)데이터 시각화 : 매주 월요일 18시 (방학) 19시 (학기)데이터 엔지니어링 : 매주 수요일 18시 (방학) 19시 (학기)모집 대상 : 대학생 / 대학원생모집 분야데이터 분석 : 머신러닝 및 딥러닝 최신논문 리뷰와 구현학습데이터 시각화 : Python과 Tableau를 활용한 데이터 전처리 및 시각화데이터 엔지니어링 : 오픈소스 활용한 분산, 실시간 처리 시스템 구현지원 후기19기 데이터 분석 합격 후기 : https://velog.io/@jus6886/%EB%B3%B4%EC%95%84%EC%A6%88-%EB%B6%84%EC%84%9D-%EB%B6%80%EB%AC%B8-%ED%95%A9%EA%B2%A9-%ED%9B%84%EA%B8%B018기 데이터 엔지니어링 합격 후기 : https://kgw7401.tistory.com/2518기 데이터 분석 합격 후기 : https://wannabenice.tistory.com/217기 데이터 분석 합격 후기 : https://tomatolife.tistory.com/9516기 데이터 시각화 합격 후기 : https://blog.naver.com/dch222/22218054655616기 데이터 분석 합격 후기 : https://bigdata-analyst.tistory.com/29414기 데이터 시각화 지원 후기 : https://blog.naver.com/kadfjs/221759101449활동 후기18기 데이터 분석 활동 후기 : https://hong-yp-ml-records.tistory.com/105 15기 데이터 분석 활동 후기 : https://hwi-doc.tistory.com/entry/BOAZ-%EB%B3%B4%EC%95%84%EC%A6%88-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%B6%84%EC%84%9D-%EB%B6%80%EB%AC%B8-%EC%88%98%EB%A3%8C-%EB%B0%8F-%ED%99%9C%EB%8F%99-%ED%9B%84%EA%B8%B0 16. 투빅스, Tobig's (20기, 23년 6월 예정)투빅스는 10주 동안 신입기수를 위한 데이터분석/머신러닝/딥러닝 집중교육을 진행합니다.이후에는 생성모델/음성/시각화/이미지/텍스트/추천/데이터엔지니어링 등 세부 분야를 선택하여 심화 세미나를 이어 갑니다.동시에, 매 기수마다 진행되는 컨퍼런스를 위해 팀을 꾸려 프로젝트를 진행합니다.투빅스는 활동량이 많습니다.매 주 있는 교육과 과제를 이해하기 위해서는 많은 시간이 필요합니다.그럼에도 함께 최선을 다하여 활동할 수 있는 분들이 많이 오셨으면 좋겠습니다. TOBIG's가 의미하는 대로 큰 사람이 될 준비가 되신 분들은 주저하지 마시고 문을 두드려주세요! 홈페이지 주소 : http://www.datamarket.kr/인스타그램 주소 : https://www.instagram.com/tobigs_official/최근 기수 : 19기최근 기수 모집 공고 : http://www.datamarket.kr/xe/board_lhOx96/81797다음 모집 일정 : 20기, 23년 6월 예상활동 장소 : 온라인 / 오프라인활동 내용 : 스터디 / 프로젝트 / 컨퍼런스모임 시각 : 매주 수요일 19시모집 대상 : 대학(원)생 ( 병역 문제 해결자 )지원 후기18기 면접 후기 : https://velog.io/@ddoddi/%EC%B2%AB-%EB%B0%9C%EA%B1%B8%EC%9D%8C-%ED%95%99%ED%9A%8C 17. 비타민, BITAmin ( 23년 1월 진행 중, 12기 7~8월 예정 )비타민 동아리 로고빅데이터에 관심이 많지만 어떻게 입문해야 할 지 모르셨던 분!많이 들어본 머신러닝, 딥러닝에 직접 입문해보고 싶으신 분!같은 관심사를 가진 사람들과 함께 스터디 및 세미나를 하고 싶으신 분!직접 데이터 분석 프로젝트를 해보고 싶으신 분!비슷한 전공자들과 함께 공모전이나 대회에 출전해보고 싶으신 분!그 외에도 빅데이터에 대한 관심과 열정만 있으시다면 모두 환영합니다🙌🙌 네이버 카페 주소 : https://cafe.naver.com/bitamin123/2512네이버 블로그 주소 : https://blog.naver.com/bita_min인스타그램 주소 : https://www.instagram.com/bitamin_official/최근 기수 : 11기11기 모집 안내 책자 : https://drive.google.com/file/d/19pmdoVFXdruPZ2b7lp3G1Qdx-_flYLoa/view다음 모집 일정 : 12기, 23년 7~8월 예상지원률 : 약 17 : 1활동 장소 : 서울권 대학교활동 내용 : 스터디 / 프로젝트 / 컨퍼런스모임 시각 : 매주 수요일 19시 ~ 21시 ( 학기 ), 토요일 15시 ~ 18시 ( 방학 )모집 대상 : 대학생 / 대학원생모집 분야 : 데이터 분석     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//itchipmunk.tistory.com/reaction';window.ReactionReqBody = {    entryId: 490}공유하기게시글 관리다람쥐의 스프링 전문가 여행기저작자표시 '자유 > 대외 활동' 카테고리의 다른 글[혼공학습단 9기] #2. 자바 기본 정말 안다고 생각해?  (1)2023.01.08[혼공학습단 #1] 한빛미디어 혼공학습단 9기 선정  (4)2023.01.08한빛미디어 나는 리뷰어다 2022 도서 서평단 2월 도서 신청 후기  (0)2022.02.04한빛미디어 나는 리뷰어다 2022 도서 서평단 신청 후기  (0)2022.02.02파이썬 중급, 인프런 리프 #5. 인프런 리프 2기 활동 후기  (0)2021.04.05태그IT동아리, IT연합동아리, SOPT, 개발동아리, 개발자, 동아리, 매쉬업댓글5    setInitialEntryComments(490, 1723627656)비밀글등록loadedComments[490]=true;findFragmentAndHighlight(490);     (adsbygoogle = window.adsbygoogle || []).push({});"
28,https://n-square.tistory.com/88,관련글,"IT/Teckweek머신러닝과 딥러닝의 차이by YEON-DU2020. 11. 30.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});면접을 보면서 받았던 질문에 대해 정리해보는 시간을 갖고자 한다. 면접을 보면서 해당 직무 중에선 관심분야가 AI 이다.. 라고 말을 했다가 굉장히 많은 질문을 받았었다.그중 흐지부지하게 대답한 것이 있다면 단호하게 말할 수 있을 정도로 ~하는 상황에서 딥러닝과 머신러닝 중 무엇을 선택하시겠습니까? 라는 질문에서 다소 어처구니 없는 답변을 했던 것 같다(..) 면접 결과는 나오지 않았지만 개인의 궁금증 해결을 위해 해보는 차이점 알아보기! 출처 : 인공지능은 마스터키가 아니다간단히 말해서 인공지능 내에 머신러닝이, 그리고 머신러닝에 딥러닝이 포함되는 형태이다. 구체적인 차이점은 다음과 같다. 머신러닝통계적인 경험을 통해 문제의 해법을 찾아가는 인간의 특징을 기계에 적용한 것이다. 그러나 인간의 실수까지도 기계가 그대로 학습한다는 단점이 있다. 또한 사람이 데이터의 특징을 분류하고, 분석해서 패턴을 입력해야 한다. 딥러닝고도화된 머신러닝의 일종으로 고차원 데이터에서 기계 스스로 패턴을 알아낼 수 있다. 기존 머신러닝과 가장 큰 차이점은 딥러닝은 분류에 사용할 데이터를 스스로 학습할 수 있는 반면, 머신러닝은 학습 데이터를 수동으로 입력해야 한다는 것이다.  참고 자료brunch.co.kr/@bnviiteye/7brunch.co.kr/@itschloe1/8wendys.tistory.com/136반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//n-square.tistory.com/reaction';window.ReactionReqBody = {    entryId: 88}공유하기게시글 관리Squared저작자표시 'IT > Teckweek' 카테고리의 다른 글안드로이드 클린 아키텍처  (0)2020.12.18TDD란?  (0)2020.12.09www.도메인.com 을 치면 일어나는 일  (1)2020.11.22싱글톤 패턴 (Singleton Pattern)  (0)2020.10.26얕은 복사와 깊은 복사  (0)2020.10.19관련글안드로이드 클린 아키텍처TDD란?www.도메인.com 을 치면 일어나는 일싱글톤 패턴 (Singleton Pattern)댓글0비밀글등록loadedComments[88]=true;findFragmentAndHighlight(88);"
29,https://thisisjava.tistory.com/514,'프로그래밍/IT 이것저것'의 다른글,"                                                  이자다의 기록                              홈태그미디어로그위치로그방명록프로그래밍/IT 이것저것데이터 직군 현실 조사이자다2023. 7. 2. 17:40     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});데이터 직군 관련해서 여러 영상들을 보며 내용들을 정리해본다. 데이터 직군 별 역할 데이터 분석가- 해당 업계의 도메인 지식 많이 필요- 의사결정자에게 발표, 설득을 위한 데이터 시각화와 커뮤니케이션 능력이 필요함. - 데이터 시각화 툴인 Power BI, Tableau, Google Analytics 등을 다룰 수 있어야함- 데이터 가공, 분석 과정에서 SQL, R, Python 등 언어를 사용하기에 데이터 분석을 위한 최소환의 수준은 갖춰야함.  데이터 사이언티스트- 수학, 통계 지식 필요- 분석 모델, 머신러닝 모델을 개발해야 하기에 관련 지식 필요함. 예시로 한 쇼핑몰의 고객별 재구매 주기 모델을 들 수 있음.- Python, scala 언어 지식 필요- Pytorch, tensor flow 라이브러리 지식 필요- 빅데이터 저장 플랫폼인 Hadoop, Spark 지식이 있으면 플러스 요인  데이터 엔지니어- 데이터 웨어하우스, 데이터베이스를 구축 및 관리, 데이터 파이프라인 구축, SQL 튜닝, 대용량/실시간 시스템 개발 등 업무 담당- 한눈에 파악하기 어려운 로그 자료들을 유의미하게 분석하고 이용할 수 있도록 데이터 전처리 작업을 거쳐 하둡과 같은 빅데이터 시스템에 저장하는 업무를 맡음.- 사실상 개발자이고 때문에 프로그래밍 지식과 더불어 Hadoop, Spark 같은 빅데이터 플랫폼 관련 업무 경험과 지식을 필요로 함.- 학생들이 학교에서 배우기 어려운 주제를 다루다보니 백엔드 개발자로 커리어를 시작해서 데이터 엔지니어로 직무 변경하는 것을 종종 보게 됨.- 데이터 엔지니어와 데이터 사이언티스트의 업무가 겹치는 경우가 많아서 머신러닝 지식을 요구하기도 함.   데이터 사이언티스트, AI 엔지니어의 현실 커리어 시작 시 데이터 사이언티스트로 시작하기 보다는 백엔드 엔지니어로 커리어를 시작해 넘어오는 것이 이상적이라고 한다.회사에서는 데이터만으로 성과를 낼만한 환경이 갖춰져 있지 않음. 웬만한 회사의 데이터는 두가지 경우다 1. 데이터가 없거나2. 데이터를 쓸 수 없는 상태 그러면 데이터가 없을 때는 데이터(로그)를 남기도록 만들어야 하는데 그러려면 백엔드 개발을 할 줄 알아야 한다. 그것을 할 줄 모르면 백엔드 개발자가 내가 원하는 대로 로그를 남기도록 설득을 해야 하고 그것을 또 개발시켜야한다. 현실적으로 그렇게 남에게 일을 시키기는 어렵다. 이렇게 다른 사람에게 백엔드쪽 개발을 의지한 상태로 진행하면 일 처리 속도가 느려지게 되고, 데이터 전처리 하는 데 코스트가 많이 들다 보면 자연스럽게 성과를 낼 수 없다. 그래서 일반적으로 데이터 사이언티스트가 신입으로 와서 성과를 내기가 진짜 힘들다. 때문에 신입을 뽑지 않는다. 추천하는 방안은 백엔드 엔지니어로 커리어를 시작해서 데이터 사이언트스트 역량을 갖추는 것. 백엔드 엔지니어는 자연스럽게 빅데이터를 접할 수 있고 로그를 마음대로 설정할 수 있음. 그러다보면 데이터를 직접 다루기도 하고 그것을 전처리하는 역할도 맡게 됨. 그걸 자연스럽게 머신러닝 문제로 변환할 수도 있고 데이터 사이언스 관점에서 접근성이 상당히 높아진다. 내가 마음만 먹으면 데이터 사이언스 문제를 풀 수 있게 된다. 때문에 데이터 사이언티스트를 바로 시작하기보다는 엔지니어링 능력을 먼저 키우는 게 커리어 면에서, 몸값을 올리는 면에서 더 좋은 방향이다. 또 하나의 이유는 전반적으로 데이터 사이언티스트 잘하는 것 보다는 엔지니어링을 잘하는게 더 시장에서 수요도 많고 몸값도 비싸다. 엔지니어링을 잘하면 어떤 프로젝트에 갖다놓아도 할 일이 넘쳐난다. 데이터 사이언티스트는 데이터가 잘 정리된 상태가 있어야 하고 문제 정의 자체를 하기가 어렵다.  백엔드 엔지니어로 시작해서 커리어를 쌓은 데이터 사이언티스트는 뭐든지 할 수 있지만 그냥 데이터 사이언티스트는 온실 속에서만 성과를 낼 수 있는 상황이다. 그래서 내가 아는 데이터 사이언티스트들은 개발도 잘한다. 비단 데이터 사이언티스트 만의 문제가 아니라 AI 리서치도 마찬가지다. 요즘 학부생들이 전부 머신러닝 쪽에만 집중한다. 이게 뭐가 문제냐면 학부생이 머신러닝 모델링 조금 할 줄 아는 걸로는 아무것도 못만든다. 실제 실무에서도 일어나는 일인데 모델링만 할 줄 알면 아무것도 안 된다. 모델링은 전체 프로젝트의 5% 밖에 안된다. 전처리 엄청나게 해야하고, 데이터 엔지니어링 엄청나게 해야하고, 소프트웨어 개발해야하고. 소프트웨어 개발의 기본적인 요구사항은 변하진 않는다. 로그 관리도 잘해야 하고, 장애 관리도 해야하고, API 속도도 맞춰야하고 이런 것들은 다 백엔드 엔지니어링에 관련된 것이다. 그러니까 AI 프로젝트에서 성과를 내고 싶으면 모델링을 잘하는 건 5% 밖에 안된다. 그런데 학부생이 모델링을 아무리 잘해봐야 업계 석박사들보다 잘하긴 힘들다. 그러면 자연스럽게 무엇이 중요해지냐. 개발을 잘해야한다. 그러니까 AI 분야로 가고 싶은 사람들도 우선 백엔드 개발을 먼저 시작하는 것을 추천한다. 커리어를 정리하자면, 백엔드로 먼저 시작하고, 데이터 엔지니어링도 좀 다루면서, 머신러닝도 보는 것을 추천한다. 바로 AI로 가고 싶은 건 안다. 그게 멋있어 보이니까. 하지만 실제로 일이 되게끔 하려면 엔지니어링을 잘 해야 한다. 대부분 면접을 보는 사람들이 어떤 식이냐면 개발을 잘 못하는데 머신러닝 지식들을 조금씩 조금씩 안다. 그런 사람들이 되게 많다. 머신러닝 공부가 핫하니까 조금 해보고, 몇 가지 예제 돌려보고, 간단하게 MNIST로 토이프로젝트 만들어보는 분들이 대부분이다. 그런 분들이 놓치고 있는 게 커머셜 프로젝트에서 빡세게 엔지니어링을 경험해 보는 것. 그 경험 자체가 진짜 중요한 요소다. 실제로 일을 할 수 있는 역량이 있다는 것을 증명하는 것이기에. 그렇기에 백엔드 개발을 추천한다. API를 어떻게 하면 좋고, 안정적으로 API를 서버를 운영하려면 어떻게 해야되고, 로그는 어떻게 남기고, 클라우드 환경에서 어떤 식으로 하면 인프라 관리를 좀 잘 할 수 있고, 장애가 났을 땐 어떻게 대응하면 좋고, 데이터 베이스에서 어떤 식으로 쿼리를 날려야지 속도가 빠르고, 이런 컴퓨터 사이언스에서 기본적인 펀더멘탈, API. 이런 것들을 실무 프로젝트에서 경험해 보는 것을 추천한다.  너무 머신러닝에만 빠지지 말고 개발 역량에 집중해서 투자를 하다 보면 더 좋은 기회들이 생길 것이다.   항상 데이터 사이언티스트 일만 할 수는 없다 한 회사에 데이터 사이언티스트로 면접을 보고, 시험을 보고 입사를 했으나 데이터 사이언티스트가 필요한 일이 거의 없어지면 개발자와 같은 일을 하게 되는 경우가 많다. 한 개발자도 데이터 사이언티스트나 백엔드 엔지니어를 오가며 일을 한다.   데이터 엔지니어는 백엔드의 한 분야이다 데이터 엔지니어는 기본적으로 백엔드 경험이 있어야 한다고 한다. 때문에 데이터 엔지니어의 분야의 평균 연봉이 높은 이유가 신입이 있을 수 없기 때문이라고 한다. 백엔드는 서비스가 빠르게 출시될 수 있게 빨리빨리 일을 쳐낸다면 데이터 엔지니어는 거기서 한발짝 떨어져서 상대적으로 느긋하게 데이터를 바라보는 직군이라고 한다. 영상 출연자의 개인적인 생각이지만 데이터 엔지니어는 일종의 백엔드 분야의 유행, 트렌드 중 하나라고 생각한다고 한다.    영상 내용들을 정리해봤는데 데이터 관련 직군 중에는 분석가가 가장 개발자랑은 떨어져 보였다. 그리고 데이터 관련 개발 직군으로 바로 취직할 순 없어 보인다. 일단 백엔드 개발자로 취업하면서 데이터 분야로 직무전환을 하는 방식이 많은 것 같다. 직무 전환은 특수대학원을 이용해 석사를 따는 방식으로 하는 경우가 많다고 하는데 그 부분은 나중에 더 살펴봐야겠다.반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//thisisjava.tistory.com/reaction';window.ReactionReqBody = {    entryId: 514}공유하기게시글 관리이자다의 기록저작자표시 '프로그래밍 > IT 이것저것' 카테고리의 다른 글XML, JSON, YAML이 뭔가요?  (0)2023.07.30백엔드 개발자가 갖춰야할 역량 탐색 - 백엔드 로드맵 8단계  (0)2023.07.14RSS(Really Simple Syndication)와 Open API(Open Application Programming Interface)란?  (0)2023.03.12센싱(Sensing)이란?  (0)2023.03.12크롤링(Crawling)과 스크래핑(Scraping)이란?  (0)2023.03.12'프로그래밍/IT 이것저것'의 다른글이전글RSS(Really Simple Syndication)와 Open API(Open Application Programming Interface)란?현재글데이터 직군 현실 조사다음글백엔드 개발자가 갖춰야할 역량 탐색 - 백엔드 로드맵 8단계관련글XML, JSON, YAML이 뭔가요?2023.07.30백엔드 개발자가 갖춰야할 역량 탐색 - 백엔드 로드맵 8단계2023.07.14RSS(Really Simple Syndication)와 Open API(Open Application Programming Interface)란?2023.03.12센싱(Sensing)이란?2023.03.12댓글 0비밀글등록loadedComments[514]=true;findFragmentAndHighlight(514);웹소설 리뷰, 프로그래밍 공부, 운동 일지 등 이것저것 기록 중반응형(adsbygoogle = window.adsbygoogle || []).push({}); 분류 전체보기 (670)  블로그 공지 (2)  일상 (33)  잡담 (27)  그림 (3)  마트 아르바이트 (3)  주관적인 소설 리뷰 (125)  노벨피아 (14)  문피아 (63)  조아라 (8)  네이버 시리즈 (4)  카카오페이지 (11)  출판 소설 (5)  일본 패러디 소설 간단 리뷰 (18)  영화 감상문 (2)  자기계발 (325)  운동일지 (254)  운동계획 (13)  글쓰기 (10)  공부 방법 (8)  살면서 명심할 것 (12)  공부일지 (8)  주식 종목 조사 (4)  주식 공부 (5)  수험서, 자기계발서 후기 (1)  취업 준비 (10)  프로그래밍 (176)  파이썬 공부 (22)  IT 이것저것 (40)  알고리즘 공부 (23)  HTML 공부 (7)  CSS 공부 (6)  수학 공부 (4)  JAVA 공부 (2)  데이터 사이언스 공부 (39)  데이터베이스 (7)  머신러닝 딥러닝 프로젝트 후보 (2)  오라클 SQL과 PLSQL (10)  R (5)  Flask (1)  개인 프로젝트 (0)  리눅스 (1)  C, C++ (3)  MFC (4) Tag노벨피아,디지몬,우마무스메 팬픽,먼치킨,경영물,내일배움카드,웹소설,패스트캠퍼스,우마무스메 패러디,대체역사물,현대물,헌터물,문피아,K디지털기초역량훈련,조아라,국비지원교육,기업물,웹소설 리뷰,웹소설리뷰,Java & Spring으로 시작하는 웹 프로그래밍,최근글과 인기글최근글인기글08142024.08.14 00:15CreateDirectory() 사용법 (하위 폴더, 하위의 하위 폴더 생성)2024.08.09 16:3608062024.08.06 20:22[마트 알바 이야기] 햇갈리는 담배 이름 문제2022.01.12 00:50약수, 약수의 개수 구하는 법2023.01.26 02:52[파이썬 공부] AttributeError의 원인과 해결 과정2021.12.27 10:15최근댓글너무 잘 보고 덕분에 마우스 잘 고쳤습니다. 정말 감사합니다.김현구LH 청년매입임대 메모 잘 봤습니다:)infobeste이자다의 기록 님, 안녕하세요~YOLO 등 모델 훈련 시 최적의 에폭수는 없다글 잘 봤⋯infobeste공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/072024/062024/05Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total124,625Today : 42Yesterday : 81Copyright © Kakao Corp. All rights reserved.관련사이트티스토리툴바hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2927739-514"",""customProps"":{""userId"":""0"",""blogId"":""2927739"",""entryId"":""514"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""514"",""entryTitle"":""데이터 직군 현실 조사"",""entryType"":""POST"",""categoryName"":""프로그래밍/IT 이것저것"",""categoryId"":""1072387"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""3767091"",""authorNickname"":""이자다"",""blogNmae"":""이자다의 기록"",""image"":"""",""plink"":""/514"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
30,https://jpub.tistory.com/1220,태그,"도서 소개파이썬 머신러닝 실무 테크닉 100 제이펍2021. 12. 14. 11:35100개의 실전 예제를 풀며 익히는 머신러닝 & 데이터 활용법이것이 현장에서 활용할 수 있는 데이터 활용술! 도서 구매 사이트(가나다순) 교보문고 / 도서11번가 / 알라딘 / 예스이십사 / 인터파크 / 쿠팡전자책 구매 사이트(가나다순)  [교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사] 출판사 제이펍도서명 파이썬 머신러닝 실무 테크닉 100지은이 시모야마 데루마사, 미키 다카유키, 이토 준지옮긴이 김모세감수자 (없음)시리즈 아이러브 A.I. 35(I♥A.I. 35) 출판일 2021년 12월 14일페이지 300쪽판  형 크라운판변형(170*225*16.6)제  본 무선(soft cover)정  가 25,000원ISBN 979-11-91600-43-8 (93000)키워드 인공지능 / AI / 머신러닝 / 딥러닝 / 파이썬 / 라이브러리 / 데이터 / 데이터 과학자 / 시각화 / 알고리즘 / 주피터 노트북분  야 인공지능 / 파이썬 관련 사이트■ (없음)관련 포스트■ 2021.12.02 - [출간 전 책 소식] - 머신러닝 실무를 지원하는 100가지 무기!관련 시리즈 ■ 아이러브 A.I.(I♥A.I.)관련 도서 ■ 파이썬으로 시작하는 캐글■ 쏙쏙 들어오는 인공지능 알고리즘관련 파일 다운로드■ (없음) 강의보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음의 자료를 보내드리겠습니다.)■ 본문의 그림과 표 정오표 페이지■ (등록되는 대로 링크를 걸어드리겠습니다)■ 미리 보기(앞표지, 차례, 옮긴이 머리말, 들어가며, 이 책의 효과적인 활용법, 베타리더 후기, 1장 '분석 준비를 위한 테크닉 10' 일부, 2장 '데이터를 시각화하고 분석하기 위한 테크닉 10' 일부, 6장 '머신러닝용 데이터를 가공하기 위한 테크닉 10' 일부, 7장 '머신러닝 모델을 구현하기 위한 테크닉 10' 일부, 마치며) sample_파이썬머신러닝실무테크닉100.pdf1.85MB 도서 구매 사이트(가나다순) 교보문고 / 도서11번가 / 알라딘 / 예스이십사 / 인터파크 / 쿠팡전자책 구매 사이트(가나다순)  [교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사] 도서 소개100개의 실전 예제를 풀며 익히는 머신러닝 & 데이터 활용법 이것이 현장에서 활용할 수 있는 데이터 활용술! 우리가 사는 세상은 그야말로 데이터로 가득한 세상입니다. 주위를 보면 데이터가 아닌 것이 없을 만큼, 우리 주위에는 수많은 데이터가 넘쳐납니다. 최근에는 이 데이터를 어떻게 활용하느냐가 개인과 비즈니스의 성과와 실적을 판가름하는 요인이 되었습니다. 하지만 실무 현장에서의 기술 활용이나 대처 방법과 같은 노하우는 입문서로 공부하는 것만으로는 결코 익힐 수 없습니다. 이 책은 큰 호평을 받았던 《파이썬 데이터 분석 실무 테크닉 100》을 잇는 것으로, 실제 실무 현장을 가정한 100개의 문제를 풀면서 현장의 관점과 응용력을 몸에 익히도록 구성한 활용서입니다. 데이터 활용 프로젝트를 시작하고, 회사 안에서 확실하게 정착시키기 위한 첫 걸음을 내딛으시기 바랍니다! 이 책의 대상 독자처음으로 데이터 활용 프로젝트를 꾸려서 사내에 확실하게 정착시키고자 하는 분기존의 프로젝트를 진행하는 데 어려움을 느끼는 분 지은이 소개시모야마 데루마사(下山輝昌) 일본전기주식회사(NEC)의 중앙연구소 하드웨어 연구 개발 부문에서 근무하였으며, 2017년에 아이큐베이터를 공동 창업하였다. 인공지능, 사물인터넷, 정보 디자인 부문에서 새로운 방향성과 가능성을 연구하며 비즈니스화를 진행하고 있으며, 머신러닝을 활용한 데이터 분석이나 대시보드 설계 등으로 업무 분야를 넓히면서 데이터 분석 컨설턴트로도 활동한다. 공저로 《파이썬 데이터 분석 실무 테크닉 100》(위키북스), 《Tableauデータ分析: 実践から活用まで(Tableau 데이터 분석: 실전에서 활용까지)》(슈와시스템)가 있다. 미키 다카유키(三木孝行) 소프트웨어 개발 회사에서 철도, 은행 등 대규모 기간 시스템 개발을 총괄하면서 시스템/IT의 요구사항 정의, 설계, 개발, 출시까지의 모든 과정을 경험했다. 2017년에 아이큐베이터를 공동 창업하였다. 독학으로 여러 언어를 습득해 C 언어보다 더 높은 수준의 언어를 주로 다룬다. 공저로 《파이썬 데이터 분석 실무 테크닉 100》(위키북스)이 있다. 이토 준지(伊藤淳二) 휴대폰 회사의 백 오피스 부서에서 근무하면서 업무 효율화/정보 연동 도구를 직접 개발한 것을 계기로 시스템 개발의 즐거움을 깨달았다. 이후 시스템 엔지니어로 전직하여 철도 및 전력 계열의 기간 시스템 개발 등에 참여했다. 요구사항 정의에서 설계, 개발, 운용까지의 모든 과정에서 능력을 발휘했으며, 현장의 시선으로 제안하는 엔지니어이자 프로젝트 관리자로서 다양한 아이디어를 성공적으로 구현했다. 이후 AI 컨설팅, 데이터 분석을 수행하는 아이큐베이터에 합류하여 그간의 경험을 살려 현장의 시선을 중시한 AI 도입을 추진하고, AI 시스템 개발, 데이터 분석에 관한 여러 안건을 맡고 있다. 옮긴이 소개김모세소프트웨어 엔지니어, 소프트웨어 품질 엔지니어, 애자일 코치 등 다양한 부문에서 소프트웨어 개발에 참여했다. 자신을 끊임없이 변화시키고, 새로운 지식을 전달하기 위해 번역을 시작했다.차례PART 1 데이터 분석 시스템CHAPTER 01 분석 준비를 위한 테크닉 10 3테크닉 1 데이터를 모두 로딩하자 5테크닉 2 데이터를 유니온(결합)하자 9테크닉 3 폴더 안에 있는 파일을 확인하자 11테크닉 4 여러 데이터를 유니온(결합)하자 13테크닉 5 데이터 통계량을 확인하자 16테크닉 6 불필요한 데이터를 제거하자 18테크닉 7 마스터 데이터를 조인(결합)하자 20테크닉 8 마스터가 존재하지 않는 코드에 이름을 설정하자 21테크닉 9 분석 기초 테이블을 파일에 저장하자 24테크닉 10 셀을 사용하기 쉽게 정리하자 25 더보기CHAPTER 02 데이터를 시각화하고 분석하기 위한 테크닉 10 28테크닉 11 데이터를 로딩하고 불필요한 항목을 제외하자 29테크닉 12 데이터 전체 이미지를 파악하자 32테크닉 13 월별 매출을 집계하자 34테크닉 14 월별 추이를 시각화하자 37테크닉 15 매출로부터 히스토그램을 만들자 39테크닉 16 시/도/군/구별 매출을 집계해서 시각화하자 41테크닉 17 클러스터링을 위해 데이터를 가공하자 43테크닉 18 클러스터링을 이용해 매장을 그룹화하자 45테크닉 19 그룹의 경향을 분석하자 47테크닉 20 클러스터링 결과를 t-SNE로 시각화하자 48 CHAPTER 03 시각화 구조를 구축하기 위한 테크닉 10 51테크닉 21 매장을 필터링해서 시각화하자 53테크닉 22 여러 매장의 상세 정보를 시각화하자 58테크닉 23 슬라이드바를 이용해 주문 건수를 조사하자 61테크닉 24 토글 버튼을 이용해 지역 데이터를 추출하자 63테크닉 25 날짜를 지정해 데이터를 추출하자 66테크닉 26 스토리를 생각해서 데이터를 구축하자 69테크닉 27 주문 취소 이유를 분석하자 75테크닉 28 가설을 검증하자 76테크닉 29 스토리를 기반으로 부속과 데이터를 조합해 대시보드를 만들자 80테크닉 30 대시보드를 개선하자 87 CHAPTER 04 보고 구조를 만들기 위한 테크닉 10 91테크닉 31 특정 매장의 매출을 엑셀로 출력하자 93테크닉 32 엑셀 테이블을 정리해 출력하자 99테크닉 33 매출 이외의 데이터도 출력하자 101테크닉 34 문제가 있는 위치를 빨간색으로 출력하자 104테크닉 35 엑셀의 셀 함수를 이용해 일 단위로 집계하자 105테크닉 36 꺾은선 그래프로 출력하자 107테크닉 37 보고서용 데이터를 준비하자 109테크닉 38 데이터시트에 필요한 데이터를 출력하자 113테크닉 39 요약 시트를 만들자 116테크닉 40 매장별 보고서를 엑셀로 출력하자 121 CHAPTER 05 분석 시스템을 구축하기 위한 테크닉 10 123테크닉 41 기본 폴더를 만들자 125테크닉 42 입력 데이터 확인 구조를 만들자 127테크닉 43 보고서(본부용) 작성 처리를 함수화하자 132테크닉 44 보고서(매장용) 작성 처리를 함수화하자 136테크닉 45 함수를 실행하고 동작을 확인하자 141테크닉 46 데이터 업데이트에 대응해 폴더를 만들자 143테크닉 47 시/도/군/구별로 폴더를 만들고 데이터를 출력하자 144테크닉 48 지난달 데이터를 동적으로 로딩하자 146테크닉 49 과거 데이터와 비교하자 151테크닉 50 화면에서 실행할 수 있게 하자 153  PART 2 머신러닝 시스템CHAPTER 06 머신러닝용 데이터를 가공하기 위한 테크닉 10 161테크닉 51 데이터 가공을 위한 밑준비를 하자 162테크닉 52 데이터를 로딩하고 데이터 가공 방향성을 검토하자 164테크닉 53 1개월분 데이터로 기본적인 가공을 하자 166테크닉 54 머신러닝용 변수를 만들자 168테크닉 55 매장 단위로 집계해서 변수를 만들자 170테크닉 56 데이터 가공과 매장별 집계를 함수로 실행하자 173테크닉 57 모든 데이터를 로딩하고 데이터를 가공하자 176테크닉 58 목적 변수를 만들자 178테크닉 59 설명 변수와 목적 변수를 연결해 머신러닝용 데이터를 완성하자 181테크닉 60 머신러닝용 데이터를 확인하고 출력하자 182 CHAPTER 07 머신러닝 모델을 구현하기 위한 테크닉 10 185테크닉 61 폴더를 만들고 머신러닝용 데이터를 저장하자 186테크닉 62 범주형 변수에 대응하자 187테크닉 63 학습 데이터와 테스트 데이터를 나누자 189테크닉 64 모델 하나를 구현하자 190테크닉 65 모델을 평가하자 192테크닉 66 모델의 중요도를 확인해 보자 196테크닉 67 모델 구현부터 평가까지의 과정을 함수화하자 197테크닉 68 모델 파일과 평가 결과를 출력하자 199테크닉 69 알고리즘을 확장해 다각적으로 평가하자 200테크닉 70 평일/휴일 모델을 한 번에 실행하자 203 CHAPTER 08 머신러닝 모델로 새로운 데이터를 예측하기 위한 테크닉 10 208테크닉 71 폴더를 만들고 데이터 로딩을 준비하자 209테크닉 72 예측할 신규 데이터를 로딩하자 210테크닉 73 신규 데이터를 매장별로 집계하자 212테크닉 74 신규 데이터의 범주형 변수에 대응하자 215테크닉 75 모델 투입 직전의 형식으로 정리하자 216테크닉 76 모델 파일을 로딩하자 217테크닉 77 신규 데이터를 예측하자 218테크닉 78 예측 결과를 히트맵으로 그리자 220테크닉 79 실적 데이터를 만들자 222테크닉 80 현장용 보고서를 만들어 출력하자 223 CHAPTER 09 소규모 머신러닝 시스템을 만들기 위한 테크닉 10 226테크닉 81 폴더를 만들고 초기 변수를 정의하자 227테크닉 82 신규 데이터를 로딩하고 매장별 데이터를 만들자 231테크닉 83 월별 매장 데이터를 업데이트하자 235테크닉 84 머신러닝용 데이터를 만들고 업데이트하자 236테크닉 85 머신러닝 모델용 사전 데이터를 가공하자 239테크닉 86 머신러닝 모델을 구현하고 평가하자 240테크닉 87 신규 데이터 예측을 위한 밑준비를 하자 244테크닉 88 신규 데이터를 예측하자 245테크닉 89 현장용 보고서를 만들고 출력하자 246테크닉 90 머신러닝 모델의 정밀도 추이를 시각화하자 249 CHAPTER 10 머신러닝 시스템 대시보드를 만들기 위한 테크닉 10 252테크닉 91 단일 데이터를 로딩하자 253테크닉 92 업데이트 데이터를 로딩해 매장별 데이터를 만들자 255테크닉 93 머신러닝 모델의 중요 변수 데이터를 로딩하고 결합하자 256테크닉 94 머신러닝 모델의 예측 결과를 로딩하고 결합하자 257테크닉 95 머신러닝 모델용 사전 데이터를 가공하자 259테크닉 96 매장 분석용 대시보드를 만들자 261테크닉 97 머신러닝 모델의 정밀도 평가 대시보드를 만들자 264테크닉 98 머신러닝 모델의 혼동 행렬 대시보드를 만들자 266테크닉 99 머신러닝 모델의 변수 중요도 분석 대시보드를 만들자 269테크닉 100 머신러닝 모델의 예측 결과를 시각화해서 검증하자 272 제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)  네이버 책 포스트 유튜브 인스타그램 트위터 페이스북 window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1220}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글머신러닝 엔지니어링  (0)2021.12.29도커, 컨테이너 빌드업!  (8)2021.12.28코드로 배우는 인공지능  (0)2021.11.19가볍게 떠먹는 데이터 분석 프로젝트  (0)2021.11.19DNS 실전 교과서  (2)2021.11.19태그ai, 데이터, 데이터 과학자, 딥러닝, 라이브러리, 머신러닝, 시각화, 알고리즘, 인공지능, 파이썬'도서 소개' Related Articles머신러닝 엔지니어링도커, 컨테이너 빌드업!코드로 배우는 인공지능가볍게 떠먹는 데이터 분석 프로젝트    setInitialEntryComments(1220, 1723617167)Secret댓글달기loadedComments[1220]=true;findFragmentAndHighlight(1220);"
31,https://lsjsj92.tistory.com/548,머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자,"본문 바로가기꿈 많은 사람의 이야기카테고리검색하기검색하기Search꿈 많은 사람의 이야기이수진의 블로그 분류 전체보기 (571)  python (85)  Data Engineering  및 Infra (33)  machine learning(머신러닝) (19)  deep learning(딥러닝) (39)  추천시스템 (26)  LLM&RAG (2)  컨퍼런스(IT, AI) (4)  python-django (15)  빅데이터 (20)  kaggle(캐글) (13)  알고리즘&자료구조 (12)  IT 및 개발 TIP (21)  생활팁 (20)  R (23)  javascript (16)  암호화폐 (0)  perl (22)  java (47)  일상 (53)  맛집 (50)  전시회(일상) (7)  spring(스프링) 프레임워크 (3)  jsp (5)  리눅스(linux) (2)  국내여행 (17)  해외여행 (2)  책 (4)  초대장 (2)  티스토리 (2)  축제 (3)  mysql (3) Guestbook세로형(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_goB19ZXe', {ignore_items: true});Notice[contact] 컨택 정보 공지Recent Posts인공지능 윤리(AI Ethics)란 무엇일까? AI개발자가 바라⋯LLM과 추천 시스템을 결합해 설명가능성(Explainabili⋯개인화를 고려한 LLM 모델 기반 추천 시스템 - PALR 추천⋯vLLM 사용법 - LLM을 쉽고 빠르게 추론(inference⋯LLM 기반 추천 시스템 논문 리뷰 - LlamaRec: Two⋯Recent Comments안녕하세요. 맥에서 Modelfile을 만들어 모델 배포하려고 ⋯안녕하세요 음 beeline으로는 제가 경험이 없어서 모르겠습니⋯혹시 여기서 beeline 으로 접속하는 방법 은 없을까요? n⋯안녕하세요. 네~ 질문 남겨주시면 답변 드리겠습니다네네~ 해결 되셨다니 다행이네요 ㅎㅎ Link #chart-time {font-size:11px; text-align:right; color:#999; padding-right: 15px;}08-14 02:04        am4core.ready(function() {            am4core.addLicense(""CH90809262"");            var chart = am4core.create(""chartdiv"", am4charts.XYChart);            chart.data = [{""timestamp"":""2024-08-08T00:00:00+09:00"",""count"":899},{""timestamp"":""2024-08-09T00:00:00+09:00"",""count"":783},{""timestamp"":""2024-08-10T00:00:00+09:00"",""count"":342},{""timestamp"":""2024-08-11T00:00:00+09:00"",""count"":334},{""timestamp"":""2024-08-12T00:00:00+09:00"",""count"":1022},{""timestamp"":""2024-08-13T00:00:00+09:00"",""count"":899},{""timestamp"":""2024-08-14T00:00:00+09:00"",""count"":45}];            var values = chart.data.map(function(value){                return value.count            });            var minValue = values.reduce(function(acc, current) {                return Math.min(acc, current);            });            var maxValue = values.reduce(function(acc, current) {                return Math.max(acc, current);            });            chart.dateFormatter.inputDateFormat = ""yyyyMMdd"";            var dateAxis = chart.xAxes.push(new am4charts.DateAxis());            var valueAxis = chart.yAxes.push(new am4charts.ValueAxis());            dateAxis.renderer.grid.template.disabled = true;            dateAxis.dateFormats.setKey(""day"", ""dd"");            dateAxis.periodChangeDateFormats.setKey(""day"", ""dd"");            dateAxis.renderer.minGridDistance = 1;            dateAxis.fontSize = ""10.5px"";            dateAxis.color = ""#ff0000"";            dateAxis.opacity = 0.5;            valueAxis.opacity = 0.5;            valueAxis.fontSize = ""10.5px"";            valueAxis.paddingBottom = 5;            valueAxis.marginLeft = -20;            valueAxis.min = minValue < 0 ? 0 : minValue;            valueAxis.max = maxValue + 10;            var series = chart.series.push(new am4charts.LineSeries());            series.dataFields.valueY = ""count"";            series.dataFields.dateX = ""timestamp"";            series.tooltipText = ""{count}""            series.strokeWidth = 1;            series.minBulletDistance = 15;            series.tooltip.background.cornerRadius = 20;            series.tooltip.background.strokeOpacity = 0;            series.tooltip.pointerOrientation = ""vertical"";            series.tooltip.label.minWidth = 40;            series.tooltip.label.minHeight = 40;            series.tooltip.label.textAlign = ""middle"";            series.tooltip.label.textValign = ""middle"";            var bullet = series.bullets.push(new am4charts.CircleBullet());            bullet.circle.strokeWidth = 2;            bullet.circle.radius = 3;            bullet.circle.fill = am4core.color(""#fff"");        });«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags개발Python머신러닝자바맛집공부추천시스템Java취업하고싶다프로그래밍딥러닝취미일상맛있다프로그래밍언어컴퓨터IT파이썬machine learningdeep learningmoreArchives2024/07 (1)2024/06 (1)2024/05 (2)2024/04 (4)2024/02 (1)Today45Total3,264,595닫기관리 메뉴글쓰기방명록RSS관리꿈 많은 사람의 이야기머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자 본문machine learning(머신러닝)머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자이수진의 블로그                            2019. 11. 22. 06:56반응형(adsbygoogle = window.adsbygoogle || []).push({});728x170(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_x7yWv3X6', {ignore_items: true});지난 포스팅까지 머신러닝 앙상블에 대해서 계속 올리고 있습니다.머신러닝 앙상블(machine learning ensemble)에서는 대표적으로 배깅(bagging)과 부스팅(boosting)이 있습니다.그 중 앙상블 부스팅(ensemble boosting)에 대해서 지속적으로 보고 있습니다. 머신러닝 부스팅 알고리즘은 틀린 부분에 가중치를 더하면서 진행하는 알고리즘인데요.Gradient Boosting Machine(GBM)은 그 가중치를 경사하강법(gradint boosting)으로 진행하였습니다.그리고 지난 포스팅에서 소개한 ensemble xgboost는 기존의 gradient boosting 알고리즘의 단점을 조금이라도 보완한 알고리즘이라고 했습니다.그렇게 강력한 성능을 제공하는 xgboost였지만, 여전히 이슈가 있었습니다.(lightgbm은 xgboost에 근간한 것이 많습니다. xgboost에 전반적인 자료를 못보셨다면 아래에서 확인하세요)https://lsjsj92.tistory.com/547 머신러닝 앙상블(ensemble) xgboost란? - Python 예제와 함께 살펴보기머신러닝에서는 앙상블(ensemble) 모델을 빼놓을 수가 없습니다. 이 앙상블에는 배깅(bagging)과 부스팅(boosting) 그리고 보팅(voting) 방법이 있습니다. 크게 보면 말이죠 이 중 ensemble bagging에 대해서는 지..lsjsj92.tistory.com본문에 나와있는 코드는 아래 github에서 확인할 수 있습니다.github.com/lsjsj92/machine_learning_basic lsjsj92/machine_learning_basicRepo for everyone who wants a machine learning basic - lsjsj92/machine_learning_basicgithub.com 머신러닝 앙상블 알고리즘 LightGBM이란? 왜 나오게 되었을까?boosting 알고리즘인 xgboost는 굉장히 좋은 성능을 보여주었지만 여전히 학습시간이 느리다는 단점이 있었습니다.알고리즘이 느린 것과 더불어 하이퍼 파라미터도 많은데요.만약, grid search등으로 하이퍼 파라미터 튜닝을 하게 되면 그 시간은 더욱 오래 걸린다는 단점이 존재했습니다.LightGBM은 이러한 단점을 보완해주기 위해 탄생하였습니다. LightGBM은 대용량 데이터 처리가 가능하고, 다른 모델들보다 더 적은 자원(메모리 등)을 사용합니다. 그리고 빠르죠.또한, GPU까지 지원해주기도 한답니다. 그래서 기존 앙상블 boosting 모델들보다 더 인기를 누리고 있기도 합니다.그러나 이 LightGBM은 너무 적은 수의 데이터를 사용하면 과적합(overfitting)의 문제가 발생할 수 있습니다. LightGBM의 특징lightgbm은 기존의 gradient boosting 알고리즘과 다르게 동작됩니다.기존 boosting 모델들은 트리를 level-wise하게 늘어나는 방법을 사용했는데요. lightgbm은 leaf wise(리프 중심) 트리 분할을 사용합니다.출처 : https://www.slideshare.net/GabrielCyprianoSaca/xgboost-lightgbm기존의 트리 들은 트리의 깊이(tree depth)를 줄이기 위해서 level wise(균형 트리)분할을 사용했는데요. lightgbm은 이것과 다르게 모델이 동작됩니다.level-wise 트리 분석은 균형을 잡아주어야 하기 때문에 tree의 depth가 줄어듭니다. 그 대신 그 균형을 잡아주기 위한 연산이 추가되는 것이 단점이죠.lightgbm은 트리의 균형은 맞추지 않고 리프 노드를 지속적으로 분할하면서 진행합니다. 그리고 이 리프 노드를 max delta loss 값을 가지는 리프 노드를 계속 분할해갑니다. 그렇기 때문에 비대칭적이고 깊은 트리가 생성되지만 동일한 leaf를 생성할 때 leaf-wise는 level-wise보다 손실을 줄일 수 있다는 것이 장점입니다. 파이썬(Python)에서 LightGBM 사용하기python에서는 이와 같은 lightgbm을 제공해줍니다.정말 간단하게 pip install lightgbm을 해서 설치할 수 있습니다.xgboost와 마찬가지로 scikit learn에서 그냥 제공해주지 않기 때문에 pip install로 lightgbm을 설치해주어야 합니다.또한, lightgbm에게도 여러가지 하이퍼 파라미터 값들이 있습니다.대체적으로 xgboost와 hyperparameter들이 비슷합니다. 하지만, xgboost와 다르게 lightgbm은 leaf-wise 방식의 알고리즘을 사용하기 때문에 leaf-wise 방식의 하이퍼 파라미터 값이 추가가 됩니다.n_estimators : 반복하려는 트리의 개수learning_rate : 학습률max_depth : 트리의 최대 깊이min_child_samples : 리프 노드가 되기 위한 최소한의 샘플 데이터 수num_leaves : 하나의 트리가 가질 수 있는 최대 리프 개수feature_fraction : 트리를 학습할 때마다 선택하는 feature의 비율reg_lambda : L2 regularizationreg_alpha : L1 regularization등의 파라미터가 lightgbm에 있습니다. 더 자세한 것을 알고 싶으시면 아래 링크를 참조하세요.https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html  기본적으로 from lightgbm import LGBMClassifier 을 통해 lightgbm을 import할 수 있습니다.그리고 plot_importance 라는 것도 import 할 수 있는데요.지난 포스팅에서 보여드린 xgboost때 처럼 마찬가지로 feature의 중요도(feature importance)를 보여주는 함수입니다.  그리고 일반 부스팅 모델들과 똑같이 사용할 수 있습니다. fit과 predict을 이용해서 학습과 예측을 할 수 있죠.이게 scikit learn에서 제공해주는 방식에 맞추어 주었기 때문에 굉장히 유용합니다또한, xgboost때와 마찬가지로 lightgbm도 early stopping(조기 종료)를 제공해줍니다.early_stopping을 위한 eval data를 준비해서 early_stopping_rounds 값을 넣고 eval_set을 넣어주면 됩니다.  그리고 나서 모델 training을 하시면 됩니다. 위에 결과를 보면 26번째 제일 좋은 값에서 더 이상 늘어나지 않았다고 나옵니다. 여기서는 early_stopping_round에 해당하는 값까지 epoch가 동작되지 못했습니다.그럼에도 불구하고 너의 가장 좋은 모델은 26번째 모델이라고 알려주고 그 모델을 기준으로 return 해줍니다. 그리고 lightgbm 또한 plot importance를 제공한다고 말씀드렸습니다.사용법은 xgboost때와 똑같습니다.feature importance를 보고 싶으시면 아래와 같이 사용하면 됩니다.  여기까지 lightgbm에 대한 간단한 설명이었습니다.반응형(adsbygoogle = window.adsbygoogle || []).push({});그리드형(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_GlGkg5lx', {ignore_items: true});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//lsjsj92.tistory.com/reaction';window.ReactionReqBody = {    entryId: 548}공유하기게시글 관리꿈 많은 사람의 이야기저작자표시 'machine learning(머신러닝)' 카테고리의 다른 글머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization)  (0)2019.12.12머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud  (0)2019.12.02머신러닝 앙상블(ensemble) xgboost란? - Python 예제와 함께 살펴보기  (15)2019.11.21윈도우10에 xgboost 설치하기 - ensemble xgboost install  (4)2019.11.18머신러닝, 딥러닝에서 데이터를 나누는 이유 - X_train, X_test, y_train, y_test이란?  (32)2019.11.17TagBoosting, Ensemble, lightgbm, machine learning, machine-learning, Python, 머신러닝, 부스팅, 앙상블, 파이썬공유하기 링크페이스북카카오스토리트위터'machine learning(머신러닝)' Related Articles머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization)2019.12.12머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud2019.12.02머신러닝 앙상블(ensemble) xgboost란? - Python 예제와 함께 살펴보기2019.11.21윈도우10에 xgboost 설치하기 - ensemble xgboost install2019.11.18more2  Comments    setInitialEntryComments(548, 1723613950)댓글쓰기 폼이름비밀번호                                        Secret                                    내용SendloadedComments[548]=true;findFragmentAndHighlight(548);            Blog is powered by            kakao / Designed by            Tistoryif(!wcs_add) var wcs_add = {};wcs_add[""wa""] = ""1498aaff6eff2c0"";if(window.wcs) {wcs_do();}티스토리툴바꿈 많은 사람의 이야기구독하기                    (function () {                         var blogTitle = '꿈 많은 사람의 이야기';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()if(!wcs_add) var wcs_add = {};   wcs_add[""wa""] = encodeURI(""1498aaff6eff2c0"");   wcs_do();document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2798029-548"",""customProps"":{""userId"":""0"",""blogId"":""2798029"",""entryId"":""548"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""548"",""entryTitle"":""머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자"",""entryType"":""POST"",""categoryName"":""machine learning(머신러닝)"",""categoryId"":""853217"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""3704517"",""authorNickname"":""이수진의 블로그"",""blogNmae"":""꿈 많은 사람의 이야기"",""image"":""kage@r82C1/btqzT495GKp/cJekkdIkbGNfennTj7DyQk"",""plink"":""/548"",""tags"":[""Boosting"",""Ensemble"",""lightgbm"",""machine learning"",""machine-learning"",""Python"",""머신러닝"",""부스팅"",""앙상블"",""파이썬""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
32,https://ebbnflow.tistory.com/165,인기 검색어,새소식
33,https://nnuk.tistory.com/18,태그,"카테고리 없음STEVAL-STWINKT1B 머신러닝 테스트 후기 누크_엠지2024. 1. 3. 17:47ST사에서 머신러닝으로 재밌는게 나왔길래 하나 구입해서 테스트해봄STEVAL-STWINKT1B 보드가 가격대가 있으니 과제비를 쓰거나 용돈을 좀 아껴서 써봐도 괜찮을듯하다.본편이 궁금한 사람들은 https://wiki.st.com/stm32mcu/wiki/AI:How_to_create_a_multi-state_vibrations_classifier_using_NanoEdge_AI_studio 여기 들어가서 보길 바람 선풍기는 올해 여름 다이소에서 3천원? 5천원인가 주고 샀던 3단 선풍기임고정할만한게 따로 없어서 고무줄로 고정함  정지 상태를 포함하여, 1단,2단,3단 속도의 진동 데이터를 뽑음 20개만 뽑으니 인식률이 너무 낮아서 50개 이상씩 뽑아봄 벤치마킹해주는데 생각보다 오래걸림 5분정도 하면 괜찮다고 함, 용량에 변화가 없으니 괜찮겠지?  정지상태의 인식률은 매우좋음 1단도 무난하게 좋음 문제는 2단계인데 소리로는 확실히 차이나는데 진동엔 조금 애매한가봄, 진동센서와 마이크정보를 같이 받아야되나 싶음 3단계는 매우 확율 높게 인식함  보드를 새로 구입하면 펌웨어가 오래되서 usb가 인식안될꺼임 위에 첨부한 링크에서 새로 다운받아야함보드를 써본 느낌은 아주 묘함 펌웨어 좀 했다면 한 연차인데 데이터들을 일일히 파악하고 특징 잡아서 결과를 내던 방법에서 데이터를 획득하고 훈련시켜 결과를 낸다는건 아주 묘하게 다가옴, 문제는 센서의 가격인데 굳이 진동센서를 쓰는게 아닌 전류도 학습이 가능하니 양산품에 적용하려면 전류로 컨트롤하는게 좋을듯함  위 학습된 데이터는 당연히 stm32 보드에서 사용할 수 있게 헤더파일로 바꿔주니 따로 구성해서 사용하면됨     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//nnuk.tistory.com/reaction';window.ReactionReqBody = {    entryId: 18}공유하기게시글 관리누크저작자표시 비영리 변경금지 태그STM32, 머신러닝, 온 디바이스    setInitialEntryComments(18, 1723627660)Secret댓글달기loadedComments[18]=true;findFragmentAndHighlight(18);"
34,https://dotiromoook.tistory.com/29,태그,"python[python] 파이썬 연재의 시작~by 도토리묵 :D2023. 3. 29.오늘부터 나는 파이썬에 대해 글을 연제 해보려 한다.난 머신러닝 엔지니어로써 파이썬을 주 언어로 사용하지만 언어 자체를 깊거나 정확하게 안다고는 확실하게 말할 수 없는 거 같다.파이썬이라는 언어 자체를 제대로 알고 초보자 적인 관점부터 다져 나가면서 남에게 쉽고 정확하고 도움 될 만한 정보를 전달하고자 글을 적으려 한다. 만약 저의 연재를 따라 오시면서 공부하다 의문점이 들거나 저보다 더 뛰어나신 분께서 보시고 제가 혹여나 잘못 언급한 부분이 있다면 언제든지 댓글로 문의 or 피드백 주시는 것을 아주 환영합니다. 그리고 파이썬 관련 연재 글은 기존 제 블로그 컨셉인 반말(친구에게 가르쳐 주는 컨셉) 이 아닌 존댓말로 글을 적을 거다. 기초적인 파이썬 문법부터 심화적인 데이터 분석과 인공지능 파트까지 다뤄볼 예정이다.(데이터 분석과 인공지능은 제 블로그의 다른 카테고리에서 병렬적으로 진행될 예정) 그럼 이제 시작해 보겠습니다. 시이~~~ 작~!window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//dotiromoook.tistory.com/reaction';window.ReactionReqBody = {    entryId: 29}공유하기게시글 관리AI 하는 빌리의 반란 'python' 카테고리의 다른 글[python] 파이썬 설치 하는 방법 (Windows 윈도우)  (0)2023.04.01[python] 파이썬 이란? (역사, 특징)  (0)2023.03.29[python] map 함수 사용법, 동작원리 및 특징 (예제포함)  (1)2023.03.28[Python] Anaconda 란? / 설치방법  (0)2022.08.04태그python, 파이썬관련글[python] 파이썬 설치 하는 방법 (Windows 윈도우)[python] 파이썬 이란? (역사, 특징)[python] map 함수 사용법, 동작원리 및 특징 (예제포함)[Python] Anaconda 란? / 설치방법댓글0비밀글댓글등록loadedComments[29]=true;findFragmentAndHighlight(29);"
35,https://keyog.tistory.com/45,Don't learn machine learning - 머신러닝 공부하지 마세요!,"지식 저장소머신러닝 공부하지 마세요! towards 게시글 해석 Keyog2021. 3. 4. 23:29안녕하세요. 정말 오랜만에 글을 올립니다.요즘 바빠서 글을 올리지 못했지만, 재미난 글을 towards에서 읽고 공유하고자 하는 마음에 글을 올리게 되었습니다.두가지의 글을 해석하고, 개인적인 의견을 작성한뒤에 글을 마치겠습니다. 게시글은 다음과 같습니다.Don't learn machine learning  5 Reasons You Don't Need to Learn Machine Learning Don’t learn machine learningLearn how to build software with ML modelstowardsdatascience.com 5 Reasons You Don’t Need to Learn Machine LearningAn increasing number of influencers preach why you should start learning Machine Learning. Should you listen to them?towardsdatascience.comDon't learn machine learning - 머신러닝 공부하지 마세요!이 글의 시작은 머신러닝은 개발자들에게 매력적이고 최소한의 관심이 있을것이라는 가정에서 시작합니다.만약 머신러닝을 공부하기로 하였고, 일반적인 공부 방법을 따른다면 선형대수학 및 다변수 미적분을 공부하는데만 2주를 소비할 수 있다고 합니다. (아니.. 제 생각으로는 완전히 이해하려면 그 이상입니다.)그 이유로는 대부분의 머신러닝 입문자료는 개발자(Developer)를 위한것이 아니라 연구자(Researcher)를 위한 자료들이기 때문에 머신러닝을 이용한 상품(Product)를 개발하는데에는 Issue가 된다고 합니다.그럼 본격적으로 읽어 볼까요?Do you want to build products, or research?2000년대 후반 이전에는 머신러닝은 연구적 성향이 강했습니다. 그렇기에 머신러닝을 이용한 의미있는 상품(Product)을 만드는 회사는 많지 않았습니다.따라서, 머신러닝에 입문하기 위한 자료들은 연구관점에서 접근합니다. 수학적 관점에서 신경망을 설명하며, 역전파(back propagation), 적대적 네트워크(adversarial networks) 같은 머신러닝의 이론들을 설명하는 것으로 시작합니다.이 것은 대학과 무관한 곳에서도 일어나는 패턴입니다. TensorFlow의 'Quickstart for Beginners' 에는 이렇게 적혀 있습니다.loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)This loss is equal to the negative log probability of the the true class : it is zero if the model is sure of the correct class. This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.log(1/10) ~= 2.3이 손실 함수는 실제 class의 음의 log확률과 동일합니다. 모델이 correct class를 맞추는 경우 0이 됩니다.훈련되지 않은 모델은 확률이 무작위 이므로 (각 class별 1/10) 초기손실은 -tf.log(1/10) ~= 2.3 에 가까워야 합니다.이미 머신러닝 수학을 잘알고 있고, 수학적인 부분을 공부하고자 한다면 이러한 글을 읽고 접근하는 것이 맞을 수 있습니다. 그러나처음 머신러닝을 배우고, 개발해보려고 하는 개발자에겐 이러한 문구는 찾던 것이 아닐 수 있습니다.프로그래밍을 처음 배울때를 예로 들면, 어셈블리어를 통해 코드 작성을 배우는 것과 같습니다. 하지만 실제로 개발자들은 어셈블리 어를 배우지는 않습니다. 코딩을 처음 배울때는 고수준 언어(python 같은)를 통해 ""hello world"" 를 작성해보는 것을 시작했을 것입니다. 그 이후에 프로젝트에 약간의 복잡한 코드들과 좀 더 low-level까지 코딩할 수 있도록 공부해왔을 것입니다.이러한 학습 방법은 SW개발자 사이에서 성공적으로 작용했고, 성공의 이유는 구축(Build)를 우선적으로 진행했기 때문입니다. 머신러닝의 경우도 마찬가지입니다. 추천엔진을 구축(Build)하는 것을 논문을 작성하고 게시하는 것보다 우선적으로 머신러닝에 접근해야합니다.How to learn ML by building software이러한 하향식 접근 방법으로는 fastai의 강의가 잘 설명되어 있습니다. (강의에 대한 내용이 약간 나오는데 생략하겠습니다.)만약, 당신이 당신의 것을 구축(Build)하는 것을 잘 배우는 사람이라면, 머신러닝을 시작하는 것도 다른 프로그래밍을 시작하는 것과 다르지 않게 시작할 수 있습니다.다음은 재밌어 보이는 NLP 프로젝트를 구축하는 순서를 나열합니다. 이러한 방식을 보고 머신러닝을 이용하여 구축(Build)하는 것에 친숙하게 느끼길 바랍니다.텍스트 자동완성, 번호판 식별 등 만들고자 하는 목표를 정합니다.프로젝트에 사용할만한 모델(GPT-2 나 YOLOv3 같은)을 찾고, 제공하는 pre-train모델을 내려받습니다. 실행 방법을 확인하고, 실행해본 뒤에 멋지다고 생각이 든다면, gpt-2-simple, darknet 과 같은 라이브러리를 사용하여 모델을 자신의 데이터에 맞게 Fine tuning 하여 당신만의 모델을 만들 수도 있습니다.마지막으로, 모델을 마이크로 서비스로 배포하세요!youtu.be/gsYEZtecXlA해당 동영상은 한명의 엔지니어가 재미삼아 만든 번호판을 인식하는 실제 응용프로그램 입니다.이 접근 방식을 통해 공부한다면, 다양한 인기 모델의 구조(Architecture)를 알고, 적합한 어플리케이션에 대해 알아볼 수 있습니다. 보다 중요한것은 머신러닝 모델을 통해 실제 제품(Product)를 구축하는데 필수적인 ML 인프라를 배운다는 것 입니다.Once you can build with machine learning, then learn the theory만약 당신이 엔지니어라면, password를 해싱해본적이 있을 것이라고 생각합니다. 당신이 password를 해싱하는 데에 암호화에 대한 연구를 몇 주 동안 했습니까? 아니면 bcrypt 같은 라이브러리를 사용했습니까?마찬가지로, 웹 app 을 처음 구축할때, 데이터베이스에 데이터를 생성할 때, 데이터 베이스의 기본지식에 대해 몇 주 동안 연구했습니까? 아니면 프레임워크와 함께 제공된 ORM을 사용했습니까?머신러닝도 마찬가지 입니다. 머신러닝을 이용한 SW를 개발하고자 한다면, 먼저 머신러닝을 이용해서 소프트웨어를 구축하고, Pre-train된 모델과, 제공되는 tool을 이용해서 일단 만드세요. 그런 다음 프로젝트의 성능을 끌어올리려하거나, 머신러닝이 동작하는 것을 좀 더 깊게 알아가기 위해 머신 러닝 이론들을 공부하며 머신러닝의 작동 방식을 공부하세요.개인적 의견저는 이 포스팅을 읽고나서, 저의 생각과 정말 딱 맞는 포스팅이라고 생각했습니다. 한국에서 실제로 채용공고들을 보면 작년과 많이 달라졌습니다. 작년만 해도 '논문을 읽고, 구현하는 데 거부감이 없으신 분', '수학, 통계 전문가' , '석사학위 이상', '딥러닝 관련 논문 게시 경험' 등 엔지니어를 구하는 공고임에도 불구하고 연구적 성향의 자격요건들, 면접 때도 개발의 영역보다는 딥러닝 관련 지식을 질문하는 등 머신러닝 이론을 통해 사람을 채용하려고하는 경우가 많았습니다. 하지만 요 근래의 채용공고를 보면 ' 개발경험', '머신러닝 파이프라인 구현', ' SW 개발경험' 등 개발자의 역량을 좀 더 중시하는 경향이 늘어난 것 같습니다. (물론 아직도 연구자와 완벽히 분리되거나 하진 않았습니다.) 실제로 회사라는 것은 결국 이익을 추구하는 집단이기 때문에, 아무리 머신러닝에 뛰어난 지식이 있더라도, 개발 능력이 부족해서 SW를 만들어서 배포할수 없다면 즉, 상품화(Product)하지 못하는 머신러닝 지식은 회사에서 필요 없을거라고 생각합니다. (특히나 스타트업은 빠르게 성장하는것이 중요하기 때문에 더더욱 그럴 것이라고 생각합니다.)즉, 머신러닝을 공부하고 또 그를 통해 취업하고 싶은 학생이라면 더더욱 개발을 먼저 해보는 것을 저 또한 좋다고 생각합니다. (물론 머신러닝/딥러닝 연구자(Researcher)가 되고 싶은 분이라면 깊게 이해하는 것이 좋지만, 대부분은 엔지니어의 영역에서 취업될 것이라고 생각하기 때문에.. 만약 연구자라고 하더라도, 자신만의 app을 만들어 보는 것은 좋다고 생각합니다.)포스팅이 많이 길어졌네요!  5 Reasons You Don't Need to Learn Machine Learning 에 대한 글은 다음 포스팅으로 넘어가서 마저 진행해보겠습니다. 간단하게 말씀드리면 현업 AI개발자가 느낀 머신러닝 엔지니어에 대한 오해 같은 느낌의 포스팅입니다. 해당 포스팅에 작성된 글과는 성격이 조금 다른 글이 되겠네요.여기까지 읽어주셔서 감사합니다! 다음 포스팅 링크를 달고 마무리 하겠습니다.2021/03/05 - [지식 저장소] - 머신러닝을 공부할 필요가 없는 5가지 이유 - towards 해석 머신러닝을 공부할 필요가 없는 5가지 이유 - towards 해석Don't learn machine learning 해석에 이어서 두번째 포스팅 입니다. 해당 게시글은 이전에 머신러닝 개발자가 되기 위한 공부 접근방법 같은 느낌의 글이었다면, 이번 글은 머신러닝 엔지니어에 대한keyog.tistory.com      (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//keyog.tistory.com/reaction';window.ReactionReqBody = {    entryId: 45}공유하기게시글 관리인간지능이 인공지능을 공부하는 장소저작자표시 '지식 저장소' 카테고리의 다른 글머신러닝에 대한  5가지 오해 (원제 : 5 Reasons You Don’t Need to Learn Machine Learning)  - towards 해석  (0)2021.03.05Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(3)  (0)2020.11.03Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(2)  (0)2020.11.03Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(1)  (0)2020.11.02DETR : End-to-end방식의 Transformers를 통한 object detection  (2)2020.07.07태그torward 해석, 개발, 딥러닝, 머신러닝'지식 저장소' Related Articles머신러닝에 대한  5가지 오해 (원제 : 5 Reasons You Don’t Need to Learn Machine Learning)  - towards 해석Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(3)Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(2)Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(1)Secret댓글달기loadedComments[45]=true;findFragmentAndHighlight(45);"
36,https://bcho.tistory.com/1174,Tag,"                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝머신러닝 모델 개발 삽질기Terry Cho2017. 4. 24. 14:27머신러닝 모델 개발 삽질 경험기조대협 (http://bcho.tistory.com)딥러닝을 공부하고 CNN 모델을 기반으로 무언가를 만들어보겠다는 생각에, 해외 유명 연예인 얼굴 사진을 가져다가 분류하는 얼굴 인식 모델을 만들어 보기로 하였다.아직도 진행중이지만, 많은 시행 착오를 겪었는데 같은 시행 착오를 겪지 않고 경험을 공유하기 위해서 겪었던 시행 착오들을 정리해 본다.학습 데이타 확보 및 분류먼저 학습용 데이타를 수집 하는 것이 가장 문제 였다. 인터넷에서 사진을 모아서 학습 데이타로 사용해도 되겠지만, 아무래도 저작권 및 초상권 문제가 있고, 일일이 사진을 하나씩 받아서 수집하거나 또는 별도의 수집기를 만드는 것도 부담이 되었다.그래서 찾은 것이 pubfig라는 셀럽 얼굴 데이타인데 http://www.cs.columbia.edu/CAVE/databases/pubfig/상용 목적이 아니라 연구용 목적이면 사용이 가능하다. 이 데이타는 파일 URL, 셀럽 이름 형태로 라벨링이 되어 있기 때문에, 학습에 적합하리라고 생각하고, 이 파일을 기반으로 데이타를 수집하였다.여기서 생긴 문제는, 이 데이타가 오래된 데이타라서 존재하지 않는 파일이 다수 있었고, 이 경우 파일을 저장하고 있는 사이트에서, 404 Not found와 같은 이미지를 리턴하였기 때문에, 이를 필터링해야 하였고, 같은 사진이 중복되서 오는 문제등이 있었기 때문에,상당량을 일일이 필터링을 해야 했다.그리고, 사진상에, 여러 얼굴이 있는 이미지가 많았기 때문에, VISION API로 얼굴을 인식해서 얼굴 사진만 잘라낼 요량이었기 때문에, 독사진만을 일일이 보고 골라내야 했다. 나중에 생각해보니 VISION API로 얼굴이 한명만 인식이 되는 사진만 필터링을 했으면 됐을텐데. 불필요한 작업이 많았다.라벨을 문자열로 쓴 문제학습 데이타에 대한 라벨을 생성할때, 괜히 가독성을 높힌다고 라벨을 문자열로 해서 각 사람의 이름을 사용하였다.CNN에서 마지막은 Softmax는 matrix이기 때문에, 라벨 문자열을 나중에 list.indexOf를 이용하여 배열로 변경할 예정이었는데, 파이썬에서는 쉽게 될지 몰라고, 텐서플로우 코드에서는 이 과정이 쉽지 않았다.그래서..결국은 라벨 데이타를 문자열이 아니라, 0~44의 int 값으로 재 생성한후에,     batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),        FLAGS.num_classes, on_value=1.0, off_value=0.0)tf.one_hot 함수를 이용하여, 1*45 행렬로 바뀌어서 사용하였다.학습용 및 검증용 데이타를 초기에 분류하지 않았던 문제학습데이타를 준비할때, 학습 데이타를 학습용과 검증용으로 따로 분류를 해놨어야 하는데, 이 작업을 안해서, 결국 모델을 만들다가 다시 학습 데이타를 7:3 비율로 학습 데이타와 검증용 데이타로 분류하는 작업을 진행하였다. 학습 데이타의 분포가 골고르지 못했던 문제사진을 모으는 과정에서 필터링 되서 버려지는 데이타가 많았고, 원본 데이타 역시 사람별로 사진 수가 고르지 못했기 때문에, 결과적으로 모여진 학습 데이타의 분포가 사람별로 고르지 못했다.학습데이타가 많은 셀럽은 200~250장, 적은 사람은 50장으로 편차가 컸다.이로 인해서 첫번째 모델의 학습이 끝난 후에, 모델을 검증해보니, 학습 데이타를 많이 준 사람으로 대부분 분류를 해냈다. 47개의 클래스 약 6000장의 사진으로 5시간 학습 시킨 결과, 예측을 검증하는 과정에서 90%이상을 모두 브래드피트로 인식해내는 문제가 생겼다. (내 맥북이 브레드피트를 좋아하는가??)그래서 결과적으로 학습데이타와 검증 데이타를 클래스별로 분포를 같게 하기 위해서, 클래스당 약 50 장의 샘플 사진으로 맞춰서 예측 결과가 편중되는 현상을 해결하려고 하였다.학습 순서가 클래스별로 된 문제클래스별 학습 데이타의 양을 균일하게 맞췄음에도 불구하고, 모델의 학습 결과가 특정 클래스들로 편향되는 현상이 발생하였다.이는 학습을 시킬때, 골고루 학습을 시켜야 하는데, 학습 데이타를 순서대로 학습을 시켰기 때문에 발생한 문제이다. 즉 풀어서 말하자면, “브래드 피트""를 20번 학습 시키고, “안젤리나 졸리""를 20분 학습 시키고, “브루스 윌리스”를 20번 학습 시켜서 모델이 첫 학습데이타 쪽으로 편향되는 현상이 발생한것인데, 이를 해결하려면 학습 데이타를 랜덤으로 만들어서 학습시켜야 한다. 예를 들어 “브래드 피트”,”안젤리나 졸리"",”브루스 윌리스"",”안젤리나 졸리"",”브루스 윌리스"", ”안젤리나 졸리"",“브래드 피트” …. 이런식으로 말이다. 즉 코드 상에서 배치 데이타를 읽어올때 셔플 처리를 하면되는데 이를 위해서 데이타를 읽는 부분을 다음과 같이 변경 하였다.def get_input_queue(csv_file_name,num_epochs = None):    train_images = []    train_labels = []    for line in open(csv_file_name,'r'):        cols = re.split(',|\n',line)        train_images.append(cols[0])        # 3rd column is label and needs to be converted to int type        train_labels.append(int(cols[2]) )                                input_queue = tf.train.slice_input_producer([train_images,train_labels],                                               num_epochs = num_epochs,shuffle = True)        return input_queueget_input_queue 함수에, csv_file_name을 인자로 주면, 이 파일을 한줄 단위로 읽어서, 첫번째는 파일명, 세번째는 라벨로 읽은 후에, 각각 train_images와  train_lables에 각각 string과 int 형으로 저장한다그 다음이 배열을 가지고 tf.train.slice_input_producer를 사용하면 배열에서 데이타를 읽어 드리는 input queue 를 생성하는데, 이때 인자로 shuffle = True로 주면 데이타를 리턴 할때 순차적으로 리턴하지 않고 셔플된 형태로 랜덤하게 리턴한다. def read_data(input_queue):    image_file = input_queue[0]    label = input_queue[1]        image =  tf.image.decode_jpeg(tf.read_file(image_file),channels=FLAGS.image_color)        return image,label,image_file다음으로, 이 큐를 이용하여 이미지 파일명과, 라벨을 읽어서 이미지 파일 데이타(텐서)와 라벨로 읽는 코드를 read_data라는 함수로 구현하였다. 입력값은 input_queue인데, input queue에서 데이타를 읽으면 첫번째는 이미지 파일명, 두번째는 라벨이 되는데, 첫번째 파일명을 tf.image.decode_jpeg함수를 이용하여 텐서로 읽은후, 읽은 이미지 데이타와 라벨을 리턴하였다.def read_data_batch(csv_file_name,batch_size=FLAGS.batch_size):    input_queue = get_input_queue(csv_file_name)    image,label,file_name= read_data(input_queue)    image = tf.reshape(image,[FLAGS.image_size,FLAGS.image_size,FLAGS.image_color])        batch_image,batch_label,batch_file = tf.train.batch([image,label,file_name],batch_size=batch_size)                                                       #,enqueue_many=True)    batch_file = tf.reshape(batch_file,[batch_size,1])    batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),        FLAGS.num_classes, on_value=1.0, off_value=0.0)    return batch_image,batch_label_on_hot,batch_file마지막으로, 배치로 데이타를 읽는 함수 부분에서 앞에 정의한 get_input_queue와 read_data 함수를 이용하여 데이타를 shuffle 된 상태로 읽은 후에, tf.train.batch를 이용하여 일정한 개수 (배치) 형태로 리턴하도록 하였다. 그 결과 예측 결과가 한쪽으로 편향되는 현상을 없앨 수 는 있었다.샘플 데이타의 부족데이타 편향 현상은 잡았지만, 클래스의 수(45)에 대비하여, 샘플데이타의 수(클래스당 50개)로 부족하여, 학습을 계속 진행해도 cross entropy 함수는 4~7 사이에서 왔다갔다 하면서 더 이상 0으로 수렴하지 않았고 정확도되 0~35% 사이를 왔다갔다 하면서 수렴을 하지 않았다. 그래서, 학습 이미지의 색이나, 방향등을 변경하는 방법으로 데이타를 뻥튀기 하려고 하는데, 이 부분은 아직 작업중.그외에 자잘한 삽질모 그외에도 엄청 여러가지 삽질을 하고 있다. 그래도 모델 하나 제대로 만들어봐야 겠다는 생각에 끝까지 우격다짐으로 진행하고 있지만, 학습을 돌다가 스크린 세이버나, 절전 모드로 들어가서 학습이 중단된 사례. 모델을 개발하다가 중간에 텐서 플로우 버전이 올라가서 코드를 수정한 일. 맥에서 개발하다가 윈도우 머신에 GPU로 바꿨더니, 파이썬 2.7이 아니라 파이썬 3.5만 지원을 해서, 2.7 코드를 모두 다시 고친일등.머신러닝이 과학이나 수학보다 노가다라는데, 몸소 느끼는 중.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1174}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기  (6)2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서  (0)2017.05.11머신러닝 라벨 데이타 타입에 대해서  (0)2017.04.10텐서플로우의 세션,그래프 그리고 함수의 개념  (1)2017.04.03텐서플로우-배치 처리에 대해서 이해하자  (2)2017.04.03TagDeep learning, Machine Learning, ML, Overview, tensorflow, 강좌, 경험, 데이타, 딥러닝, 라벨, 머신러닝, 삽질, 샘플, 정재, 조대협, 초보, 텐서플로우, 튜토리얼, 편중, 편협'빅데이타 & 머신러닝/머신러닝'의 다른글이전글머신러닝 라벨 데이타 타입에 대해서현재글머신러닝 모델 개발 삽질기다음글얼굴 인식 모델 - 학습용 데이타 처리에 대해서관련글연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서2017.05.11머신러닝 라벨 데이타 타입에 대해서2017.04.10텐서플로우의 세션,그래프 그리고 함수의 개념2017.04.03loadedComments[1174]=true;findFragmentAndHighlight(1174);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag머신러닝,Tutorial,강좌,구글,google,Machine Learning,클라우드,초보,튜토리얼,소개,node.js,클라우드 컴퓨팅,빅데이타,조대협,딥러닝,Kubernetes,tensorflow,텐서플로우,쿠버네티스,cloud,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1174"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1174"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1174"",""entryTitle"":""머신러닝 모델 개발 삽질기"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":"""",""plink"":""/1174"",""tags"":[""Deep learning"",""Machine Learning"",""ML"",""Overview"",""tensorflow"",""강좌"",""경험"",""데이타"",""딥러닝"",""라벨"",""머신러닝"",""삽질"",""샘플"",""정재"",""조대협"",""초보"",""텐서플로우"",""튜토리얼"",""편중"",""편협""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
37,https://jisungs.tistory.com/447,새로운 지식을 향한 걸음,"jisung's 책읽기/기술서처음 배우는 머신러닝 - 새로운 지식을 향한 걸음by jisungStory2019. 11. 12.반응형(adsbygoogle = window.adsbygoogle || []).push({});Photo by  Chris Ried  on  Unsplash처음 배우는 머신러닝새로운 지식을 향한 걸음 인공지능은 최근 개발 분야에서 가장 큰 화두입니다. 많은 데이터 과학자들이 인공지능 연구에 매진하고 있습니다. 그 덕분에 많은 발전이 있었습니다.  2016년이 벌써 까마득하게 느껴집니다. 모든 사람들이 아직 컴퓨터는 바둑으로 사람을 이길 수 없다고 했지만 그 해 이세돌 구단과의 대전에서 구글의 알파고는 4승 1패로 승리했습니다.  인공지능 분야에서는 큰 성취였고 인간의 분야에선 아쉬움이 남는 결과였습니다.  그 이후로 몇년이 지났습니다. 간간히 들리는 바로는 그 인공지능은 더욱 발전하여 이제는 인간이 도저히 범접할 수 없는 경지에 도달했다고 들었습니다. 그리고 그 발달된 인공지능을 통해 구글은 앞으로 어디로 나아갈지 예측할 수 없는 회사가 되어 버렸습니다.  앞서 나가는 분들은 그 분들의 분야에서 열심히 해주셔서 앞으로 인류의 발전에 기여하실 거라고 믿습니다. 반면에 책벌레인 저는 새로 읽을 분야가 생겨서 기쁠 따름입니다. 제가 이번에 고른 책은 인공지능의 한분야인 머신러닝을 다룬 책 “ 처음 배우는 머신러닝”입니다.  이 책은 제가 접해본 기술 서적 중에서 어려운 기술을 쉽게 설명해주는 몇 안되는 책중에 하나입니다. 많은 기술 서적들은 전문가의 언어로 전문적으로 설명하기 때문에 저 같은 일반인이 읽기에는 어려운 부분이 많습니다. 특히 용어에 대한 정의 없이 본론으로 들어가는 책들이 많은데 그럴 경우 읽어 나가다가 맥락을 놓치게 되고 결국 이해를 포기하게 됩니다. 반면에 이 책은 초반에 용어 정리부터 후반에 실전 예제까지 잘 갖춰진 기술 서적이었습니다.  얼마전에도 머신러닝에 대한 책을 한 권 골랐습니다. 그 책을 읽어 나가다가 결국 포기를 했었습니다. 그 이유는 책의 내용을 수식으로 설명하려 했기 때문입니다. 수학을 싫어하지는 않습니다만 고도의 상징체계를 사용하고 있는 수학은 어떤 패턴을 효율적으로 표현할 수는 있지만 그것을 활자로 인식했을 때 이해하기에는 어렵습니다. 하지만 수학의 바탕 위에 세워진 인공지능 기술인 만큼 수식 없이는 말할 수 없는 영역도 존재합니다. 꼭 필요한 부분에서는 수학을 사용하고 그 세부적인 학습은 독자에게 맞기는 것 그 절제의 균형을 잡는 것이 저자의 역량이 아닌가 합니다.  처음 배우는 머신러닝 기술 서적을 읽은 만큼 기술의 한 요소를 소개하고 넘어가겠습니다. 바로 손실함수 입니다.  이 책에서 정의하고 있는 손실 함수는 다음과 같습니다. 모델이 실제로 데이터를 바르게 표현했는지 혹은 얼마나 예측이 정확한지 수학적으로 표현하는 것이 손실 함수입니다. 처음 배우는 머신러닝  p. 58  즉 데이터를 통해 머신러닝이 만든 모델이 어떤 데이터를 입력받아 만들어낸 출력이 제대로 예측 했는지 또는 얼마나 틀렸는지 보여주는 함수라는 뜻인 것 같습니다. 결국 손실 함수는 답을 알고 있다는 뜻이 됩니다. 그럼 모델을 통해 예측할 필요가 없는 게 아닌가 하는 의구심이 들지만 더 이상의 기술에 대한 철학적 접근을 했다가는 뇌가 망가질 것 같아 여기서 멈추어야 할 것 같습니다. 그 언젠가 머신러닝을 제대로 공부한 분을 만나게 된다면 한번 여쭤 보고 싶은 부분이기도 합니다.  예전에 어디서 주워들은 표현으로 ‘그 분야를 알기 위해서는 개론서 열권을 읽으면 된다’라는 말을 들은 적이 있습니다. 인공지능 분야는 앞으로 어디까지 발전하게 될지 알 수 없는 분야이기도 하고 연구된 지 오래되어 많은 개론서 교양서들이 나와있는 분야이기도 합니다. 앞으로도 꾸준히 관련 책을 읽을 수 있을 것 같아 기대됩니다.  정말 잘 정리된 머신러닝 기술서 ‘처음 배우는 머신러닝’ 이었습니다. 2019/10/29 - [하루 책읽기/하루 기술서] - 딥러닝 첫걸음 - 인공지능 이해하기 딥러닝 첫걸음 - 인공지능 이해하기딥러닝 첫걸음 새로운 개념에 익숙해지기 알파고의 바둑 승리 이후 인공지능에 대한 관심이 높아졌습니다. 하지만 인공지능이라는 주제 자체게 어려운 것이다 보니 책을 구해 읽어 보아도 머릿속에 잘 그려지지..jisungs.tistory.com2019/05/10 - [하루 책읽기/하루 기술서] - 생각하는 프로그래밍 #2 - 엔지니어의 직업정신 생각하는 프로그래밍 #2 - 엔지니어의 직업정신생각하는 프로그래밍 #2 엔지니어의 직업정신 프로그래머의 입장에서 생각해야 할 것들을 수필의 형태로 정리한 책을 읽고 있습니다. 컴퓨터라는 분야가 생긴지 얼마 되지 않아 그렇게 오래 되었다고 할 수는 없..jisungs.tistory.com2019/01/29 - [하루 책읽기/하루 기술서] - 알고리즘 문제해결 전략 - 어떻게 문제를 해결 할 것인가? 알고리즘 문제해결 전략 - 어떻게 문제를 해결 할 것인가?알고리즘 문제해결 전략 어떻게 문제를 해결할 것인가? 저는 학창시절 수학을 못하는 학생이었습니다. 저를 가르쳤던 많은 선생님들은 이과 보다는 문과를 추천하셨고 저는 그런 주변 사람들의 반응이 싫었습니다..jisungs.tistory.com반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jisungs.tistory.com/reaction';window.ReactionReqBody = {    entryId: 447}공유하기게시글 관리Jisung's Story저작자표시 비영리 변경금지 'jisung's 책읽기 > 기술서' 카테고리의 다른 글강화학습 첫걸음 - 새로운 지식의 무거운 첫걸음  (0)2019.12.05텐서플로 첫걸음 - IT거인의 빅피쳐  (0)2019.11.26딥러닝 첫걸음 - 인공지능 이해하기  (0)2019.10.29생각하는 프로그래밍 #2 - 엔지니어의 직업정신  (0)2019.05.10생각하는 프로그래밍 - Programming Pearls 2/E  (1)2019.05.05태그구글, 김승연지음, 머신러닝, 손실함수, 인공지능, 정용주 지음, 처음 배우는 머신러닝, 한빛미디어관련글강화학습 첫걸음 - 새로운 지식의 무거운 첫걸음텐서플로 첫걸음 - IT거인의 빅피쳐딥러닝 첫걸음 - 인공지능 이해하기생각하는 프로그래밍 #2 - 엔지니어의 직업정신댓글0비밀글등록loadedComments[447]=true;findFragmentAndHighlight(447);"
38,https://benn.tistory.com/32,Tag,"                                                  Bee's 데이터 과학                              홈태그방명록Data Science | AI/Python데이터 분석에 쓰이는 파이썬 라이브러리 소개Letter_B2021. 9. 24. 14:21728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});이번 글에서는 데이터 분석에 자주 쓰이는 패키지를 소개하겠습니다.데이터 분석을 위한 라이브러리 NumPyNumPy (넘파이)는 Numerical Python (""숫자 파이썬"")의 약자로 수치 연산을 수행하는 데 사용되는 라이브러리입니다. 넘파이만의 배열 자료구조 (ndarray)를 이용해 파이썬의 기본 리스트와 딕셔너리보다 빠르게 수치계산을 할 수 있습니다.예제) 아래는 파이썬 range와 넘파이의 arange 함수를 이용하여 숫자 0부터 100만까지 생성한 후, 모든 수의 제곱을 계산하는 데에 걸리는 시간을 비교해본 것입니다. 넘파이의 배열이 훨씬 더 빠르게 계산이 되는 걸 확인할 수 있습니다.파이썬 리스트 &amp;amp; 반복문 vs 넘파이 배열 계산 속도 비교pandas판다스는 데이터 처리 및 분석을 위해 만들어진 패키지입니다. SQL 테이블이나 엑셀 같이 표 형식으로 되어있는 데이터 처리 및 분석에 용이하고 빨라서 자주 쓰이는 패키지입니다. 예제) 표 형식의 데이터. 파이썬에서는 DataFrame 객체라고 불립니다.출처: geeksforgeeks.orgmatplotlib파이썬의 대표적인 데이터 시각화 라이브러리입니다. 웹사이트에서 다양한 차트와 코드를 확인할 수 있습니다. 출처: https://matplotlib.org/SciPySciPy (사이파이)는 과학 컴퓨팅을 위한 수학 라이브러리입니다. 수학, 과학, 엔지니어링 분야에서 많이 쓰이며 분야에 따라 subpackage가 존재합니다. SciPy subpackages:- scipy.io: 다양한 파일을 읽고 쓰는 데에 사용됨- scipy.linalg: 선형 대수에 쓰이는 패키지- scipy.stats: 다양한 통계 검사 및 기술 통계에 사용됨scikit-learn가장 많이 쓰이는 머신러닝 라이브러리입니다. 분류, 회귀, 클러스터링, 차원 축소 등 다양한 머신러닝 모델링이 가능합니다.예제) scikit-learn의 다양한 분류 classifier출처: scikit-learn.org위 패키지들은 자주 사용되는 패키지로서 Anaconda 배포반을 설치하면 같이 자동으로 설치가 됩니다. 아래 글에서 아나콘다 설치법을 확인하실수 있습니다.https://benn.tistory.com/26 [Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인아나콘다 Anaconda 아나콘다 (Anaconda)는 파이썬을 포함한 데이터 과학에 필요한 다양한 언어 및 패키지의 배포입니다. 프로젝트마다 다른 환경을 만드는데도 편리하고 환경마다 필요한 패키지를benn.tistory.com이 외에도 keras, statsmodels, plotly, seaborn 등 더 많은 패키지가 존재하지만 데이터 분석을 처음 접할 때 자주 쓰이는 패키지 위주로 간단히 설명해보았습니다. 데이터 분석 공부를 하다 보면 자연스럽게 이것저것 찾아가며 익숙하게 쓰이게 되는 패키지들입니다. 오타나 질문은 댓글로 남겨주세요 :)728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//benn.tistory.com/reaction';window.ReactionReqBody = {    entryId: 32}공유하기게시글 관리Bee's 데이터 과학저작자표시 'Data Science | AI > Python' 카테고리의 다른 글[파이썬] 파이 차트 그리기 (feat. matplotlib)  (0)2021.11.04[파이썬/matplotlib]  선 그래프 그리기 + 테마 (스타일 시트) 설정  (0)2021.09.27[파이썬] 판다스 pandas csv 파일 불러오기 &  데이터 살펴보기  (0)2021.09.23[데이터 분석] 파이썬 Pandas 행, 열 삭제  (0)2021.06.27[Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인  (0)2021.06.17Tagnumpy, pandas, scipy, 데이터 분석, 라이브러리, 머신러닝, 파이썬'Data Science | AI/Python'의 다른글이전글[파이썬] 판다스 pandas csv 파일 불러오기 &  데이터 살펴보기현재글데이터 분석에 쓰이는 파이썬 라이브러리 소개다음글[파이썬/matplotlib]  선 그래프 그리기 + 테마 (스타일 시트) 설정관련글[파이썬] 파이 차트 그리기 (feat. matplotlib)2021.11.04[파이썬/matplotlib]  선 그래프 그리기 + 테마 (스타일 시트) 설정2021.09.27[파이썬] 판다스 pandas csv 파일 불러오기 &  데이터 살펴보기2021.09.23[데이터 분석] 파이썬 Pandas 행, 열 삭제2021.06.27댓글 0댓글비밀글등록loadedComments[32]=true;findFragmentAndHighlight(32);반응형(adsbygoogle = window.adsbygoogle || []).push({});👋  저는 시드니에서 거주하는 데이터 과학자입니다. 현재 컴퓨터 비전 관련 일을 하고 있습니다. 분류 전체보기 (54)  Data Science | AI (44)  머신러닝 및 딥러닝 (8)  논문 리뷰 (0)  통계, 수학 (5)  Python (17)  R (5)  SQL (4)  클라우드 (2)  데이터 시각화 (3)  Web development (7)  웹 분석 (1)  알고리즘 (1)  Career Journal (3)  TIL (0) Tag라이브러리,다운로드,통계,데이터분석,설치,CSS,데이터 과학,판다스,데이터 분석,pandas,데이터과학,파이썬,PYTHON,sql,통계학,딥러닝,머신러닝,머신러닝 논문,데이터 시각화,R,최근글과 인기글최근글인기글[머신러닝] 생성적 적대 신경망 Generative Adversarial Network (GAN) 정리2024.06.27 15:55머신러닝/딥러닝 논문 읽는 방법 (앤드류 응 교수님법)2024.06.21 10:58[딥러닝 / 수학] 코사인 유사도 cosine similarity 이해하기2024.06.21 09:10[Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인2021.06.17 12:16비주얼 스튜디오 테마 추천 및 변경하기2023.02.16 11:36비주얼 스튜디오 코드 폰트 바꾸기, 크기 바꾸기 + 코딩용 폰트 추천!2023.02.17 08:56최근댓글안녕하세요!저도 OMSA 시작할 때 파이썬 완전 초보였어요! 지원 당시, 본문에 언⋯ Letter_B안녕하세요!OMSA을 알고나서 관심을 가지고 서치하다가 들어왔습니다. 자세한 후기 감사드⋯ Sophia잘~ 보고갑니다 김도훈공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/062024/052024/012023/082023/062023/042023/022022/112022/102022/08Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total435,663Today : 149Yesterday : 502블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트티스토리툴바Bee's 데이터 과학구독하기                    (function () {                         var blogTitle = 'Bee\'s 데이터 과학';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4565392-32"",""customProps"":{""userId"":""0"",""blogId"":""4565392"",""entryId"":""32"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""32"",""entryTitle"":""데이터 분석에 쓰이는 파이썬 라이브러리 소개"",""entryType"":""POST"",""categoryName"":""Data Science | AI/Python"",""categoryId"":""487723"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4648833"",""authorNickname"":""Letter_B"",""blogNmae"":""Bee's 데이터 과학"",""image"":""kage@v2O5e/btrf5iZNuCL/w43NDL7m3bqepTvLA9cm9K"",""plink"":""/32"",""tags"":[""numpy"",""pandas"",""scipy"",""데이터 분석"",""라이브러리"",""머신러닝"",""파이썬""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
39,https://bcho.tistory.com/1301,IDE 환경,"                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝쿠버네티스 기반의 End2End 머신러닝 플랫폼 Kubeflow #1 - 소개Terry Cho2019. 1. 9. 00:41End2End 머신러닝 플랫폼 Kubeflow조대협 (http://bcho.tistory.com)머신러닝 파이프라인머신러닝에 대한 사람들의 선입견중의 하나는 머신러닝에서 수학의 비중이 높고, 이를 기반으로한 모델 개발이 전체 시스템의 대부분 일 것이라는 착각이다.그러나 여러 연구와 경험을 참고해보면, 머신러닝 시스템에서 머신러닝 모델이 차지하는 비중은 전체의 5% 에 불과하다.실제로 모델을 개발해서 시스템에 배포할때 까지는 모델 개발 시간보다 데이타 분석에 소요되는 시간 그리고 개발된 모델을 반복적으로 학습하면서 튜닝하는 시간이 훨씬 더 길다. 머신러닝 파이프라인은 데이타 탐색에서 부터, 모델 개발, 테스트 그리고 모델을 통한 서비스와 같이 훨씬 더 복잡한 과정을 거친다. 이를 머신러닝 End to End 파이프라인이라고 하는데, 자세하게 그 내용을 살펴보면 다음 그림과 같다. Data ingestion : 머신러닝에 필요한 학습 데이타를 외부로 부터 받아서 저장하는 단계Data analytics : 수집된 데이타를 분석하여, 의미를 찾아내고,필요한 피쳐(특징)을 찾아내는 단계로 주로 빅데이타 분석 시스템이 많이 활용된다. EDA (Exploratory Data Analytics) 방법을 많이 사용하는데, 저장된 데이타를 그래프로 시각화해서 각 값간의 관계나 데이타의 분포등을 분석한다. Data Transformation : 수집된 데이타에서 학습에 필요한 데이타만 걸러내고, 학습에 적절하도록 컨버팅 하는 단계. 예를 들어 이미지 데이타의 크기를 정형화하고, 크롭핑 처리를 한후에, 행렬 데이타로 변환하는 과정등이 이에 해당한다.Data Validation : 변환된 데이타가 문제는 없는지 데이타 포맷이나 범위등을 검증하는 단계Data Splitting : 머신러닝 학습을 위해서 데이타를 학습용,테스트용,검증용으로 나눈다.Build a Model : 머신러닝 모델을 만들고 학습하는 단계Model Validation : 만들어진 모델을 검증하는 단계Training at scale : 더 많은 데이타를 더 큰 인프라에서 학습 시켜서 정확도를 높이고, 하이퍼 패러미터 튜닝을 통해서 모델을 튜닝하는 단계로 주로 대규모 클러스터나 GPU 자원등을 활용한다.Roll out : 학습된 모델을 운영환경에 배포하는 단계Serving : 배포된 모델을 통해서 머신러닝 모델을 서비스로 제공하는 형태. 유스케이스에 따라서 배치 형태로 서빙을 하거나 실시간으로 서빙하는 방법이 있다.Monitoring : 머신러닝 모델 서비스를 모니터링 해서 정확도등에 문제가 없는지 지속적으로 관찰하는 단계Logging : 모델에 서비스에 대한 로그 모니터링이 과정을 데이타의 변동이 있거나 모델을 향상시키고자 하거나 정확도가 떨어지는 경우 첫번째 과정부터 반복을 한다. 위에서 설명한 파이프라인 흐름을 시스템 아키텍쳐로 표현해보면 다음과 같다. 먼저 GPU를 지원하는 인프라 위에 머신러닝 플랫폼이 올라가게 되고, 빅데이타 분석 플랫폼이 같이 사용된다.머신러닝 플랫폼은 데이타를 분석하는 EDA 단계의 데이타 분석 플랫폼 그리고, 분석된 데이타를 변환 및 검증하고 학습,테스트,검증 데이타로 나누는 Data Processing 시스템이 붙고, 이 데이타를 이용해서, 모델을 개발한후에, 이 모델을 학습 시키기 위한 학습 (Training) 플랫폼이 필요하다. 학습된 모델을 검증하고, 이 검증 결과에 따라서 하이퍼 패러미터를 튜닝한 후에, 이를 운영환경에 배포하여 서비스 한다. 데이타 분석 및 모델 개발 학습 단계는 주로 데이타 사이언티스트에 의해서 이루어지는데, 이러한 엔지니어들이 사용할 개발 환경이 필요한데, 주로 노트북 기반 (예. 파이썬 주피터 노트북)의 환경이 많이 사용된다.학습이 완료된 모델을 서빙하는 Inference 엔진이 필요하고, 이를 외부 API로 노출하기 위해서 API 키 인증, 오토스케일링, 로깅 및 모니터링을 위한 API Serving 플랫폼이 필요하다. 컴포넌트가 많은 만큼 여기에 사용되는 프레임웍도 많다. 먼저 모델 개발 및 학습을 위해서는 머신러닝 프레임웍이 필요한데, Tensorflow, PyTorch, Sklearn, XGBoost등 목적에 따라서 서로 다른 프레임웍을 사용하게 되며, 완성된 모델을 서빙하는 경우에도 Tensorflow Serving, Uber에서 개발한 Horovod 등 다양한 플랫폼이 있다. 또한 모델을 서빙할때 REST API등으로 외부에 서비스 하려면 보안 요건에 대한 처리가 필요하기 때문에 별도의 API 인증 메커니즘등이 추가되어야 하고, 스케일링을 위한 오토 스케일링 지원 그리고 모델의 배포와 테스트를 위한 배포 프레임웍, A/B 테스트 환경등이 준비되어야 한다. 일부만 이야기한것이지만 실제 운영 환경에서 사용되는 머신러닝 시스템은 훨씬 더 복잡하고 많은 기술을 필요로 한다.Kubeflow comes in이러한 복잡성 때문에 머신러닝 플랫폼은 높은 난이도를 가지고 있고, 데이타 분석과 모델 개발에 집중해야 하는 머신러닝 엔지니어 입장에서는 큰 부담이 된다. (배보다 배꼽이 크다)그래서 이러한 복잡성을 줄이고 머신러닝 엔지니어의 원래 업인 데이타 분석과 머신러닝 모델 개발에만 집중할 수 있도록 플랫폼을 추상화 해놓은 오픈 소스 프레임웍이 Kubeflow이다. 위에서 설명한 머신러닝 파이프라인의 End to End 전체를 커버할 수 있게 하고, 모든 단계의 컴포넌트를 패키지화 해놔서, 어려운 설치 없이 머신러닝 엔지니어는 머신러닝 모델 개발의 각 단계를 손쉽게 할 수 있도록 해준다. Kuberflow는 Kubernetes(쿠버네티스) + ml flow 를 합한 의미로, 쿠버네티스 플랫폼 위에서 작동한다.쿠버네티스는 도커 컨테이너 관리 플랫폼으로, 이 컨테이너 기술을 이용하여 머신러닝에 필요한 컴포넌트를 패키징하여 배포한다. 쿠버네티스에 대한 자세한 설명은 링크를 참고하기 바란다. 이로 인해서 가질 수 있는 장점은 다음과 같다.클라우드나 On-Prem (데이타 센터), 개인 개발 환경에 상관 없이 동일한 머신러닝 플랫폼을 손쉽게 만들 수 있기 때문에 특정 벤더나 플랫폼에 종속되지 않는다. 컨테이너 기술을 이용해서 필요한 경우에만 컨테이너를 생성해서 사용하고, 사용이 끝나면 컨테이너를 삭제하는 방식이기 때문에 자원 활용율이 매우 높다. 특히 쿠버네티스의 경우에는 스케쥴링 기능을 이용해서 비어있는 하드웨어 자원에 컨테이너를 배포해서 (꾸겨넣는 방식으로) 사용하기 때문에 집적률이 매우 높다. 컨테이너로 패키징이 되어있기 때문에 내부 구조를 알필요가 없이 단순하게 컨테이너만 배포하면 된다. 또한 쿠버네티스는 오픈소스 플랫폼이기 때문에 여러 종류의 머신러닝 관련 기술들이 손쉽게 합쳐지고 있다. Kubeflow 컴포넌트 구성그러면 간단하게 Kubeflow의 컴포넌트 구성을 살펴보자.IDE 환경IDE 개발환경으로는 JupyterLab을 지원한다. JupyterLab은 Jupyter 노트북의 확장 버전으로 코드 콘솔뿐 아니라 파일 브라우져나 시각화창등 확장된 UI를 지원한다. <출처 : https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html>개인적으로 기존 노트북 환경에 비해서 좋은 점은 주피터 노트북을 필요할때 마다 손쉽게 생성이 가능하며, 생성할때 마다 GPU 지원 여부나 텐서플로우 버전등을 손쉽게 선택이 가능하다. <그림. 노트북 생성시 텐서플로우와 GPU 지원 여부를 선택하는 화면>또한 아래 그림과 같이 노트북 인스턴스의 하드웨어 스펙 (CPU, Memory, GPU)를 정의할 수 있다. GPU 드라이버그리고 쿠버네티스상에서 GPU를 사용할 수 있도록 GPU 드라이버를 미리 패키징 해놓았다. 머신러닝 프레임웍을 사용하면 항상 까다로운 부분이 GPU 드라이버 설정이나 업그레이드인데, 이를 미리 해놓았기 때문에 머신러닝 엔지니어 입장에서 별도의 노력없이 손쉽게 GPU를 사용할 수 있다.머신러닝 프레임웍머신러닝 프레임웍으로는 현재 텐서플로우, 파이토치, MxNet등을 지원하는데, 플러그인 컴포넌트 형태이기 때문에 앞으로 더 많은 프레임웍을 지원할 것으로 기대된다. 데이타 프로세싱데이타 프로세싱에서 데이타 변환 (Transformation)과 데이타 검증 (Validation)은 텐서플로우의 확장팩인 TFX에서 지원하는 TFDV (Tensorflow Data Validation)과 TFT (Tensorflow Transform)을 이용해서 지원한다.학습 환경개발된 모델을 학습할때 특히 분산학습의 경우에는 텐서플로우 클러스터와 우버에서 개발된 텐서플로우용 분산 학습 플랫폼인 Hornovod를 지원한다.  모델 검증학습된 모델 검증은 데이타 프로세싱과 마친가지로 텐서플로우 확장팩인 TFX의 TFMA (Tensorflow Model Analysis)를 지원한다.하이퍼 패러미터 튜닝학습된 모델에 대한 하이퍼 패레미터 튜닝은 katLib라는 컴포넌트를 이용해서 지원한다. 모델 서빙학습이 완료된 모델은 TFX 패키지의 일부인 Tensorflow Serving 을 사용하거나 모델 서빙 전문 플랫폼인 SeldonIO를 사용한다. SeldonIO는 텐서플로우뿐만 아니라 Sklearn, Spark 모델, H2O 모델, R 모델등 좀 더 다양한 모델을 지원한다. API 서비스서비스된 모델에 대한 API 키 인증이나 라우팅등을 위해서 API 게이트 웨이가 필요한데, API 게이트 웨이로 Ambassador라는 오픈 소스를 이용한다. 이를 통해서 API 키등의 인증을 지원하고, 쿠버네티스 위에 네트워크 플랫폼인 ISTIO를 사용하여, API 서비스에 대한 모니터링 및 서비스 라우팅을 지원하는데, 서비스 라우팅 기능은 새 모델을 배포했을때 새모델로 트래픽을 10%만 보내고 기존 모델로 트래픽을 90% 보내서 새모델을 테스트하는 카날리 테스트나 API 통신에 대한 보안등 여러기능을 지원한다. Istio에 대한 자세한 설명은 링크를 참조하기 바란다. 워크플로우이러한 컴포넌트를 매번 메뉴얼로 실행할 수 는 없고, 워크플로우 흐름에 따라서 자동으로 파이프라인을 관리할 수 있는 기능이 필요한데, 이를 워크플로우 엔진이라고 하고, Kubeflow에서는 argo라는 컨테이너 기반의 워크플로우 엔진을 사용한다. 자세한 내용은 링크 참조.그런데 argo는 일반적인 워크플로우를 위해서 디자인된 플랫폼으로 머신러닝 파이프라인에 최적화되어 있지 않다. (예를 들어 학습 단계 종료후, 학습 결과/accuracy등을 모니터링 한다던지, Tensorflow Dashboard와 통합된다던지.) 그래서 argo위해 머신러닝 기능을 확장하여 개발중인 오픈소스가 Kubeflow pipeline이 있다. Kubeflow pipeline에 대해서는 나중에 더 자세히 설명하도록 한다. 컴포넌트에 대한 정의Kubeflow에서 사용되는 거의 모든 컴포넌트에 대해서 설명하였다. 그러면 이런 컴포넌트를 어떻게 쿠버네티스에 배포하고, 어떻게 실행을 할것인가? 매번 쿠버네티스의 설정 파일을 만들어서 하기에는 파일의 수도 많고 반복작업이면서 또한 쿠버네티스에 대한 높은 전문성을 필요로하기 때문에 어렵다.그래서 이러한 반복작업을 줄여주고, 템플릿화하여 실행하도록 해주는 엔진이 ksonnet 이라는 오픈소스를 사용한다. ksonnet은 jsonnet 템플릿 엔진 기반으로, 위에서 나열한 컴포넌트들을 쿠버네티스에 설치할 수 있도록 해주고, 각 단계별 컴포넌트를 손쉽게 실행할 수 있도록 해준다.이 솔루션들을 앞에서 설명한 머신러닝 플랫폼 아키텍쳐에 맵핑 시켜보면 다음과 같은 그림이 된다.Kubeflow는 현재 개발중인 버전으로 이글을 쓰는 현재 0.4 버전이 개발중이다. 컨셉적으로 매우 훌륭하고 0.4 버전인것에 비해서는 매우 완성도가 높지만 1.0 릴리즈 전이기 때문에 다소 변화가 심하기 때문에 버전간 호환이 안될 수 있다. 이점을 염두하고 사용하기 바란다.Kubeflow를 이해하기 위해서는 먼저 Kubeflow의 컴포넌트를 배포하고 실행하게 해주는 ksonnet에 대한 이해가 먼저 필요하다. 다음 글에서는 이 ksonnet에 대해서 알아보도록 하겠다. window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1301}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글자연어 처리 - 단어 표현 방법  (0)2019.08.04AutoEncoder vs Variant AutoEncoder  (0)2019.05.10AutoEncoder (오토 인코더) 기반 추천 엔진  (0)2018.01.06K Fold Cross Validation  (0)2018.01.02Apache Beam (Dataflow)를 이용하여, 이미지 파일을 tfrecord로 컨버팅 하기  (0)2018.01.01TagDeep learning, end2end, Istio, katlib, kubeflow, Machine Learning, production, seldonio, tensorflow, TFX, 노트북, 딥러닝, 머신러닝, 아키텍쳐, 운영환경, 조대협, 주피터, 쿠버네티스, 텐서플로우'빅데이타 & 머신러닝/머신러닝'의 다른글이전글AutoEncoder (오토 인코더) 기반 추천 엔진현재글쿠버네티스 기반의 End2End 머신러닝 플랫폼 Kubeflow #1 - 소개다음글AutoEncoder vs Variant AutoEncoder관련글자연어 처리 - 단어 표현 방법2019.08.04AutoEncoder vs Variant AutoEncoder2019.05.10AutoEncoder (오토 인코더) 기반 추천 엔진2018.01.06K Fold Cross Validation2018.01.02loadedComments[1301]=true;findFragmentAndHighlight(1301);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag머신러닝,딥러닝,tensorflow,강좌,cloud,node.js,조대협,구글,초보,Machine Learning,튜토리얼,빅데이타,Kubernetes,클라우드 컴퓨팅,google,쿠버네티스,클라우드,Tutorial,소개,텐서플로우,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1301"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1301"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1301"",""entryTitle"":""쿠버네티스 기반의 End2End 머신러닝 플랫폼 Kubeflow #1 - 소개"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":""cfile6.uf@994FF14C5C34C41711358A.png"",""plink"":""/1301"",""tags"":[""Deep learning"",""end2end"",""Istio"",""katlib"",""kubeflow"",""Machine Learning"",""production"",""seldonio"",""tensorflow"",""TFX"",""노트북"",""딥러닝"",""머신러닝"",""아키텍쳐"",""운영환경"",""조대협"",""주피터"",""쿠버네티스"",""텐서플로우""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
40,https://bcho.tistory.com/1139,"코스트 함수의 최소값을 찾는 알고리즘을 옵티마이져(Optimizer)라고 하는데, 상황에 따라 여러 종류의 옵티마이져를 사용할 수 있다. 여기서는 경사 하강법 (Gradient Descent) 라는 옵티마이져에 대해서 소개하도록 하겠다.경사 하강법","                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝수학포기자를 위한 딥러닝-#2 머신러닝 개념 이해Terry Cho2016. 10. 4. 15:29수포자를 위한 딥러닝#2 - 선형회귀분석을 통한 머신러닝의 기본 개념 이해조대협 (http://bcho.tistory.com)Linear Regression을 통한 머신 러닝의 개념 이해거리에 따른 택시 요금 문제머신러닝이란 무엇일까? 개념 이해를 돕기 위해서 선형 회귀 (Linear Regression)이라는 머신러닝 모델을 보자.먼저 선형 회귀 (Linear regression)이 무엇인지 부터 이해를 해야 하는데, 쉽게 설명하자면 결과값 (output value)이 있고 그 결과값을 결정할 것이라고 추정되는 입력값 (input value)과 결과 값의 연관관계를 찾는 것이고 이를 선형 관계를 통해 찾는 방법이 선형 회귀 (Linear regression)이다.  예를 들어서 설명해보자, 택시 요금을 예로 들어보자,택시 요금은 물론 막히냐 마냐에 따라 편차가 있지만, 대부분 거리에 비례해서 요금이 부과된다. 그래서 결과값 (요금)과 입력값 (거리)의 관계를 찾아야 한다.거리별 요금을 그래프로 나타내보면 대략 다음과 같은 분포를 띄게 된다원본 데이타의 거리를 x_data 그리고, 그 거리에서 측정된 택시 요금을 y_origin 이라고 하자. 가설 (Hypothesis) 정의거리와 요금이 서로 비례하기 때문에, 거리(x_data)와 요금(y_data)간의 상관 관계는 다음과 같이 일차 방정식과 형태의 그래프를 그리게 된다고 가정하자. W (Weight)는 그래프의 각도, b는 bias를 뜻한다y_data = Wx_data + b이 일차 방정식 형태로 대충 1차원 그래프를 그려보자 같은 형태로 아래와 같이 그래프를 그려봤다.그래프를 그려보니 그래프의 각이 안맞는것 같다. 그래프의 각도와 높이를 보정해보자그래프를 보정했지만 또 안 맞는 것 같다. 그렇다면 최적의 그래프의 각도 W와, 높이 B는 어떻게 찾아야 하는 것일까?코스트(비용) 함수우리가 구하고자 하는 그래프는 실제 값에서 그래프의 값까지 차이가 가장 작은 값을 구하고자 하는 것이다. 아래 그림을 보자, 아래와 같이 y_data=Wx_data +b와 같은 그래프를 그렸다고 하자.원래 값에서 우리가 예측한 값의 차이는 (원래값과 계산된 값의 차이) = 측정값 - 그래프의 값인데, 차이를 d라고 하자. 그리고 그래프에 의해서 계산된 값은 y_data라고 하면 택시 거리 x_data 에서 원래 측정된 값을 y_orgin라고 해서 수식으로 나타내면,  d = y_data - y_origin이 된다. 이때 측정값은 여러개가 있기 때문에 n이라고 하면  n번째 측정한 택시비와 산식에 의해서 예측된 값의 차이는 dn이 된다.dn = y_data_n - y_origin_n즉 우리가 구하고자 하는 값은 dn의 합이 최소가 되는 W와 b의 값을 구하고자 하는 것이다.다르게 설명하면 실제 측정한값과, 예측한 값의 차이가 최소가 되는 W와 b를 구하고자 하는 것이다.dn은 위의 그래프에서 처럼 그래프 위에도 있을 수 있지만 (이경우 dn은 양수), 그래프 아래에도 있을 수 있기 때문에, (이경우 dn은 음수). 합을 구하면, 예측 선에서의 실측값 까지의 거리의 합이 되지 않기 때문에, dn에 대한 절대값을 사용한다고 하자.그리고 n이 측정에 따라 여러개가 될 수 있기 때문에, 평균을 사용하자. ( ABS(d1)+ABS(d2)+ABS(d3)+.....+ABS(dn)) ) / n즉 우리가 구하고자 하는 W와 b는 위의 함수의 값이 최소가 되는 값을 구하면 된다.이렇게 측정된 값에서 연산된 값간의 차이를 연산하는 함수를 비용 함수 또는 영어로 코스트 함수 (Cost function이라고 한다.사람이 일일이 계산할 수 없이니 컴퓨터를 이용해서 W=0.1,0.2,0.3,.... b=0.1,0.2,0.3,..... 식으로 넣어보고 이 코스트 함수가 가장 최소화되는 W와 b의 값을 찾을 수 있다.옵티마이져 (Optimizer)코스트 함수의 최소값을 찾는 알고리즘을 옵티마이져(Optimizer)라고 하는데, 상황에 따라 여러 종류의 옵티마이져를 사용할 수 있다. 여기서는 경사 하강법 (Gradient Descent) 라는 옵티마이져에 대해서 소개하도록 하겠다.경사 하강법그러면 W와 b를 구할때 W와 b를 어떤식으로 증가 또는 감소 시켜서 코스트 함수의 최소값을 가장 효율적으로 찾아낼 수 있을까? 위에서 언급한것 처럼 W를 0.0에서 부터 ). 0.1씩 증가시켜나가고 b도 같이 0.0에서 부터 1씩 증가 시켜 나갈까? 무한한 컴퓨팅 자원을 이용하면 되기는 하겠지만, 이렇게 무식하게 계산하지는 않는다.코스트 함수를 최적화 시킬 수 있는 여러가지 방법이 있지만, Linear regression의 경우에는 경사 하강법 (그레이언트 디센트 : Gradient descent)라는 방식을 사용한다. 경사하강법에 대해서는 자세하게 알필요는 없고 ”대략 이런 개념을 사용하는 구나” 하는 정도만 알면 된다. 경사 하강법을 사용하기 위해서는 위의 코스트 함수를,측정값과 예측값의 절대값의 평균이 아니라 평균 제곱 오차라는 함수를 사용한다. 이 함수는 형식으로 정의되는데, 평균 제곱 오차 함수 (Mean square error function)이라고 한다. Cost =  Sum( (y_data_n - y_origin_n) ^ 2) / n풀어서 설명하면, n 번째의 원래데이타(y_origin_n)와 예측 데이타(y_data_n)의 차이를 제곱(^2)해서, 이 값을 n으로 나눈 평균 값이다. 즉 이 Cost가 최소가 되는 W와 b값을 구하면 된다. 편의상 W하나만을 가지고 설명해보자. 위의 그래프를 W와 b에 대한 상관 그래프로 그려보면 다음과 같은 함수 형태가 된다. 이 그래프에서 W에 대한 적정값에 대한 예측을 시작하는 점을 위의 그림에서 파란 점이라고 하면, 경사 하강법은 현재 W의 위치에 대해서, 경사가 아래로 되어 있는 부분으로 점을 움직이는 방법이다. 어느 방향으로 W를 움직이면 Cost 값이 작아지는지는 현재 W위치에서 비용 함수를 미분하면 된다. (고등학교 수학이 기억이 나지 않을 수 있겠지만 미분의 개념은 그래프에서 그 점에 대한 기울기를 구하는 것이다. )이렇게, 경사를 따라서 아래로 내려가다 보면 Cost 함수가 최소화가 되는 W 값을 찾을 수 있다. 이렇게 경사를 따라서 하강 (내려가면서) 최소값을 찾는다고 하여 경사 하강법이라고 한다.  학습 코스트 함수가 정의 되었으면  실제 데이타 x_data_n과 y_data_n을 넣어서 경사하강법에 의해서 코스트 함수가 최소가 되는 W와 b를 구한다. 이 작업은 W값을 변화시키면서 반복적으로 x_data_n로 계산을 하여, 실제 측정 데이타와 가설에 의해서 예측된 결과값에 대한 차이를 찾아내고 최적의 W와 b값을 찾아낸다.예측학습 과정에 의해서 최적의 W와 b를 찾았으면 이제, 이 값들을 이용해서 예측 해보자학습에 의해서 찾아낸 W가 1600, b가 2000이라고 하면, 앞의 가설에서 정의한 함수는 Wx*b였기 때문에, 예측 함수는 y = Wx +b거리에 따른 택시비 = W*(거리) + b거리에 따른 택시비 = 1600 * (거리) + 2000이 되고, 이를 학습된 모델 이라고 한다.이제 예측을 수행해보자, 거리가 10km일 때 택시비는 얼마일까? 공식에 따라택시비 = 1600 * 10km + 2000으로, 18000원이 된다.머신 러닝의 순서지금까지 택시 거리와 택시비에 대한 문제를 가지고 머신 러닝에 대한 기본 원리를 살펴보았다.이를 요약해서 머신 러닝이란 것이 어떤 개념을 가지고 있는지 다시 정리해보자.기본 개념은 데이타를 기반으로해서 어떤 가설 (공식)을 만들어 낸 다음, 그 가설에서 나온 값이 실제 측정값과의 차이(코스트 함수)가 최소한의 값을 가지도록 변수에 대한 값을 컴퓨터를 이용해서 찾은 후, 이 찾아진 값을 가지고 학습된 모델을 정의해서 예측을 수행 하는 것이다.  학습 단계즉 모델을 만들기 위해서, 실제 데이타를 수집하고, 이 수집된 데이타에서 어떤 특징(피쳐)를 가지고 예측을 할것인지 피쳐들을 정의한 다음에, 이 피쳐를 기반으로 예측을 한 가설을 정의하고, 이 가설을 기반으로 학습을 시킨다.예측 단계학습이 끝나면 모델 (함수)가 주어지고, 예측은 단순하게, 모델에 값을 넣으면, 학습된 모델에 의해서 결과값을 리턴해준다.지금까지 Linear regression 분석을 통한 머신러닝의 원리에 대해서 간략하게 알아보았다. 다음 다음장에서는 이 모델을 어떻게 프로그래밍 언어를 이용하여 학습을 시키고 운영을 하는지에 대해서 알아보도록 하겠다.Thanx to 이글은 딥러닝 전문가 김홍회 박사님(Ayden Kim - https://www.facebook.com/Ayden.Kim )이 검수해주셨습니다. 감사합니다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1139}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글수학포기자를 위한 딥러닝-#4 로지스틱 회귀를 이용한 분류 모델  (4)2016.10.10수학포기자를 위한 딥러닝-#3 텐서플로우로 선형회귀 학습을 구현해보자  (8)2016.10.05수학포기자를 위한 딥러닝-#1 머신러닝과 딥러닝 개요  (5)2016.10.04나이브 베이즈 분류 (Naive Bayesian classification) #1 - 소개  (8)2015.03.31머신러닝 개념 소개 및 kNN 알고리즘 소개  (3)2015.03.22Taglinear regression, Machine Learning, ML, tensorflow, 가설, 강좌, 머신 러닝 이해, 머신러닝, 비용 함수, 선형 회귀, 소개, 수학, 쉬운, 예측, 조대협, 코스트 함수, 텐서플로우, 튜토리얼, 포기자, 피쳐, 피쳐 엔지니어링, 학습'빅데이타 & 머신러닝/머신러닝'의 다른글이전글수학포기자를 위한 딥러닝-#1 머신러닝과 딥러닝 개요현재글수학포기자를 위한 딥러닝-#2 머신러닝 개념 이해다음글수학포기자를 위한 딥러닝-#3 텐서플로우로 선형회귀 학습을 구현해보자관련글수학포기자를 위한 딥러닝-#4 로지스틱 회귀를 이용한 분류 모델2016.10.10수학포기자를 위한 딥러닝-#3 텐서플로우로 선형회귀 학습을 구현해보자2016.10.05수학포기자를 위한 딥러닝-#1 머신러닝과 딥러닝 개요2016.10.04나이브 베이즈 분류 (Naive Bayesian classification) #1 - 소개2015.03.31loadedComments[1139]=true;findFragmentAndHighlight(1139);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag초보,Tutorial,클라우드 컴퓨팅,조대협,cloud,소개,빅데이타,튜토리얼,google,tensorflow,쿠버네티스,구글,Kubernetes,머신러닝,강좌,node.js,Machine Learning,딥러닝,텐서플로우,클라우드,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1139"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1139"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1139"",""entryTitle"":""수학포기자를 위한 딥러닝-#2 머신러닝 개념 이해"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":""cfile6.uf@2401C85057EF60452CA3C9.png"",""plink"":""/1139"",""tags"":[""linear regression"",""Machine Learning"",""ML"",""tensorflow"",""가설"",""강좌"",""머신 러닝 이해"",""머신러닝"",""비용 함수"",""선형 회귀"",""소개"",""수학"",""쉬운"",""예측"",""조대협"",""코스트 함수"",""텐서플로우"",""튜토리얼"",""포기자"",""피쳐"",""피쳐 엔지니어링"",""학습""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
41,https://mokeya.tistory.com/78,"그런데, 머신 러닝이란 정확히 뭔데요?","Programming/Knowledge[데이터 사이언티스트 독학 03] 기계학습(머신러닝)은 무엇인가, 어디서 배울 수 있나by 지표덕후2021. 8. 21..adsbygoogle.post-top-first {display:block;}.adsbygoogle.post-top-second {display:none}@media (min-width: 680px) {.adsbygoogle.post-top-first {display:inline-block;min-width:300px;max-width:300px;width:100%;height:250px;}.adsbygoogle.post-top-second {display:inline-block;margin-left:20px;min-width:300px;max-width:300px;width:100%;height:250px;}}@media (min-width: 768px) {.adsbygoogle.post-top-first {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}.adsbygoogle.post-top-second {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}}(adsbygoogle = window.adsbygoogle || []).push({});(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});싱가폴 출신의 데이터 사이언티스트, Travis Tang님의 아티클을 번역한 글입니다.데이터 사이언티스트 wannabe라면, 일독할 가치가 충분한 글입니다.Travis Tang님은 화학공학을 전공했지만 테크기업에서 데이터 분석가로 사회생활을 시작했습니다.몇 차례에 걸쳐 포스팅 될 그의 이 아티클은 화학공학도가데이터 사이언티스트로 일하기까지의 여정과 필요한 스킬셋(skill set)을 구체적으로 담고 있습니다.Tang은, 데이터 사이언티스트로 나아가는 데 필요한 정보는 홍수처럼 넘치는데오히려 그 때문에 최고의 자원을 선별해내는 것이 어렵다고 토로합니다.그렇기 때문에 먼저 아래의 질문에 답을 할 수 있어야 한다고 강변합니다.데이터 과학이란 무엇입니까?아, 이것은 인사 담당자와 기업의 면접관 모두를 당황하게 만드는 대답하기 어려운 질문입니다. 사실, 회사마다 데이터 과학을 다르게 정의하여 용어가 모호하고 다소 이해하기 어렵습니다. 프로그래밍이라고 하는 사람도 있고 수학이라고 말하는 사람도 있고 데이터를 이해하는 일이라고 말하는 사람도 있습니다. 모두 어느 정도 맞는 말입니다. 나(Travis Tang)에게 가장 동의하는 정의는 다음과 같습니다.데이터 사이언스data science는 수학, 컴퓨터 과학, 도메인 지식 분야에서 도출된 기술과 이론을 사용하는, 학제를 넘나드는(inter-disciplinary) 분야이다.아래 그림은 위의 정의를 잘 보여주는 이미지입니다.데이터 사이언스는 다양한 학문들의 교차로이 이미지에서 각 분야의 지식이 뭉쳐 데이터 과학을 형성한다는 것을 보여주기 위하여 분야 사이의 경계를 흐릿하게 묘사했습니다.자, 그럼 데이터 사이언스, 데이터 과학을 배우기 위해선 뭘 해야 할까요?일련의 게시물을 통해 저는 데이터 사이언티스트로 나아가는 과정에서 제가 배운 것들을 알려드리려 합니다. 이를 통해 저와 같은 입장에 있는 분들이 데이터 사이언스를 배워나가는 데에 도움이 되었으면 합니다. 이 아티클은 아래와 같은 내용으로 구성될 예정입니다.1부 — SQL, Python 및 R을 사용한 데이터 처리2부 — 수학, 확률 및 통계3부 — 컴퓨터 과학 기초4부 — 기계학습=머신러닝(본 게시물의 내용)5부 — 첫 번째 기계 학습 프로젝트 구축     (adsbygoogle = window.adsbygoogle || []).push({});머신러닝이나 데이터 사이어스를 배우고 싶지만 어디서부터 시작해야 할지 막막하신가요? 저 역시 그랬습니다. 그리고 저는 제 시간을 가장 잘 사용할 수 있는 과정을 찾기 위해 인터넷을 뒤지며 긴 밤을 보낸 것을 기억합니다. 고된 검색 끝에 전 머신러닝 학습을 배우는 데 탁월한 리소스를 찾았고 그것들은 제가 무사히 면접을 치르고 데이터 사이언스 분야에취업하는 데에 큰 도움이 되었습니다. 이 게시물에서는 제가 요긴하게 활용했떤 머신러닝 코스를 공유하여 저와 같은 주제로 밤새고 계실 분들께 큰 도움을 드리려 합니다.오늘날 머신러닝은 종종 전세계의 많은 문제에 대한 치트키로 선전되고 있습니다. 머신러닝의 도움으로 우리는 스마트해진 검색엔진, 자율주행 자동차, 실시간 음성인식의 이점을 누리고, 인간 게놈의 신비를 엄청나게 풀기까지 했습니다. 우리 일상생활에 머신러닝이 편재해있다는 사실은 머신러닝이 인간의 삶을 대규모로 개선할 수 있으리라는 가능성을 시사합니다. 머신러닝의 매력이 여기에 있습니다.배우는 데 관심이 없는 외부인에게는 머신러닝이 막연한 유행어에 불과합니다. 기계학습을 시작하고자 하는 새내기들에게 기계학습은 진입장벽이 높은 난해한 개념처럼 보일 수 있습니다. 그러나 기계학습이 신비하거나 이해하기 어려울 필요는 없습니다. 만약 기계학습에 대한 지식을 쌓고자 하는 진정한 열망과 약간의 인내심만 있다면 당신은 기계학습을 시작할 완벽한 위치에 있습니다.그런데, 머신 러닝이란 정확히 뭔데요?저는 머신러닝을 기계가 스스로 학습하도록 가르치는 과학이라고 생각하고 싶습니다. 더 엄격하게 말하면 기계학습의 아버지인 Arthur Samuel은 1959년에 이를 다음과 같이 우아하게 정의했습니다.명시적으로 프로그래밍하지 않고도 컴퓨터에 학습 능력을 부여하는 연구 분야 [1]이것은 우리가 기존 프로그래밍을 정의한 것과는 완전히 다릅니다. 전통적인 프로그래밍에서 우리는 컴퓨터에 짜여진 규칙(program)와 입력(input)을 제공합니다. 차례로 우리는 출력(output)을 기대합니다. 예를 들어 계산기 프로그램에 1+1 입력을 제공하면 출력이 무엇인지 모두 알 수 있습니다.기계학습은 컴퓨터에 일부 입력(input) 및 출력(output)을 제공합니다. 시간이 지남에 따라 기계는 입력과 출력 간의 관계를 더 잘 학습합니다. 새로운 입력을 제공하면 예측된 출력을 알려줄 수 있습니다. 예를 들어 Elon은 중고 Tesla를 구매할 계획입니다. 그는 Craigslist에서 Tesla 차량 가격에 대해 조사한 결과 거의 새 Tesla 차량이 약 40,000달러부터 시작한다는 것을 발견했습니다. 그는 또한 자동차가 1년이 될 때마다 Tesla 가격이 약 $1,000씩 떨어진다는 사실도 알고 있습니다. 그런 다음 그는 5년 된 자동차가 35,000달러라고 예측합니다.     (adsbygoogle = window.adsbygoogle || []).push({});다시 말해, Elon은 기계학습에서 중요한 개념인 회귀(regression)를 방금 발명했습니다! 기계학습에서 프로그램은 입력과 출력 사이의 패턴을 인식하고 출력을 예측합니다.인공지능(AI, Artificial Intelligence)과 딥 러닝(Deep Learning)은 또 뭔데요?머신러닝과 밀접한 관련이 있는 유행어들입니다. 서로의 관계는 정확히 무엇일까요? 이것은 아래 다이어그램에 잘 드러나 있습니다.이 벤다이어그램에서 볼 수 있듯이 딥 러닝은 뇌가 뉴런에서 뉴런으로 정보를 전송하는 방식을 알고리즘으로 모방한 기계학습의 하위 집합입니다. 딥 러닝이 기계학습의 보다 고도화된 형태으로 간주될 때도 있습니다. 그러므로 사실 학습자는 딥 러닝에 뛰어들려 해도 결국 머신러닝의 기초를 이해해야만 합니다.반면, 머신러닝은 인공지능(AI)의 하위 집합입니다. AI는 추론, 계획 및 학습과 같은 인지 지능을 기계가 모방하는 것이라고 생각하면 됩니다. 물론 추론, 계획, 학습에만 국한되지는 않고, 보다 다양한 형태일 수 있습니다. [2]     (adsbygoogle = window.adsbygoogle || []).push({});이게 전부 데이터 사이언스랑 어떤 관련이 있습니까?데이터 사이언스는 수학, 컴퓨터 과학, 도메인 지식 분야에서 도출된 기술과 이론을 사용하는, 학제를 넘나드는 분야입니다. [3] 데이터 과학이 무엇인지 설명하기 위해 저는 아래의 벤다이어그램을 사용하고 싶습니다.보시다시피 데이터 과학은 수학, 컴퓨터 과학 및 도메인 전문 지식과 같은 다양한 영역의 지식이 결합된 것입니다. 기계학습은 '수학'과 '컴퓨터 사이언스'를 만나는 지점에 있습니다. 대규모 데이터세트에 적용된 우아한 수학 방정식과 (컴퓨터의) 연산능력이 합류하는 지점인 것입니다. 따라서 머신러닝은 데이터 사이언스의 도드라진 구성 요소입니다.다 알겠는데요, 어디서 배울 수 있나요?우리가 학습할 수 있는 머신러닝 코스는 무수히 많습니다. 이것은 머신러닝 입문에서 대학원 수준 수업, 실제 수업에서 온라인 수업에 이르기까지 전방위적으로 제공되고 있습니다. 데이터 과학 분야의 초보자들에게 인기 있는 몇 가지 기계학습 입문 수업은 다음과 같습니다.Udacity의 기계 학습 수업 소개Python을 사용한 Datacamp의 / Dataquest 기계 학습 기초EdX 기반 Columbia University의 기계 학습Udemy의 기계 학습 A-ZHarvard University의 무료 기계 학습 과정...개인적으로 목록에 있는 이러한 기계학습 코스 중 일부를 시도해봤지만,일부 수업은 깊이와 엄격함 측면에서 다소 부실했습니다.데이터 과학자로서의 커리어 패스에 도움이 될 만한 엄격한 머신러닝 수업을 찾고 계시다면 이 포스팅이 분명 도움이 될 것 같습니다. 오늘 저는 개인적으로 가장 좋아하는 머신러닝 입문 강의를 공유하려 합니다. 바로 Coursera의 Andrew Ng(스탠포드 대학교)의 머신 러닝입니다. 필요한 선행 지식, 수업에서 뭘 얻을 수 있는지, 이 수업을 온전히 누릴 수 있는 방법에 대해 조언을 할까 합니다.Coursera의 Andrew Ng의 머신 러닝이 기계학습 과정은 초보자를 위한 최고의 기계학습 코스로 지속적으로 선전되어 왔습니다. 370만 명의 등록자가 내린150,000개 평가점수가 4.9점이라는 점도 이 코스가 얼마나 믿을 만한지 암시합니다.무료로 수업에 참석할 수 있습니다(audit version). 학습자는 언제든지 무료로 등록할 수 있습니다. 단, 무료로 등록한 경우에는 수료증을 발급받을 수 없습니다. 대부분의 프로그래밍 연습과 퀴즈에 대한 피드백을 받을 수도 없습니다.Coursera에서 7일 무료 평가판을 제공하고 있으며, 7일이 가기 전에 언제든지 과정을 반환할 수 있습니다.인증서 비용은 $49입니다. 제 사견을 말씀드리면, 저는 이 수료증이 내가 수업을 완주하고자 하는 의지가 있음을 증명하는 훌륭한 방법이라 생각합니다. 도움이 필요한 학습자를 위한 재정적인 지원도 하고 있으므로 부담 가지지 마시고 Coursera에 문의해보십시오.이 코스의 강사인 Andrew Ng는 소개가 거의 필요 없는 인물입니다. 그는 스탠포드 대학교 겸임교수이자 코세라(Coursera)와 구글 브레인(Google Brain)의 공동 설립자이자 바이두(Baidu)의 전 부사장으로, 머신러닝 분야에서 두말할 것 없이 가장 영향력 있는 인물입니다.     (adsbygoogle = window.adsbygoogle || []).push({});이 수업에서 특히 좋았던 점1년 전 쯤에, 데이터 사이언스로 나아가고 싶지만 어디서부터 시작해야 할지 몰랐던 저는 '데이터 사이언스 배우는 방법'을 미친듯이 검색했습니다. 저는 엄청난 양의 배워야 할 것(수학, 확률, 통계, 기계학습 등)들과 그만큼 엄청난 양의 자원들에 빠르게 압도당했고, 가장 인기 있는 것처럼 보이는 수업을 듣게 되었습니다. 바로 Andrew Ng’s Machine Learning입니다.지금의 저는 이 수업을 수강하게 된 것을 정말 기쁘게 생각합니다.이 기계학습 과정을 마치고 데이터 사이언스 인턴십을 통해 행운을 시험해보려 했던 때가 생생하게 기억납니다. 정말 두려웠지만 수업을 들은 사실이 저를 조금 진정시켰습니다. 그 첫 번째 데이터 사이언스 직무 면접에서 제가 느낀 건, 대부분의 기계학습 실무자가 그 코스에 대해 알고 있거나, 익숙하다는 점입니다. 인터뷰 당시 제가 그 코스를 이수했다고 말했을 때 면접관이 수긍의 의미로 고개를 끄덕였는데 그게 기분 좋은 기억으로 남아있습니다.내가 수업을 완료했다는 사실은 채용 관리자가 '수업에서 무엇을 배웠는가?', '수업에서 가장 어려웠던 부분?', '우리 회사의 상황에는 어떻게 적용할 수 있나?'와 같은 후속 질문을 할 수 있는 발판을 제공했습니다. 돌이켜 보면, 수업을 이수했다는 사실 자체가 학습동기의 표시이자 기계학습에 대한 기본 지식을 보유하고 있다는 신호로 인식되었을 수 있습니다. 두 가지 모두 고용 관리자가 데이터 사이언티스트를 고용하고자 할 때 보는 필수 자질입니다.사실대로 이야기하자면, 이 코스만 있던 제 이력서로는 데이터 사이언트 인턴십에 채용될 수 없었습니다. 그러나 그 분야의 전문가들의 언어로 대화를 나눌 수 있다는 사실은 제게 큰 자신감을 주었습니다. 이를 통해 데이터 사이언스 전문가들과 네트워크를 구축하고 그들로부터 배울 수 있었습니다.     (adsbygoogle = window.adsbygoogle || []).push({});어떤 사람이 들으면 좋을까?이 수업은 데이터 분석, 데이터 과학, 기계학습 또는 AI 분야에서 테크니컬한 역할을 추구하려는 진지한 학생을 대상으로 합니다. 또한 기계학습에 대한 배경 지식이 없는 초보자나 기계학습 개념을 복습하려는 사람들도 대상이 될 수 있습니다. 명시적으로 언급되지는 않았지만 이 수업은 수학적 엄격함을 요구합니다. 때문에 기계학습에 대한 깊은 이해를 원하는 학습자에게는 강한 배움의 자극이 되겠지만, 기계학습의 톱니바퀴에 관심이 거의 없는 학습자는 아마 떨어져나가게 될 겁니다.쏟아야 할 시간은 만만치 않습니다. 수업을 이수하는 데에 약 60시간이 걸립니다. 매일 2시간을 투자할 수 있다고 가정하면 이 과정은 한 달이 걸립니다. 수학이나 프로그래밍 숙련도에 따라 이 소요시간이 다를 수는 있습니다.이런 사람은 안 듣는 게 낫습니다.그러니, 앞서 언급한 바를 염두에 둔다면 이 수업은 기계학습과 기계학습이 문제를 해결하는 방법에 대한 일반적인 질적 이해를 원하는 비기술적(non-technical) 학습자가 듣기엔 적절하지 않습니다. 만약 당신이 이런 사람이라면, Andrew Ng이 진행하는 AI for everyone을 수강하시는 게 더 나을 수 있습니다. 이 강의는 AI 전반과 전문 용어를 이해하고자 하는 비기술 전문가를 대상으로 합니다. 게다가 이 수업은 훨씬 더 짧아서 약 6시간만 투자하면 됩니다. 수학과 프로그래밍에 대한 개념이 없다면 이 과정 역시 쉽지는 않을 겁니다. 동기와 관심을 지속하는 것이 어렵다는 것을 이 강의를 통해 알게 될 수도 있습니다.수학은 암만 해도 어렵습니다. 수학 없이 기계학습을 할 수는 없나요?글쎄요, 수학을 이해하지 않고 기계학습을 수행할 때 치명적인 단점이 있습니다. 첫 번째, 기계학습을 맹목적으로 구현하는 기술(skill sets)을 당신이 가지고 있다면 당신은 Google Cloud에서 제공하는 것과 같은 자동화된 기계학습 AutoML에 의해 쉽게 대체할 수 있습니다. 두 번째, 데이터 과학자의 가치는 런타임 및 저장 복잡성과 데이터세트에 대한 적합성까지 고려하여 최상의 성능을 발휘하는 적절한 알고리즘을 신중하게 선택하는 데 있습니다.당신이 자동차의 소유자라고 상상해보십시오. 물론 차가 달릴 때 부드럽게 운전할 수 있습니다. 그러나 자동차를 만들어야 하거나 자동차 결함을 해결해야 하는 경우에는, 자동차를 달리게 하는 톱니바퀴와 바퀴에 대한 이해가 필요합니다. 자동차의 내부 작동을 이해하지 못한다면 이들 중 어느 것도 불가능합니다. 이 자동차는 데이터 사이언스의 알고리즘입니다. 내부에서 어떻게 작동하는지 모른다면 기계학습 알고리즘을 구축할 수 없습니다.데이터 사이언티스트, 분석가 및 엔지니어로서 우리의 역할은 기계학습 모델을 사용하는 것뿐만 아니라 이를 구축, 유지 관리 및 배포하는 것입니다. 그러려면 수학을 알아야 합니다.알겠습니다. 배우고 싶은데, 수학이나 코딩에 대한 배경지식이 없습니다...걱정 마세요! Coursera에는 수업에 대한 전제 조건이 없습니다. 아래에 제가 언급할 강의를 듣지 않고도 코스를 시작할 수 있습니다. 그러나 코스를 성공적으로 마치고자 한다면 몇 가지는 선행학습 하시는 게 좋습니다.권장하는 코딩 지식Datacamp 및 Dataquest의 python 및 R 과정에 참석한 저는 MATLAB 및 python에 대한 기본적인 이해를 바탕으로 이 과정을 시작했습니다. 이 과정은 초반부터 MATLAB에 대한 간략하고 쉬운 소개를 제공하므로, 코딩 경험이 없어도 걱정 안 해도 됩니다. 이는 학습자가 필요한 코딩 능력을 빠르게 익히는 데 도움이 됩니다.만약 다른 프로그래밍 언어에는 익숙하지만 MATLAB에는 익숙하지 않은 경우에는 해당 언어에 대해 너무 신경쓰지 말고 바로 과정을 시작하는 것이 좋습니다. 그러나 여전히 MATLAB을 배우는 데 시간을 할애하고 싶다면 다음과 같은 훌륭한 자원들이 있습니다.MIT Open Courseware (무료)University of Vanderbilt on Coursera (유료) 권장하는 수학 코딩 지식     (adsbygoogle = window.adsbygoogle || []).push({});제가 추천한 코세라 강의는 고등학교 수준의 미적분 및 선형 대수학에 대한 약간의 지식을 전제합니다. 수학에 능숙할수록 코스를 쉽게 통과할 수 있으며 그 반대의 경우도 마찬가지입니다.Andrew Ng의 수업은 선형 대수학에서 약간의 복습을 제공하므로 선형 대수학 지식이 가물가물하더라도 걱정할 필요 없습니다. 하지만 수업을 시작하기 전에 다음 질문을 스스로에게 하는 것이 좋습니다.차별화 규칙을 자신 있게 알고 있습니까? 그렇지 않다면 Khan Academy의 미적분 수업을 찾아보세요.행렬이 무엇이며 행렬에 대한 연산(전치, 산술, 내적)을 수행하는 방법을 알고 있습니까? 그렇지 않다면 Khan Academy’s Linear Algebra playlist를 찾아보세요.다음 그림은 수업에서 마주한 몇 가지 수학 문제입니다. 이런 표기법이 편안하세요? 그렇지 않다면 위의 링크로 들어가서 얼른 지식을 환기해두시는 게 좋습니다.  뭘 배워갈까?기계학습을 배우려면 일반적으로 알아야 할 사항기계학습으로 해결할 수 있는 다양한 유형의 문제.다양한 문제를 해결하기 위한 다양한 유형의 알고리즘.서로 다른 데이터세트에 대한 각 알고리즘의 강점과 약점.각 알고리즘을 뒷받침하는 수학 및 가정.기계학습의 절충trade-off(편향-분산 절충)기계학습의 모범 사례.기계학습 알고리즘의 적용.이러한 개념을 다루기 위해 Andrew Ng의 수업은 알고리즘별로 구성된 장으로 나뉩니다. 각 클래스는 논리적으로 진행됩니다. 먼저 알고리즘에 대한 간략한 소개와 실제 적용 사례를 제공하여 독자를 준비시킵니다. 그런 다음 설득력 있는 다이어그램 설명을 통해 알고리즘에 대한 독자의 직관을 구축합니다. 이러한 직관은 알고리즘의 수학을 이해하는 마찰을 줄여줍니다.강의 후에는 퀴즈를 통해 이해도를 테스트할 수 있습니다. 학습내용을 내재화하기 위해 첫 번째 원칙을 사용하여 Matlab에서 알고리즘을 처음부터 구현할 수도 있습니다. 이 수업에서 배우게 될 내용이 과정은 기계학습 분야의 핵심에 대한 폭넓은 조감도를 제공합니다. 다음은 수업에서 다루는 개념의 마인드맵입니다.함께 보면 좋을 책Andrew Ng의 코스에는 공식 교과서가 없지만 확신이 서지 않을 때 교과서를 참조하는 게 도움이 됩니다. 이를 위해 저는 무료로 온라인 제공되는 교재인 Introduction to Statistical Learning(온라인 Free)을 추천합니다. 이 책은 머신러닝 알고리즘에 대한 수학적 직관력을 높일 수 있도록 명쾌한 설명과 삽화를 제공합니다. 한 가지 주의할 점은 R을 기본 언어로 사용한다는 것입니다.     (adsbygoogle = window.adsbygoogle || []).push({});발전을 위한 팁과 요령질문같은 자리에 오래 머무르는 것은 정말 쉽습니다. Coursera는 당신과 같은 학습자가 질문할 수 있는 포럼을 제공합니다. 도움을 줄 사람이 필요하면 언제든지 저에게도 개인적으로 연락하십시오. 제가 할 수 있는 한 최대한 도와 드리겠습니다.천천히 흡수이 코스에서 다루는 개념은 결코 간단하지 않습니다. 수업을 소화하며 진행하는 것은 지극히 바람직한 일이므로 천천히 수강하십시오.약간의 휴식을 취하십시오.특정 코드 블록을 끈덕지게 시도했지만 원하는 출력을 제공하지 않으면 한 걸음 물러나서 휴식을 취해야 할 때일 수 있습니다.도중에 메모를 합니다.종이에 메모하고 코딩하는 것이 다이어그램을 그려 개념을 시각화하는 것만큼 유용하다는 것을 알았습니다. 또한 내 생각을 공식화하는 데 도움이 되기 때문에 내 컴퓨터에 코드를 구현하기 전에 종이에 코드를 적어두는 것이 도움이 됩니다.확신이 든다면 오늘 시도해 보시기 바랍니다.이 코스 후에는,축하합니다! 이제 코스를 하나 수료하고 당신은 지식에 굶주린 사람이니 기계학습이 무엇이고, 수학적 기초가 무엇인지에 대한 더 많은 지식을 얻을 준비가 된 것입니다. 다음은 당신에게 드리는 몇 가지 제안입니다.Other data science skills(SQL, python 및 R)에 대한 복습새로 발견한 기술을 시험해볼 흥미로운 프로젝트통계 및 확률 수업Coursera의 deep learning 수업이 코스의 고급 버전인, CS229 Machine Learning 수강(이를 위해서는 선형 대수학, 통계 및 확률에 대한 고급(학부/대학원) 이해가 필요)머신러닝을 전혀 몰랐던 학습자로서 이 강의를 듣고 나니 엄청난 희망이 생겼습니다. 다른 기계학습 및 데이터 사이언스의 개념을 배울 수 있는 훌륭한 토대를 제공해 주었습니다. 꾸준히 하시면 단시간에 코스를 마치고 저와 같은 성취감을 받으실 수 있으실 거라 확신합니다.참고문헌[1] Mitchell, Tom (1997). Machine Learning. New York: McGraw Hill. ISBN 0–07–042807–7. OCLC 36417892.[2] Russell, Stuart J.; Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, New Jersey: Prentice Hall. ISBN 978–0–13–604259–4.[3] Dhar, V. (2013). “Data science and prediction”. Communications of the ACM. 56 (12): 64–73. doi:10.1145/2500499. S2CID 6107147. Archived from the original on 9 November 2014. Retrieved 2 September 2015.반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//mokeya.tistory.com/reaction';window.ReactionReqBody = {    entryId: 78}공유하기게시글 관리지표덕후,  지덕智德저작자표시 비영리 변경금지 'Programming > Knowledge' 카테고리의 다른 글[웹개발] 파이썬 웹 프레임워크(Web Frameworks)에 대한 간단 지식과 추천 프레임워크  (0)2022.01.15[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계  (0)2021.09.10[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라  (0)2021.08.26[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기  (0)2021.08.19[데이터 사이언티스트 독학 01] Data Science의 정의, 데이터 처리(Data Processing)를 배우는 방법  (0)2021.08.18     (adsbygoogle = window.adsbygoogle || []).push({});태그Coursera, Introduction to Statistical Learning, 기계학습강의, 데이터사이언스, 데이터사이언티스트, 독학, 머신러닝강의, 머신러닝교재, 앤드류응, 코세라관련글[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기[데이터 사이언티스트 독학 01] Data Science의 정의, 데이터 처리(Data Processing)를 배우는 방법댓글0비밀글댓글등록loadedComments[78]=true;findFragmentAndHighlight(78);"
42,https://hyunie-y.tistory.com/23,ABOUT ME,"홈 분류 전체보기 (107)  Data Engineering (21)  SQL (3)  Books (5)  AWS, Spark (11)  분류하기 애매한 것들 (1)  Project (20)  D.D.P (Datahub) (4)  Collecting Event Data (4)  CICD (9)  Toxic speech detection (2)  CS기초 (25)  Algorithm, Data Structures (6)  Coding Test (6)  Network (2)  OS,HW (11)  Deep Learning (5)  Statistics (3)  Tips (25)  궁금점의 기록 (7)  정리 중인 글 (0) ABOUT ME-트위터인스타그램Today-Yesterday-Total-머신러닝을 배웠던 데이터 엔지니어머신러닝을 배웠던 데이터 엔지니어메뉴검색컨텐츠 검색IP주소와 포트포워딩이란, 포트포워딩 설정하기(iptime)CS기초/Network2021. 10. 26. 23:26     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90반응형(adsbygoogle = window.adsbygoogle || []).push({}); 로컬 젠킨스와 Github webhook 연결을 하려다보니 IP주소가 필요했다. IP주소란 컴퓨터 네트워크에서 장치들이 서로를 인식하고 통신을 하기 위해서 사용하는 특수한 번호(ref. Wiki)라고 되어있는데 쉽게 말하면 통신을 위한 장치의 주소같은 개념이다.우리가 편지를 보내기 위해서는 수신자의 주소를 적어야하는 것 처럼 Webhook이 내 컴퓨터의 젠킨스로 정보를 보내기 위해서는 내 컴퓨터가 어디에 있는지 알아야하니 컴퓨터의 ip주소가 필요한 것이다. 인터넷에서 특정 사이트로 접속할 때 - 이 동작도 접속해달라는 post요청을 보내게 되는데 - http://www.google.com 과 같은 주소를 입력하는데 이것도 사실 이 주소기 DNS 서버라는 것을 통해 IP주소로 바뀌어서 전달된다. 즉, http://www.google.com을 주소창에 입력하는 것과 해당 서버의 외부IP주소인 216.58.200.68을 주소창에 입력하는 것과 같다.  맥에서 내 컴퓨터의 ip주소를 확인하려면 환경설정>네트워크에 들어가거나 터미널에 `ipconfig getifaddr en0`를 치면 되는데 문제는 공유기로 wifi에 접속하여 인터넷을 사용할 때다. 이럴 경우 보여지는 ip주소는 공유기에서 할당한 주소이며, 외부에서 접근이 불가하다.  공유기에서 할당한 192.168.0.21 이라는 주소는 공유기 내의 주소이기 때문에 같은 공유기 망 내에서만 접속이 가능합니다.하지만 LTE 망을 사용 중인 핸드폰이나 회사, 학교 컴퓨터에서는 192.168.0.21 이라는 주소를 쳐봤자 엉뚱한 곳으로 가게 됩니다.비유하자면 '192.168.0.21' 이라는 것은 '3동 406호'라고만 써있는 주소와도 같습니다.​같은 아파트에 살고 있다면 3동 406호라는 주소만으로도 친구 집에 갈 수 있지만, 외부인 입장에게 주소를 알려줄 때는 AA시, BB구 등의 광역 주소를 알려줘야지 3동 406호라는 주소만으로는 주소 기능을 할 수 없을 것입니다.출처: https://solbel.tistory.com/396 위의 예시에서 얘기하는 광역주소가 공유기의 IP주소이고 외부에서는 여기까지 알 수 있다. 각 인터넷 회선마다 고유한 값을 가지며 이 주소에 접속한 후 공유기 내에서 분배되는 주소까지 알면 외부에서도 내 컴퓨터로 접속을 할 수 있게 되는 것이다. 2022. 11 추가 - 여기에서 제가 사용한 ""공유기의 IP주소""라는 단어에 혼돈의 여지가 있는 것 같습니다. 아래 댓글에서 지적한 대로, 여기에서 사용한 ""공유기의 IP주소""라는 표현은 ISP를 통해 부여받은 공인 IP주소를 의미하며, 네트워크의 기초지식이 없는 분들을 위해 아주 쉬운 표현을 사용하고자 하는 과정에서 잘못 받아들여질 수 있는 표현이 사용된 것 같습니다.  포트라는 개념은 기기 내에 할당된 방 같은 느낌인데, 각 방마다 고유의 번호를 가진다 (Jenkins 8080, Postgres 5432...). 내 컴퓨터에서 Flask로 접속하고자 할 때는 ""로컬 호스트의 Flask의 포트로 들어가""라고 해야하는데, 이 요청을 `http://127.0.0.1:5000`이라는 url로 수행하는 것이다. 여기에서 127.0.0.1이 localhost 주소이고 5000이 Flask의 방 번호, 즉 포트 번호이다. 포트포워딩이란 포트포워딩(Port Forwarding)은 공유기의 포트를 통해 이 공유기와 연결된 기기들의 특정 포트에 진입할 수 있게 하는 기능이다. 만약 공유기에 컴퓨터와 핸드폰이 연결되어 있는데 그냥 공유기 주소 + 포트번호로 입력한다면 공유기의 '어느 기기'의 포트로 들어가야하는 지 알 수 없다. 따라서 포트 포워딩은 공유기에 연결된 기기의 포트를 특정 번호를 통해 전달(forwarding)해 주는 것이라고 이해할 수 있다. 또는 공유기에 기기+해당 기기의 포트에 해당하는 포트 번호를 할당 해 주는 것이라고 해도 될 듯하다. 예를 들어 공유기의 180포트로 접속하면 핸드폰의 5000 포트에 접속하게하고, 280포트로 접속하면 컴퓨터의 5000포트에 접속하게 하는 것이다. 여기서 180, 280등을 지정하는 작업이 포트포워딩이다. 포트포워딩 설정하기 포트포워딩 설정은 공유기에서 한다. 여기부터 iptime을 기준으로 글을 작성한다.http://192.168.0.1 을 통해 공유기 설정페이지에 접속 (공유기 제조사 별로 다른 경우도 있다고 하니 검색)로그인 (초기 id/ 비밀번호는 admin/admin이고, 기존에 설정해놓은 id/비밀번호를 잊어버렸다면 공유기의 reset 버튼을 10초 정도 눌러 초기화한다)Setting(관리도구)왼쪽 메뉴에서 Advanced Setup(고급 설정)> NAT/Routing(NAT/라우터 관리) > Port Forwarding(포트포워드 설정) > Add new rule(새규칙 추가) 클릭하기 사진의 사각형 부분을 채운다Rule Name(규칙 이름): 기억하기 쉬운 이름으로 설정 (문자나 숫자나 아무거나) Internal IP(내부 IP주소): 공유기에서 할당한 내 컴퓨터의 IP주소로 위에서 작성한 방법으로 확인할 수 있다.External port(외부 포트): 외부에서 접속할 때 사용할 포트로 사용자가 외우기 쉬우면서 기존 포트 번호와 겹치지 않는 번호로 설정할 수 있다.Internal port(내부 포트): 내 컴퓨터에서 어플리케이션에 접속할 때 사용하는 포트 번호이다 (e.g. Jenkins면 8080)다 작성한 후 Apply(적용 또는 수정) 버튼을 눌러주면 된다.   해당 설정을 완료했다면 이제 내가 할당한 포트번호와 공인 IP주소를 통해 외부에서 내 컴퓨터의 어플리케이션에 접근이 가능하게 된다. 공인IP주소는 Naver등에서 'ip 주소'같은 키워드로 확인할 수 있으며, 최종 접근 경로는 {공인IP주소}:{위에서 설정한 외부 포트번호}가 된다.  예를 들어 Naver에서 확인한 공인IP주소가 211.156.32.67이고 내가 설정한 외부 포트번호가 8000이면 외부에서는 http://211.156.32.67:8000이라는 주소로 접근이 가능하게 된다. 참고 블로그: https://solbel.tistory.com/396728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//hyunie-y.tistory.com/reaction';window.ReactionReqBody = {    entryId: 23}공유하기게시글 관리머신러닝을 배웠던 데이터 엔지니어저작자표시 'CS기초 > Network' 카테고리의 다른 글네트워크: 초보도 이해하길 바라는 CIDR블록이란?  (0)2022.12.04TAGiptime포트포워딩, IP주소, 맥ip주소확인, 포트포워딩, 포트포워딩설정관련글 관련글 더보기네트워크: 초보도 이해하길 바라는 CIDR블록이란?댓글 4댓글                                                    접기댓글 펼치기이전 댓글 더보기    setInitialEntryComments(23, 1723620349)                                                            비밀글등록loadedComments[23]=true;findFragmentAndHighlight(23);인기포스트IP주소와 포트포워딩이란, 포트포워딩 설정하기(ipti⋯시간 단위 정리 - ns, ms, us, ps, fs운영체제 5: 컨텍스트 스위칭 (Context Swit⋯문자열 합치기 - CONCAT과 ||ABOUT MELINKADMINadmin글쓰기105,84387185티스토리툴바머신러닝을 배웠던 데이터 엔지니어구독하기                    (function () {                         var blogTitle = '머신러닝을 배웠던 데이터 엔지니어';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4763539-23"",""customProps"":{""userId"":""0"",""blogId"":""4763539"",""entryId"":""23"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""23"",""entryTitle"":""IP주소와 포트포워딩이란, 포트포워딩 설정하기(iptime)"",""entryType"":""POST"",""categoryName"":""CS기초/Network"",""categoryId"":""1024457"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4926031"",""authorNickname"":""Hyunie"",""blogNmae"":""머신러닝을 배웠던 데이터 엔지니어"",""image"":""kage@NxyJc/btriSLekh2C/wK9YEY81TTtl29miUjrDfk"",""plink"":""/23"",""tags"":[""iptime포트포워딩"",""IP주소"",""맥ip주소확인"",""포트포워딩"",""포트포워딩설정""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
43,https://jpub.tistory.com/835,태그,"도서 소개패턴 인식과 머신 러닝 제이펍2018. 9. 11. 11:46 2019 대한민국학술원 우수학술도서 선정!현대 패턴 인식과 머신 러닝의 개념과 효과적 이해를 위한 수학적 사고!컴퓨터 비전과 머신 러닝 분야의 고전이자 필독서인 비숍책, 이젠 한국어판으로 공부하세요! 출판사 제이펍원출판사 Springer원서명 Pattern Recognition and Machine Learning(원서 ISBN: 9780387310732)저자명 크리스토퍼 비숍역자명 김형진출판일 2018년 9월 10일페이지 852쪽시리즈 I♥A.I. 11(아이러브A.I. 11)판 형 46배판변형(188*245*37)제 본 무선(soft cover)정 가 46,000원ISBN 979-11-88621-25-5 (93000)키워드 인공지능 / 패턴 인식 / 머신 러닝 / 알고리즘 / 베이지안 / 뉴럴 네트워크 / 컴퓨터 비전 / 신호 처리 / 데이터 마이닝분야 인공지능 / 머신 러닝 / 패턴 인식 관련 사이트■ 저자(Bishop) 페이지■ 저작권사 도서소개 페이지■ 아마존 도서소개 페이지 관련 포스트■ 2018/08/29 - [출간전 책소식] - 한글로 만나는 비숍 책! 관련 시리즈■ I♥A.I 시리즈 관련 도서■ (관련 시리즈 참고하세요) 관련 파일 다운로드■ 1, 2, 3, 8장에 대한 영문 강의교안(pdf, ppt), 원서 샘플 챕터(chapter 8, PDF), www 표시 연습문제 해답(PDF), 본문의 그림(jpeg, png, pdf, eps 포맷), 원서 에라타(참고로, 이 자료들은 저자 웹 사이트에서 다운받은 것들입니다. ) 강의보조 자료교재로 채택하신 분들은 아래의 저작권사 링크에서 해답집을 신청해 주세요. 이와 관련해 궁금하신 분들은 다음 메일로 연락주시기 바랍니다. jeipubmarketer@gmail.com■ 연습문제 전체에 대한 해답 신청 폼 샘플 PDF(차례, 옮긴이 머리말, 서문, 베타리더 후기, 1장 '소개' 일부, 3장 '선형 회귀 모델' 일부, 8장 '그래프 모델' 일부, 13장 '순차 데이터' 일부) 패턴인식과머신러닝_sample.pdf다운로드 정오표 페이지■ http://jpub.tistory.com/837 도서구매 사이트(가나다순)[강컴] [교보문고] [도서11번가] [반디앤루니스] [알라딘] [예스이십사] [인터파크] 도서 소개현대 패턴 인식과 머신 러닝의 개념과 효과적 이해를 위한 수학적 사고!컴퓨터 비전과 머신 러닝 분야의 고적인자 필독서인 비숍책, 이젠 한국어판으로 공부하세요! 지난 수년간 머신 러닝은 그 어느 때보다도 뜨거운 관심을 받았다. 특히, 2016년 알파고와 이세돌 9단의 대국은 더 많은 사람이 인공지능 분야에 관심을 가지게 하는 촉매제가 되었다. 이는 딥 러닝을 비롯한 여러 머신 러닝 알고리즘의 성능이 최근 매우 향상되었기 때문이다. 머신 러닝은 최근에 새롭게 생겨난 기술이 아니다. 데이터를 기반으로 해서 최적화 문제를 풀거나 예측해야 하는 다양한 분야에서 이미 오랜 시간 동안 머신 러닝 기술이 활용되었다. 최근에 가장 주목을 받고 있는 딥 러닝은 수십 년 전에 처음 제안된 뉴럴 네트워크 알고리즘이 기반이다. 오랜 시간 동안 학계로부터 외면받고 있었던 뉴럴 네트워크 기술이 GPU 등 하드웨어의 발전과 구글/페이스북 등의 회사에서 발생하는 엄청난 양의 데이터, 여러 알고리즘 개선법 등을 만나면서 새로운 모습을 보이게 된 것이다. 이 책은 지난 수십 년간 발전되어 온 확률/통계 기반의 패턴 인식과 머신 러닝 분야의 전반적인 내용을 다루고 있다. 내용을 이해하는 데 있어서 패턴 인식이나 머신 러닝 분야에 대한 사전 지식은 필요하지 않지만, 다변량 미적분과 기초 선형 대수학을 다뤄본 경험은 필요하다. 또한 기초적인 확률 이론에 대한 소개가 포함되어 있으므로 확률론에 대한 기초 지식이 반드시 필요하지는 않다. 기본적으로 학부 고학년생들이나 박사과정 1년 차 학생들을 대상으로 하고 있으나, 해당 분야의 연구자들이나 업계에서 머신 러닝을 활용하는 사람들이 읽기에도 적합하다. 그리고 머신 러닝, 통계, 컴퓨터 공학, 신호 처리, 컴퓨터 비전, 데이터 마이닝, 바이오 인포매틱스와 같은 분야의 강의 과정에서 사용하기도 적합하다. 지은이 소개크리스토퍼 비숍(Christopher M. Bishop)크리스토퍼 M. 비숍은 마이크로소프트 리서치 케임브리지의 부 디렉터이자 에든버러 대학교 컴퓨터 공학과의 학과장을 맡고 있다. 또한, 케임브리지 다윈 칼리지와 왕립 공학회의 펠로우이기도 하다. 크리스는 양자론에 관한 논문으로 세인트 캐서린 대학과 옥스퍼드 대학교에서 물리학 학사, 에든버러 대학교에서 이론 물리학 박사 학위를 취득했다. 옮긴이 소개김형진다양한 현실 세계의 문제들을 머신 러닝을 이용하여 해결하는 데 관심이 많은 소프트웨어 엔지니어이자 데이터 과학자다. 카이스트 전산학과 학부과정과 스탠퍼드 전산학과 석사과정을 마친 후, 링크드인 데이터팀에서 친구 추천 등 각종 데이터 기반 제품의 개발에 참여하였다. 그 후 스타트업에서 자연어 처리 시스템을 만들었으며, 현재는 우버 매칭팀의 머신 러닝 엔지니어로서 실시간으로 드라이버와 승객의 연결을 최적화하는 문제를 풀고 있다.   차례CHAPTER 1 소개 11.1 예시: 다항식 곡선 피팅 _ 51.2 확률론 _ 131.3 모델 선택 _ 361.4 차원의 저주 _ 371.5 결정 이론 _ 421.6 정보 이론 _ 54더보기CHAPTER 2 확률 분포 752.1 이산 확률 변수 _ 762.2 다항 변수 _ 832.3 가우시안 분포 _ 872.4 지수족 _ 1262.5 비매개변수적 방법 _ 134 CHAPTER 3 선형 회귀 모델 1553.1 선형 기저 함수 모델 _ 1563.2 편향 분산 분해 _ 1663.3 베이지안 선형 회귀 _ 1723.4 베이지안 모델 비교 _ 1813.5 증거 근사 _ 186 CHAPTER 4 선형 분류 모델 2014.1 판별 함수 _ 2034.2 확률적 생성 모델 _ 2214.3 확률적 판별 모델 _ 2294.4 라플라스 근사 _ 2404.5 베이지안 로지스틱 회귀 _ 245 CHAPTER 5 뉴럴 네트워크 2535.1 피드 포워드 네트워크 함수 _ 2555.2 네트워크 훈련 _ 2615.3 오차 역전파 _ 2715.4 헤시안 행렬 _ 2815.5 뉴럴 네트워크에서의 정규화 _ 2895.6 혼합 밀도 네트워크 _ 3065.7 베이지안 뉴럴 네트워크 _ 312 CHAPTER 6 커널 방법론 3276.1 듀얼 표현 _ 3296.2 커널의 구성 _ 3306.3 방사 기저 함수 네트워크 _ 3366.4 가우시안 과정 _ 341 CHAPTER 7 희박한 커널 머신 3637.1 최대 마진 분류기 _ 3647.2 상관 벡터 머신 _ 387 CHAPTER 8 그래프 모델 4038.1 베이지안 네트워크 _ 4048.2 조건부 독립 _ 4188.3 마르코프 무작위장 _ 4318.4 그래프 모델에서의 추론 _ 443 CHAPTER 9 혼합 모델과 EM 4779.1 K 평균 집단화 _ 4789.2 혼합 가우시안 _ 4859.3 EM에 대한 다른 관점 _ 4959.4 일반적 EM 알고리즘 _ 507 CHAPTER 10 근사 추정 51710.1 변분적 추론 _ 51810.2 예시: 변분적 가우시안 혼합 분포 _ 53110.3 변분적 선형 회귀 _ 54510.4 지수족 분포 _ 54910.5 지역적 변분 방법론 _ 55210.6 변분적 로지스틱 회귀 _ 55810.7 EP _ 566 CHAPTER 11 표집법 58711.1 기본적인 표집 알고리즘 _ 59011.2 마르코프 연쇄 몬테 카를로 _ 60311.3 기브스 표집법 _ 60811.4 조각 표집법 _ 61311.5 하이브리드 몬테 카를로 알고리즘 _ 61511.6 분할 함수 추정 _ 622 CHAPTER 12 연속 잠재 변수 62712.1 PCA _ 62912.2 확률적 PCA _ 64012.3 커널 PCA _ 65712.4 비선형 잠재 변수 모델 _ 662 CHAPTER 13 순차 데이터 67713.1 마르코프 모델 _ 67913.2 은닉 마르코프 모델 _ 68213.3 선형 동적 시스템 _ 710 CHAPTER 14 모델 조합 72914.1 베이지안 모델 평균 _ 73014.2 위원회 방식 _ 73214.3 부스팅 _ 73314.4 트리 기반 모델 _ 74014.5 조건부 혼합 모델 _ 744 부록 A. 데이터 집합 757손글씨 숫자 _ 757오일 흐름 _ 758오래된 믿음 _ 761합성 데이터 _ 762 부록 B. 확률 분포 765베르누이 분포 _ 765베타 분포 _ 766이항 분포 _ 766디리클레 분포 _ 767감마 분포 _ 768가우시안 분포 _ 768가우시안 감마 분포 _ 770가우시안 위샤트 분포 _ 770다항 분포 _ 771정규 분포 _ 772스튜던트 t 분포 _ 772균등 분포 _ 773폰 미제스 분포 _ 773위샤트 분포 _ 774 부록 C. 행렬의 성질 775기본 행렬 성질 _ 775대각합과 행렬식 _ 777행렬 미분 _ 778고윳값 공식 _ 779 부록 D. 변분법 783 부록 E. 라그랑주 승수법 787  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 835}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글아마존 웹 서비스 부하 테스트 입문  (0)2018.09.27코딩 교육을 위한 마이크로비트  (0)2018.09.20마이크로소프트 봇 프레임워크 프로그래밍: 챗봇 구축을 향한 다층적 접근  (0)2018.08.31웹 서비스를 만들며 배우는 node.js 프로그래밍: 설치에서 배포까지  (0)2018.08.03모던 C++로 배우는 동시성 프로그래밍  (0)2018.08.03태그deep learning, machine learing, Pattern recognition, 기계학습, 김형진, 뉴럴네트워크, 딥러닝, 머신러닝, 베이지안, 비숍, 신경망, 신호처리, 심층학습, 아이러브인공지능, 제이펍, 컴퓨터비전, 패턴인식'도서 소개' Related Articles아마존 웹 서비스 부하 테스트 입문코딩 교육을 위한 마이크로비트마이크로소프트 봇 프레임워크 프로그래밍: 챗봇 구축을 향한 다층적 접근웹 서비스를 만들며 배우는 node.js 프로그래밍: 설치에서 배포까지    setInitialEntryComments(835, 1723618413)Secret댓글달기loadedComments[835]=true;findFragmentAndHighlight(835);"
44,https://goodman710012-1.tistory.com/entry/%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%B1%84%EC%9A%A9-%EC%9E%90%EC%84%B8%ED%9E%88-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0,1. 네이버 채용 자세히 알아보기," 팁앤테크 - 생활 팁과 기술 블로그xclose 팁앤테크 - 생활 팁과 기술 블로그  분류 전체보기 (37) 홈태그방명록카테고리 없음 · 2024. 6. 28. fullscreen넓게보기fullscreen_exit원래대로네이버 채용 자세히 알아보기     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); } 네이버 채용 자세히 알아보기네이버 채용네이버는 ""사람들의 삶에 기쁨과 편의를 더하는 서비스로 세상을 바꾸는 회사""를 비전으로 인터넷 서비스를 제공하는 기업입니다. 검색 포털, 커뮤니티, 쇼핑, 금융 등 다양한 분야에서 혁신적인 서비스를 개발하고 운영하고 있습니다. 네이버 채용에서는 현재 다음과 같은 분야의 인재를 모집하고 있습니다. - 엔지니어링 (소프트웨어 개발자, 데이터 과학자, 머신러닝 엔지니어, 인프라 엔지니어, 보안 엔지니어 등) - 제품 관리 (제품 매니저, UX 디자이너, 데이터 분석가 등) - 운영 (사업 개발, 마케팅, 고객 지원 등) - 디자인 (그래픽 디자이너, 웹 디자이너, UI/UX 디자이너 등) - 기타 (재무, 인사, 법무 등) 네이버는 혁신과 창의성을 중시하는 직원 중심의 회사입니다. 우수한 근무 환경과 성장 기회를 제공하며, 직원의 웰빙과 다양성을 존중합니다. 네이버에 합류하여 함께 세상을 바꾸는 서비스를 만들어 보세요! 네이버 채용 자세히 알아보기네이버 채용 자세히 알아보기 네이버는 대한민국의 대표적인 인터넷 회사로, 포털 사이트 네이버를 운영하고 있습니다. 네이버는 매력적인 급여 및 복지, 혁신적인 업무 환경, 재능 있는 동료들과 함께 일할 기회 등 다양한 장점을 제공합니다. 네이버 채용 과정 네이버 채용 과정은 일반적으로 다음 단계로 진행됩니다. 서류 심사: 이력서 및 자기소개서 제출 1차 전화 면접: 전화를 통한 자기소개 및 업무 관련 질문 2차 실무 면접: 관련 업무 경험 및 기술 능력 평가 최종 면접: 회사 문화 적합성 및 직책에 대한 역량 평가 네이버의 근무 환경 네이버는 직원들의 복지와 성장을 중시하는 근무 환경을 제공합니다. 주요 특징은 다음과 같습니다. 혁신적인 업무 환경: 직원들이 창의력을 발휘하고 혁신을 추구할 수 있는 환경 재능 있는 동료들: 각 분야의 전문가들과 함께 일할 수 있는 기회 적극적인 지원 체계: 멘토링 프로그램, 교육 기회 등 직원 성장을 지원하는 다양한 프로그램 급여 및 복지: 업계 최고 수준의 급여, 주식 옵션, 의료 보험 등 포괄적인 복지 패키지 네이버 채용 지원 방법 네이버 채용 지원은 네이버 공식 홈페이지(www.naver.com/jobs)를 통해 가능합니다. 지원자는 지원하고자 하는 직책을 선택하고, 이력서와 자기소개서를 제출해야 합니다. 네이버 채용에 성공하려면 다음 사항이 중요합니다. 자격 요건 충족: 지원 직책에 필요한 학력, 경험, 기술을 갖추고 있는지 확인 매력적인 이력서 및 자기소개서: 자신의 강점, 관련 경험, 네이버에 대한 열정을 명확하게 표현 면접 준비: 업무 관련 질문에 대비하고 네이버에 대한 지식을 쌓음 적극적인 자세: 채용 담당자와 소통하고, 피드백을 받아 자신의 지원서를 개선 네이버는 끊임없이 인재를 모집하며, 재능 있고 열정적인 지원자를 환영합니다. 회사 문화에 적합하고, 혁신을 추구하는 열정이 있는 지원자는 네이버 채용에 도전해 보시기 바랍니다.## 네이버 채용 꿀팁 합격률 높이는 지원서 - 지원 서류 중시: 네이버는 지원 서류를 꼼꼼히 검토하며, 특히 자기소개서와 경력서를 중요시합니다. - 적합한 자격과 경험 강조: 지원하는 직무와 관련된 자격과 경험을 명확히 제시하십시오. - 성과 중심의 서술: 경력서에서 과거 성과를 구체적으로 서술하고, 숫자와 사례를 사용하여 측정 가능한 결과를 강조하십시오. - 열정과 동기 강조: 자기소개서에서 네이버에 합류하고자 하는 열정과 동기를 설명하십시오. - 교정 및 리뷰: 지원 서류를 제출하기 전에 철저히 교정하고, 가능한 경우 피드백을 구하십시오. 면접 성공 지침 - 기업 문화 연구: 네이버의 기업 문화와 가치관에 대해 미리 연구하십시오. - 질문 준비: 면접관이 흔히 하는 질문을 연습하고, 자신의 대답을 준비하십시오. - 능력과 기술 강조: 면접에서 자신의 능력과 기술을 자신 있고 명확하게 전달하십시오. - 창의적 사고력 과시: 네이버는 창의적 사고력을 가진 지원자를 찾고 있습니다. 면접 중에 독특하고 혁신적인 아이디어를 제시하십시오. - 열정 표현: 네이버에 대한 열정과 조직에 기여하고자 하는 의지를 보여주십시오. 기타 유용한 팁 - 네트워킹 참여: 네이버 직원과 네트워킹 행사에 참석하여 정보를 수집하고 인맥을 구축하십시오. - 채용 정보 확인: 네이버 채용 웹사이트와 소셜 미디어 계정을 정기적으로 확인하여 최신 채용 정보를 파악하십시오. - 온라인 테스트 및 과제 준비: 지원 절차가 온라인 테스트나 과제를 포함할 수 있음을 인지하고 미리 준비하십시오. - 긍정적인 태도 유지: 지원 과정 내내 긍정적인 태도를 유지하고 자신감을 갖추십시오.네이버 채용 꿀팁 1네이버에 지원하려면 몇 가지 중요한 꿀팁이 있습니다. 첫째, 네이버는 기술적인 면접을 매우 중시하기 때문에 기술적 기반을 탄탄히 다지세요. 둘째, 행동 면접에 대비하세요. 네이버는 문화적 적합성을 중요하게 생각하므로 회사 문화에 잘 맞는지 보여주는 예시를 준비하세요. 셋째, 네이버의 영어 능력 요구 사항을 반드시 충족하세요. 네이버는 글로벌 기업이므로 영어 구사 능력이 필수적입니다. 넷째, 네이버의 채용 과정은 경쟁이 치열합니다. 포기하지 말고 꾸준히 노력하세요.네이버 채용 꿀팁기술적 기반 탄탄히 다지기행동 면접에 대비하기영어 능력 요구 사항 충족하기포기하지 않고 꾸준히 노력하기1. 네이버 채용 꿀팁실력 준비- 기본기부터 꼼꼼히 复习 - 과거 개발 경험 및 프로젝트 소개서 작성에 注力 - 시험 문제 연습을 통해 문제 유형 파악정보 수집- 네이버 채용 공고 페이지 정기적으로 조회 - 네이버 채용 홈피 및 기업 블로그 확인 - 인사이드 네이버 채용자 인터뷰 기사 참고자기 소개서 작성- 개인 특징, 기술, 경험을 구체적 사례로 제시 - 네이버의 비전과 가치관에 부합하도록 표현 - 자신에게만 있는 고유한 장점 강조면접 대비- 기본 礼儀와 태도 중시 - 자기 소개서를 정확히 설명할 수 있는 준비 - 기술적 질문에 대한 대비와 문제 해결 능력 발휘네트워킹- 채용 담당자나 현직 직원과 연결 - 네이버 관련 행사 및 워크샵 참여 - 업계 네트워크를 통해 정보 교환지원 이후- 결과 통보까지 참을성 있는 기다림 - 결과가 불합격이라도 피드백을 요청 - 성공을 위해 지속적인 노력과 개발네이버 채용 꿀팁 2네이버 채용에 성공하는 데에는 여러 가지 꿀팁이 있습니다. 가장 우선적으로 고려해야 할 점은 이력서와 자기소개서를 완벽하게 작성하는 것입니다. 깔끔하고 간결하게 작성된 이력서와 자기소개서는 채용 담당자에게 귀하의 자격을 빠르게 파악할 수 있도록 도울 것입니다. 또한 네이버 기업 문화에 대해 잘 알고 있는 것도 중요합니다. 공감대를 형성하기 위해 회사의 가치관과 비전을 조사하세요. 이렇게 하면 합면 가능성이 높아집니다. 네이버 채용에 성공하려면 인내심을 갖는 것도 중요합니다. 채용 과정은 시간이 많이 걸릴 수 있습니다. 그러나 포기하지 마세요. 계속 지원하고 네트워킹을 통해 기회를 찾으세요. 마지막으로 자신감을 갖는 것이 중요합니다. 귀하의 자격에 대해 자신감을 갖고 인터뷰에 임하면 채용 담당자에게 긍정적인 인상을 줄 수 있습니다. 그러나 자만하지 않고 항상 겸손한 자세를 유지하세요.<tr style=""background-color: lightblue; </body>1. 네이버 채용 자세히 알아보기채용 분야엔지니어링마케팅디자인제품 관리운영인사기타채용 절차이력서 및 자기소개서 제출전화 면접대면 면접과제 수행건강 검진복리 후생경쟁력 있는 급여주식 옵션의료 보험연금휴가교육 지원네이버 문화혁신 중심협업적 환경사용자 지향성장 및 학습 기회인재 채용 기준업무 관련 기술 및 경험문제 해결 능력팀워크 및 협업 능력의사 소통 능력열정과 성장 의지네이버 채용에 대해 자세히 알아보기 네이버는 한국에서 가장 큰 검색 엔진과 포털 사이트로, 여러 분야에서 뛰어난 인재를 채용하고 있습니다. 네이버 채용에 관심이 있으시면 공식 홈페이지를 방문해 자세한 정보를 확인하세요. 네이버는 다양한 직무를 제공하며, 귀하의 기술과 경험에 적합한 기회를 찾을 수 있습니다. 또한 네이버는 직원에게 뛰어난 혜택과 개발 기회를 제공하여 직원들이 성장하고 성공할 수 있는 환경을 조성합니다. 네이버 채용에 지원하시면 혁신적이고 동적인 환경에서 일할 수 있는 기회를 얻게 됩니다. 네이버는 귀하의 경력에 도전과 성장의 기회를 제공합니다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//goodman710012-1.tistory.com/reaction';window.ReactionReqBody = {    entryId: 36}공유하기게시글 관리팁앤테크 - 생활 팁과 기술 블로그저작자표시 비영리 변경금지  네이버, 채용 loadedComments[36]=true;findFragmentAndHighlight(36);var sortComment=""Comment-asc"";if(""comment-desc""==sortComment){var sortCommentcss="".post-reply .tt-list-reply { display: flex; flex-direction: column-reverse; }.post-reply .tt-list-reply li.tt-item-reply:first-child {order:1}.post-reply .tt-list-reply li.tt-item-reply.rp_general:first-child {order:0}"",styleElement=document.createElement(""style"");styleElement.innerHTML=sortCommentcss;document.head.appendChild(styleElement)}var writeCommentPosotion=""write-Comment-top"";""write-Comment-top""==writeCommentPosotion&&(sortCommentcss="".post-reply .tt-comment-cont{ display: flex; flex-direction: column-reverse; } .post-reply .tt-box-total {order:1;}"",styleElement=document.createElement(""style""),styleElement.innerHTML=sortCommentcss,document.head.appendChild(styleElement));    var contentContainer=document.querySelector("".e-content.post-content"");if(contentContainer){var tocSpace=document.createElement(""div"");tocSpace.classList.add(""toc-space"");contentContainer.insertBefore(tocSpace,contentContainer.firstChild);var headings=contentContainer.querySelectorAll(""h2, h3"");if(headings.length>0){var tocContainer=document.createElement(""div"");tocContainer.classList.add(""toc-wrap"");var ulContainer=document.createElement(""ul"");ulContainer.classList.add(""toc"");headings.forEach(function(heading,index){var tocItem=document.createElement(""li"");tocItem.classList.add(""toc-item"");var tocLink=document.createElement(""a"");tocLink.href=""#section-""+index;tocLink.textContent=heading.textContent;if(heading.tagName===""H2"")tocItem.classList.add(""h2"");else if(heading.tagName===""H3"")tocItem.classList.add(""h3"");tocItem.appendChild(tocLink);ulContainer.appendChild(tocItem);heading.id=""section-""+index;tocLink.addEventListener(""click"",function(event){event.preventDefault();var target=document.querySelector(tocLink.getAttribute(""href""));if(target){var scrollOffset= (window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth) >= 450 ? 120 : 80;var targetPosition=target.offsetTop+scrollOffset;window.scrollTo({top:targetPosition,behavior:""smooth""})}})});var tocTitle=document.createElement(""strong"");tocTitle.textContent=""\ubaa9\ucc28"";var tocIcon = document.createElement(""div"");tocIcon.classList.add(""toc-icon"");var tocTitleContainer=document.createElement(""div"");tocTitleContainer.classList.add(""toc-title"");tocTitleContainer.appendChild(tocIcon);tocTitleContainer.appendChild(tocTitle);tocContainer.appendChild(tocTitleContainer);tocContainer.appendChild(ulContainer);tocSpace.appendChild(tocContainer)}};document.addEventListener(""DOMContentLoaded"",function(){var g=document.querySelectorAll("".e-content.post-content img"");g.forEach(function(a,b){var l=a.getAttribute(""alt""),h=a.getAttribute(""data-filename"");l||a.setAttribute(""alt"",h?h:""etc-image-""+b)});if(0<g.length){var k=function(){if(0<window.pageYOffset){var a=blockedStylesheets.find(function(b){return b.href.includes(""lightbox"")});a&&loadStylesheet(a.href);(a=blockedScripts.find(function(b){return b.src.includes(""lightbox"")}))&&loadScript(a.src).then(function(){var b=lightbox;b.options.fadeDuration=200;b.options.resizeDuration=200;b.options.wrapAround=!1;b.options.albumLabel=""%1 / %2""})[""catch""](function(){});window.removeEventListener(""scroll"",k)}};window.addEventListener(""scroll"",k,{passive:!0})}var c=document.getElementById(""widen-btn""),d=document.getElementById(""original-btn""),e=document.querySelector(""#container #main #sidebar""),f=document.querySelector("".h-entry .content-width"");c&&d&&e&&f&&(c.addEventListener(""click"",function(a){a.preventDefault();e.style.display=""none"";c.style.display=""none"";d.style.display=""inline-block"";f.classList.add(""wide"")}),d.addEventListener(""click"",function(a){a.preventDefault();e.style.display=""block"";d.style.display=""none"";c.style.display=""inline-block"";f.classList.remove(""wide"")}))});공지사항전체 카테고리  분류 전체보기 (37) 최근 글머리가띵하고어지러워요 자세히 알아보기치핵 2기 자세히 알아보기itq한글시험일정 자세히 알아보기공무원 블로그 수익 자세히 알아보기네이버 채용 자세히 알아보기인기 글충북 진천 출렁다리 자세히 알아보기24년 예비군 원격교육 자세히 알아보기머리가띵하고어지러워요 자세히 알아보기itq한글시험일정 자세히 알아보기저돌적 뜻 자세히 알아보기최근 댓글마곡통 - 마곡 부동산정보 06.17 잘~읽고　가요~~ 좋은 하루되세요 태그#아이오닉7#GV90#itq한글시험일정#애사비#머리가띵하고어지러워요#자세히#kmo시험#네오룬#세부여행계획#송진가루전체 방문자오늘7어제2전체289Copyright © 쭈미로운 생활 All rights reserved.Designed by JJuumdocument.addEventListener(""DOMContentLoaded"",function(){function m(a,b){if(a.isIntersecting){if(a.target.classList.contains(""post-reply"")){var c=blockedStylesheets.find(function(d){return d.href.includes(""comment"")});c&&loadStylesheet(c.href);(c=blockedScripts.find(function(d){return d.src.includes(""comment"")}))&&loadScript(c.src).then(function(){var d=new Event(""load"");window.dispatchEvent(d)})[""catch""](function(){})}else a.target.classList.contains(""container_postbtn"")?g||((c=blockedStylesheets.find(function(d){return d.href.includes(""postBtn"")}))&&loadStylesheet(c.href),(c=blockedScripts.find(function(d){return d.src.includes(""reaction-button-container"")}))&&loadScript(c.src),a.target.style.visibility=""visible"",g=!0):""PRE""!==a.target.parentElement.tagName||""CODE""!==a.target.tagName||h||(loadStylesheet(""//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/vs2015.min.css""),loadScript(""//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"").then(function(){hljs.highlightAll();loadScript(""//cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"").then(function(){hljs.initLineNumbersOnLoad()})[""catch""](function(){})})[""catch""](function(){}),h=!0);b.unobserve(a.target)}}function k(){if(0<window.pageYOffset){var a=blockedScripts.find(function(b){return b.src.includes(""googletagmanager.com/gtag/js?id"")});a&&loadScript(a.src).then(function(){var b=document.createElement(""script"");b.innerHTML=blockedScriptContents[0].textContent;document.head.appendChild(b)})[""catch""](function(){});window.removeEventListener(""scroll"",k)}}mutationObserver.disconnect();var h=!1,g=!1,l=!1,e=document.querySelectorAll("".post-reply, .container_postbtn, pre code""),n=new IntersectionObserver(function(a,b){a.forEach(function(c){m(c,b)})},{root:null,rootMargin:""200px"",threshold:.2});e.forEach(function(a){n.observe(a)});window.addEventListener(""scroll"",function(){var a=(document.body.scrollTop||document.documentElement.scrollTop)/(document.documentElement.scrollHeight-document.documentElement.clientHeight)*100,b=document.getElementById(""progress"");b&&(b.style.width=a+""%"")},{passive:!0});var f=document.getElementById(""header_wrap"");f&&window.addEventListener(""scroll"",function(){50<window.scrollY?f.classList.add(""shrink""):f.classList.remove(""shrink"")},{passive:!0});(e=document.querySelector("".btn_topMenu""))&&e.addEventListener(""click"",function(a){a.stopPropagation();if(a=document.querySelector("".dropdown-content"")){if(!l){var b=blockedScripts.find(function(c){return c.src.includes(""menubar.min"")});b&&loadScript(b.src);if(b=document.querySelector("".dropdown-profile_bg img""))b.src=b.dataset.src,b.style.display=""block"",b.removeAttribute(""data-src"");l=!0}a.classList.toggle(""dropdown-content-toggle"")}});(e=document.querySelector("".btn_close""))&&e.addEventListener(""click"",function(a){a.stopPropagation();(a=document.querySelector("".dropdown-content""))&&a.classList.remove(""dropdown-content-toggle"")});document.querySelectorAll("".post_category_name"").forEach(function(a){var b=a.textContent.trim().split(""/"")[1];b&&(a.textContent=b.trim())});document.querySelectorAll("".p-category"").forEach(function(a){var b=a.textContent.split(""/"")[1];b&&(a.textContent=b.trim())});document.querySelectorAll(""iframe"").forEach(function(a){var b=a.getAttribute(""name"");a.setAttribute(""title"",b||""inner iframe"")});(e=document.getElementById(""content""))&&e.classList.add(""show"");window.addEventListener(""scroll"",k,{passive:!0})});티스토리툴바document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""6950785-36"",""customProps"":{""userId"":""0"",""blogId"":""6950785"",""entryId"":""36"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""36"",""entryTitle"":""네이버 채용 자세히 알아보기"",""entryType"":""POST"",""categoryName"":""카테고리 없음"",""categoryId"":""0"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""6598754"",""authorNickname"":""쿠첸"",""blogNmae"":""팁앤테크 - 생활 팁과 기술 블로그"",""image"":""kage@LccEs/btsIeko89Yr/d6img91hkvXqXg4lJeXanK"",""plink"":""/entry/%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%B1%84%EC%9A%A9-%EC%9E%90%EC%84%B8%ED%9E%88-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0"",""tags"":[""네이버"",""채용""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
45,https://keyog.tistory.com/45,Don't learn machine learning - 머신러닝 공부하지 마세요!,"지식 저장소머신러닝 공부하지 마세요! towards 게시글 해석 Keyog2021. 3. 4. 23:29안녕하세요. 정말 오랜만에 글을 올립니다.요즘 바빠서 글을 올리지 못했지만, 재미난 글을 towards에서 읽고 공유하고자 하는 마음에 글을 올리게 되었습니다.두가지의 글을 해석하고, 개인적인 의견을 작성한뒤에 글을 마치겠습니다. 게시글은 다음과 같습니다.Don't learn machine learning  5 Reasons You Don't Need to Learn Machine Learning Don’t learn machine learningLearn how to build software with ML modelstowardsdatascience.com 5 Reasons You Don’t Need to Learn Machine LearningAn increasing number of influencers preach why you should start learning Machine Learning. Should you listen to them?towardsdatascience.comDon't learn machine learning - 머신러닝 공부하지 마세요!이 글의 시작은 머신러닝은 개발자들에게 매력적이고 최소한의 관심이 있을것이라는 가정에서 시작합니다.만약 머신러닝을 공부하기로 하였고, 일반적인 공부 방법을 따른다면 선형대수학 및 다변수 미적분을 공부하는데만 2주를 소비할 수 있다고 합니다. (아니.. 제 생각으로는 완전히 이해하려면 그 이상입니다.)그 이유로는 대부분의 머신러닝 입문자료는 개발자(Developer)를 위한것이 아니라 연구자(Researcher)를 위한 자료들이기 때문에 머신러닝을 이용한 상품(Product)를 개발하는데에는 Issue가 된다고 합니다.그럼 본격적으로 읽어 볼까요?Do you want to build products, or research?2000년대 후반 이전에는 머신러닝은 연구적 성향이 강했습니다. 그렇기에 머신러닝을 이용한 의미있는 상품(Product)을 만드는 회사는 많지 않았습니다.따라서, 머신러닝에 입문하기 위한 자료들은 연구관점에서 접근합니다. 수학적 관점에서 신경망을 설명하며, 역전파(back propagation), 적대적 네트워크(adversarial networks) 같은 머신러닝의 이론들을 설명하는 것으로 시작합니다.이 것은 대학과 무관한 곳에서도 일어나는 패턴입니다. TensorFlow의 'Quickstart for Beginners' 에는 이렇게 적혀 있습니다.loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)This loss is equal to the negative log probability of the the true class : it is zero if the model is sure of the correct class. This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.log(1/10) ~= 2.3이 손실 함수는 실제 class의 음의 log확률과 동일합니다. 모델이 correct class를 맞추는 경우 0이 됩니다.훈련되지 않은 모델은 확률이 무작위 이므로 (각 class별 1/10) 초기손실은 -tf.log(1/10) ~= 2.3 에 가까워야 합니다.이미 머신러닝 수학을 잘알고 있고, 수학적인 부분을 공부하고자 한다면 이러한 글을 읽고 접근하는 것이 맞을 수 있습니다. 그러나처음 머신러닝을 배우고, 개발해보려고 하는 개발자에겐 이러한 문구는 찾던 것이 아닐 수 있습니다.프로그래밍을 처음 배울때를 예로 들면, 어셈블리어를 통해 코드 작성을 배우는 것과 같습니다. 하지만 실제로 개발자들은 어셈블리 어를 배우지는 않습니다. 코딩을 처음 배울때는 고수준 언어(python 같은)를 통해 ""hello world"" 를 작성해보는 것을 시작했을 것입니다. 그 이후에 프로젝트에 약간의 복잡한 코드들과 좀 더 low-level까지 코딩할 수 있도록 공부해왔을 것입니다.이러한 학습 방법은 SW개발자 사이에서 성공적으로 작용했고, 성공의 이유는 구축(Build)를 우선적으로 진행했기 때문입니다. 머신러닝의 경우도 마찬가지입니다. 추천엔진을 구축(Build)하는 것을 논문을 작성하고 게시하는 것보다 우선적으로 머신러닝에 접근해야합니다.How to learn ML by building software이러한 하향식 접근 방법으로는 fastai의 강의가 잘 설명되어 있습니다. (강의에 대한 내용이 약간 나오는데 생략하겠습니다.)만약, 당신이 당신의 것을 구축(Build)하는 것을 잘 배우는 사람이라면, 머신러닝을 시작하는 것도 다른 프로그래밍을 시작하는 것과 다르지 않게 시작할 수 있습니다.다음은 재밌어 보이는 NLP 프로젝트를 구축하는 순서를 나열합니다. 이러한 방식을 보고 머신러닝을 이용하여 구축(Build)하는 것에 친숙하게 느끼길 바랍니다.텍스트 자동완성, 번호판 식별 등 만들고자 하는 목표를 정합니다.프로젝트에 사용할만한 모델(GPT-2 나 YOLOv3 같은)을 찾고, 제공하는 pre-train모델을 내려받습니다. 실행 방법을 확인하고, 실행해본 뒤에 멋지다고 생각이 든다면, gpt-2-simple, darknet 과 같은 라이브러리를 사용하여 모델을 자신의 데이터에 맞게 Fine tuning 하여 당신만의 모델을 만들 수도 있습니다.마지막으로, 모델을 마이크로 서비스로 배포하세요!youtu.be/gsYEZtecXlA해당 동영상은 한명의 엔지니어가 재미삼아 만든 번호판을 인식하는 실제 응용프로그램 입니다.이 접근 방식을 통해 공부한다면, 다양한 인기 모델의 구조(Architecture)를 알고, 적합한 어플리케이션에 대해 알아볼 수 있습니다. 보다 중요한것은 머신러닝 모델을 통해 실제 제품(Product)를 구축하는데 필수적인 ML 인프라를 배운다는 것 입니다.Once you can build with machine learning, then learn the theory만약 당신이 엔지니어라면, password를 해싱해본적이 있을 것이라고 생각합니다. 당신이 password를 해싱하는 데에 암호화에 대한 연구를 몇 주 동안 했습니까? 아니면 bcrypt 같은 라이브러리를 사용했습니까?마찬가지로, 웹 app 을 처음 구축할때, 데이터베이스에 데이터를 생성할 때, 데이터 베이스의 기본지식에 대해 몇 주 동안 연구했습니까? 아니면 프레임워크와 함께 제공된 ORM을 사용했습니까?머신러닝도 마찬가지 입니다. 머신러닝을 이용한 SW를 개발하고자 한다면, 먼저 머신러닝을 이용해서 소프트웨어를 구축하고, Pre-train된 모델과, 제공되는 tool을 이용해서 일단 만드세요. 그런 다음 프로젝트의 성능을 끌어올리려하거나, 머신러닝이 동작하는 것을 좀 더 깊게 알아가기 위해 머신 러닝 이론들을 공부하며 머신러닝의 작동 방식을 공부하세요.개인적 의견저는 이 포스팅을 읽고나서, 저의 생각과 정말 딱 맞는 포스팅이라고 생각했습니다. 한국에서 실제로 채용공고들을 보면 작년과 많이 달라졌습니다. 작년만 해도 '논문을 읽고, 구현하는 데 거부감이 없으신 분', '수학, 통계 전문가' , '석사학위 이상', '딥러닝 관련 논문 게시 경험' 등 엔지니어를 구하는 공고임에도 불구하고 연구적 성향의 자격요건들, 면접 때도 개발의 영역보다는 딥러닝 관련 지식을 질문하는 등 머신러닝 이론을 통해 사람을 채용하려고하는 경우가 많았습니다. 하지만 요 근래의 채용공고를 보면 ' 개발경험', '머신러닝 파이프라인 구현', ' SW 개발경험' 등 개발자의 역량을 좀 더 중시하는 경향이 늘어난 것 같습니다. (물론 아직도 연구자와 완벽히 분리되거나 하진 않았습니다.) 실제로 회사라는 것은 결국 이익을 추구하는 집단이기 때문에, 아무리 머신러닝에 뛰어난 지식이 있더라도, 개발 능력이 부족해서 SW를 만들어서 배포할수 없다면 즉, 상품화(Product)하지 못하는 머신러닝 지식은 회사에서 필요 없을거라고 생각합니다. (특히나 스타트업은 빠르게 성장하는것이 중요하기 때문에 더더욱 그럴 것이라고 생각합니다.)즉, 머신러닝을 공부하고 또 그를 통해 취업하고 싶은 학생이라면 더더욱 개발을 먼저 해보는 것을 저 또한 좋다고 생각합니다. (물론 머신러닝/딥러닝 연구자(Researcher)가 되고 싶은 분이라면 깊게 이해하는 것이 좋지만, 대부분은 엔지니어의 영역에서 취업될 것이라고 생각하기 때문에.. 만약 연구자라고 하더라도, 자신만의 app을 만들어 보는 것은 좋다고 생각합니다.)포스팅이 많이 길어졌네요!  5 Reasons You Don't Need to Learn Machine Learning 에 대한 글은 다음 포스팅으로 넘어가서 마저 진행해보겠습니다. 간단하게 말씀드리면 현업 AI개발자가 느낀 머신러닝 엔지니어에 대한 오해 같은 느낌의 포스팅입니다. 해당 포스팅에 작성된 글과는 성격이 조금 다른 글이 되겠네요.여기까지 읽어주셔서 감사합니다! 다음 포스팅 링크를 달고 마무리 하겠습니다.2021/03/05 - [지식 저장소] - 머신러닝을 공부할 필요가 없는 5가지 이유 - towards 해석 머신러닝을 공부할 필요가 없는 5가지 이유 - towards 해석Don't learn machine learning 해석에 이어서 두번째 포스팅 입니다. 해당 게시글은 이전에 머신러닝 개발자가 되기 위한 공부 접근방법 같은 느낌의 글이었다면, 이번 글은 머신러닝 엔지니어에 대한keyog.tistory.com      (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//keyog.tistory.com/reaction';window.ReactionReqBody = {    entryId: 45}공유하기게시글 관리인간지능이 인공지능을 공부하는 장소저작자표시 '지식 저장소' 카테고리의 다른 글머신러닝에 대한  5가지 오해 (원제 : 5 Reasons You Don’t Need to Learn Machine Learning)  - towards 해석  (0)2021.03.05Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(3)  (0)2020.11.03Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(2)  (0)2020.11.03Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(1)  (0)2020.11.02DETR : End-to-end방식의 Transformers를 통한 object detection  (2)2020.07.07태그torward 해석, 개발, 딥러닝, 머신러닝'지식 저장소' Related Articles머신러닝에 대한  5가지 오해 (원제 : 5 Reasons You Don’t Need to Learn Machine Learning)  - towards 해석Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(3)Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(2)Imbalance Problems in Object Detection : 객체 검출 분야의 불균형 문제 A Review(1)Secret댓글달기loadedComments[45]=true;findFragmentAndHighlight(45);"
46,https://bcho.tistory.com/1174,Tag,"                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝머신러닝 모델 개발 삽질기Terry Cho2017. 4. 24. 14:27머신러닝 모델 개발 삽질 경험기조대협 (http://bcho.tistory.com)딥러닝을 공부하고 CNN 모델을 기반으로 무언가를 만들어보겠다는 생각에, 해외 유명 연예인 얼굴 사진을 가져다가 분류하는 얼굴 인식 모델을 만들어 보기로 하였다.아직도 진행중이지만, 많은 시행 착오를 겪었는데 같은 시행 착오를 겪지 않고 경험을 공유하기 위해서 겪었던 시행 착오들을 정리해 본다.학습 데이타 확보 및 분류먼저 학습용 데이타를 수집 하는 것이 가장 문제 였다. 인터넷에서 사진을 모아서 학습 데이타로 사용해도 되겠지만, 아무래도 저작권 및 초상권 문제가 있고, 일일이 사진을 하나씩 받아서 수집하거나 또는 별도의 수집기를 만드는 것도 부담이 되었다.그래서 찾은 것이 pubfig라는 셀럽 얼굴 데이타인데 http://www.cs.columbia.edu/CAVE/databases/pubfig/상용 목적이 아니라 연구용 목적이면 사용이 가능하다. 이 데이타는 파일 URL, 셀럽 이름 형태로 라벨링이 되어 있기 때문에, 학습에 적합하리라고 생각하고, 이 파일을 기반으로 데이타를 수집하였다.여기서 생긴 문제는, 이 데이타가 오래된 데이타라서 존재하지 않는 파일이 다수 있었고, 이 경우 파일을 저장하고 있는 사이트에서, 404 Not found와 같은 이미지를 리턴하였기 때문에, 이를 필터링해야 하였고, 같은 사진이 중복되서 오는 문제등이 있었기 때문에,상당량을 일일이 필터링을 해야 했다.그리고, 사진상에, 여러 얼굴이 있는 이미지가 많았기 때문에, VISION API로 얼굴을 인식해서 얼굴 사진만 잘라낼 요량이었기 때문에, 독사진만을 일일이 보고 골라내야 했다. 나중에 생각해보니 VISION API로 얼굴이 한명만 인식이 되는 사진만 필터링을 했으면 됐을텐데. 불필요한 작업이 많았다.라벨을 문자열로 쓴 문제학습 데이타에 대한 라벨을 생성할때, 괜히 가독성을 높힌다고 라벨을 문자열로 해서 각 사람의 이름을 사용하였다.CNN에서 마지막은 Softmax는 matrix이기 때문에, 라벨 문자열을 나중에 list.indexOf를 이용하여 배열로 변경할 예정이었는데, 파이썬에서는 쉽게 될지 몰라고, 텐서플로우 코드에서는 이 과정이 쉽지 않았다.그래서..결국은 라벨 데이타를 문자열이 아니라, 0~44의 int 값으로 재 생성한후에,     batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),        FLAGS.num_classes, on_value=1.0, off_value=0.0)tf.one_hot 함수를 이용하여, 1*45 행렬로 바뀌어서 사용하였다.학습용 및 검증용 데이타를 초기에 분류하지 않았던 문제학습데이타를 준비할때, 학습 데이타를 학습용과 검증용으로 따로 분류를 해놨어야 하는데, 이 작업을 안해서, 결국 모델을 만들다가 다시 학습 데이타를 7:3 비율로 학습 데이타와 검증용 데이타로 분류하는 작업을 진행하였다. 학습 데이타의 분포가 골고르지 못했던 문제사진을 모으는 과정에서 필터링 되서 버려지는 데이타가 많았고, 원본 데이타 역시 사람별로 사진 수가 고르지 못했기 때문에, 결과적으로 모여진 학습 데이타의 분포가 사람별로 고르지 못했다.학습데이타가 많은 셀럽은 200~250장, 적은 사람은 50장으로 편차가 컸다.이로 인해서 첫번째 모델의 학습이 끝난 후에, 모델을 검증해보니, 학습 데이타를 많이 준 사람으로 대부분 분류를 해냈다. 47개의 클래스 약 6000장의 사진으로 5시간 학습 시킨 결과, 예측을 검증하는 과정에서 90%이상을 모두 브래드피트로 인식해내는 문제가 생겼다. (내 맥북이 브레드피트를 좋아하는가??)그래서 결과적으로 학습데이타와 검증 데이타를 클래스별로 분포를 같게 하기 위해서, 클래스당 약 50 장의 샘플 사진으로 맞춰서 예측 결과가 편중되는 현상을 해결하려고 하였다.학습 순서가 클래스별로 된 문제클래스별 학습 데이타의 양을 균일하게 맞췄음에도 불구하고, 모델의 학습 결과가 특정 클래스들로 편향되는 현상이 발생하였다.이는 학습을 시킬때, 골고루 학습을 시켜야 하는데, 학습 데이타를 순서대로 학습을 시켰기 때문에 발생한 문제이다. 즉 풀어서 말하자면, “브래드 피트""를 20번 학습 시키고, “안젤리나 졸리""를 20분 학습 시키고, “브루스 윌리스”를 20번 학습 시켜서 모델이 첫 학습데이타 쪽으로 편향되는 현상이 발생한것인데, 이를 해결하려면 학습 데이타를 랜덤으로 만들어서 학습시켜야 한다. 예를 들어 “브래드 피트”,”안젤리나 졸리"",”브루스 윌리스"",”안젤리나 졸리"",”브루스 윌리스"", ”안젤리나 졸리"",“브래드 피트” …. 이런식으로 말이다. 즉 코드 상에서 배치 데이타를 읽어올때 셔플 처리를 하면되는데 이를 위해서 데이타를 읽는 부분을 다음과 같이 변경 하였다.def get_input_queue(csv_file_name,num_epochs = None):    train_images = []    train_labels = []    for line in open(csv_file_name,'r'):        cols = re.split(',|\n',line)        train_images.append(cols[0])        # 3rd column is label and needs to be converted to int type        train_labels.append(int(cols[2]) )                                input_queue = tf.train.slice_input_producer([train_images,train_labels],                                               num_epochs = num_epochs,shuffle = True)        return input_queueget_input_queue 함수에, csv_file_name을 인자로 주면, 이 파일을 한줄 단위로 읽어서, 첫번째는 파일명, 세번째는 라벨로 읽은 후에, 각각 train_images와  train_lables에 각각 string과 int 형으로 저장한다그 다음이 배열을 가지고 tf.train.slice_input_producer를 사용하면 배열에서 데이타를 읽어 드리는 input queue 를 생성하는데, 이때 인자로 shuffle = True로 주면 데이타를 리턴 할때 순차적으로 리턴하지 않고 셔플된 형태로 랜덤하게 리턴한다. def read_data(input_queue):    image_file = input_queue[0]    label = input_queue[1]        image =  tf.image.decode_jpeg(tf.read_file(image_file),channels=FLAGS.image_color)        return image,label,image_file다음으로, 이 큐를 이용하여 이미지 파일명과, 라벨을 읽어서 이미지 파일 데이타(텐서)와 라벨로 읽는 코드를 read_data라는 함수로 구현하였다. 입력값은 input_queue인데, input queue에서 데이타를 읽으면 첫번째는 이미지 파일명, 두번째는 라벨이 되는데, 첫번째 파일명을 tf.image.decode_jpeg함수를 이용하여 텐서로 읽은후, 읽은 이미지 데이타와 라벨을 리턴하였다.def read_data_batch(csv_file_name,batch_size=FLAGS.batch_size):    input_queue = get_input_queue(csv_file_name)    image,label,file_name= read_data(input_queue)    image = tf.reshape(image,[FLAGS.image_size,FLAGS.image_size,FLAGS.image_color])        batch_image,batch_label,batch_file = tf.train.batch([image,label,file_name],batch_size=batch_size)                                                       #,enqueue_many=True)    batch_file = tf.reshape(batch_file,[batch_size,1])    batch_label_on_hot=tf.one_hot(tf.to_int64(batch_label),        FLAGS.num_classes, on_value=1.0, off_value=0.0)    return batch_image,batch_label_on_hot,batch_file마지막으로, 배치로 데이타를 읽는 함수 부분에서 앞에 정의한 get_input_queue와 read_data 함수를 이용하여 데이타를 shuffle 된 상태로 읽은 후에, tf.train.batch를 이용하여 일정한 개수 (배치) 형태로 리턴하도록 하였다. 그 결과 예측 결과가 한쪽으로 편향되는 현상을 없앨 수 는 있었다.샘플 데이타의 부족데이타 편향 현상은 잡았지만, 클래스의 수(45)에 대비하여, 샘플데이타의 수(클래스당 50개)로 부족하여, 학습을 계속 진행해도 cross entropy 함수는 4~7 사이에서 왔다갔다 하면서 더 이상 0으로 수렴하지 않았고 정확도되 0~35% 사이를 왔다갔다 하면서 수렴을 하지 않았다. 그래서, 학습 이미지의 색이나, 방향등을 변경하는 방법으로 데이타를 뻥튀기 하려고 하는데, 이 부분은 아직 작업중.그외에 자잘한 삽질모 그외에도 엄청 여러가지 삽질을 하고 있다. 그래도 모델 하나 제대로 만들어봐야 겠다는 생각에 끝까지 우격다짐으로 진행하고 있지만, 학습을 돌다가 스크린 세이버나, 절전 모드로 들어가서 학습이 중단된 사례. 모델을 개발하다가 중간에 텐서 플로우 버전이 올라가서 코드를 수정한 일. 맥에서 개발하다가 윈도우 머신에 GPU로 바꿨더니, 파이썬 2.7이 아니라 파이썬 3.5만 지원을 해서, 2.7 코드를 모두 다시 고친일등.머신러닝이 과학이나 수학보다 노가다라는데, 몸소 느끼는 중.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1174}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기  (6)2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서  (0)2017.05.11머신러닝 라벨 데이타 타입에 대해서  (0)2017.04.10텐서플로우의 세션,그래프 그리고 함수의 개념  (1)2017.04.03텐서플로우-배치 처리에 대해서 이해하자  (2)2017.04.03TagDeep learning, Machine Learning, ML, Overview, tensorflow, 강좌, 경험, 데이타, 딥러닝, 라벨, 머신러닝, 삽질, 샘플, 정재, 조대협, 초보, 텐서플로우, 튜토리얼, 편중, 편협'빅데이타 & 머신러닝/머신러닝'의 다른글이전글머신러닝 라벨 데이타 타입에 대해서현재글머신러닝 모델 개발 삽질기다음글얼굴 인식 모델 - 학습용 데이타 처리에 대해서관련글연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서2017.05.11머신러닝 라벨 데이타 타입에 대해서2017.04.10텐서플로우의 세션,그래프 그리고 함수의 개념2017.04.03loadedComments[1174]=true;findFragmentAndHighlight(1174);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag머신러닝,Tutorial,강좌,구글,google,Machine Learning,클라우드,초보,튜토리얼,소개,node.js,클라우드 컴퓨팅,빅데이타,조대협,딥러닝,Kubernetes,tensorflow,텐서플로우,쿠버네티스,cloud,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1174"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1174"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1174"",""entryTitle"":""머신러닝 모델 개발 삽질기"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":"""",""plink"":""/1174"",""tags"":[""Deep learning"",""Machine Learning"",""ML"",""Overview"",""tensorflow"",""강좌"",""경험"",""데이타"",""딥러닝"",""라벨"",""머신러닝"",""삽질"",""샘플"",""정재"",""조대협"",""초보"",""텐서플로우"",""튜토리얼"",""편중"",""편협""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
47,https://jisungs.tistory.com/447,새로운 지식을 향한 걸음,"jisung's 책읽기/기술서처음 배우는 머신러닝 - 새로운 지식을 향한 걸음by jisungStory2019. 11. 12.반응형(adsbygoogle = window.adsbygoogle || []).push({});Photo by  Chris Ried  on  Unsplash처음 배우는 머신러닝새로운 지식을 향한 걸음 인공지능은 최근 개발 분야에서 가장 큰 화두입니다. 많은 데이터 과학자들이 인공지능 연구에 매진하고 있습니다. 그 덕분에 많은 발전이 있었습니다.  2016년이 벌써 까마득하게 느껴집니다. 모든 사람들이 아직 컴퓨터는 바둑으로 사람을 이길 수 없다고 했지만 그 해 이세돌 구단과의 대전에서 구글의 알파고는 4승 1패로 승리했습니다.  인공지능 분야에서는 큰 성취였고 인간의 분야에선 아쉬움이 남는 결과였습니다.  그 이후로 몇년이 지났습니다. 간간히 들리는 바로는 그 인공지능은 더욱 발전하여 이제는 인간이 도저히 범접할 수 없는 경지에 도달했다고 들었습니다. 그리고 그 발달된 인공지능을 통해 구글은 앞으로 어디로 나아갈지 예측할 수 없는 회사가 되어 버렸습니다.  앞서 나가는 분들은 그 분들의 분야에서 열심히 해주셔서 앞으로 인류의 발전에 기여하실 거라고 믿습니다. 반면에 책벌레인 저는 새로 읽을 분야가 생겨서 기쁠 따름입니다. 제가 이번에 고른 책은 인공지능의 한분야인 머신러닝을 다룬 책 “ 처음 배우는 머신러닝”입니다.  이 책은 제가 접해본 기술 서적 중에서 어려운 기술을 쉽게 설명해주는 몇 안되는 책중에 하나입니다. 많은 기술 서적들은 전문가의 언어로 전문적으로 설명하기 때문에 저 같은 일반인이 읽기에는 어려운 부분이 많습니다. 특히 용어에 대한 정의 없이 본론으로 들어가는 책들이 많은데 그럴 경우 읽어 나가다가 맥락을 놓치게 되고 결국 이해를 포기하게 됩니다. 반면에 이 책은 초반에 용어 정리부터 후반에 실전 예제까지 잘 갖춰진 기술 서적이었습니다.  얼마전에도 머신러닝에 대한 책을 한 권 골랐습니다. 그 책을 읽어 나가다가 결국 포기를 했었습니다. 그 이유는 책의 내용을 수식으로 설명하려 했기 때문입니다. 수학을 싫어하지는 않습니다만 고도의 상징체계를 사용하고 있는 수학은 어떤 패턴을 효율적으로 표현할 수는 있지만 그것을 활자로 인식했을 때 이해하기에는 어렵습니다. 하지만 수학의 바탕 위에 세워진 인공지능 기술인 만큼 수식 없이는 말할 수 없는 영역도 존재합니다. 꼭 필요한 부분에서는 수학을 사용하고 그 세부적인 학습은 독자에게 맞기는 것 그 절제의 균형을 잡는 것이 저자의 역량이 아닌가 합니다.  처음 배우는 머신러닝 기술 서적을 읽은 만큼 기술의 한 요소를 소개하고 넘어가겠습니다. 바로 손실함수 입니다.  이 책에서 정의하고 있는 손실 함수는 다음과 같습니다. 모델이 실제로 데이터를 바르게 표현했는지 혹은 얼마나 예측이 정확한지 수학적으로 표현하는 것이 손실 함수입니다. 처음 배우는 머신러닝  p. 58  즉 데이터를 통해 머신러닝이 만든 모델이 어떤 데이터를 입력받아 만들어낸 출력이 제대로 예측 했는지 또는 얼마나 틀렸는지 보여주는 함수라는 뜻인 것 같습니다. 결국 손실 함수는 답을 알고 있다는 뜻이 됩니다. 그럼 모델을 통해 예측할 필요가 없는 게 아닌가 하는 의구심이 들지만 더 이상의 기술에 대한 철학적 접근을 했다가는 뇌가 망가질 것 같아 여기서 멈추어야 할 것 같습니다. 그 언젠가 머신러닝을 제대로 공부한 분을 만나게 된다면 한번 여쭤 보고 싶은 부분이기도 합니다.  예전에 어디서 주워들은 표현으로 ‘그 분야를 알기 위해서는 개론서 열권을 읽으면 된다’라는 말을 들은 적이 있습니다. 인공지능 분야는 앞으로 어디까지 발전하게 될지 알 수 없는 분야이기도 하고 연구된 지 오래되어 많은 개론서 교양서들이 나와있는 분야이기도 합니다. 앞으로도 꾸준히 관련 책을 읽을 수 있을 것 같아 기대됩니다.  정말 잘 정리된 머신러닝 기술서 ‘처음 배우는 머신러닝’ 이었습니다. 2019/10/29 - [하루 책읽기/하루 기술서] - 딥러닝 첫걸음 - 인공지능 이해하기 딥러닝 첫걸음 - 인공지능 이해하기딥러닝 첫걸음 새로운 개념에 익숙해지기 알파고의 바둑 승리 이후 인공지능에 대한 관심이 높아졌습니다. 하지만 인공지능이라는 주제 자체게 어려운 것이다 보니 책을 구해 읽어 보아도 머릿속에 잘 그려지지..jisungs.tistory.com2019/05/10 - [하루 책읽기/하루 기술서] - 생각하는 프로그래밍 #2 - 엔지니어의 직업정신 생각하는 프로그래밍 #2 - 엔지니어의 직업정신생각하는 프로그래밍 #2 엔지니어의 직업정신 프로그래머의 입장에서 생각해야 할 것들을 수필의 형태로 정리한 책을 읽고 있습니다. 컴퓨터라는 분야가 생긴지 얼마 되지 않아 그렇게 오래 되었다고 할 수는 없..jisungs.tistory.com2019/01/29 - [하루 책읽기/하루 기술서] - 알고리즘 문제해결 전략 - 어떻게 문제를 해결 할 것인가? 알고리즘 문제해결 전략 - 어떻게 문제를 해결 할 것인가?알고리즘 문제해결 전략 어떻게 문제를 해결할 것인가? 저는 학창시절 수학을 못하는 학생이었습니다. 저를 가르쳤던 많은 선생님들은 이과 보다는 문과를 추천하셨고 저는 그런 주변 사람들의 반응이 싫었습니다..jisungs.tistory.com반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jisungs.tistory.com/reaction';window.ReactionReqBody = {    entryId: 447}공유하기게시글 관리Jisung's Story저작자표시 비영리 변경금지 'jisung's 책읽기 > 기술서' 카테고리의 다른 글강화학습 첫걸음 - 새로운 지식의 무거운 첫걸음  (0)2019.12.05텐서플로 첫걸음 - IT거인의 빅피쳐  (0)2019.11.26딥러닝 첫걸음 - 인공지능 이해하기  (0)2019.10.29생각하는 프로그래밍 #2 - 엔지니어의 직업정신  (0)2019.05.10생각하는 프로그래밍 - Programming Pearls 2/E  (1)2019.05.05태그구글, 김승연지음, 머신러닝, 손실함수, 인공지능, 정용주 지음, 처음 배우는 머신러닝, 한빛미디어관련글강화학습 첫걸음 - 새로운 지식의 무거운 첫걸음텐서플로 첫걸음 - IT거인의 빅피쳐딥러닝 첫걸음 - 인공지능 이해하기생각하는 프로그래밍 #2 - 엔지니어의 직업정신댓글0비밀글등록loadedComments[447]=true;findFragmentAndHighlight(447);"
48,https://benn.tistory.com/32,Tag,"                                                  Bee's 데이터 과학                              홈태그방명록Data Science | AI/Python데이터 분석에 쓰이는 파이썬 라이브러리 소개Letter_B2021. 9. 24. 14:21728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});이번 글에서는 데이터 분석에 자주 쓰이는 패키지를 소개하겠습니다.데이터 분석을 위한 라이브러리 NumPyNumPy (넘파이)는 Numerical Python (""숫자 파이썬"")의 약자로 수치 연산을 수행하는 데 사용되는 라이브러리입니다. 넘파이만의 배열 자료구조 (ndarray)를 이용해 파이썬의 기본 리스트와 딕셔너리보다 빠르게 수치계산을 할 수 있습니다.예제) 아래는 파이썬 range와 넘파이의 arange 함수를 이용하여 숫자 0부터 100만까지 생성한 후, 모든 수의 제곱을 계산하는 데에 걸리는 시간을 비교해본 것입니다. 넘파이의 배열이 훨씬 더 빠르게 계산이 되는 걸 확인할 수 있습니다.파이썬 리스트 &amp;amp; 반복문 vs 넘파이 배열 계산 속도 비교pandas판다스는 데이터 처리 및 분석을 위해 만들어진 패키지입니다. SQL 테이블이나 엑셀 같이 표 형식으로 되어있는 데이터 처리 및 분석에 용이하고 빨라서 자주 쓰이는 패키지입니다. 예제) 표 형식의 데이터. 파이썬에서는 DataFrame 객체라고 불립니다.출처: geeksforgeeks.orgmatplotlib파이썬의 대표적인 데이터 시각화 라이브러리입니다. 웹사이트에서 다양한 차트와 코드를 확인할 수 있습니다. 출처: https://matplotlib.org/SciPySciPy (사이파이)는 과학 컴퓨팅을 위한 수학 라이브러리입니다. 수학, 과학, 엔지니어링 분야에서 많이 쓰이며 분야에 따라 subpackage가 존재합니다. SciPy subpackages:- scipy.io: 다양한 파일을 읽고 쓰는 데에 사용됨- scipy.linalg: 선형 대수에 쓰이는 패키지- scipy.stats: 다양한 통계 검사 및 기술 통계에 사용됨scikit-learn가장 많이 쓰이는 머신러닝 라이브러리입니다. 분류, 회귀, 클러스터링, 차원 축소 등 다양한 머신러닝 모델링이 가능합니다.예제) scikit-learn의 다양한 분류 classifier출처: scikit-learn.org위 패키지들은 자주 사용되는 패키지로서 Anaconda 배포반을 설치하면 같이 자동으로 설치가 됩니다. 아래 글에서 아나콘다 설치법을 확인하실수 있습니다.https://benn.tistory.com/26 [Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인아나콘다 Anaconda 아나콘다 (Anaconda)는 파이썬을 포함한 데이터 과학에 필요한 다양한 언어 및 패키지의 배포입니다. 프로젝트마다 다른 환경을 만드는데도 편리하고 환경마다 필요한 패키지를benn.tistory.com이 외에도 keras, statsmodels, plotly, seaborn 등 더 많은 패키지가 존재하지만 데이터 분석을 처음 접할 때 자주 쓰이는 패키지 위주로 간단히 설명해보았습니다. 데이터 분석 공부를 하다 보면 자연스럽게 이것저것 찾아가며 익숙하게 쓰이게 되는 패키지들입니다. 오타나 질문은 댓글로 남겨주세요 :)728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//benn.tistory.com/reaction';window.ReactionReqBody = {    entryId: 32}공유하기게시글 관리Bee's 데이터 과학저작자표시 'Data Science | AI > Python' 카테고리의 다른 글[파이썬] 파이 차트 그리기 (feat. matplotlib)  (0)2021.11.04[파이썬/matplotlib]  선 그래프 그리기 + 테마 (스타일 시트) 설정  (0)2021.09.27[파이썬] 판다스 pandas csv 파일 불러오기 &  데이터 살펴보기  (0)2021.09.23[데이터 분석] 파이썬 Pandas 행, 열 삭제  (0)2021.06.27[Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인  (0)2021.06.17Tagnumpy, pandas, scipy, 데이터 분석, 라이브러리, 머신러닝, 파이썬'Data Science | AI/Python'의 다른글이전글[파이썬] 판다스 pandas csv 파일 불러오기 &  데이터 살펴보기현재글데이터 분석에 쓰이는 파이썬 라이브러리 소개다음글[파이썬/matplotlib]  선 그래프 그리기 + 테마 (스타일 시트) 설정관련글[파이썬] 파이 차트 그리기 (feat. matplotlib)2021.11.04[파이썬/matplotlib]  선 그래프 그리기 + 테마 (스타일 시트) 설정2021.09.27[파이썬] 판다스 pandas csv 파일 불러오기 &  데이터 살펴보기2021.09.23[데이터 분석] 파이썬 Pandas 행, 열 삭제2021.06.27댓글 0댓글비밀글등록loadedComments[32]=true;findFragmentAndHighlight(32);반응형(adsbygoogle = window.adsbygoogle || []).push({});👋  저는 시드니에서 거주하는 데이터 과학자입니다. 현재 컴퓨터 비전 관련 일을 하고 있습니다. 분류 전체보기 (54)  Data Science | AI (44)  머신러닝 및 딥러닝 (8)  논문 리뷰 (0)  통계, 수학 (5)  Python (17)  R (5)  SQL (4)  클라우드 (2)  데이터 시각화 (3)  Web development (7)  웹 분석 (1)  알고리즘 (1)  Career Journal (3)  TIL (0) Tag라이브러리,다운로드,통계,데이터분석,설치,CSS,데이터 과학,판다스,데이터 분석,pandas,데이터과학,파이썬,PYTHON,sql,통계학,딥러닝,머신러닝,머신러닝 논문,데이터 시각화,R,최근글과 인기글최근글인기글[머신러닝] 생성적 적대 신경망 Generative Adversarial Network (GAN) 정리2024.06.27 15:55머신러닝/딥러닝 논문 읽는 방법 (앤드류 응 교수님법)2024.06.21 10:58[딥러닝 / 수학] 코사인 유사도 cosine similarity 이해하기2024.06.21 09:10[Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인2021.06.17 12:16비주얼 스튜디오 테마 추천 및 변경하기2023.02.16 11:36비주얼 스튜디오 코드 폰트 바꾸기, 크기 바꾸기 + 코딩용 폰트 추천!2023.02.17 08:56최근댓글안녕하세요!저도 OMSA 시작할 때 파이썬 완전 초보였어요! 지원 당시, 본문에 언⋯ Letter_B안녕하세요!OMSA을 알고나서 관심을 가지고 서치하다가 들어왔습니다. 자세한 후기 감사드⋯ Sophia잘~ 보고갑니다 김도훈공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/062024/052024/012023/082023/062023/042023/022022/112022/102022/08Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total435,663Today : 149Yesterday : 502블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트티스토리툴바Bee's 데이터 과학구독하기                    (function () {                         var blogTitle = 'Bee\'s 데이터 과학';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4565392-32"",""customProps"":{""userId"":""0"",""blogId"":""4565392"",""entryId"":""32"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""32"",""entryTitle"":""데이터 분석에 쓰이는 파이썬 라이브러리 소개"",""entryType"":""POST"",""categoryName"":""Data Science | AI/Python"",""categoryId"":""487723"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4648833"",""authorNickname"":""Letter_B"",""blogNmae"":""Bee's 데이터 과학"",""image"":""kage@v2O5e/btrf5iZNuCL/w43NDL7m3bqepTvLA9cm9K"",""plink"":""/32"",""tags"":[""numpy"",""pandas"",""scipy"",""데이터 분석"",""라이브러리"",""머신러닝"",""파이썬""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
49,https://bcho.tistory.com/1301,IDE 환경,"                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝쿠버네티스 기반의 End2End 머신러닝 플랫폼 Kubeflow #1 - 소개Terry Cho2019. 1. 9. 00:41End2End 머신러닝 플랫폼 Kubeflow조대협 (http://bcho.tistory.com)머신러닝 파이프라인머신러닝에 대한 사람들의 선입견중의 하나는 머신러닝에서 수학의 비중이 높고, 이를 기반으로한 모델 개발이 전체 시스템의 대부분 일 것이라는 착각이다.그러나 여러 연구와 경험을 참고해보면, 머신러닝 시스템에서 머신러닝 모델이 차지하는 비중은 전체의 5% 에 불과하다.실제로 모델을 개발해서 시스템에 배포할때 까지는 모델 개발 시간보다 데이타 분석에 소요되는 시간 그리고 개발된 모델을 반복적으로 학습하면서 튜닝하는 시간이 훨씬 더 길다. 머신러닝 파이프라인은 데이타 탐색에서 부터, 모델 개발, 테스트 그리고 모델을 통한 서비스와 같이 훨씬 더 복잡한 과정을 거친다. 이를 머신러닝 End to End 파이프라인이라고 하는데, 자세하게 그 내용을 살펴보면 다음 그림과 같다. Data ingestion : 머신러닝에 필요한 학습 데이타를 외부로 부터 받아서 저장하는 단계Data analytics : 수집된 데이타를 분석하여, 의미를 찾아내고,필요한 피쳐(특징)을 찾아내는 단계로 주로 빅데이타 분석 시스템이 많이 활용된다. EDA (Exploratory Data Analytics) 방법을 많이 사용하는데, 저장된 데이타를 그래프로 시각화해서 각 값간의 관계나 데이타의 분포등을 분석한다. Data Transformation : 수집된 데이타에서 학습에 필요한 데이타만 걸러내고, 학습에 적절하도록 컨버팅 하는 단계. 예를 들어 이미지 데이타의 크기를 정형화하고, 크롭핑 처리를 한후에, 행렬 데이타로 변환하는 과정등이 이에 해당한다.Data Validation : 변환된 데이타가 문제는 없는지 데이타 포맷이나 범위등을 검증하는 단계Data Splitting : 머신러닝 학습을 위해서 데이타를 학습용,테스트용,검증용으로 나눈다.Build a Model : 머신러닝 모델을 만들고 학습하는 단계Model Validation : 만들어진 모델을 검증하는 단계Training at scale : 더 많은 데이타를 더 큰 인프라에서 학습 시켜서 정확도를 높이고, 하이퍼 패러미터 튜닝을 통해서 모델을 튜닝하는 단계로 주로 대규모 클러스터나 GPU 자원등을 활용한다.Roll out : 학습된 모델을 운영환경에 배포하는 단계Serving : 배포된 모델을 통해서 머신러닝 모델을 서비스로 제공하는 형태. 유스케이스에 따라서 배치 형태로 서빙을 하거나 실시간으로 서빙하는 방법이 있다.Monitoring : 머신러닝 모델 서비스를 모니터링 해서 정확도등에 문제가 없는지 지속적으로 관찰하는 단계Logging : 모델에 서비스에 대한 로그 모니터링이 과정을 데이타의 변동이 있거나 모델을 향상시키고자 하거나 정확도가 떨어지는 경우 첫번째 과정부터 반복을 한다. 위에서 설명한 파이프라인 흐름을 시스템 아키텍쳐로 표현해보면 다음과 같다. 먼저 GPU를 지원하는 인프라 위에 머신러닝 플랫폼이 올라가게 되고, 빅데이타 분석 플랫폼이 같이 사용된다.머신러닝 플랫폼은 데이타를 분석하는 EDA 단계의 데이타 분석 플랫폼 그리고, 분석된 데이타를 변환 및 검증하고 학습,테스트,검증 데이타로 나누는 Data Processing 시스템이 붙고, 이 데이타를 이용해서, 모델을 개발한후에, 이 모델을 학습 시키기 위한 학습 (Training) 플랫폼이 필요하다. 학습된 모델을 검증하고, 이 검증 결과에 따라서 하이퍼 패러미터를 튜닝한 후에, 이를 운영환경에 배포하여 서비스 한다. 데이타 분석 및 모델 개발 학습 단계는 주로 데이타 사이언티스트에 의해서 이루어지는데, 이러한 엔지니어들이 사용할 개발 환경이 필요한데, 주로 노트북 기반 (예. 파이썬 주피터 노트북)의 환경이 많이 사용된다.학습이 완료된 모델을 서빙하는 Inference 엔진이 필요하고, 이를 외부 API로 노출하기 위해서 API 키 인증, 오토스케일링, 로깅 및 모니터링을 위한 API Serving 플랫폼이 필요하다. 컴포넌트가 많은 만큼 여기에 사용되는 프레임웍도 많다. 먼저 모델 개발 및 학습을 위해서는 머신러닝 프레임웍이 필요한데, Tensorflow, PyTorch, Sklearn, XGBoost등 목적에 따라서 서로 다른 프레임웍을 사용하게 되며, 완성된 모델을 서빙하는 경우에도 Tensorflow Serving, Uber에서 개발한 Horovod 등 다양한 플랫폼이 있다. 또한 모델을 서빙할때 REST API등으로 외부에 서비스 하려면 보안 요건에 대한 처리가 필요하기 때문에 별도의 API 인증 메커니즘등이 추가되어야 하고, 스케일링을 위한 오토 스케일링 지원 그리고 모델의 배포와 테스트를 위한 배포 프레임웍, A/B 테스트 환경등이 준비되어야 한다. 일부만 이야기한것이지만 실제 운영 환경에서 사용되는 머신러닝 시스템은 훨씬 더 복잡하고 많은 기술을 필요로 한다.Kubeflow comes in이러한 복잡성 때문에 머신러닝 플랫폼은 높은 난이도를 가지고 있고, 데이타 분석과 모델 개발에 집중해야 하는 머신러닝 엔지니어 입장에서는 큰 부담이 된다. (배보다 배꼽이 크다)그래서 이러한 복잡성을 줄이고 머신러닝 엔지니어의 원래 업인 데이타 분석과 머신러닝 모델 개발에만 집중할 수 있도록 플랫폼을 추상화 해놓은 오픈 소스 프레임웍이 Kubeflow이다. 위에서 설명한 머신러닝 파이프라인의 End to End 전체를 커버할 수 있게 하고, 모든 단계의 컴포넌트를 패키지화 해놔서, 어려운 설치 없이 머신러닝 엔지니어는 머신러닝 모델 개발의 각 단계를 손쉽게 할 수 있도록 해준다. Kuberflow는 Kubernetes(쿠버네티스) + ml flow 를 합한 의미로, 쿠버네티스 플랫폼 위에서 작동한다.쿠버네티스는 도커 컨테이너 관리 플랫폼으로, 이 컨테이너 기술을 이용하여 머신러닝에 필요한 컴포넌트를 패키징하여 배포한다. 쿠버네티스에 대한 자세한 설명은 링크를 참고하기 바란다. 이로 인해서 가질 수 있는 장점은 다음과 같다.클라우드나 On-Prem (데이타 센터), 개인 개발 환경에 상관 없이 동일한 머신러닝 플랫폼을 손쉽게 만들 수 있기 때문에 특정 벤더나 플랫폼에 종속되지 않는다. 컨테이너 기술을 이용해서 필요한 경우에만 컨테이너를 생성해서 사용하고, 사용이 끝나면 컨테이너를 삭제하는 방식이기 때문에 자원 활용율이 매우 높다. 특히 쿠버네티스의 경우에는 스케쥴링 기능을 이용해서 비어있는 하드웨어 자원에 컨테이너를 배포해서 (꾸겨넣는 방식으로) 사용하기 때문에 집적률이 매우 높다. 컨테이너로 패키징이 되어있기 때문에 내부 구조를 알필요가 없이 단순하게 컨테이너만 배포하면 된다. 또한 쿠버네티스는 오픈소스 플랫폼이기 때문에 여러 종류의 머신러닝 관련 기술들이 손쉽게 합쳐지고 있다. Kubeflow 컴포넌트 구성그러면 간단하게 Kubeflow의 컴포넌트 구성을 살펴보자.IDE 환경IDE 개발환경으로는 JupyterLab을 지원한다. JupyterLab은 Jupyter 노트북의 확장 버전으로 코드 콘솔뿐 아니라 파일 브라우져나 시각화창등 확장된 UI를 지원한다. <출처 : https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html>개인적으로 기존 노트북 환경에 비해서 좋은 점은 주피터 노트북을 필요할때 마다 손쉽게 생성이 가능하며, 생성할때 마다 GPU 지원 여부나 텐서플로우 버전등을 손쉽게 선택이 가능하다. <그림. 노트북 생성시 텐서플로우와 GPU 지원 여부를 선택하는 화면>또한 아래 그림과 같이 노트북 인스턴스의 하드웨어 스펙 (CPU, Memory, GPU)를 정의할 수 있다. GPU 드라이버그리고 쿠버네티스상에서 GPU를 사용할 수 있도록 GPU 드라이버를 미리 패키징 해놓았다. 머신러닝 프레임웍을 사용하면 항상 까다로운 부분이 GPU 드라이버 설정이나 업그레이드인데, 이를 미리 해놓았기 때문에 머신러닝 엔지니어 입장에서 별도의 노력없이 손쉽게 GPU를 사용할 수 있다.머신러닝 프레임웍머신러닝 프레임웍으로는 현재 텐서플로우, 파이토치, MxNet등을 지원하는데, 플러그인 컴포넌트 형태이기 때문에 앞으로 더 많은 프레임웍을 지원할 것으로 기대된다. 데이타 프로세싱데이타 프로세싱에서 데이타 변환 (Transformation)과 데이타 검증 (Validation)은 텐서플로우의 확장팩인 TFX에서 지원하는 TFDV (Tensorflow Data Validation)과 TFT (Tensorflow Transform)을 이용해서 지원한다.학습 환경개발된 모델을 학습할때 특히 분산학습의 경우에는 텐서플로우 클러스터와 우버에서 개발된 텐서플로우용 분산 학습 플랫폼인 Hornovod를 지원한다.  모델 검증학습된 모델 검증은 데이타 프로세싱과 마친가지로 텐서플로우 확장팩인 TFX의 TFMA (Tensorflow Model Analysis)를 지원한다.하이퍼 패러미터 튜닝학습된 모델에 대한 하이퍼 패레미터 튜닝은 katLib라는 컴포넌트를 이용해서 지원한다. 모델 서빙학습이 완료된 모델은 TFX 패키지의 일부인 Tensorflow Serving 을 사용하거나 모델 서빙 전문 플랫폼인 SeldonIO를 사용한다. SeldonIO는 텐서플로우뿐만 아니라 Sklearn, Spark 모델, H2O 모델, R 모델등 좀 더 다양한 모델을 지원한다. API 서비스서비스된 모델에 대한 API 키 인증이나 라우팅등을 위해서 API 게이트 웨이가 필요한데, API 게이트 웨이로 Ambassador라는 오픈 소스를 이용한다. 이를 통해서 API 키등의 인증을 지원하고, 쿠버네티스 위에 네트워크 플랫폼인 ISTIO를 사용하여, API 서비스에 대한 모니터링 및 서비스 라우팅을 지원하는데, 서비스 라우팅 기능은 새 모델을 배포했을때 새모델로 트래픽을 10%만 보내고 기존 모델로 트래픽을 90% 보내서 새모델을 테스트하는 카날리 테스트나 API 통신에 대한 보안등 여러기능을 지원한다. Istio에 대한 자세한 설명은 링크를 참조하기 바란다. 워크플로우이러한 컴포넌트를 매번 메뉴얼로 실행할 수 는 없고, 워크플로우 흐름에 따라서 자동으로 파이프라인을 관리할 수 있는 기능이 필요한데, 이를 워크플로우 엔진이라고 하고, Kubeflow에서는 argo라는 컨테이너 기반의 워크플로우 엔진을 사용한다. 자세한 내용은 링크 참조.그런데 argo는 일반적인 워크플로우를 위해서 디자인된 플랫폼으로 머신러닝 파이프라인에 최적화되어 있지 않다. (예를 들어 학습 단계 종료후, 학습 결과/accuracy등을 모니터링 한다던지, Tensorflow Dashboard와 통합된다던지.) 그래서 argo위해 머신러닝 기능을 확장하여 개발중인 오픈소스가 Kubeflow pipeline이 있다. Kubeflow pipeline에 대해서는 나중에 더 자세히 설명하도록 한다. 컴포넌트에 대한 정의Kubeflow에서 사용되는 거의 모든 컴포넌트에 대해서 설명하였다. 그러면 이런 컴포넌트를 어떻게 쿠버네티스에 배포하고, 어떻게 실행을 할것인가? 매번 쿠버네티스의 설정 파일을 만들어서 하기에는 파일의 수도 많고 반복작업이면서 또한 쿠버네티스에 대한 높은 전문성을 필요로하기 때문에 어렵다.그래서 이러한 반복작업을 줄여주고, 템플릿화하여 실행하도록 해주는 엔진이 ksonnet 이라는 오픈소스를 사용한다. ksonnet은 jsonnet 템플릿 엔진 기반으로, 위에서 나열한 컴포넌트들을 쿠버네티스에 설치할 수 있도록 해주고, 각 단계별 컴포넌트를 손쉽게 실행할 수 있도록 해준다.이 솔루션들을 앞에서 설명한 머신러닝 플랫폼 아키텍쳐에 맵핑 시켜보면 다음과 같은 그림이 된다.Kubeflow는 현재 개발중인 버전으로 이글을 쓰는 현재 0.4 버전이 개발중이다. 컨셉적으로 매우 훌륭하고 0.4 버전인것에 비해서는 매우 완성도가 높지만 1.0 릴리즈 전이기 때문에 다소 변화가 심하기 때문에 버전간 호환이 안될 수 있다. 이점을 염두하고 사용하기 바란다.Kubeflow를 이해하기 위해서는 먼저 Kubeflow의 컴포넌트를 배포하고 실행하게 해주는 ksonnet에 대한 이해가 먼저 필요하다. 다음 글에서는 이 ksonnet에 대해서 알아보도록 하겠다. window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1301}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글자연어 처리 - 단어 표현 방법  (0)2019.08.04AutoEncoder vs Variant AutoEncoder  (0)2019.05.10AutoEncoder (오토 인코더) 기반 추천 엔진  (0)2018.01.06K Fold Cross Validation  (0)2018.01.02Apache Beam (Dataflow)를 이용하여, 이미지 파일을 tfrecord로 컨버팅 하기  (0)2018.01.01TagDeep learning, end2end, Istio, katlib, kubeflow, Machine Learning, production, seldonio, tensorflow, TFX, 노트북, 딥러닝, 머신러닝, 아키텍쳐, 운영환경, 조대협, 주피터, 쿠버네티스, 텐서플로우'빅데이타 & 머신러닝/머신러닝'의 다른글이전글AutoEncoder (오토 인코더) 기반 추천 엔진현재글쿠버네티스 기반의 End2End 머신러닝 플랫폼 Kubeflow #1 - 소개다음글AutoEncoder vs Variant AutoEncoder관련글자연어 처리 - 단어 표현 방법2019.08.04AutoEncoder vs Variant AutoEncoder2019.05.10AutoEncoder (오토 인코더) 기반 추천 엔진2018.01.06K Fold Cross Validation2018.01.02loadedComments[1301]=true;findFragmentAndHighlight(1301);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag머신러닝,딥러닝,tensorflow,강좌,cloud,node.js,조대협,구글,초보,Machine Learning,튜토리얼,빅데이타,Kubernetes,클라우드 컴퓨팅,google,쿠버네티스,클라우드,Tutorial,소개,텐서플로우,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1301"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1301"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1301"",""entryTitle"":""쿠버네티스 기반의 End2End 머신러닝 플랫폼 Kubeflow #1 - 소개"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":""cfile6.uf@994FF14C5C34C41711358A.png"",""plink"":""/1301"",""tags"":[""Deep learning"",""end2end"",""Istio"",""katlib"",""kubeflow"",""Machine Learning"",""production"",""seldonio"",""tensorflow"",""TFX"",""노트북"",""딥러닝"",""머신러닝"",""아키텍쳐"",""운영환경"",""조대협"",""주피터"",""쿠버네티스"",""텐서플로우""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
50,https://bcho.tistory.com/1139,"코스트 함수의 최소값을 찾는 알고리즘을 옵티마이져(Optimizer)라고 하는데, 상황에 따라 여러 종류의 옵티마이져를 사용할 수 있다. 여기서는 경사 하강법 (Gradient Descent) 라는 옵티마이져에 대해서 소개하도록 하겠다.경사 하강법","                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝수학포기자를 위한 딥러닝-#2 머신러닝 개념 이해Terry Cho2016. 10. 4. 15:29수포자를 위한 딥러닝#2 - 선형회귀분석을 통한 머신러닝의 기본 개념 이해조대협 (http://bcho.tistory.com)Linear Regression을 통한 머신 러닝의 개념 이해거리에 따른 택시 요금 문제머신러닝이란 무엇일까? 개념 이해를 돕기 위해서 선형 회귀 (Linear Regression)이라는 머신러닝 모델을 보자.먼저 선형 회귀 (Linear regression)이 무엇인지 부터 이해를 해야 하는데, 쉽게 설명하자면 결과값 (output value)이 있고 그 결과값을 결정할 것이라고 추정되는 입력값 (input value)과 결과 값의 연관관계를 찾는 것이고 이를 선형 관계를 통해 찾는 방법이 선형 회귀 (Linear regression)이다.  예를 들어서 설명해보자, 택시 요금을 예로 들어보자,택시 요금은 물론 막히냐 마냐에 따라 편차가 있지만, 대부분 거리에 비례해서 요금이 부과된다. 그래서 결과값 (요금)과 입력값 (거리)의 관계를 찾아야 한다.거리별 요금을 그래프로 나타내보면 대략 다음과 같은 분포를 띄게 된다원본 데이타의 거리를 x_data 그리고, 그 거리에서 측정된 택시 요금을 y_origin 이라고 하자. 가설 (Hypothesis) 정의거리와 요금이 서로 비례하기 때문에, 거리(x_data)와 요금(y_data)간의 상관 관계는 다음과 같이 일차 방정식과 형태의 그래프를 그리게 된다고 가정하자. W (Weight)는 그래프의 각도, b는 bias를 뜻한다y_data = Wx_data + b이 일차 방정식 형태로 대충 1차원 그래프를 그려보자 같은 형태로 아래와 같이 그래프를 그려봤다.그래프를 그려보니 그래프의 각이 안맞는것 같다. 그래프의 각도와 높이를 보정해보자그래프를 보정했지만 또 안 맞는 것 같다. 그렇다면 최적의 그래프의 각도 W와, 높이 B는 어떻게 찾아야 하는 것일까?코스트(비용) 함수우리가 구하고자 하는 그래프는 실제 값에서 그래프의 값까지 차이가 가장 작은 값을 구하고자 하는 것이다. 아래 그림을 보자, 아래와 같이 y_data=Wx_data +b와 같은 그래프를 그렸다고 하자.원래 값에서 우리가 예측한 값의 차이는 (원래값과 계산된 값의 차이) = 측정값 - 그래프의 값인데, 차이를 d라고 하자. 그리고 그래프에 의해서 계산된 값은 y_data라고 하면 택시 거리 x_data 에서 원래 측정된 값을 y_orgin라고 해서 수식으로 나타내면,  d = y_data - y_origin이 된다. 이때 측정값은 여러개가 있기 때문에 n이라고 하면  n번째 측정한 택시비와 산식에 의해서 예측된 값의 차이는 dn이 된다.dn = y_data_n - y_origin_n즉 우리가 구하고자 하는 값은 dn의 합이 최소가 되는 W와 b의 값을 구하고자 하는 것이다.다르게 설명하면 실제 측정한값과, 예측한 값의 차이가 최소가 되는 W와 b를 구하고자 하는 것이다.dn은 위의 그래프에서 처럼 그래프 위에도 있을 수 있지만 (이경우 dn은 양수), 그래프 아래에도 있을 수 있기 때문에, (이경우 dn은 음수). 합을 구하면, 예측 선에서의 실측값 까지의 거리의 합이 되지 않기 때문에, dn에 대한 절대값을 사용한다고 하자.그리고 n이 측정에 따라 여러개가 될 수 있기 때문에, 평균을 사용하자. ( ABS(d1)+ABS(d2)+ABS(d3)+.....+ABS(dn)) ) / n즉 우리가 구하고자 하는 W와 b는 위의 함수의 값이 최소가 되는 값을 구하면 된다.이렇게 측정된 값에서 연산된 값간의 차이를 연산하는 함수를 비용 함수 또는 영어로 코스트 함수 (Cost function이라고 한다.사람이 일일이 계산할 수 없이니 컴퓨터를 이용해서 W=0.1,0.2,0.3,.... b=0.1,0.2,0.3,..... 식으로 넣어보고 이 코스트 함수가 가장 최소화되는 W와 b의 값을 찾을 수 있다.옵티마이져 (Optimizer)코스트 함수의 최소값을 찾는 알고리즘을 옵티마이져(Optimizer)라고 하는데, 상황에 따라 여러 종류의 옵티마이져를 사용할 수 있다. 여기서는 경사 하강법 (Gradient Descent) 라는 옵티마이져에 대해서 소개하도록 하겠다.경사 하강법그러면 W와 b를 구할때 W와 b를 어떤식으로 증가 또는 감소 시켜서 코스트 함수의 최소값을 가장 효율적으로 찾아낼 수 있을까? 위에서 언급한것 처럼 W를 0.0에서 부터 ). 0.1씩 증가시켜나가고 b도 같이 0.0에서 부터 1씩 증가 시켜 나갈까? 무한한 컴퓨팅 자원을 이용하면 되기는 하겠지만, 이렇게 무식하게 계산하지는 않는다.코스트 함수를 최적화 시킬 수 있는 여러가지 방법이 있지만, Linear regression의 경우에는 경사 하강법 (그레이언트 디센트 : Gradient descent)라는 방식을 사용한다. 경사하강법에 대해서는 자세하게 알필요는 없고 ”대략 이런 개념을 사용하는 구나” 하는 정도만 알면 된다. 경사 하강법을 사용하기 위해서는 위의 코스트 함수를,측정값과 예측값의 절대값의 평균이 아니라 평균 제곱 오차라는 함수를 사용한다. 이 함수는 형식으로 정의되는데, 평균 제곱 오차 함수 (Mean square error function)이라고 한다. Cost =  Sum( (y_data_n - y_origin_n) ^ 2) / n풀어서 설명하면, n 번째의 원래데이타(y_origin_n)와 예측 데이타(y_data_n)의 차이를 제곱(^2)해서, 이 값을 n으로 나눈 평균 값이다. 즉 이 Cost가 최소가 되는 W와 b값을 구하면 된다. 편의상 W하나만을 가지고 설명해보자. 위의 그래프를 W와 b에 대한 상관 그래프로 그려보면 다음과 같은 함수 형태가 된다. 이 그래프에서 W에 대한 적정값에 대한 예측을 시작하는 점을 위의 그림에서 파란 점이라고 하면, 경사 하강법은 현재 W의 위치에 대해서, 경사가 아래로 되어 있는 부분으로 점을 움직이는 방법이다. 어느 방향으로 W를 움직이면 Cost 값이 작아지는지는 현재 W위치에서 비용 함수를 미분하면 된다. (고등학교 수학이 기억이 나지 않을 수 있겠지만 미분의 개념은 그래프에서 그 점에 대한 기울기를 구하는 것이다. )이렇게, 경사를 따라서 아래로 내려가다 보면 Cost 함수가 최소화가 되는 W 값을 찾을 수 있다. 이렇게 경사를 따라서 하강 (내려가면서) 최소값을 찾는다고 하여 경사 하강법이라고 한다.  학습 코스트 함수가 정의 되었으면  실제 데이타 x_data_n과 y_data_n을 넣어서 경사하강법에 의해서 코스트 함수가 최소가 되는 W와 b를 구한다. 이 작업은 W값을 변화시키면서 반복적으로 x_data_n로 계산을 하여, 실제 측정 데이타와 가설에 의해서 예측된 결과값에 대한 차이를 찾아내고 최적의 W와 b값을 찾아낸다.예측학습 과정에 의해서 최적의 W와 b를 찾았으면 이제, 이 값들을 이용해서 예측 해보자학습에 의해서 찾아낸 W가 1600, b가 2000이라고 하면, 앞의 가설에서 정의한 함수는 Wx*b였기 때문에, 예측 함수는 y = Wx +b거리에 따른 택시비 = W*(거리) + b거리에 따른 택시비 = 1600 * (거리) + 2000이 되고, 이를 학습된 모델 이라고 한다.이제 예측을 수행해보자, 거리가 10km일 때 택시비는 얼마일까? 공식에 따라택시비 = 1600 * 10km + 2000으로, 18000원이 된다.머신 러닝의 순서지금까지 택시 거리와 택시비에 대한 문제를 가지고 머신 러닝에 대한 기본 원리를 살펴보았다.이를 요약해서 머신 러닝이란 것이 어떤 개념을 가지고 있는지 다시 정리해보자.기본 개념은 데이타를 기반으로해서 어떤 가설 (공식)을 만들어 낸 다음, 그 가설에서 나온 값이 실제 측정값과의 차이(코스트 함수)가 최소한의 값을 가지도록 변수에 대한 값을 컴퓨터를 이용해서 찾은 후, 이 찾아진 값을 가지고 학습된 모델을 정의해서 예측을 수행 하는 것이다.  학습 단계즉 모델을 만들기 위해서, 실제 데이타를 수집하고, 이 수집된 데이타에서 어떤 특징(피쳐)를 가지고 예측을 할것인지 피쳐들을 정의한 다음에, 이 피쳐를 기반으로 예측을 한 가설을 정의하고, 이 가설을 기반으로 학습을 시킨다.예측 단계학습이 끝나면 모델 (함수)가 주어지고, 예측은 단순하게, 모델에 값을 넣으면, 학습된 모델에 의해서 결과값을 리턴해준다.지금까지 Linear regression 분석을 통한 머신러닝의 원리에 대해서 간략하게 알아보았다. 다음 다음장에서는 이 모델을 어떻게 프로그래밍 언어를 이용하여 학습을 시키고 운영을 하는지에 대해서 알아보도록 하겠다.Thanx to 이글은 딥러닝 전문가 김홍회 박사님(Ayden Kim - https://www.facebook.com/Ayden.Kim )이 검수해주셨습니다. 감사합니다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1139}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글수학포기자를 위한 딥러닝-#4 로지스틱 회귀를 이용한 분류 모델  (4)2016.10.10수학포기자를 위한 딥러닝-#3 텐서플로우로 선형회귀 학습을 구현해보자  (8)2016.10.05수학포기자를 위한 딥러닝-#1 머신러닝과 딥러닝 개요  (5)2016.10.04나이브 베이즈 분류 (Naive Bayesian classification) #1 - 소개  (8)2015.03.31머신러닝 개념 소개 및 kNN 알고리즘 소개  (3)2015.03.22Taglinear regression, Machine Learning, ML, tensorflow, 가설, 강좌, 머신 러닝 이해, 머신러닝, 비용 함수, 선형 회귀, 소개, 수학, 쉬운, 예측, 조대협, 코스트 함수, 텐서플로우, 튜토리얼, 포기자, 피쳐, 피쳐 엔지니어링, 학습'빅데이타 & 머신러닝/머신러닝'의 다른글이전글수학포기자를 위한 딥러닝-#1 머신러닝과 딥러닝 개요현재글수학포기자를 위한 딥러닝-#2 머신러닝 개념 이해다음글수학포기자를 위한 딥러닝-#3 텐서플로우로 선형회귀 학습을 구현해보자관련글수학포기자를 위한 딥러닝-#4 로지스틱 회귀를 이용한 분류 모델2016.10.10수학포기자를 위한 딥러닝-#3 텐서플로우로 선형회귀 학습을 구현해보자2016.10.05수학포기자를 위한 딥러닝-#1 머신러닝과 딥러닝 개요2016.10.04나이브 베이즈 분류 (Naive Bayesian classification) #1 - 소개2015.03.31loadedComments[1139]=true;findFragmentAndHighlight(1139);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag초보,Tutorial,클라우드 컴퓨팅,조대협,cloud,소개,빅데이타,튜토리얼,google,tensorflow,쿠버네티스,구글,Kubernetes,머신러닝,강좌,node.js,Machine Learning,딥러닝,텐서플로우,클라우드,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1139"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1139"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1139"",""entryTitle"":""수학포기자를 위한 딥러닝-#2 머신러닝 개념 이해"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":""cfile6.uf@2401C85057EF60452CA3C9.png"",""plink"":""/1139"",""tags"":[""linear regression"",""Machine Learning"",""ML"",""tensorflow"",""가설"",""강좌"",""머신 러닝 이해"",""머신러닝"",""비용 함수"",""선형 회귀"",""소개"",""수학"",""쉬운"",""예측"",""조대협"",""코스트 함수"",""텐서플로우"",""튜토리얼"",""포기자"",""피쳐"",""피쳐 엔지니어링"",""학습""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
51,https://mokeya.tistory.com/78,"그런데, 머신 러닝이란 정확히 뭔데요?","Programming/Knowledge[데이터 사이언티스트 독학 03] 기계학습(머신러닝)은 무엇인가, 어디서 배울 수 있나by 지표덕후2021. 8. 21..adsbygoogle.post-top-first {display:block;}.adsbygoogle.post-top-second {display:none}@media (min-width: 680px) {.adsbygoogle.post-top-first {display:inline-block;min-width:300px;max-width:300px;width:100%;height:250px;}.adsbygoogle.post-top-second {display:inline-block;margin-left:20px;min-width:300px;max-width:300px;width:100%;height:250px;}}@media (min-width: 768px) {.adsbygoogle.post-top-first {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}.adsbygoogle.post-top-second {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}}(adsbygoogle = window.adsbygoogle || []).push({});(adsbygoogle = window.adsbygoogle || []).push({});반응형(adsbygoogle = window.adsbygoogle || []).push({});싱가폴 출신의 데이터 사이언티스트, Travis Tang님의 아티클을 번역한 글입니다.데이터 사이언티스트 wannabe라면, 일독할 가치가 충분한 글입니다.Travis Tang님은 화학공학을 전공했지만 테크기업에서 데이터 분석가로 사회생활을 시작했습니다.몇 차례에 걸쳐 포스팅 될 그의 이 아티클은 화학공학도가데이터 사이언티스트로 일하기까지의 여정과 필요한 스킬셋(skill set)을 구체적으로 담고 있습니다.Tang은, 데이터 사이언티스트로 나아가는 데 필요한 정보는 홍수처럼 넘치는데오히려 그 때문에 최고의 자원을 선별해내는 것이 어렵다고 토로합니다.그렇기 때문에 먼저 아래의 질문에 답을 할 수 있어야 한다고 강변합니다.데이터 과학이란 무엇입니까?아, 이것은 인사 담당자와 기업의 면접관 모두를 당황하게 만드는 대답하기 어려운 질문입니다. 사실, 회사마다 데이터 과학을 다르게 정의하여 용어가 모호하고 다소 이해하기 어렵습니다. 프로그래밍이라고 하는 사람도 있고 수학이라고 말하는 사람도 있고 데이터를 이해하는 일이라고 말하는 사람도 있습니다. 모두 어느 정도 맞는 말입니다. 나(Travis Tang)에게 가장 동의하는 정의는 다음과 같습니다.데이터 사이언스data science는 수학, 컴퓨터 과학, 도메인 지식 분야에서 도출된 기술과 이론을 사용하는, 학제를 넘나드는(inter-disciplinary) 분야이다.아래 그림은 위의 정의를 잘 보여주는 이미지입니다.데이터 사이언스는 다양한 학문들의 교차로이 이미지에서 각 분야의 지식이 뭉쳐 데이터 과학을 형성한다는 것을 보여주기 위하여 분야 사이의 경계를 흐릿하게 묘사했습니다.자, 그럼 데이터 사이언스, 데이터 과학을 배우기 위해선 뭘 해야 할까요?일련의 게시물을 통해 저는 데이터 사이언티스트로 나아가는 과정에서 제가 배운 것들을 알려드리려 합니다. 이를 통해 저와 같은 입장에 있는 분들이 데이터 사이언스를 배워나가는 데에 도움이 되었으면 합니다. 이 아티클은 아래와 같은 내용으로 구성될 예정입니다.1부 — SQL, Python 및 R을 사용한 데이터 처리2부 — 수학, 확률 및 통계3부 — 컴퓨터 과학 기초4부 — 기계학습=머신러닝(본 게시물의 내용)5부 — 첫 번째 기계 학습 프로젝트 구축     (adsbygoogle = window.adsbygoogle || []).push({});머신러닝이나 데이터 사이어스를 배우고 싶지만 어디서부터 시작해야 할지 막막하신가요? 저 역시 그랬습니다. 그리고 저는 제 시간을 가장 잘 사용할 수 있는 과정을 찾기 위해 인터넷을 뒤지며 긴 밤을 보낸 것을 기억합니다. 고된 검색 끝에 전 머신러닝 학습을 배우는 데 탁월한 리소스를 찾았고 그것들은 제가 무사히 면접을 치르고 데이터 사이언스 분야에취업하는 데에 큰 도움이 되었습니다. 이 게시물에서는 제가 요긴하게 활용했떤 머신러닝 코스를 공유하여 저와 같은 주제로 밤새고 계실 분들께 큰 도움을 드리려 합니다.오늘날 머신러닝은 종종 전세계의 많은 문제에 대한 치트키로 선전되고 있습니다. 머신러닝의 도움으로 우리는 스마트해진 검색엔진, 자율주행 자동차, 실시간 음성인식의 이점을 누리고, 인간 게놈의 신비를 엄청나게 풀기까지 했습니다. 우리 일상생활에 머신러닝이 편재해있다는 사실은 머신러닝이 인간의 삶을 대규모로 개선할 수 있으리라는 가능성을 시사합니다. 머신러닝의 매력이 여기에 있습니다.배우는 데 관심이 없는 외부인에게는 머신러닝이 막연한 유행어에 불과합니다. 기계학습을 시작하고자 하는 새내기들에게 기계학습은 진입장벽이 높은 난해한 개념처럼 보일 수 있습니다. 그러나 기계학습이 신비하거나 이해하기 어려울 필요는 없습니다. 만약 기계학습에 대한 지식을 쌓고자 하는 진정한 열망과 약간의 인내심만 있다면 당신은 기계학습을 시작할 완벽한 위치에 있습니다.그런데, 머신 러닝이란 정확히 뭔데요?저는 머신러닝을 기계가 스스로 학습하도록 가르치는 과학이라고 생각하고 싶습니다. 더 엄격하게 말하면 기계학습의 아버지인 Arthur Samuel은 1959년에 이를 다음과 같이 우아하게 정의했습니다.명시적으로 프로그래밍하지 않고도 컴퓨터에 학습 능력을 부여하는 연구 분야 [1]이것은 우리가 기존 프로그래밍을 정의한 것과는 완전히 다릅니다. 전통적인 프로그래밍에서 우리는 컴퓨터에 짜여진 규칙(program)와 입력(input)을 제공합니다. 차례로 우리는 출력(output)을 기대합니다. 예를 들어 계산기 프로그램에 1+1 입력을 제공하면 출력이 무엇인지 모두 알 수 있습니다.기계학습은 컴퓨터에 일부 입력(input) 및 출력(output)을 제공합니다. 시간이 지남에 따라 기계는 입력과 출력 간의 관계를 더 잘 학습합니다. 새로운 입력을 제공하면 예측된 출력을 알려줄 수 있습니다. 예를 들어 Elon은 중고 Tesla를 구매할 계획입니다. 그는 Craigslist에서 Tesla 차량 가격에 대해 조사한 결과 거의 새 Tesla 차량이 약 40,000달러부터 시작한다는 것을 발견했습니다. 그는 또한 자동차가 1년이 될 때마다 Tesla 가격이 약 $1,000씩 떨어진다는 사실도 알고 있습니다. 그런 다음 그는 5년 된 자동차가 35,000달러라고 예측합니다.     (adsbygoogle = window.adsbygoogle || []).push({});다시 말해, Elon은 기계학습에서 중요한 개념인 회귀(regression)를 방금 발명했습니다! 기계학습에서 프로그램은 입력과 출력 사이의 패턴을 인식하고 출력을 예측합니다.인공지능(AI, Artificial Intelligence)과 딥 러닝(Deep Learning)은 또 뭔데요?머신러닝과 밀접한 관련이 있는 유행어들입니다. 서로의 관계는 정확히 무엇일까요? 이것은 아래 다이어그램에 잘 드러나 있습니다.이 벤다이어그램에서 볼 수 있듯이 딥 러닝은 뇌가 뉴런에서 뉴런으로 정보를 전송하는 방식을 알고리즘으로 모방한 기계학습의 하위 집합입니다. 딥 러닝이 기계학습의 보다 고도화된 형태으로 간주될 때도 있습니다. 그러므로 사실 학습자는 딥 러닝에 뛰어들려 해도 결국 머신러닝의 기초를 이해해야만 합니다.반면, 머신러닝은 인공지능(AI)의 하위 집합입니다. AI는 추론, 계획 및 학습과 같은 인지 지능을 기계가 모방하는 것이라고 생각하면 됩니다. 물론 추론, 계획, 학습에만 국한되지는 않고, 보다 다양한 형태일 수 있습니다. [2]     (adsbygoogle = window.adsbygoogle || []).push({});이게 전부 데이터 사이언스랑 어떤 관련이 있습니까?데이터 사이언스는 수학, 컴퓨터 과학, 도메인 지식 분야에서 도출된 기술과 이론을 사용하는, 학제를 넘나드는 분야입니다. [3] 데이터 과학이 무엇인지 설명하기 위해 저는 아래의 벤다이어그램을 사용하고 싶습니다.보시다시피 데이터 과학은 수학, 컴퓨터 과학 및 도메인 전문 지식과 같은 다양한 영역의 지식이 결합된 것입니다. 기계학습은 '수학'과 '컴퓨터 사이언스'를 만나는 지점에 있습니다. 대규모 데이터세트에 적용된 우아한 수학 방정식과 (컴퓨터의) 연산능력이 합류하는 지점인 것입니다. 따라서 머신러닝은 데이터 사이언스의 도드라진 구성 요소입니다.다 알겠는데요, 어디서 배울 수 있나요?우리가 학습할 수 있는 머신러닝 코스는 무수히 많습니다. 이것은 머신러닝 입문에서 대학원 수준 수업, 실제 수업에서 온라인 수업에 이르기까지 전방위적으로 제공되고 있습니다. 데이터 과학 분야의 초보자들에게 인기 있는 몇 가지 기계학습 입문 수업은 다음과 같습니다.Udacity의 기계 학습 수업 소개Python을 사용한 Datacamp의 / Dataquest 기계 학습 기초EdX 기반 Columbia University의 기계 학습Udemy의 기계 학습 A-ZHarvard University의 무료 기계 학습 과정...개인적으로 목록에 있는 이러한 기계학습 코스 중 일부를 시도해봤지만,일부 수업은 깊이와 엄격함 측면에서 다소 부실했습니다.데이터 과학자로서의 커리어 패스에 도움이 될 만한 엄격한 머신러닝 수업을 찾고 계시다면 이 포스팅이 분명 도움이 될 것 같습니다. 오늘 저는 개인적으로 가장 좋아하는 머신러닝 입문 강의를 공유하려 합니다. 바로 Coursera의 Andrew Ng(스탠포드 대학교)의 머신 러닝입니다. 필요한 선행 지식, 수업에서 뭘 얻을 수 있는지, 이 수업을 온전히 누릴 수 있는 방법에 대해 조언을 할까 합니다.Coursera의 Andrew Ng의 머신 러닝이 기계학습 과정은 초보자를 위한 최고의 기계학습 코스로 지속적으로 선전되어 왔습니다. 370만 명의 등록자가 내린150,000개 평가점수가 4.9점이라는 점도 이 코스가 얼마나 믿을 만한지 암시합니다.무료로 수업에 참석할 수 있습니다(audit version). 학습자는 언제든지 무료로 등록할 수 있습니다. 단, 무료로 등록한 경우에는 수료증을 발급받을 수 없습니다. 대부분의 프로그래밍 연습과 퀴즈에 대한 피드백을 받을 수도 없습니다.Coursera에서 7일 무료 평가판을 제공하고 있으며, 7일이 가기 전에 언제든지 과정을 반환할 수 있습니다.인증서 비용은 $49입니다. 제 사견을 말씀드리면, 저는 이 수료증이 내가 수업을 완주하고자 하는 의지가 있음을 증명하는 훌륭한 방법이라 생각합니다. 도움이 필요한 학습자를 위한 재정적인 지원도 하고 있으므로 부담 가지지 마시고 Coursera에 문의해보십시오.이 코스의 강사인 Andrew Ng는 소개가 거의 필요 없는 인물입니다. 그는 스탠포드 대학교 겸임교수이자 코세라(Coursera)와 구글 브레인(Google Brain)의 공동 설립자이자 바이두(Baidu)의 전 부사장으로, 머신러닝 분야에서 두말할 것 없이 가장 영향력 있는 인물입니다.     (adsbygoogle = window.adsbygoogle || []).push({});이 수업에서 특히 좋았던 점1년 전 쯤에, 데이터 사이언스로 나아가고 싶지만 어디서부터 시작해야 할지 몰랐던 저는 '데이터 사이언스 배우는 방법'을 미친듯이 검색했습니다. 저는 엄청난 양의 배워야 할 것(수학, 확률, 통계, 기계학습 등)들과 그만큼 엄청난 양의 자원들에 빠르게 압도당했고, 가장 인기 있는 것처럼 보이는 수업을 듣게 되었습니다. 바로 Andrew Ng’s Machine Learning입니다.지금의 저는 이 수업을 수강하게 된 것을 정말 기쁘게 생각합니다.이 기계학습 과정을 마치고 데이터 사이언스 인턴십을 통해 행운을 시험해보려 했던 때가 생생하게 기억납니다. 정말 두려웠지만 수업을 들은 사실이 저를 조금 진정시켰습니다. 그 첫 번째 데이터 사이언스 직무 면접에서 제가 느낀 건, 대부분의 기계학습 실무자가 그 코스에 대해 알고 있거나, 익숙하다는 점입니다. 인터뷰 당시 제가 그 코스를 이수했다고 말했을 때 면접관이 수긍의 의미로 고개를 끄덕였는데 그게 기분 좋은 기억으로 남아있습니다.내가 수업을 완료했다는 사실은 채용 관리자가 '수업에서 무엇을 배웠는가?', '수업에서 가장 어려웠던 부분?', '우리 회사의 상황에는 어떻게 적용할 수 있나?'와 같은 후속 질문을 할 수 있는 발판을 제공했습니다. 돌이켜 보면, 수업을 이수했다는 사실 자체가 학습동기의 표시이자 기계학습에 대한 기본 지식을 보유하고 있다는 신호로 인식되었을 수 있습니다. 두 가지 모두 고용 관리자가 데이터 사이언티스트를 고용하고자 할 때 보는 필수 자질입니다.사실대로 이야기하자면, 이 코스만 있던 제 이력서로는 데이터 사이언트 인턴십에 채용될 수 없었습니다. 그러나 그 분야의 전문가들의 언어로 대화를 나눌 수 있다는 사실은 제게 큰 자신감을 주었습니다. 이를 통해 데이터 사이언스 전문가들과 네트워크를 구축하고 그들로부터 배울 수 있었습니다.     (adsbygoogle = window.adsbygoogle || []).push({});어떤 사람이 들으면 좋을까?이 수업은 데이터 분석, 데이터 과학, 기계학습 또는 AI 분야에서 테크니컬한 역할을 추구하려는 진지한 학생을 대상으로 합니다. 또한 기계학습에 대한 배경 지식이 없는 초보자나 기계학습 개념을 복습하려는 사람들도 대상이 될 수 있습니다. 명시적으로 언급되지는 않았지만 이 수업은 수학적 엄격함을 요구합니다. 때문에 기계학습에 대한 깊은 이해를 원하는 학습자에게는 강한 배움의 자극이 되겠지만, 기계학습의 톱니바퀴에 관심이 거의 없는 학습자는 아마 떨어져나가게 될 겁니다.쏟아야 할 시간은 만만치 않습니다. 수업을 이수하는 데에 약 60시간이 걸립니다. 매일 2시간을 투자할 수 있다고 가정하면 이 과정은 한 달이 걸립니다. 수학이나 프로그래밍 숙련도에 따라 이 소요시간이 다를 수는 있습니다.이런 사람은 안 듣는 게 낫습니다.그러니, 앞서 언급한 바를 염두에 둔다면 이 수업은 기계학습과 기계학습이 문제를 해결하는 방법에 대한 일반적인 질적 이해를 원하는 비기술적(non-technical) 학습자가 듣기엔 적절하지 않습니다. 만약 당신이 이런 사람이라면, Andrew Ng이 진행하는 AI for everyone을 수강하시는 게 더 나을 수 있습니다. 이 강의는 AI 전반과 전문 용어를 이해하고자 하는 비기술 전문가를 대상으로 합니다. 게다가 이 수업은 훨씬 더 짧아서 약 6시간만 투자하면 됩니다. 수학과 프로그래밍에 대한 개념이 없다면 이 과정 역시 쉽지는 않을 겁니다. 동기와 관심을 지속하는 것이 어렵다는 것을 이 강의를 통해 알게 될 수도 있습니다.수학은 암만 해도 어렵습니다. 수학 없이 기계학습을 할 수는 없나요?글쎄요, 수학을 이해하지 않고 기계학습을 수행할 때 치명적인 단점이 있습니다. 첫 번째, 기계학습을 맹목적으로 구현하는 기술(skill sets)을 당신이 가지고 있다면 당신은 Google Cloud에서 제공하는 것과 같은 자동화된 기계학습 AutoML에 의해 쉽게 대체할 수 있습니다. 두 번째, 데이터 과학자의 가치는 런타임 및 저장 복잡성과 데이터세트에 대한 적합성까지 고려하여 최상의 성능을 발휘하는 적절한 알고리즘을 신중하게 선택하는 데 있습니다.당신이 자동차의 소유자라고 상상해보십시오. 물론 차가 달릴 때 부드럽게 운전할 수 있습니다. 그러나 자동차를 만들어야 하거나 자동차 결함을 해결해야 하는 경우에는, 자동차를 달리게 하는 톱니바퀴와 바퀴에 대한 이해가 필요합니다. 자동차의 내부 작동을 이해하지 못한다면 이들 중 어느 것도 불가능합니다. 이 자동차는 데이터 사이언스의 알고리즘입니다. 내부에서 어떻게 작동하는지 모른다면 기계학습 알고리즘을 구축할 수 없습니다.데이터 사이언티스트, 분석가 및 엔지니어로서 우리의 역할은 기계학습 모델을 사용하는 것뿐만 아니라 이를 구축, 유지 관리 및 배포하는 것입니다. 그러려면 수학을 알아야 합니다.알겠습니다. 배우고 싶은데, 수학이나 코딩에 대한 배경지식이 없습니다...걱정 마세요! Coursera에는 수업에 대한 전제 조건이 없습니다. 아래에 제가 언급할 강의를 듣지 않고도 코스를 시작할 수 있습니다. 그러나 코스를 성공적으로 마치고자 한다면 몇 가지는 선행학습 하시는 게 좋습니다.권장하는 코딩 지식Datacamp 및 Dataquest의 python 및 R 과정에 참석한 저는 MATLAB 및 python에 대한 기본적인 이해를 바탕으로 이 과정을 시작했습니다. 이 과정은 초반부터 MATLAB에 대한 간략하고 쉬운 소개를 제공하므로, 코딩 경험이 없어도 걱정 안 해도 됩니다. 이는 학습자가 필요한 코딩 능력을 빠르게 익히는 데 도움이 됩니다.만약 다른 프로그래밍 언어에는 익숙하지만 MATLAB에는 익숙하지 않은 경우에는 해당 언어에 대해 너무 신경쓰지 말고 바로 과정을 시작하는 것이 좋습니다. 그러나 여전히 MATLAB을 배우는 데 시간을 할애하고 싶다면 다음과 같은 훌륭한 자원들이 있습니다.MIT Open Courseware (무료)University of Vanderbilt on Coursera (유료) 권장하는 수학 코딩 지식     (adsbygoogle = window.adsbygoogle || []).push({});제가 추천한 코세라 강의는 고등학교 수준의 미적분 및 선형 대수학에 대한 약간의 지식을 전제합니다. 수학에 능숙할수록 코스를 쉽게 통과할 수 있으며 그 반대의 경우도 마찬가지입니다.Andrew Ng의 수업은 선형 대수학에서 약간의 복습을 제공하므로 선형 대수학 지식이 가물가물하더라도 걱정할 필요 없습니다. 하지만 수업을 시작하기 전에 다음 질문을 스스로에게 하는 것이 좋습니다.차별화 규칙을 자신 있게 알고 있습니까? 그렇지 않다면 Khan Academy의 미적분 수업을 찾아보세요.행렬이 무엇이며 행렬에 대한 연산(전치, 산술, 내적)을 수행하는 방법을 알고 있습니까? 그렇지 않다면 Khan Academy’s Linear Algebra playlist를 찾아보세요.다음 그림은 수업에서 마주한 몇 가지 수학 문제입니다. 이런 표기법이 편안하세요? 그렇지 않다면 위의 링크로 들어가서 얼른 지식을 환기해두시는 게 좋습니다.  뭘 배워갈까?기계학습을 배우려면 일반적으로 알아야 할 사항기계학습으로 해결할 수 있는 다양한 유형의 문제.다양한 문제를 해결하기 위한 다양한 유형의 알고리즘.서로 다른 데이터세트에 대한 각 알고리즘의 강점과 약점.각 알고리즘을 뒷받침하는 수학 및 가정.기계학습의 절충trade-off(편향-분산 절충)기계학습의 모범 사례.기계학습 알고리즘의 적용.이러한 개념을 다루기 위해 Andrew Ng의 수업은 알고리즘별로 구성된 장으로 나뉩니다. 각 클래스는 논리적으로 진행됩니다. 먼저 알고리즘에 대한 간략한 소개와 실제 적용 사례를 제공하여 독자를 준비시킵니다. 그런 다음 설득력 있는 다이어그램 설명을 통해 알고리즘에 대한 독자의 직관을 구축합니다. 이러한 직관은 알고리즘의 수학을 이해하는 마찰을 줄여줍니다.강의 후에는 퀴즈를 통해 이해도를 테스트할 수 있습니다. 학습내용을 내재화하기 위해 첫 번째 원칙을 사용하여 Matlab에서 알고리즘을 처음부터 구현할 수도 있습니다. 이 수업에서 배우게 될 내용이 과정은 기계학습 분야의 핵심에 대한 폭넓은 조감도를 제공합니다. 다음은 수업에서 다루는 개념의 마인드맵입니다.함께 보면 좋을 책Andrew Ng의 코스에는 공식 교과서가 없지만 확신이 서지 않을 때 교과서를 참조하는 게 도움이 됩니다. 이를 위해 저는 무료로 온라인 제공되는 교재인 Introduction to Statistical Learning(온라인 Free)을 추천합니다. 이 책은 머신러닝 알고리즘에 대한 수학적 직관력을 높일 수 있도록 명쾌한 설명과 삽화를 제공합니다. 한 가지 주의할 점은 R을 기본 언어로 사용한다는 것입니다.     (adsbygoogle = window.adsbygoogle || []).push({});발전을 위한 팁과 요령질문같은 자리에 오래 머무르는 것은 정말 쉽습니다. Coursera는 당신과 같은 학습자가 질문할 수 있는 포럼을 제공합니다. 도움을 줄 사람이 필요하면 언제든지 저에게도 개인적으로 연락하십시오. 제가 할 수 있는 한 최대한 도와 드리겠습니다.천천히 흡수이 코스에서 다루는 개념은 결코 간단하지 않습니다. 수업을 소화하며 진행하는 것은 지극히 바람직한 일이므로 천천히 수강하십시오.약간의 휴식을 취하십시오.특정 코드 블록을 끈덕지게 시도했지만 원하는 출력을 제공하지 않으면 한 걸음 물러나서 휴식을 취해야 할 때일 수 있습니다.도중에 메모를 합니다.종이에 메모하고 코딩하는 것이 다이어그램을 그려 개념을 시각화하는 것만큼 유용하다는 것을 알았습니다. 또한 내 생각을 공식화하는 데 도움이 되기 때문에 내 컴퓨터에 코드를 구현하기 전에 종이에 코드를 적어두는 것이 도움이 됩니다.확신이 든다면 오늘 시도해 보시기 바랍니다.이 코스 후에는,축하합니다! 이제 코스를 하나 수료하고 당신은 지식에 굶주린 사람이니 기계학습이 무엇이고, 수학적 기초가 무엇인지에 대한 더 많은 지식을 얻을 준비가 된 것입니다. 다음은 당신에게 드리는 몇 가지 제안입니다.Other data science skills(SQL, python 및 R)에 대한 복습새로 발견한 기술을 시험해볼 흥미로운 프로젝트통계 및 확률 수업Coursera의 deep learning 수업이 코스의 고급 버전인, CS229 Machine Learning 수강(이를 위해서는 선형 대수학, 통계 및 확률에 대한 고급(학부/대학원) 이해가 필요)머신러닝을 전혀 몰랐던 학습자로서 이 강의를 듣고 나니 엄청난 희망이 생겼습니다. 다른 기계학습 및 데이터 사이언스의 개념을 배울 수 있는 훌륭한 토대를 제공해 주었습니다. 꾸준히 하시면 단시간에 코스를 마치고 저와 같은 성취감을 받으실 수 있으실 거라 확신합니다.참고문헌[1] Mitchell, Tom (1997). Machine Learning. New York: McGraw Hill. ISBN 0–07–042807–7. OCLC 36417892.[2] Russell, Stuart J.; Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, New Jersey: Prentice Hall. ISBN 978–0–13–604259–4.[3] Dhar, V. (2013). “Data science and prediction”. Communications of the ACM. 56 (12): 64–73. doi:10.1145/2500499. S2CID 6107147. Archived from the original on 9 November 2014. Retrieved 2 September 2015.반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//mokeya.tistory.com/reaction';window.ReactionReqBody = {    entryId: 78}공유하기게시글 관리지표덕후,  지덕智德저작자표시 비영리 변경금지 'Programming > Knowledge' 카테고리의 다른 글[웹개발] 파이썬 웹 프레임워크(Web Frameworks)에 대한 간단 지식과 추천 프레임워크  (0)2022.01.15[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계  (0)2021.09.10[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라  (0)2021.08.26[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기  (0)2021.08.19[데이터 사이언티스트 독학 01] Data Science의 정의, 데이터 처리(Data Processing)를 배우는 방법  (0)2021.08.18     (adsbygoogle = window.adsbygoogle || []).push({});태그Coursera, Introduction to Statistical Learning, 기계학습강의, 데이터사이언스, 데이터사이언티스트, 독학, 머신러닝강의, 머신러닝교재, 앤드류응, 코세라관련글[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기[데이터 사이언티스트 독학 01] Data Science의 정의, 데이터 처리(Data Processing)를 배우는 방법댓글0비밀글댓글등록loadedComments[78]=true;findFragmentAndHighlight(78);"
52,https://hyunie-y.tistory.com/23,ABOUT ME,"홈 분류 전체보기 (107)  Data Engineering (21)  SQL (3)  Books (5)  AWS, Spark (11)  분류하기 애매한 것들 (1)  Project (20)  D.D.P (Datahub) (4)  Collecting Event Data (4)  CICD (9)  Toxic speech detection (2)  CS기초 (25)  Algorithm, Data Structures (6)  Coding Test (6)  Network (2)  OS,HW (11)  Deep Learning (5)  Statistics (3)  Tips (25)  궁금점의 기록 (7)  정리 중인 글 (0) ABOUT ME-트위터인스타그램Today-Yesterday-Total-머신러닝을 배웠던 데이터 엔지니어머신러닝을 배웠던 데이터 엔지니어메뉴검색컨텐츠 검색IP주소와 포트포워딩이란, 포트포워딩 설정하기(iptime)CS기초/Network2021. 10. 26. 23:26728x90반응형(adsbygoogle = window.adsbygoogle || []).push({}); 로컬 젠킨스와 Github webhook 연결을 하려다보니 IP주소가 필요했다. IP주소란 컴퓨터 네트워크에서 장치들이 서로를 인식하고 통신을 하기 위해서 사용하는 특수한 번호(ref. Wiki)라고 되어있는데 쉽게 말하면 통신을 위한 장치의 주소같은 개념이다.우리가 편지를 보내기 위해서는 수신자의 주소를 적어야하는 것 처럼 Webhook이 내 컴퓨터의 젠킨스로 정보를 보내기 위해서는 내 컴퓨터가 어디에 있는지 알아야하니 컴퓨터의 ip주소가 필요한 것이다. 인터넷에서 특정 사이트로 접속할 때 - 이 동작도 접속해달라는 post요청을 보내게 되는데 - http://www.google.com 과 같은 주소를 입력하는데 이것도 사실 이 주소기 DNS 서버라는 것을 통해 IP주소로 바뀌어서 전달된다. 즉, http://www.google.com을 주소창에 입력하는 것과 해당 서버의 외부IP주소인 216.58.200.68을 주소창에 입력하는 것과 같다.  맥에서 내 컴퓨터의 ip주소를 확인하려면 환경설정>네트워크에 들어가거나 터미널에 `ipconfig getifaddr en0`를 치면 되는데 문제는 공유기로 wifi에 접속하여 인터넷을 사용할 때다. 이럴 경우 보여지는 ip주소는 공유기에서 할당한 주소이며, 외부에서 접근이 불가하다.  공유기에서 할당한 192.168.0.21 이라는 주소는 공유기 내의 주소이기 때문에 같은 공유기 망 내에서만 접속이 가능합니다.하지만 LTE 망을 사용 중인 핸드폰이나 회사, 학교 컴퓨터에서는 192.168.0.21 이라는 주소를 쳐봤자 엉뚱한 곳으로 가게 됩니다.비유하자면 '192.168.0.21' 이라는 것은 '3동 406호'라고만 써있는 주소와도 같습니다.​같은 아파트에 살고 있다면 3동 406호라는 주소만으로도 친구 집에 갈 수 있지만, 외부인 입장에게 주소를 알려줄 때는 AA시, BB구 등의 광역 주소를 알려줘야지 3동 406호라는 주소만으로는 주소 기능을 할 수 없을 것입니다.출처: https://solbel.tistory.com/396 위의 예시에서 얘기하는 광역주소가 공유기의 IP주소이고 외부에서는 여기까지 알 수 있다. 각 인터넷 회선마다 고유한 값을 가지며 이 주소에 접속한 후 공유기 내에서 분배되는 주소까지 알면 외부에서도 내 컴퓨터로 접속을 할 수 있게 되는 것이다. 2022. 11 추가 - 여기에서 제가 사용한 ""공유기의 IP주소""라는 단어에 혼돈의 여지가 있는 것 같습니다. 아래 댓글에서 지적한 대로, 여기에서 사용한 ""공유기의 IP주소""라는 표현은 ISP를 통해 부여받은 공인 IP주소를 의미하며, 네트워크의 기초지식이 없는 분들을 위해 아주 쉬운 표현을 사용하고자 하는 과정에서 잘못 받아들여질 수 있는 표현이 사용된 것 같습니다.  포트라는 개념은 기기 내에 할당된 방 같은 느낌인데, 각 방마다 고유의 번호를 가진다 (Jenkins 8080, Postgres 5432...). 내 컴퓨터에서 Flask로 접속하고자 할 때는 ""로컬 호스트의 Flask의 포트로 들어가""라고 해야하는데, 이 요청을 `http://127.0.0.1:5000`이라는 url로 수행하는 것이다. 여기에서 127.0.0.1이 localhost 주소이고 5000이 Flask의 방 번호, 즉 포트 번호이다. 포트포워딩이란 포트포워딩(Port Forwarding)은 공유기의 포트를 통해 이 공유기와 연결된 기기들의 특정 포트에 진입할 수 있게 하는 기능이다. 만약 공유기에 컴퓨터와 핸드폰이 연결되어 있는데 그냥 공유기 주소 + 포트번호로 입력한다면 공유기의 '어느 기기'의 포트로 들어가야하는 지 알 수 없다. 따라서 포트 포워딩은 공유기에 연결된 기기의 포트를 특정 번호를 통해 전달(forwarding)해 주는 것이라고 이해할 수 있다. 또는 공유기에 기기+해당 기기의 포트에 해당하는 포트 번호를 할당 해 주는 것이라고 해도 될 듯하다. 예를 들어 공유기의 180포트로 접속하면 핸드폰의 5000 포트에 접속하게하고, 280포트로 접속하면 컴퓨터의 5000포트에 접속하게 하는 것이다. 여기서 180, 280등을 지정하는 작업이 포트포워딩이다. 포트포워딩 설정하기 포트포워딩 설정은 공유기에서 한다. 여기부터 iptime을 기준으로 글을 작성한다.http://192.168.0.1 을 통해 공유기 설정페이지에 접속 (공유기 제조사 별로 다른 경우도 있다고 하니 검색)로그인 (초기 id/ 비밀번호는 admin/admin이고, 기존에 설정해놓은 id/비밀번호를 잊어버렸다면 공유기의 reset 버튼을 10초 정도 눌러 초기화한다)Setting(관리도구)왼쪽 메뉴에서 Advanced Setup(고급 설정)> NAT/Routing(NAT/라우터 관리) > Port Forwarding(포트포워드 설정) > Add new rule(새규칙 추가) 클릭하기 사진의 사각형 부분을 채운다Rule Name(규칙 이름): 기억하기 쉬운 이름으로 설정 (문자나 숫자나 아무거나) Internal IP(내부 IP주소): 공유기에서 할당한 내 컴퓨터의 IP주소로 위에서 작성한 방법으로 확인할 수 있다.External port(외부 포트): 외부에서 접속할 때 사용할 포트로 사용자가 외우기 쉬우면서 기존 포트 번호와 겹치지 않는 번호로 설정할 수 있다.Internal port(내부 포트): 내 컴퓨터에서 어플리케이션에 접속할 때 사용하는 포트 번호이다 (e.g. Jenkins면 8080)다 작성한 후 Apply(적용 또는 수정) 버튼을 눌러주면 된다.   해당 설정을 완료했다면 이제 내가 할당한 포트번호와 공인 IP주소를 통해 외부에서 내 컴퓨터의 어플리케이션에 접근이 가능하게 된다. 공인IP주소는 Naver등에서 'ip 주소'같은 키워드로 확인할 수 있으며, 최종 접근 경로는 {공인IP주소}:{위에서 설정한 외부 포트번호}가 된다.  예를 들어 Naver에서 확인한 공인IP주소가 211.156.32.67이고 내가 설정한 외부 포트번호가 8000이면 외부에서는 http://211.156.32.67:8000이라는 주소로 접근이 가능하게 된다. 참고 블로그: https://solbel.tistory.com/396728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//hyunie-y.tistory.com/reaction';window.ReactionReqBody = {    entryId: 23}공유하기게시글 관리머신러닝을 배웠던 데이터 엔지니어저작자표시 'CS기초 > Network' 카테고리의 다른 글네트워크: 초보도 이해하길 바라는 CIDR블록이란?  (0)2022.12.04TAGiptime포트포워딩, IP주소, 맥ip주소확인, 포트포워딩, 포트포워딩설정관련글 관련글 더보기네트워크: 초보도 이해하길 바라는 CIDR블록이란?댓글 4댓글                                                    접기댓글 펼치기이전 댓글 더보기    setInitialEntryComments(23, 1723620349)                                                            비밀글등록loadedComments[23]=true;findFragmentAndHighlight(23);인기포스트IP주소와 포트포워딩이란, 포트포워딩 설정하기(ipti⋯시간 단위 정리 - ns, ms, us, ps, fs운영체제 5: 컨텍스트 스위칭 (Context Swit⋯문자열 합치기 - CONCAT과 ||ABOUT MELINKADMINadmin글쓰기105,84387185티스토리툴바머신러닝을 배웠던 데이터 엔지니어구독하기                    (function () {                         var blogTitle = '머신러닝을 배웠던 데이터 엔지니어';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4763539-23"",""customProps"":{""userId"":""0"",""blogId"":""4763539"",""entryId"":""23"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""23"",""entryTitle"":""IP주소와 포트포워딩이란, 포트포워딩 설정하기(iptime)"",""entryType"":""POST"",""categoryName"":""CS기초/Network"",""categoryId"":""1024457"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4926031"",""authorNickname"":""Hyunie"",""blogNmae"":""머신러닝을 배웠던 데이터 엔지니어"",""image"":""kage@NxyJc/btriSLekh2C/wK9YEY81TTtl29miUjrDfk"",""plink"":""/23"",""tags"":[""iptime포트포워딩"",""IP주소"",""맥ip주소확인"",""포트포워딩"",""포트포워딩설정""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
53,https://jpub.tistory.com/835,태그,"도서 소개패턴 인식과 머신 러닝 제이펍2018. 9. 11. 11:46 2019 대한민국학술원 우수학술도서 선정!현대 패턴 인식과 머신 러닝의 개념과 효과적 이해를 위한 수학적 사고!컴퓨터 비전과 머신 러닝 분야의 고전이자 필독서인 비숍책, 이젠 한국어판으로 공부하세요! 출판사 제이펍원출판사 Springer원서명 Pattern Recognition and Machine Learning(원서 ISBN: 9780387310732)저자명 크리스토퍼 비숍역자명 김형진출판일 2018년 9월 10일페이지 852쪽시리즈 I♥A.I. 11(아이러브A.I. 11)판 형 46배판변형(188*245*37)제 본 무선(soft cover)정 가 46,000원ISBN 979-11-88621-25-5 (93000)키워드 인공지능 / 패턴 인식 / 머신 러닝 / 알고리즘 / 베이지안 / 뉴럴 네트워크 / 컴퓨터 비전 / 신호 처리 / 데이터 마이닝분야 인공지능 / 머신 러닝 / 패턴 인식 관련 사이트■ 저자(Bishop) 페이지■ 저작권사 도서소개 페이지■ 아마존 도서소개 페이지 관련 포스트■ 2018/08/29 - [출간전 책소식] - 한글로 만나는 비숍 책! 관련 시리즈■ I♥A.I 시리즈 관련 도서■ (관련 시리즈 참고하세요) 관련 파일 다운로드■ 1, 2, 3, 8장에 대한 영문 강의교안(pdf, ppt), 원서 샘플 챕터(chapter 8, PDF), www 표시 연습문제 해답(PDF), 본문의 그림(jpeg, png, pdf, eps 포맷), 원서 에라타(참고로, 이 자료들은 저자 웹 사이트에서 다운받은 것들입니다. ) 강의보조 자료교재로 채택하신 분들은 아래의 저작권사 링크에서 해답집을 신청해 주세요. 이와 관련해 궁금하신 분들은 다음 메일로 연락주시기 바랍니다. jeipubmarketer@gmail.com■ 연습문제 전체에 대한 해답 신청 폼 샘플 PDF(차례, 옮긴이 머리말, 서문, 베타리더 후기, 1장 '소개' 일부, 3장 '선형 회귀 모델' 일부, 8장 '그래프 모델' 일부, 13장 '순차 데이터' 일부) 패턴인식과머신러닝_sample.pdf다운로드 정오표 페이지■ http://jpub.tistory.com/837 도서구매 사이트(가나다순)[강컴] [교보문고] [도서11번가] [반디앤루니스] [알라딘] [예스이십사] [인터파크] 도서 소개현대 패턴 인식과 머신 러닝의 개념과 효과적 이해를 위한 수학적 사고!컴퓨터 비전과 머신 러닝 분야의 고적인자 필독서인 비숍책, 이젠 한국어판으로 공부하세요! 지난 수년간 머신 러닝은 그 어느 때보다도 뜨거운 관심을 받았다. 특히, 2016년 알파고와 이세돌 9단의 대국은 더 많은 사람이 인공지능 분야에 관심을 가지게 하는 촉매제가 되었다. 이는 딥 러닝을 비롯한 여러 머신 러닝 알고리즘의 성능이 최근 매우 향상되었기 때문이다. 머신 러닝은 최근에 새롭게 생겨난 기술이 아니다. 데이터를 기반으로 해서 최적화 문제를 풀거나 예측해야 하는 다양한 분야에서 이미 오랜 시간 동안 머신 러닝 기술이 활용되었다. 최근에 가장 주목을 받고 있는 딥 러닝은 수십 년 전에 처음 제안된 뉴럴 네트워크 알고리즘이 기반이다. 오랜 시간 동안 학계로부터 외면받고 있었던 뉴럴 네트워크 기술이 GPU 등 하드웨어의 발전과 구글/페이스북 등의 회사에서 발생하는 엄청난 양의 데이터, 여러 알고리즘 개선법 등을 만나면서 새로운 모습을 보이게 된 것이다. 이 책은 지난 수십 년간 발전되어 온 확률/통계 기반의 패턴 인식과 머신 러닝 분야의 전반적인 내용을 다루고 있다. 내용을 이해하는 데 있어서 패턴 인식이나 머신 러닝 분야에 대한 사전 지식은 필요하지 않지만, 다변량 미적분과 기초 선형 대수학을 다뤄본 경험은 필요하다. 또한 기초적인 확률 이론에 대한 소개가 포함되어 있으므로 확률론에 대한 기초 지식이 반드시 필요하지는 않다. 기본적으로 학부 고학년생들이나 박사과정 1년 차 학생들을 대상으로 하고 있으나, 해당 분야의 연구자들이나 업계에서 머신 러닝을 활용하는 사람들이 읽기에도 적합하다. 그리고 머신 러닝, 통계, 컴퓨터 공학, 신호 처리, 컴퓨터 비전, 데이터 마이닝, 바이오 인포매틱스와 같은 분야의 강의 과정에서 사용하기도 적합하다. 지은이 소개크리스토퍼 비숍(Christopher M. Bishop)크리스토퍼 M. 비숍은 마이크로소프트 리서치 케임브리지의 부 디렉터이자 에든버러 대학교 컴퓨터 공학과의 학과장을 맡고 있다. 또한, 케임브리지 다윈 칼리지와 왕립 공학회의 펠로우이기도 하다. 크리스는 양자론에 관한 논문으로 세인트 캐서린 대학과 옥스퍼드 대학교에서 물리학 학사, 에든버러 대학교에서 이론 물리학 박사 학위를 취득했다. 옮긴이 소개김형진다양한 현실 세계의 문제들을 머신 러닝을 이용하여 해결하는 데 관심이 많은 소프트웨어 엔지니어이자 데이터 과학자다. 카이스트 전산학과 학부과정과 스탠퍼드 전산학과 석사과정을 마친 후, 링크드인 데이터팀에서 친구 추천 등 각종 데이터 기반 제품의 개발에 참여하였다. 그 후 스타트업에서 자연어 처리 시스템을 만들었으며, 현재는 우버 매칭팀의 머신 러닝 엔지니어로서 실시간으로 드라이버와 승객의 연결을 최적화하는 문제를 풀고 있다.   차례CHAPTER 1 소개 11.1 예시: 다항식 곡선 피팅 _ 51.2 확률론 _ 131.3 모델 선택 _ 361.4 차원의 저주 _ 371.5 결정 이론 _ 421.6 정보 이론 _ 54더보기CHAPTER 2 확률 분포 752.1 이산 확률 변수 _ 762.2 다항 변수 _ 832.3 가우시안 분포 _ 872.4 지수족 _ 1262.5 비매개변수적 방법 _ 134 CHAPTER 3 선형 회귀 모델 1553.1 선형 기저 함수 모델 _ 1563.2 편향 분산 분해 _ 1663.3 베이지안 선형 회귀 _ 1723.4 베이지안 모델 비교 _ 1813.5 증거 근사 _ 186 CHAPTER 4 선형 분류 모델 2014.1 판별 함수 _ 2034.2 확률적 생성 모델 _ 2214.3 확률적 판별 모델 _ 2294.4 라플라스 근사 _ 2404.5 베이지안 로지스틱 회귀 _ 245 CHAPTER 5 뉴럴 네트워크 2535.1 피드 포워드 네트워크 함수 _ 2555.2 네트워크 훈련 _ 2615.3 오차 역전파 _ 2715.4 헤시안 행렬 _ 2815.5 뉴럴 네트워크에서의 정규화 _ 2895.6 혼합 밀도 네트워크 _ 3065.7 베이지안 뉴럴 네트워크 _ 312 CHAPTER 6 커널 방법론 3276.1 듀얼 표현 _ 3296.2 커널의 구성 _ 3306.3 방사 기저 함수 네트워크 _ 3366.4 가우시안 과정 _ 341 CHAPTER 7 희박한 커널 머신 3637.1 최대 마진 분류기 _ 3647.2 상관 벡터 머신 _ 387 CHAPTER 8 그래프 모델 4038.1 베이지안 네트워크 _ 4048.2 조건부 독립 _ 4188.3 마르코프 무작위장 _ 4318.4 그래프 모델에서의 추론 _ 443 CHAPTER 9 혼합 모델과 EM 4779.1 K 평균 집단화 _ 4789.2 혼합 가우시안 _ 4859.3 EM에 대한 다른 관점 _ 4959.4 일반적 EM 알고리즘 _ 507 CHAPTER 10 근사 추정 51710.1 변분적 추론 _ 51810.2 예시: 변분적 가우시안 혼합 분포 _ 53110.3 변분적 선형 회귀 _ 54510.4 지수족 분포 _ 54910.5 지역적 변분 방법론 _ 55210.6 변분적 로지스틱 회귀 _ 55810.7 EP _ 566 CHAPTER 11 표집법 58711.1 기본적인 표집 알고리즘 _ 59011.2 마르코프 연쇄 몬테 카를로 _ 60311.3 기브스 표집법 _ 60811.4 조각 표집법 _ 61311.5 하이브리드 몬테 카를로 알고리즘 _ 61511.6 분할 함수 추정 _ 622 CHAPTER 12 연속 잠재 변수 62712.1 PCA _ 62912.2 확률적 PCA _ 64012.3 커널 PCA _ 65712.4 비선형 잠재 변수 모델 _ 662 CHAPTER 13 순차 데이터 67713.1 마르코프 모델 _ 67913.2 은닉 마르코프 모델 _ 68213.3 선형 동적 시스템 _ 710 CHAPTER 14 모델 조합 72914.1 베이지안 모델 평균 _ 73014.2 위원회 방식 _ 73214.3 부스팅 _ 73314.4 트리 기반 모델 _ 74014.5 조건부 혼합 모델 _ 744 부록 A. 데이터 집합 757손글씨 숫자 _ 757오일 흐름 _ 758오래된 믿음 _ 761합성 데이터 _ 762 부록 B. 확률 분포 765베르누이 분포 _ 765베타 분포 _ 766이항 분포 _ 766디리클레 분포 _ 767감마 분포 _ 768가우시안 분포 _ 768가우시안 감마 분포 _ 770가우시안 위샤트 분포 _ 770다항 분포 _ 771정규 분포 _ 772스튜던트 t 분포 _ 772균등 분포 _ 773폰 미제스 분포 _ 773위샤트 분포 _ 774 부록 C. 행렬의 성질 775기본 행렬 성질 _ 775대각합과 행렬식 _ 777행렬 미분 _ 778고윳값 공식 _ 779 부록 D. 변분법 783 부록 E. 라그랑주 승수법 787  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 835}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글아마존 웹 서비스 부하 테스트 입문  (0)2018.09.27코딩 교육을 위한 마이크로비트  (0)2018.09.20마이크로소프트 봇 프레임워크 프로그래밍: 챗봇 구축을 향한 다층적 접근  (0)2018.08.31웹 서비스를 만들며 배우는 node.js 프로그래밍: 설치에서 배포까지  (0)2018.08.03모던 C++로 배우는 동시성 프로그래밍  (0)2018.08.03태그deep learning, machine learing, Pattern recognition, 기계학습, 김형진, 뉴럴네트워크, 딥러닝, 머신러닝, 베이지안, 비숍, 신경망, 신호처리, 심층학습, 아이러브인공지능, 제이펍, 컴퓨터비전, 패턴인식'도서 소개' Related Articles아마존 웹 서비스 부하 테스트 입문코딩 교육을 위한 마이크로비트마이크로소프트 봇 프레임워크 프로그래밍: 챗봇 구축을 향한 다층적 접근웹 서비스를 만들며 배우는 node.js 프로그래밍: 설치에서 배포까지    setInitialEntryComments(835, 1723618413)Secret댓글달기loadedComments[835]=true;findFragmentAndHighlight(835);"
54,https://goodman710012-1.tistory.com/entry/%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%B1%84%EC%9A%A9-%EC%9E%90%EC%84%B8%ED%9E%88-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0,1. 네이버 채용 자세히 알아보기," 팁앤테크 - 생활 팁과 기술 블로그xclose 팁앤테크 - 생활 팁과 기술 블로그  분류 전체보기 (37) 홈태그방명록카테고리 없음 · 2024. 6. 28. fullscreen넓게보기fullscreen_exit원래대로네이버 채용 자세히 알아보기 네이버 채용 자세히 알아보기네이버 채용네이버는 ""사람들의 삶에 기쁨과 편의를 더하는 서비스로 세상을 바꾸는 회사""를 비전으로 인터넷 서비스를 제공하는 기업입니다. 검색 포털, 커뮤니티, 쇼핑, 금융 등 다양한 분야에서 혁신적인 서비스를 개발하고 운영하고 있습니다. 네이버 채용에서는 현재 다음과 같은 분야의 인재를 모집하고 있습니다. - 엔지니어링 (소프트웨어 개발자, 데이터 과학자, 머신러닝 엔지니어, 인프라 엔지니어, 보안 엔지니어 등) - 제품 관리 (제품 매니저, UX 디자이너, 데이터 분석가 등) - 운영 (사업 개발, 마케팅, 고객 지원 등) - 디자인 (그래픽 디자이너, 웹 디자이너, UI/UX 디자이너 등) - 기타 (재무, 인사, 법무 등) 네이버는 혁신과 창의성을 중시하는 직원 중심의 회사입니다. 우수한 근무 환경과 성장 기회를 제공하며, 직원의 웰빙과 다양성을 존중합니다. 네이버에 합류하여 함께 세상을 바꾸는 서비스를 만들어 보세요! 네이버 채용 자세히 알아보기네이버 채용 자세히 알아보기 네이버는 대한민국의 대표적인 인터넷 회사로, 포털 사이트 네이버를 운영하고 있습니다. 네이버는 매력적인 급여 및 복지, 혁신적인 업무 환경, 재능 있는 동료들과 함께 일할 기회 등 다양한 장점을 제공합니다. 네이버 채용 과정 네이버 채용 과정은 일반적으로 다음 단계로 진행됩니다. 서류 심사: 이력서 및 자기소개서 제출 1차 전화 면접: 전화를 통한 자기소개 및 업무 관련 질문 2차 실무 면접: 관련 업무 경험 및 기술 능력 평가 최종 면접: 회사 문화 적합성 및 직책에 대한 역량 평가 네이버의 근무 환경 네이버는 직원들의 복지와 성장을 중시하는 근무 환경을 제공합니다. 주요 특징은 다음과 같습니다. 혁신적인 업무 환경: 직원들이 창의력을 발휘하고 혁신을 추구할 수 있는 환경 재능 있는 동료들: 각 분야의 전문가들과 함께 일할 수 있는 기회 적극적인 지원 체계: 멘토링 프로그램, 교육 기회 등 직원 성장을 지원하는 다양한 프로그램 급여 및 복지: 업계 최고 수준의 급여, 주식 옵션, 의료 보험 등 포괄적인 복지 패키지 네이버 채용 지원 방법 네이버 채용 지원은 네이버 공식 홈페이지(www.naver.com/jobs)를 통해 가능합니다. 지원자는 지원하고자 하는 직책을 선택하고, 이력서와 자기소개서를 제출해야 합니다. 네이버 채용에 성공하려면 다음 사항이 중요합니다. 자격 요건 충족: 지원 직책에 필요한 학력, 경험, 기술을 갖추고 있는지 확인 매력적인 이력서 및 자기소개서: 자신의 강점, 관련 경험, 네이버에 대한 열정을 명확하게 표현 면접 준비: 업무 관련 질문에 대비하고 네이버에 대한 지식을 쌓음 적극적인 자세: 채용 담당자와 소통하고, 피드백을 받아 자신의 지원서를 개선 네이버는 끊임없이 인재를 모집하며, 재능 있고 열정적인 지원자를 환영합니다. 회사 문화에 적합하고, 혁신을 추구하는 열정이 있는 지원자는 네이버 채용에 도전해 보시기 바랍니다.## 네이버 채용 꿀팁 합격률 높이는 지원서 - 지원 서류 중시: 네이버는 지원 서류를 꼼꼼히 검토하며, 특히 자기소개서와 경력서를 중요시합니다. - 적합한 자격과 경험 강조: 지원하는 직무와 관련된 자격과 경험을 명확히 제시하십시오. - 성과 중심의 서술: 경력서에서 과거 성과를 구체적으로 서술하고, 숫자와 사례를 사용하여 측정 가능한 결과를 강조하십시오. - 열정과 동기 강조: 자기소개서에서 네이버에 합류하고자 하는 열정과 동기를 설명하십시오. - 교정 및 리뷰: 지원 서류를 제출하기 전에 철저히 교정하고, 가능한 경우 피드백을 구하십시오. 면접 성공 지침 - 기업 문화 연구: 네이버의 기업 문화와 가치관에 대해 미리 연구하십시오. - 질문 준비: 면접관이 흔히 하는 질문을 연습하고, 자신의 대답을 준비하십시오. - 능력과 기술 강조: 면접에서 자신의 능력과 기술을 자신 있고 명확하게 전달하십시오. - 창의적 사고력 과시: 네이버는 창의적 사고력을 가진 지원자를 찾고 있습니다. 면접 중에 독특하고 혁신적인 아이디어를 제시하십시오. - 열정 표현: 네이버에 대한 열정과 조직에 기여하고자 하는 의지를 보여주십시오. 기타 유용한 팁 - 네트워킹 참여: 네이버 직원과 네트워킹 행사에 참석하여 정보를 수집하고 인맥을 구축하십시오. - 채용 정보 확인: 네이버 채용 웹사이트와 소셜 미디어 계정을 정기적으로 확인하여 최신 채용 정보를 파악하십시오. - 온라인 테스트 및 과제 준비: 지원 절차가 온라인 테스트나 과제를 포함할 수 있음을 인지하고 미리 준비하십시오. - 긍정적인 태도 유지: 지원 과정 내내 긍정적인 태도를 유지하고 자신감을 갖추십시오.네이버 채용 꿀팁 1네이버에 지원하려면 몇 가지 중요한 꿀팁이 있습니다. 첫째, 네이버는 기술적인 면접을 매우 중시하기 때문에 기술적 기반을 탄탄히 다지세요. 둘째, 행동 면접에 대비하세요. 네이버는 문화적 적합성을 중요하게 생각하므로 회사 문화에 잘 맞는지 보여주는 예시를 준비하세요. 셋째, 네이버의 영어 능력 요구 사항을 반드시 충족하세요. 네이버는 글로벌 기업이므로 영어 구사 능력이 필수적입니다. 넷째, 네이버의 채용 과정은 경쟁이 치열합니다. 포기하지 말고 꾸준히 노력하세요.네이버 채용 꿀팁기술적 기반 탄탄히 다지기행동 면접에 대비하기영어 능력 요구 사항 충족하기포기하지 않고 꾸준히 노력하기1. 네이버 채용 꿀팁실력 준비- 기본기부터 꼼꼼히 复习 - 과거 개발 경험 및 프로젝트 소개서 작성에 注力 - 시험 문제 연습을 통해 문제 유형 파악정보 수집- 네이버 채용 공고 페이지 정기적으로 조회 - 네이버 채용 홈피 및 기업 블로그 확인 - 인사이드 네이버 채용자 인터뷰 기사 참고자기 소개서 작성- 개인 특징, 기술, 경험을 구체적 사례로 제시 - 네이버의 비전과 가치관에 부합하도록 표현 - 자신에게만 있는 고유한 장점 강조면접 대비- 기본 礼儀와 태도 중시 - 자기 소개서를 정확히 설명할 수 있는 준비 - 기술적 질문에 대한 대비와 문제 해결 능력 발휘네트워킹- 채용 담당자나 현직 직원과 연결 - 네이버 관련 행사 및 워크샵 참여 - 업계 네트워크를 통해 정보 교환지원 이후- 결과 통보까지 참을성 있는 기다림 - 결과가 불합격이라도 피드백을 요청 - 성공을 위해 지속적인 노력과 개발네이버 채용 꿀팁 2네이버 채용에 성공하는 데에는 여러 가지 꿀팁이 있습니다. 가장 우선적으로 고려해야 할 점은 이력서와 자기소개서를 완벽하게 작성하는 것입니다. 깔끔하고 간결하게 작성된 이력서와 자기소개서는 채용 담당자에게 귀하의 자격을 빠르게 파악할 수 있도록 도울 것입니다. 또한 네이버 기업 문화에 대해 잘 알고 있는 것도 중요합니다. 공감대를 형성하기 위해 회사의 가치관과 비전을 조사하세요. 이렇게 하면 합면 가능성이 높아집니다. 네이버 채용에 성공하려면 인내심을 갖는 것도 중요합니다. 채용 과정은 시간이 많이 걸릴 수 있습니다. 그러나 포기하지 마세요. 계속 지원하고 네트워킹을 통해 기회를 찾으세요. 마지막으로 자신감을 갖는 것이 중요합니다. 귀하의 자격에 대해 자신감을 갖고 인터뷰에 임하면 채용 담당자에게 긍정적인 인상을 줄 수 있습니다. 그러나 자만하지 않고 항상 겸손한 자세를 유지하세요.<tr style=""background-color: lightblue; </body>1. 네이버 채용 자세히 알아보기채용 분야엔지니어링마케팅디자인제품 관리운영인사기타채용 절차이력서 및 자기소개서 제출전화 면접대면 면접과제 수행건강 검진복리 후생경쟁력 있는 급여주식 옵션의료 보험연금휴가교육 지원네이버 문화혁신 중심협업적 환경사용자 지향성장 및 학습 기회인재 채용 기준업무 관련 기술 및 경험문제 해결 능력팀워크 및 협업 능력의사 소통 능력열정과 성장 의지네이버 채용에 대해 자세히 알아보기 네이버는 한국에서 가장 큰 검색 엔진과 포털 사이트로, 여러 분야에서 뛰어난 인재를 채용하고 있습니다. 네이버 채용에 관심이 있으시면 공식 홈페이지를 방문해 자세한 정보를 확인하세요. 네이버는 다양한 직무를 제공하며, 귀하의 기술과 경험에 적합한 기회를 찾을 수 있습니다. 또한 네이버는 직원에게 뛰어난 혜택과 개발 기회를 제공하여 직원들이 성장하고 성공할 수 있는 환경을 조성합니다. 네이버 채용에 지원하시면 혁신적이고 동적인 환경에서 일할 수 있는 기회를 얻게 됩니다. 네이버는 귀하의 경력에 도전과 성장의 기회를 제공합니다.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//goodman710012-1.tistory.com/reaction';window.ReactionReqBody = {    entryId: 36}공유하기게시글 관리팁앤테크 - 생활 팁과 기술 블로그저작자표시 비영리 변경금지  네이버, 채용 loadedComments[36]=true;findFragmentAndHighlight(36);var sortComment=""Comment-asc"";if(""comment-desc""==sortComment){var sortCommentcss="".post-reply .tt-list-reply { display: flex; flex-direction: column-reverse; }.post-reply .tt-list-reply li.tt-item-reply:first-child {order:1}.post-reply .tt-list-reply li.tt-item-reply.rp_general:first-child {order:0}"",styleElement=document.createElement(""style"");styleElement.innerHTML=sortCommentcss;document.head.appendChild(styleElement)}var writeCommentPosotion=""write-Comment-top"";""write-Comment-top""==writeCommentPosotion&&(sortCommentcss="".post-reply .tt-comment-cont{ display: flex; flex-direction: column-reverse; } .post-reply .tt-box-total {order:1;}"",styleElement=document.createElement(""style""),styleElement.innerHTML=sortCommentcss,document.head.appendChild(styleElement));    var contentContainer=document.querySelector("".e-content.post-content"");if(contentContainer){var tocSpace=document.createElement(""div"");tocSpace.classList.add(""toc-space"");contentContainer.insertBefore(tocSpace,contentContainer.firstChild);var headings=contentContainer.querySelectorAll(""h2, h3"");if(headings.length>0){var tocContainer=document.createElement(""div"");tocContainer.classList.add(""toc-wrap"");var ulContainer=document.createElement(""ul"");ulContainer.classList.add(""toc"");headings.forEach(function(heading,index){var tocItem=document.createElement(""li"");tocItem.classList.add(""toc-item"");var tocLink=document.createElement(""a"");tocLink.href=""#section-""+index;tocLink.textContent=heading.textContent;if(heading.tagName===""H2"")tocItem.classList.add(""h2"");else if(heading.tagName===""H3"")tocItem.classList.add(""h3"");tocItem.appendChild(tocLink);ulContainer.appendChild(tocItem);heading.id=""section-""+index;tocLink.addEventListener(""click"",function(event){event.preventDefault();var target=document.querySelector(tocLink.getAttribute(""href""));if(target){var scrollOffset= (window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth) >= 450 ? 120 : 80;var targetPosition=target.offsetTop+scrollOffset;window.scrollTo({top:targetPosition,behavior:""smooth""})}})});var tocTitle=document.createElement(""strong"");tocTitle.textContent=""\ubaa9\ucc28"";var tocIcon = document.createElement(""div"");tocIcon.classList.add(""toc-icon"");var tocTitleContainer=document.createElement(""div"");tocTitleContainer.classList.add(""toc-title"");tocTitleContainer.appendChild(tocIcon);tocTitleContainer.appendChild(tocTitle);tocContainer.appendChild(tocTitleContainer);tocContainer.appendChild(ulContainer);tocSpace.appendChild(tocContainer)}};document.addEventListener(""DOMContentLoaded"",function(){var g=document.querySelectorAll("".e-content.post-content img"");g.forEach(function(a,b){var l=a.getAttribute(""alt""),h=a.getAttribute(""data-filename"");l||a.setAttribute(""alt"",h?h:""etc-image-""+b)});if(0<g.length){var k=function(){if(0<window.pageYOffset){var a=blockedStylesheets.find(function(b){return b.href.includes(""lightbox"")});a&&loadStylesheet(a.href);(a=blockedScripts.find(function(b){return b.src.includes(""lightbox"")}))&&loadScript(a.src).then(function(){var b=lightbox;b.options.fadeDuration=200;b.options.resizeDuration=200;b.options.wrapAround=!1;b.options.albumLabel=""%1 / %2""})[""catch""](function(){});window.removeEventListener(""scroll"",k)}};window.addEventListener(""scroll"",k,{passive:!0})}var c=document.getElementById(""widen-btn""),d=document.getElementById(""original-btn""),e=document.querySelector(""#container #main #sidebar""),f=document.querySelector("".h-entry .content-width"");c&&d&&e&&f&&(c.addEventListener(""click"",function(a){a.preventDefault();e.style.display=""none"";c.style.display=""none"";d.style.display=""inline-block"";f.classList.add(""wide"")}),d.addEventListener(""click"",function(a){a.preventDefault();e.style.display=""block"";d.style.display=""none"";c.style.display=""inline-block"";f.classList.remove(""wide"")}))});공지사항전체 카테고리  분류 전체보기 (37) 최근 글머리가띵하고어지러워요 자세히 알아보기치핵 2기 자세히 알아보기itq한글시험일정 자세히 알아보기공무원 블로그 수익 자세히 알아보기네이버 채용 자세히 알아보기인기 글충북 진천 출렁다리 자세히 알아보기24년 예비군 원격교육 자세히 알아보기머리가띵하고어지러워요 자세히 알아보기itq한글시험일정 자세히 알아보기저돌적 뜻 자세히 알아보기최근 댓글마곡통 - 마곡 부동산정보 06.17 잘~읽고　가요~~ 좋은 하루되세요 태그#아이오닉7#GV90#itq한글시험일정#애사비#머리가띵하고어지러워요#자세히#kmo시험#네오룬#세부여행계획#송진가루전체 방문자오늘7어제2전체289Copyright © 쭈미로운 생활 All rights reserved.Designed by JJuumdocument.addEventListener(""DOMContentLoaded"",function(){function m(a,b){if(a.isIntersecting){if(a.target.classList.contains(""post-reply"")){var c=blockedStylesheets.find(function(d){return d.href.includes(""comment"")});c&&loadStylesheet(c.href);(c=blockedScripts.find(function(d){return d.src.includes(""comment"")}))&&loadScript(c.src).then(function(){var d=new Event(""load"");window.dispatchEvent(d)})[""catch""](function(){})}else a.target.classList.contains(""container_postbtn"")?g||((c=blockedStylesheets.find(function(d){return d.href.includes(""postBtn"")}))&&loadStylesheet(c.href),(c=blockedScripts.find(function(d){return d.src.includes(""reaction-button-container"")}))&&loadScript(c.src),a.target.style.visibility=""visible"",g=!0):""PRE""!==a.target.parentElement.tagName||""CODE""!==a.target.tagName||h||(loadStylesheet(""//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/vs2015.min.css""),loadScript(""//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"").then(function(){hljs.highlightAll();loadScript(""//cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"").then(function(){hljs.initLineNumbersOnLoad()})[""catch""](function(){})})[""catch""](function(){}),h=!0);b.unobserve(a.target)}}function k(){if(0<window.pageYOffset){var a=blockedScripts.find(function(b){return b.src.includes(""googletagmanager.com/gtag/js?id"")});a&&loadScript(a.src).then(function(){var b=document.createElement(""script"");b.innerHTML=blockedScriptContents[0].textContent;document.head.appendChild(b)})[""catch""](function(){});window.removeEventListener(""scroll"",k)}}mutationObserver.disconnect();var h=!1,g=!1,l=!1,e=document.querySelectorAll("".post-reply, .container_postbtn, pre code""),n=new IntersectionObserver(function(a,b){a.forEach(function(c){m(c,b)})},{root:null,rootMargin:""200px"",threshold:.2});e.forEach(function(a){n.observe(a)});window.addEventListener(""scroll"",function(){var a=(document.body.scrollTop||document.documentElement.scrollTop)/(document.documentElement.scrollHeight-document.documentElement.clientHeight)*100,b=document.getElementById(""progress"");b&&(b.style.width=a+""%"")},{passive:!0});var f=document.getElementById(""header_wrap"");f&&window.addEventListener(""scroll"",function(){50<window.scrollY?f.classList.add(""shrink""):f.classList.remove(""shrink"")},{passive:!0});(e=document.querySelector("".btn_topMenu""))&&e.addEventListener(""click"",function(a){a.stopPropagation();if(a=document.querySelector("".dropdown-content"")){if(!l){var b=blockedScripts.find(function(c){return c.src.includes(""menubar.min"")});b&&loadScript(b.src);if(b=document.querySelector("".dropdown-profile_bg img""))b.src=b.dataset.src,b.style.display=""block"",b.removeAttribute(""data-src"");l=!0}a.classList.toggle(""dropdown-content-toggle"")}});(e=document.querySelector("".btn_close""))&&e.addEventListener(""click"",function(a){a.stopPropagation();(a=document.querySelector("".dropdown-content""))&&a.classList.remove(""dropdown-content-toggle"")});document.querySelectorAll("".post_category_name"").forEach(function(a){var b=a.textContent.trim().split(""/"")[1];b&&(a.textContent=b.trim())});document.querySelectorAll("".p-category"").forEach(function(a){var b=a.textContent.split(""/"")[1];b&&(a.textContent=b.trim())});document.querySelectorAll(""iframe"").forEach(function(a){var b=a.getAttribute(""name"");a.setAttribute(""title"",b||""inner iframe"")});(e=document.getElementById(""content""))&&e.classList.add(""show"");window.addEventListener(""scroll"",k,{passive:!0})});티스토리툴바document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""6950785-36"",""customProps"":{""userId"":""0"",""blogId"":""6950785"",""entryId"":""36"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""36"",""entryTitle"":""네이버 채용 자세히 알아보기"",""entryType"":""POST"",""categoryName"":""카테고리 없음"",""categoryId"":""0"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""6598754"",""authorNickname"":""쿠첸"",""blogNmae"":""팁앤테크 - 생활 팁과 기술 블로그"",""image"":""kage@LccEs/btsIeko89Yr/d6img91hkvXqXg4lJeXanK"",""plink"":""/entry/%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%B1%84%EC%9A%A9-%EC%9E%90%EC%84%B8%ED%9E%88-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0"",""tags"":[""네이버"",""채용""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
55,https://sexybill.tistory.com/78,공공기관 면접 1분 자기소개 예시,"합격한 면접 1분 자기소개 예시 - 공공기관 편2020.11.06 17:58빌하임의 생산성 라이프글 작성자: 빌하임     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }      (adsbygoogle = window.adsbygoogle || []).push({}); 합격한 면접 1분 자기소개 예시 - 공공기관 편공공기관 면접 1분 자기소개 예시안녕하세요. 빌하임입니다. 이번 글은 실제로 합격을 이뤄낸 면접 1분 자기소개 예시를 다룹니다. 저처럼 합격하기까지 시행착오를 겪지 않고, 1분 자기소개에서 면접관의 질문과 좋은 반응을 얻고 싶은 분들은 아래를 참고하세요.      (adsbygoogle = window.adsbygoogle || []).push({}); 저는 공공기관에 들어가기 위해 일대일, 일대다, 다대다 면접부터 토론/토의면접, 인성면접, AI면접, 영어면접, 프레젠테이션 면접, 롤플레잉 면접 등 산전수전 다 겪었습니다.  공기업의 경우 서류와 필기시험은 강의를 수강하고 철저히 준비하여 떨어진 적이 거의 없었기 때문에 면접 경험만큼은 그 누구보다 많다고 자신할 수 있습니다. 실무면접, 임원면접까지 포함하면 지금까지 경험한 면접만 10차례가 넘는데요, 대략 기억나는 것만 적어보면 다음과 같습니다. 공무원 면접 2회 (경력경쟁채용 포함), 한국공항공사면접 3회, 인천국제공항공사 면접 2회, 한국전력공사 면접 1회, 지방 공단면접 3회 등  이렇게 경험이 많다보니 굳이 학원을 다닐 필요 없이 면접을 준비할 수 있다고 생각하며 준비했지만, 스터디를 하더라도 정작 저는 떨어지고 남들은 붙여주는 괴현상을 겪어보며 마음을 바꾸게 되었습니다. 그렇게 면접학원과 스터디를 전전하며 결국 면접을 통과하는 자기소개는 따로 있다는 것을 알게 되었습니다. 아무리 스펙과 말빨이 뛰어나도 나머지 1%를 채우기 위해서는 아래와 같은 전문가의 지도를 받은 1분 자기소개가 필요하다는 것을 말입니다.       (adsbygoogle = window.adsbygoogle || []).push({}); 덕분에 위에 서술한 기관 중 한 곳에 합격할 수 있었습니다. 물론 표정과 몸짓까지 알려주는 면접 전문가만큼은 아니지만, 그들로부터 배운 맞춤형 1분 자기소개 예시를 알려드리겠습니다. 면접 1분 자기소개 예시 - 작성법1분 자기소개는 자기 분석부터자기소개는 역시 먼저 자신의 성향 분석하는 것에서 시작됩니다. 강점과 장점만 강조하려 욕심을 부리다가 자기소개가 안드로메다로 갈 수 있습니다. 떨어지지 않고 싶으시다면 아래를 참고하세요.       (adsbygoogle = window.adsbygoogle || []).push({}); 자신이 작성한 자소서를 바탕으로 AI가 자기 분석을 도와주는 도구가 있습니다. 아래 사진은 채용사이트인 ‘사람인’에서 자신의 성격을 분석하는 방법을 설명합니다. 사람인 AI 역량 분석 : 작성한 자기소개서를 이력서에 입력 후 역량분석을 한다. 위에서 보시듯 저의 성향은 ‘실용적, 생산적, 도구다루기, 순응, 말이 적음, 공정, 신뢰, 진솔, 양심적, 정직’이 키워드인 것을 알 수 있습니다. 아래는 이를 바탕으로 작성한 블라인드 면접 1분 자기소개 예시입니다.안녕하십니까! OO지역 OO 직무에 지원한 지원자 #번입니다. 저는 (직무와 연관된 경험)으로부터 신재생에너지의 사업성을 알게 되었고, OO기업의 (원하는 부서 구체적으로)에서 근무하고 싶다는 꿈을 갖게 되었습니다. 그래서 먼저 (직무와 연관된 기업, 아르바이트 경험)을 하였습니다. 그곳에서 (직무경험#1)과 (직무경험#2)을 해보았지만 고객에 대한 이해는 끝이 없었습니다. 몇 번의 실패가 있었지만, 그런 실패가 고객을 진정으로 이해하는 계기를 마련해 주었고, 결국 팀원과 함께 (실패를 극복한 성공경험)을 해냈습니다. 이처럼 전공이 달라도(전공이 다른 경우) 노력으로 극복할 수 있으며, (성공경험으로 부터 배운 점)으로 OO에서도 조직에 기여하는 신입사원이 되겠습니다. 감사합니다. 면접관 사진 앞에서 하면 더욱 효과적 1분 자기소개 예시는 40초 내외의 분량으로 길이도 적절하며, 면접관이 알고 싶어 하는 모든 것이 드러나 있습니다. 1. 지원동기2. 직무관련 경험3. 어려움을 극복한 경험 (장·단점 및 업무상 강점)4. 전공 등 부족해 보이는 스펙에 대한 보강 설명5. 조직을 대하는 자세 이처럼 면접 1분 자기소개 예시에서 보시다시피, 자기소개는 단순하지 않고 철저히 전략적으로 세워야 함을 알 수 있습니다. 이것을 혼자하시기 어렵다면 경험상 차라리 면접학원을 가시는 것을 추천 드립니다.       (adsbygoogle = window.adsbygoogle || []).push({}); 또한 이미 아시는 바와 같이 사기업은 이윤창출이 목적인만큼, 공공기관의 1분 자기소개는 사기업과 다르게 조직의 특성을 고려하셔야 합니다. 그 반대도 마찬가지겠죠? 다음에는 AI면접, 영어면접, 토론면접, 롤플레잉면접에 대한 포스팅으로 돌아오겠습니다.  AI 면접의 모든 것 (feat. 꿀팁과 후기)AI 면접의 모든 것 (feat. 꿀팁과 후기) # AI 면접이란? 안녕하세요. 빌하임입니다. 이번 글은 AI 면접을 다룹니다. 공기업의 AI면접 후기를 바탕으로 작성한 정보입니다. 만약 공기업이 아니거나, 이sexybill.tistory.com  합격한 자소서 지원동기 예시 - 공기업 및 사기업합격한 자소서 지원동기 예시 - 공기업 및 사기업 자소서 지원동기 예시 안녕하세요. 빌하임입니다. 이 글은 합격한 자소서 지원동기 예시를 다룹니다. 공기업과 사기업의 유형에 따라 자소서sexybill.tistory.com이상 생산성1번지 빌하임이었습니다.읽어주셔서 감사합니다.       (adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//sexybill.tistory.com/reaction';window.ReactionReqBody = {    entryId: 78}공유하기게시글 관리빌하임의 생산성 1번지저작자표시 비영리 변경금지 생산성댓글공유하기다른 글댓글이 댓글의 메뉴 토글    setInitialEntryComments(78, 1723618752)방문자 정보이름암호운영자에게만 공개작성하기loadedComments[78]=true;findFragmentAndHighlight(78);이 글 공유하기구독하기구독하기카카오톡카카오톡라인라인트위터트위터FacebookFacebook카카오스토리카카오스토리밴드밴드네이버 블로그네이버 블로그PocketPocketEvernoteEvernote다른 글썩지않는 깐마늘 보관법썩지않는 깐마늘 보관법2020.11.12AI 면접의 모든 것 (feat. 꿀팁과 후기)AI 면접의 모든 것 (feat. 꿀팁과 후기)2020.11.08굴밥 만드는법 - 백종원 레시피 응용굴밥 만드는법 - 백종원 레시피 응용2020.11.02담배 끊는법 (부제:자면서 3400만원 버는 법)담배 끊는법 (부제:자면서 3400만원 버는 법)2020.10.30다른 글 더 둘러보기let generalThumb=""https://blog.kakaocdn.net/dn/dbGiuN/btqMMjsmR8j/jujrFMvtyZ3RzJzgKEG4S1/img.jpg"";"
56,https://pt1000.tistory.com/67,SNS(소셜 미디어) 데이터,"4차산업혁명빅데이터(Big Data) 정의, 5가지 특징, 적용사례, 직업_총정리by 부매경2021. 5. 3.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90(adsbygoogle = window.adsbygoogle || []).push({});안녕하십니까, 부매경입니다.  오늘은 4차 산업 혁명의 기반인 빅데이터(Big Data)에 대해서 알아보겠습니다. 빅데이터란 무엇인가? 적용사례는 무엇인지, 관련 직업은 어떤 것이 있는지 한번 알아보겠습니다. 빅데이터(Big Data)란? 빅데이터 정의컴퓨터, 모바일, 센서 등을 통해 생성되는 방대한 데이터, 정보의 바다기존의 데이터 수집, 관리, 처리해주는 데이터베이스를 초과 : 제타바이트급디지털로 기록할 수 있는 SNS, 사물인터넷, 센서, 내비게이션, 카메라 등 모든 전자기기에서 생성4차 산업혁명에서의 빅데이터 핵심 정의는 정보의 바다에서 가치 있는 데이터를 분석 이해하고, 새로운 가치를 창조해 내는 것이해를 돕기 위한 예 유튜브에서 내가 검색한 기록은 데이터가 되고 유튜브는 내가 만들어낸 데이터를 바탕으로 나의 취향을 분석분석된 결과로 나에게 내가 좋아할 만한 영상을 제공 빅데이터(Big Data) 생성 방식빅데이터는 크게 정형 및 비정형 테이터로 구분하여 생성되는데, 생성 출처는 크게 3가지 정도로 구분할 수 있습니다. SNS(소셜 미디어) 데이터소셜 미디어를 통한 동영상, 이미지, 게시글, 댓글 등의 Data 생성불특정 다수의 Data로 트렌드에 민감함2023년까지 약 27억 명이 소셜 미디어 데이터 사용 전망출처 : 부매경 티스토리 캡쳐머신 데이터사물인터넷(IoT) 기기와 기기(자동차, 비행기, 드론 등)의 센서로 데이터 생성기업, 국가 중심으로 머신 데이터가 급증하고 있음데이터가 가장 많이 생성되는 곳으로 2025년까지 40억 이상 생성 전망출처 : 이코노믹 리뷰, 스마트카 센서로 데이터 기록거래 데이터 구매 및 금융 거래 등을 통한 데이터 생성코로나로 인해 비대면 거래 증가로 데이터 생성 급증함 최근 댓글, 후기 등을 통해 문자, 이미지, 동영상 등 다양한 데이터 생성빅데이터 특징기존 빅데이터 특징(3V) 출처 : 위키미디어Volume 볼륨데이터의 양이 제타바이트 급으로 증가, 데이터를 안전하게 저장, 관리 방법 요구Velocity 속도빠른 속도로 생성되는 데이터데이터 처리, 분석을 빠른 시간 내에 수행 실시간으로 데이터 생성 및 분석/처리를 통해 가치 창출Variety 다양성정형화 + 비정형화 Data의 결합 기존의 정형화된 Data는 빅데이터의 가치가 없음 예를 들어 SNS에서좋아요 클릭은 정형화된 Data + 댓글의 개인적인 의견은 비 정형화된 Data기업의 재무제표는 정형화된 Data + 기업의 재무제표 평가 댓글은 비 정형화된 Data새로운 빅데이터 특정(2V)Veracity 진실성많은 양의 데이터를 수집할수록 중요성 대두정형화된 Data는 단순 오타나, 오류가 진실성의 판단 기준비 정형화된 Data는 개인의 거짓 정보, 성향 및 데이터의 출처 등이 판단 기준Value 가치빅데이터를 활용하는 궁극적인 목적은 새로운 가치를 창출빅데이터의 분석을 통해 인사이트 제공빅데이터와 머신러닝 기존 AI 관련 포스팅을 통해 언급한 바와 같이 머신러닝은 오래된 기술입니다. 하지만 빅데이터란 개념이 없는 시절에는 크게 인정받지 못 했습니다. 지금 머신러닝은 빅데이터가 제공해주는 정보로 데이터 내 패던을 분석의사결정을 내릴 수 있는 정보를 제공하고, 이러한 프로세스를 자동화합니다. 결국 양질의 빅데이터와 머신러닝 기술이 결합하여 기업의 가치를 창출하는 구조가현재 잘 나가는 회사들의 기본 플랫폼입니다.  인공지능(AI) 1편_인공지능의 역사 (tistory.com) 인공지능(AI) 1편_인공지능의 역사안녕하십니까, 부매경입니다. 미래 사회의 가장 핵심적이고 무서운 기술 중에 하나가 바로 인공지능(AI)입니다. 머스크 형도 인공지능에 대한 우려를 지속적으로 표명하였습니다. 인공지능은 악pt1000.tistory.com빅데이터 활용 분야 빅데이터의 활용은 사실 모든 분야에 적용됩니다. 활용범위는 무한대에 가까울 정도로 앞으로 그 시장이 성장할 것으로 보고 있습니다. 재무금융 서비스에 빅데이터 활용도는 매우 높습니다.  금융거래 부정행위 조사 및 감시금융상품의 리스크 분석 및 자동 추천고객의 투자분석, 제품 추천, 피트백운송 및 물류빅데이터 분석을 통해 경로 계획, 적재 통합쿠팡, 마켓 컬리 등의 당일 배송 서비스가 대표적이 예임의료빅데이터 분석을 통해 정확하고 신뢰성 있는 진단 빅데이터를 분석을 통한 신약, 백신 개발농업식물, 가축 등의 최적의 조건에서 성장할 수 있도록 분석유통, 운송, 판매 프로세스 최적화  빅데이터(Big Data) 직업빅데이터는 크게 데이터를 수집, 저장, 관리, 처리하는 플랫폼플랫폼의 데이터를 통해 분석, 그리고 가치를 창출하여 활용하는 3가지로 나눌 수 있습니다.  데이터 플랫폼 관련 전문가빅데이터를 수집, 저장, 관리, 처리하는 플랫폼을 만들거나, 관리하는 전문가들오라클 전문가, 인공지능 전문가, 플랫폼 개발 전문가, 클라우드 전무가필요역량으로 기초 프로그래밍, 데이터베이스 기초, 멀티 플랫폼 서비스 개발, 데이터 분석 및 시각화, 빅데이터 기반 서비스 구현빅데이터 분석가빅데이터 관련 직업에 핵심 직군으로 말 그대로 데이터 플랫폼에서 제공받은 데이터를 분석하는 직업4차 산업혁명에 핵심 직군으로 생각되며 기본적으로 위에서 언급한 역량은 기본적으로 요구핵심 역량으로 통계학, 비즈니스 컨설팅, 데이터 분석 프로그래밍, 머신러닝(AI) 등이 필요함의사 결정자 빅데이터 분석가가 제시한 의견에 대한 최종 결정자 빅데이터 분석가의 역량은 기본적(원리)으로 이해는 해야 함 기본적으로 4차 산업혁명에 필요한 기술에 대한 역량은 유사하며, 기존 포스팅 한 내용과 같이 C 그룹으로 수렴되는 것 같습니다. (상세 내용은 아래 참고^^)미래의 인재상_4차산업혁명 그리고 그 후 (tistory.com) 미래의 인재상_4차산업혁명 그리고 그 후안녕하십니까, 부경매입니다. 오늘은 4차 산업혁명, 지금 우리가 살고 앞으로 우리 집 어린 XY염색체가 살아가야 할 사회에 필요한 인재상에 대해 고민해 보았습니다. 집에서 열심히 유튜브 보거pt1000.tistory.com이상입니다. 다음에는 더 좋은 정보로 찾아뵙겠습니다. 감사합니다.     window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//pt1000.tistory.com/reaction';window.ReactionReqBody = {    entryId: 67}공유하기게시글 관리부자는 매일아침 뭘 할까? '4차산업혁명' 카테고리의 다른 글UAM 도심항공교통 정의 및 총 정리_UAM 2파전 승자는? 현대자동차 vs 한화시스템  (26)2021.05.06미래 직업_미래 유망 직업 25가지_총 정리  (15)2021.05.04신재생에너지 정의 및 종류_대표 5가지 에너지  (6)2021.04.29스마트팜_교육, 창업, 현실_2027년까지 3800억 지원  (7)2021.04.27MZ세대 뜻? 특징_프로 N잡러 시대  (9)2021.04.24태그big data, 빅데이터, 빅데이터 분석가, 빅데이터 정의, 빅데이터 직업, 빅데이터 특징, 빅데이터란관련글UAM 도심항공교통 정의 및 총 정리_UAM 2파전 승자는? 현대자동차 vs 한화시스템미래 직업_미래 유망 직업 25가지_총 정리신재생에너지 정의 및 종류_대표 5가지 에너지스마트팜_교육, 창업, 현실_2027년까지 3800억 지원loadedComments[67]=true;findFragmentAndHighlight(67);"
57,https://linkareer.com/activity/160548,스타트업,채용 시 마감 (D170)[피플펀드컴퍼니] 머신러닝(ML) 소프트웨어 엔지니어2030피플펀드컴퍼니기업형태스타트업접수기간시작일2023.11.28마감일모집 시 마감채용형태신입모집직무IT/인터넷근무지역서울 서초구홈페이지https://www.peoplefund.co.kr/공유하기홈페이지 지원스크랩0스크랩한 사용자 전체보기 (0명)피플펀드컴퍼니 채팅방88명채팅방 참여하기상세내용합격자료HOT담당자Q&A 상세내용머신러닝(ML) 소프트웨어 엔지니어[담당업무]고객에게 혁신적인 금융 상품을 제공할 수 있는 적합한 모델을 실험하고 고도화 합니다.금융 데이터를 활용한 설계 및 가공을 주도합니다.[접수기간]채용시 마감[채용공고]지원서 다운로드'지원서 파일 없음'이 활동에 관심을 가지는 사용자 (0명)합격스펙 & 합격자소서더보기오른쪽 화살표최종합격후기더보기오른쪽 화살표인기 활동 리스트 보러가기오른쪽 화살표담당자 Q&A (0)등록담당자가 인증된 공고입니다. 댓글을 달면 담당자가 직접 답변해 드립니다.이 공고 조회자가 많이 본 공고
58,https://jpub.tistory.com/208,태그,"전자책제이펍이 펴낸 전자책 모음 제이펍2012. 3. 12. 17:04저희 제이펍에서 펴내는 전자책 리스트를 한눈에 볼 수 있는 페이지입니다. 계속해서 등록 날짜별로 도서 리스트를 공유해 드리겠습니다.참고로 말씀드리자면, 전자책은 종이책 출간 후 대략 2~3개월 후에 발매됩니다.또한 오라일리 출판사의 번역서는 유통 플랫폼 이슈가 있어서 전자책 제작을 하지 않고 있으니 이 점 양해 바랍니다.(취소선이 그어진 건 절판입니다) 18차_2024년 6월 14일 출간(12종)파이썬과 비교하며 배우는 러스트 프로그래밍  아이패드로 시작하는 디지털 문방구 실전 SQL 퀵스타트  러스트 서버, 서비스, 앱 만들기 실무에 바로 쓰는 일잘러의 UiPath 업무 자동화 자바 잘 읽는 법 실전 스벨트 & 스벨트킷 입문 퀴즈로 배우는 디자인 초자동화 시대가 온다 클라우드 네이티브 스프링 인 액션 고도 엔진 4 게임 개발 프로젝트(제2판)데이터 분석을 위한 줄리아17차_2024년 3월 15일 출간(17종) 누구나 쉽게 캔바로 끝내는 콘텐츠 디자인 누구나 할 수 있는 유튜브 돈 벌기 첫걸음 러스트 프로그래밍 공식 가이드(제2판) 제로부터 시작하는 러스트 백엔드 프로그래밍 키워드로 완성하는 AI 아트 테크닉 with 미드저니, 니지저니 코딩도 하고, 사장도 합니다 Go 언어로 배우는 웹 애플리케이션 개발 혼란유발자들 사이버 보안의 공격과 방어 머신러닝 시스템 구축 실전 가이드 프런트엔드 개발을 위한 보안 입문 숏폼으로 성공하는 마케팅 원칙 100 실무에 바로 쓰는 일잘러의 협업 도구 컨설팅 내 맘대로 그리는 캐릭터 이모티콘 with 프로크리에이트 모니터링의 새로운 미래 관측 가능성 Plotly로 시작하는 인터랙티브 데이터 시각화 in R & 파이썬 자바 트러블슈팅 16차_2023년 12월 14일(15종) Let’s 주짓수 챗GPT로 만드는 주식 & 암호화폐 자동매매 시스템 프롬프트 엔지니어링으로 인공지능 제대로 일 시키기그림으로 배우는 구글 클라우드 101 웹 개발 새로고침 실무에 바로 쓰는 일잘러의 마이크로카피 작성법 객체지향 파이썬 나의 첫 HTML & CSS 웹 디자인 줄리아 머신러닝, 딥러닝, 강화학습 인간 vs. AI 정규표현식 문제 풀이 대결 핵심만 골라 배우는 SwiftUI 기반의 iOS 프로그래밍(개정증보판) 오늘부터 프로듀서! 아이패드로 나만의 음악 만들기 with 개러지밴드 실전 스프링 부트 시바테이블 자동화 실무 사례로 배우는 구글 앱스 스크립트  15차_2023년 9월 15일(10종) 컴퓨팅의 정수(판매 중지됨)API 해킹의 모든 것 러브드 프런트엔드 개발자를 위한 테스트 가이드진짜 쓰는 프리미어 프로 영상 편집로블록스 게임 스크립트로 코딩 입문하기 초보 해커를 위한 칼리 리눅스 입문디자인 패턴의 아름다움ARM Cortex-M 기반의 아두이노 프로그래밍누구나 쉽게 3단계 드로잉 14차_2023년 6월 15일(12종)자바와 파이썬으로 만드는 빅데이터 시스템나는 네이버 프런트엔드 개발자입니다실무에 바로 쓰는 일잘러의 엑셀 입문백엔드 프로그래밍을 위한 PHP & MySQL아트 오브 셸 원라이너 160제이펙티브 소프트웨어 테스팅인공지능 소프트웨어 품질 보증을 위한 테스트 기법개발자를 위한 시프트-레프트 테스트파이썬을 이용한 퀀트 투자 포트폴리오 만들기그림으로 배우는 StatQuest 머신러닝 강의진짜 쓰는 일러스트레이터 진짜 쓰는 윈도우 11 13차_2023년 3월 10일(16종) 대한민국 소프트웨어 성공 방정식 <== 무료 리얼월드 암호학레트로 게임 개발 바이블실무에 바로 쓰는 Go 언어 핸즈온 가이드NestJS로 배우는 백엔드 프로그래밍핵심만 골라 배우는 젯팩 컴포즈라즈베리파이 피코, 마이크로파이썬을 만나다웹3.0과 메타버스가 만드는 디지털 혁명웹 디자인, 이렇게 하면 되나요?Go 언어를 활용한 분산 서비스 개발실무에 바로 쓰는 일잘러의 기획서 작성법세상에 하나뿐인 디자인 굿즈 만들기기초 탄탄 UX/UI 디자인을 위한 Adobe XD진짜 쓰는 포토샵 & 일러스트레이터유튜브 채널 운영을 위한 포토샵 디자인기초 탄탄 오토캐드 AutoCAD LT 도면 작성 강의12차_2022년 12월 9일(14종)개발자를 위한 PL/SQL 프로그래밍 <== 무료 업무와 일상을 정리하는 새로운 방법 노션 Notion(개정2판) 실무에 바로 쓰는 일잘러의 엑셀 데이터 분석 유니티로 배우는 게임 디자인 패턴(제2판) 제로 트러스트 구글 엔지니어는 아무도 믿지 않는다 네트워크 운용 및 유지 보수의 모든 것 코딩 인터뷰를 위한 알고리즘 치트시트 누구나 할 수 있는 유니티 2D 게임 제작 삐뽀삐뽀 보안 119 예제로 배우는 파이썬 머신러닝(제3판) 모두를 위한 클라우드 컴퓨팅 인어별에서 온 하비 프레젠테이션 디자인, 이렇게 하면 되나요? 송쌤의 엔트리 인공지능 학교11차_2022년 9월 27일(15종)디자이너의 포토샵 테크닉 141 전문가를 위한 파이썬 프로그래밍(제4판) 그림으로 공부하는 마이크로서비스 구조 딥러닝을 위한 수학 파이썬 자동화 교과서 Fusion 360으로 디자인하는 나만의 굿즈 3D 프린팅 세상에 없던 금융, 디파이(심화편) AWS로 시작하는 인프라 구축의 정석 행복을 그리는 시간, 아이패드 드로잉 with 어도비 프레스코 좋은 코드, 나쁜 코드 비전공자를 위한 인공지능 교과서 진짜 쓰는 실무 엑셀 사물인터넷을 품은 라즈베리 파이(개정판) 사물인터넷을 위한 리눅스 프로그래밍 with 라즈베리 파이(전면개정판) 서버/인프라를 지탱하는 기술너 오랫동안 이런 걸 원하고 있었구나 10차_2022년 6월 22일(19종)네트워크 이해 및 설계 가이드(개정판) 쏙쏙 들어오는 함수형 코딩 실무에 바로 적용하는 파이썬 코드 레시피 302 마스터링 자기주권신원 효율성이 배가되는 WSL2 가이드북 Apache Airflow 기반의 데이터 파이프라인 알 스웨이가트의 파이썬 프로젝트 세상에 없던 금융, 디파이(입문편) 단단한 심층강화학습 파이썬 머신러닝 실무 테크닉 100 코드로 배우는 인공지능 가볍게 떠먹는 데이터 분석 프로젝트 유튜브 영상 편집을 위한 파이널 컷 프로 X 디자인, 이렇게 하면 되나요? 돈이 되는 IT 트렌드 실무에 바로 쓰는 일잘러의 보고서 작성법 프로그래머를 위한 파이썬 임베디드 엔지니어 교과서 IT에 몸담은 이들을 위한 지적 생산 기술 9차_2022년 3월 23일(12종)Go 언어를 활용한 네트워크 프로그래밍 프로그래머의 뇌 머신러닝 엔지니어링 도커, 컨테이너 빌드업! DNS 실전 교과서 그림으로 공부하는 TCP/IP 구조 임파워드실전에서 바로 쓰는 시계열 데이터 처리와 분석 in R 엑셀과 비교하며 배우는 파이썬 데이터 분석 쏙쏙 들어오는 인공지능 알고리즘 다양한 예제로 배우는 CSS 설계 실전 가이드 웹 개발자를 위한 대규모 서비스를 지탱하는 기술 8차_2021년 12월 20일(15종)유저가 모이는 모바일 RPG 기획 작법서 인공지능(제4판) 2 인공지능(제4판) 1 21개의 작고 재미난 파이썬 프로젝트 블록체인 인 액션 실무 예제로 배우는 데이터 공학 핵심만 골라 배우는 안드로이드 스튜디오 Arctic Fox & 프로그래밍 세상에서 제일 쉬운 키네마스터 영상 편집 파이썬으로 배우는 게임 개발 실전편 파이썬으로 배우는 게임 개발 입문편 검색을 위한 딥러닝 인스타그램 마케팅을 위한 상품 사진의 비밀 37 케라스 창시자의 딥러닝 with R 리액트 인 액션 모두를 위한 리눅스 프로그래밍 7차_2021년 7월 26일(14종)논쟁적 UX <== 무료파이썬 챌린지어도비 스케치 앱으로 기록하는 스마트폰 & 아이패드 드로잉PM 인터뷰의 모든 것해커의 기쁨 백설공주 거울과 인공지능 이야기허교수의 ARM Mbed 프로그래밍 입문아마존 웹 서비스 부하 테스트 입문실무에 바로 적용하는 안드로이드 프로그래밍(제4판)그림으로 공부하는 오라클 구조(개정판)오픈스택 기반의 프라이빗 클라우드 서비스효율적 개발로 이끄는 파이썬 실천 기술업무와 일상을 정리하는 새로운 방법 노션 Notion(개정판)이베이 & 아마존 해외 역직구 셀링 6차_2021년 4월 15일(12종)C포자를 위한 본격 C 언어 프로그래밍 <== 무료자바 개발자를 위한 97가지 제안 그림으로 공부하는 IT 인프라 구조(개정판) 심층 강화학습 인 액션 실무에 바로 적용하는 자바스크립트 코드 레시피 278 15단계로 배우는 도커와 쿠버네티스 데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집 핵심만 골라 배우는 SwiftUI 기반의 iOS 프로그래밍 네트워크 쉽게, 더 쉽게(제4판) 빅데이터를 지탱하는 기술 자바 기반의 마이크로서비스 이해와 아키텍처 구축하기 TCP/IP 쉽게, 더 쉽게 5차_2020년 12월 16일(13종)통계의 아름다움한 권으로 끝내는 블록체인 교과서송쌤의 엔트리 콘텐츠 작품집자기주권 신원증명 구조 분석서객체지향 사고 프로세스(제5판)구글에서 배운 직장인 실무 컴퓨터 활용 45창업부터 운영까지 단계별로 실천하는 SNS 마케팅똥손 탈출 100일 100 드로잉파이썬으로 배우는 자연어 처리 인 액션실습으로 완성하는 구글 클라우드 플랫폼 인 액션알파고를 분석하며 배우는 인공지능따라하며 배우는 데이터 과학인공지능, 인간을 유혹하다 <== 무료 4차_2020년 09월 03일(12종)키워드로 정리하는 정보보안 119스프링 인 액션(제5판)단단한 강화학습딥러닝 인 더 브라우저송쌤의 스크래치 코딩 학교송쌤의 엔트리 게임 코딩 학교모던 C++로 배우는 동시성 프로그래밍몽고디비 인 액션(제2판)송쌤의 엔트리 코딩 학교Go 인 액션Flask 기반의 파이썬 웹 프로그래밍벤츠 타는 프로그래머 <== 무료 3차_2020년 06월 03일(12종)단단한 머신러닝알파제로를 분석하며 배우는 인공지능머신러닝 도감러스트 프로그래밍 공식 가이드카이젠 저니빅 너드 랜치의 코틀린 프로그래밍하이퍼레저 패브릭으로 배우는 블록체인알고리즘 도감처음 만나는 알고리즘실리콘밸리 견문록 <== 무료아두이노 상상을 스케치하다코드로 알아보는 ARM 리눅스 커널 2차_2020년 04월 09일(11종)함수형 언어 산책프로페셔널 안드로이드(제4판)오렌지노의 영상 편집을 위한 유튜브 배경음악고양이도 할 수 있는 Vue.js파이토치 첫걸음앤디 필드의 유쾌한 R 통계학빅데이터 분석과 활용심층 학습R로 배우는 실무 데이터 과학클린 소프트웨어세븐 데이터베이스 1차_ 2020년 01월 02일(12종)업무와 일상을 정리하는 새로운 방법 Notion 코딩 강화 파이썬신경망과 심층학습브레인 이미테이션 개발자도 궁금한 IT 인프라코드로 알아보는 ARM 리눅스 커널(제2판)스프링 부트로 배우는 자바 웹 개발인스파이어드(개정증보판)한 권으로 배우는 파이썬 기초 & 알고리즘 사고법어서 와, 컴퓨터 없는 코딩은 처음이지?2D/3D 멀티 플랫폼 게임을 위한 유니티 2018코어 이더리움 프로그래밍 <== 무료===============================================================출판사의 사정으로 인해 당분간 전자책을 판매하지 않기로 하였습니다. 추후 적당한 시기에 새로운 형태의 전자책을 준비하여 다시 선보이도록 하겠습니다. 지금까지 전자책을 이용해주신 분들께 감사의 말씀을 드립니다. 이 포스트는 제이펍에서 출간하는 전자책(앱북) 전체 리스트를 보여주는 포스트입니다. 앞으로 추가될 때마다 별도의 소개 포스트를 작성하지 않고 이 포스트에 추가하도록 하겠습니다. 현재는 아이패드용 앱북 형태로만 준비되어 있어 앱스토어에서만 구매하실 수 있음을 알려드립니다. 다른 버전(안드로이드나 PC용 등)으로 제작되면 추후 다시 안내해드리겠습니다. 앱북 제작업체: 두나무현재 판매 중인 전자책 아론 힐리가스의 오브젝티브-C 프로그래밍  도서소개: http://jpub.tistory.com/223판매가: 12.99$  핵심만 골라 배우는 iOS 프로그래밍   도서소개: http://jpub.tistory.com/184판매가: 14.99$    제로데이   도서소개: http://jpub.tistory.com/191판매가: 7.99$핵심만 골라 배우는 오브젝티브-C 프로그래밍  도서소개: http://jpub.tistory.com/179판매가: 11.99$       window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 208}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기저작자표시 비영리 변경금지 태그두나무, 앱북, 전자책, 제이펍이전 댓글 더보기    setInitialEntryComments(208, 1723627670)Secret댓글달기loadedComments[208]=true;findFragmentAndHighlight(208);"
59,https://jpub.tistory.com/1014,태그,"도서 소개단단한 머신러닝: 머신러닝 기본 개념을 제대로 정리한 인공지능 교과서 제이펍2020. 2. 26. 14:56간결한 설명과 최소한의 수학적 지식을 통해 체계적으로 정리한 머신러닝 입문서!도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]출판사 제이펍저작권사 清华大学出版社원서명 机器学习(원서 ISBN: 9787302423287)저자명 조우쯔화역자명 김태헌출판일 2020년 2월 28일페이지 536쪽시리즈 I♥A.I. 24(아이러브 인공지능 24)판 형 188*245*26제 본 무선(soft cover)정 가 30,000원ISBN 979-11-88621-98-9(93000)키워드 머신러닝 / 딥러닝 / 인공지능 / 신경망 / 베이지안 / 강화학습 / 기계학습 / 심층학습 / 준지도학습 / 클러스터링 / 서포트 벡터 머신 / 앙상블 학습분야 인공지능 / 머신러닝관련 사이트■ 저작권사 도서 소개 페이지■ dangdang 도서 소개 페이지■ 역자 도서 A/S 블로그관련 포스트■ 2020/02/14 - [출간전 책소식] - 50만 부가 판매된 중국의 인공지능 서적!관련 시리즈■ I♥A.I 시리즈관련 도서■ (관련 시리즈 참고) 강의보조자료 다운로드교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표관련 파일 다운로드■ 한국어 버전 연습문제 해답(이 자료는 저작권사로부터 제공받지 못한 자료입니다. 역자께서 개인적으로 시간과 노력을 들여 준비하고 있으며, 순차적으로 등록될 예정임을 안내해 드립니다)■ 중국어 버전 연습문제 해답(이 자료는 저작권사로부터 공식적으로 인정받은 자료는 아님을 밝힙니다)샘플 PDF(차례, 추천사, 옮긴이 머리말, 머리말, 이 책의 사용법, 베타리더 후기, 주요 기호표, 1장 '서론' 전체, 2장 '모델 평가 및 선택' 일부, 3장 '선형 모델' 일부, 16장 '강화 학습' 일부) 단단한머신러닝_sample.pdf정오표 페이지■ https://jpub.tistory.com/1028도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]도서 소개간결한 설명과 최소한의 수학적 지식을 통해 체계적으로 정리한 머신러닝 입문서!출간 3개월 만에 3만 부 판매!(중국 기준)누적 50만 부 돌파!(2020년 2월 중국 기준)중국 주요서점 장기 베스트셀러(중국 기준)이 책은 인공지능 분야의 명예의 전당이라는 AAAI의 펠로우로 선정된 저자가 머신러닝을 처음 접하는 독자를 위해 2년간 정성을 다해 집필한 책입니다. 이공계 고학년과 대학원의 16주 머신러닝 강의에 맞춰 각 장이 30페이지가 넘지 않는 16개의 장과 수준 있는 연습문제로 구성하였으며, 최대한 다양한 독자에게 머신러닝을 소개하기 위해 최소한의 수학적 지식만을 사용하였습니다.이 책의 주요 목적은 독자들에게 나무와 숲을 함께 볼 수 있는 ‘초급 지도’를 제공해 머신러닝 입문자들이 올바른 방향으로 나갈 수 있도록 도와주는 것입니다. 다양한 머신러닝 알고리즘을 이해하기 쉽도록 이론뿐만 아니라 내부 처리 로직까지 설명하고 있어서 실제 머신러닝 기법의 개념과 원리를 탄탄하게 배울 수 있습니다.아울러 체계적이고 간결한 내용 전개는 학부나 대학원의 교재뿐만 아니라 독학을 위한 자습서나 연구 참고용 도서로도 좋습니다.지은이 소개조우쯔화(Zhou Zhihua)난징대학교 컴퓨터과학과 교수미국 컴퓨터학회(ACM) 선정 우수과학자AAAI, IEEE, IAPR, IET/IEE 펠로우국가 우수청년장학금 수상자Chang Jiang Scholars 특별 초청 교수현) 중국 인공지능학회 머신러닝 전문위원회 회장, 중국 컴퓨터학회 인공지능 및 패턴인식 전문위원회 부회장, IEEE 컴퓨터학회 난징지부 의장옮긴이 소개김태헌하나금융융합기술원에서 데이터 과학자로 일하면서 로보어드바이저, 신용평가 시스템 개발 등의 프로젝트에 참여하고 있다. 중학생 시절부터 10여년간을 중국에서 보냈으며, 베이징 대학교를 졸업하고 미국 캘리포니아 대학교 샌디에이고 캠퍼스에서 국제경제 석사 학위를 받았다.차례CHAPTER 01 서론 11.1 들어가며 11.2 머신러닝의 기본 용어 21.3 가설 공간 51.4 귀납적 편향 81.5 발전 과정 131.6 응용 현황 181.7 더 읽을거리 22연습문제 25 참고문헌 26 머신러닝 쉼터 28더보기접기CHAPTER 02 모델 평가 및 선택 292.1 경험 오차 및 과적합 292.2 평가 방법 312.3 모델 성능 측정 372.4 비교 검증 472.5 편향과 분산 572.6 더 읽을거리 59연습문제 61 참고문헌 62 머신러닝 쉼터 64CHAPTER 03 선형 모델 653.1 기본 형식 653.2 선형 회귀 663.3 로지스틱 회귀 703.4 선형 판별분석 733.5 다중 분류 학습 773.6 클래스 불균형 문제 803.7 더 읽을거리 83연습문제 85 참고문헌 86 머신러닝 쉼터 88CHAPTER 04 의사결정 트리 894.1 기본 프로세스 894.2 분할 선택 924.3 가지치기 984.4 연속값과 결측값 1034.5 다변량 의사결정 트리 1104.6 더 읽을거리 113연습문제 115 참고문헌 117 머신러닝 쉼터 118CHAPTER 05 신경망 1195.1 뉴런 모델 1195.2 퍼셉트론과 다층 네트워크 1215.3 오차 역전파 알고리즘 1245.4 글로벌 미니멈과 로컬 미니멈 1305.5 기타 신경망 1335.6 딥러닝 1395.7 더 읽을거리 142연습문제 144 참고문헌 145 머신러닝 쉼터 148CHAPTER 06 서포트 벡터 머신 1496.1 마진과 서포트 벡터 1496.2 쌍대문제 1516.3 커널 함수 1556.4 소프트 마진과 정규화 1586.5 서포터 벡터 회귀 1636.6 커널 기법 1676.7 더 읽을거리 170연습문제 172 참고문헌 173 머신러닝 쉼터 175CHAPTER 07 베이지안 분류기 1777.1 베이지안 결정 이론 1777.2 최대 우도 추정 1797.3 나이브 베이즈 분류기 1817.4 세미 나이브 베이즈 분류기 1867.5 베이지안 네트워크 1887.6 EM 알고리즘 1957.7 더 읽을거리 197연습문제 199 참고문헌 200 머신러닝 쉼터 202CHAPTER 08 앙상블 학습 2038.1 객체와 앙상블 2038.2 부스팅 2068.3 배깅과 랜덤 포레스트 2118.4 결합 전략 2158.5 다양성 2218.6 더 읽을거리 227연습문제 229 참고문헌 231 머신러닝 쉼터 234CHAPTER 09 클러스터링 2359.1 클러스터링 학습 문제 2359.2 성능 척도 2369.3 거리 계산법 2389.4 프로토타입 클러스터링 2419.5 밀도 클러스터링 2529.6 계층 클러스터링 2559.7 더 읽을거리 259연습문제 262 참고문헌 264 머신러닝 쉼터 266CHAPTER 10 차원 축소와 척도 학습 26710.1 k-최근접 이웃 기법 26710.2 임베딩 26910.3 주성분 분석 27310.4 커널 선형 차원 축소 27510.5 매니폴드 학습 27810.6 척도 학습 28210.7 더 읽을거리 285연습문제 287 참고문헌 288 머신러닝 쉼터 290CHAPTER 11 특성 선택과 희소 학습 29111.1 부분집합 탐색과 평가 29111.2 필터식 선택 29411.3 포괄식 선택 29611.4 임베딩식 선택과 L1 정규화 29811.5 희소 표현과 사전 학습 30111.6 압축 센싱 30411.7 더 읽을거리 308연습문제 310 참고문헌 311 머신러닝 쉼터 314CHAPTER 12 계산 학습 이론 31512.1 기초 지식 31512.2 PAC 학습 31712.3 유한 가설 공간 31912.4 VC 차원 32312.5 라데마허 복잡도 32912.6 안정성 33512.7 더 읽을거리 339연습문제 341 참고문헌 342 머신러닝 쉼터 343CHAPTER 13 준지도 학습 34513.1 언레이블된 데이터 34513.2 생성적 방법 34813.3 준지도 SVM 35213.4 그래프 준지도 학습 35513.5 불일치에 기반한 방법 35913.6 준지도 클러스터링 36313.7 더 읽을거리 368연습문제 370 참고문헌 372 머신러닝 쉼터 374CHAPTER 14 확률 그래피컬 모델 37514.1 은닉 마르코프 모델 37514.2 마르코프 랜덤 필드 37914.3 조건 랜덤 필드 38314.4 학습과 추론 38614.5 근사추론 39014.6 토픽 모델 39714.7 더 읽을거리 400연습문제 403 참고문헌 404 머신러닝 쉼터 406CHAPTER 15 규칙 학습 40715.1 기본 개념 40715.2 순차적 커버링 41015.3 가지치기 최적화 41415.4 일차 규칙 학습 41615.5 귀납 논리 프로그래밍 42015.6 더 읽을거리 428연습문제 431 참고문헌 432 머신러닝 쉼터 434CHAPTER 16 강화 학습 43516.1 과업과 보상 43516.2 K-암드 밴딧 43816.3 모델 기반 학습 44316.4 모델-프리 학습 45016.5 가치 함수 근사 45716.6 이미테이션 러닝 46016.7 더 읽을거리 462연습문제 464 참고문헌 465 머신러닝 쉼터 467APPENDIX A 행렬 469A.1 기본 연산 469A.2 도함수 470A.3 특잇값 분해 472APPENDIX B 최적화 474B.1 라그랑주 승수법 474B.2 이차 프로그래밍 477B.3 반정형 프로그래밍 478B.4 경사하강법 479B.5 좌표하강법 480APPENDIX C 확률 분포 482C.1 자주 사용하는 확률 분포 482C.2 켤레 분포 487C.3 KL 발산 488에필로그 489찾아보기 494접기제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!) 네이버 책  포스트  유튜브  인스타그램  트위터  페이스북window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1014}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글파이썬으로 배우는 자연어 처리 인 액션  (0)2020.03.02인스타그램 마케팅을 위한 상품 사진의 비밀 37  (0)2020.02.26딥러닝 인 더 브라우저: 자바스크립트 프레임워크를 이용한 딥러닝 웹 개발  (0)2020.02.18유튜브 영상 편집을 위한 프리미어 프로  (10)2020.01.15풍부한 그림과 사진으로 배우는 네트워크 쉽게 더 쉽게(제4판)  (0)2020.01.10태그Machine Learning, 강화학습, 기계학습, 김태헌, 딥러닝, 머신러닝, 베이지안, 신경망, 심층학습, 아이러브인공지능, 인공지능, 제이펍, 조우쯔화, 중국책'도서 소개' Related Articles파이썬으로 배우는 자연어 처리 인 액션인스타그램 마케팅을 위한 상품 사진의 비밀 37딥러닝 인 더 브라우저: 자바스크립트 프레임워크를 이용한 딥러닝 웹 개발유튜브 영상 편집을 위한 프리미어 프로Secret댓글달기loadedComments[1014]=true;findFragmentAndHighlight(1014);"
60,https://goodman710012-1.tistory.com/entry/%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%B1%84%EC%9A%A9-%EC%9E%90%EC%84%B8%ED%9E%88-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0,1. 네이버 채용 자세히 알아보기," 팁앤테크 - 생활 팁과 기술 블로그xclose 팁앤테크 - 생활 팁과 기술 블로그  분류 전체보기 (37) 홈태그방명록카테고리 없음 · 2024. 6. 28. fullscreen넓게보기fullscreen_exit원래대로네이버 채용 자세히 알아보기     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); } 네이버 채용 자세히 알아보기네이버 채용네이버는 ""사람들의 삶에 기쁨과 편의를 더하는 서비스로 세상을 바꾸는 회사""를 비전으로 인터넷 서비스를 제공하는 기업입니다. 검색 포털, 커뮤니티, 쇼핑, 금융 등 다양한 분야에서 혁신적인 서비스를 개발하고 운영하고 있습니다. 네이버 채용에서는 현재 다음과 같은 분야의 인재를 모집하고 있습니다. - 엔지니어링 (소프트웨어 개발자, 데이터 과학자, 머신러닝 엔지니어, 인프라 엔지니어, 보안 엔지니어 등) - 제품 관리 (제품 매니저, UX 디자이너, 데이터 분석가 등) - 운영 (사업 개발, 마케팅, 고객 지원 등) - 디자인 (그래픽 디자이너, 웹 디자이너, UI/UX 디자이너 등) - 기타 (재무, 인사, 법무 등) 네이버는 혁신과 창의성을 중시하는 직원 중심의 회사입니다. 우수한 근무 환경과 성장 기회를 제공하며, 직원의 웰빙과 다양성을 존중합니다. 네이버에 합류하여 함께 세상을 바꾸는 서비스를 만들어 보세요! 네이버 채용 자세히 알아보기네이버 채용 자세히 알아보기 네이버는 대한민국의 대표적인 인터넷 회사로, 포털 사이트 네이버를 운영하고 있습니다. 네이버는 매력적인 급여 및 복지, 혁신적인 업무 환경, 재능 있는 동료들과 함께 일할 기회 등 다양한 장점을 제공합니다. 네이버 채용 과정 네이버 채용 과정은 일반적으로 다음 단계로 진행됩니다. 서류 심사: 이력서 및 자기소개서 제출 1차 전화 면접: 전화를 통한 자기소개 및 업무 관련 질문 2차 실무 면접: 관련 업무 경험 및 기술 능력 평가 최종 면접: 회사 문화 적합성 및 직책에 대한 역량 평가 네이버의 근무 환경 네이버는 직원들의 복지와 성장을 중시하는 근무 환경을 제공합니다. 주요 특징은 다음과 같습니다. 혁신적인 업무 환경: 직원들이 창의력을 발휘하고 혁신을 추구할 수 있는 환경 재능 있는 동료들: 각 분야의 전문가들과 함께 일할 수 있는 기회 적극적인 지원 체계: 멘토링 프로그램, 교육 기회 등 직원 성장을 지원하는 다양한 프로그램 급여 및 복지: 업계 최고 수준의 급여, 주식 옵션, 의료 보험 등 포괄적인 복지 패키지 네이버 채용 지원 방법 네이버 채용 지원은 네이버 공식 홈페이지(www.naver.com/jobs)를 통해 가능합니다. 지원자는 지원하고자 하는 직책을 선택하고, 이력서와 자기소개서를 제출해야 합니다. 네이버 채용에 성공하려면 다음 사항이 중요합니다. 자격 요건 충족: 지원 직책에 필요한 학력, 경험, 기술을 갖추고 있는지 확인 매력적인 이력서 및 자기소개서: 자신의 강점, 관련 경험, 네이버에 대한 열정을 명확하게 표현 면접 준비: 업무 관련 질문에 대비하고 네이버에 대한 지식을 쌓음 적극적인 자세: 채용 담당자와 소통하고, 피드백을 받아 자신의 지원서를 개선 네이버는 끊임없이 인재를 모집하며, 재능 있고 열정적인 지원자를 환영합니다. 회사 문화에 적합하고, 혁신을 추구하는 열정이 있는 지원자는 네이버 채용에 도전해 보시기 바랍니다.## 네이버 채용 꿀팁 합격률 높이는 지원서 - 지원 서류 중시: 네이버는 지원 서류를 꼼꼼히 검토하며, 특히 자기소개서와 경력서를 중요시합니다. - 적합한 자격과 경험 강조: 지원하는 직무와 관련된 자격과 경험을 명확히 제시하십시오. - 성과 중심의 서술: 경력서에서 과거 성과를 구체적으로 서술하고, 숫자와 사례를 사용하여 측정 가능한 결과를 강조하십시오. - 열정과 동기 강조: 자기소개서에서 네이버에 합류하고자 하는 열정과 동기를 설명하십시오. - 교정 및 리뷰: 지원 서류를 제출하기 전에 철저히 교정하고, 가능한 경우 피드백을 구하십시오. 면접 성공 지침 - 기업 문화 연구: 네이버의 기업 문화와 가치관에 대해 미리 연구하십시오. - 질문 준비: 면접관이 흔히 하는 질문을 연습하고, 자신의 대답을 준비하십시오. - 능력과 기술 강조: 면접에서 자신의 능력과 기술을 자신 있고 명확하게 전달하십시오. - 창의적 사고력 과시: 네이버는 창의적 사고력을 가진 지원자를 찾고 있습니다. 면접 중에 독특하고 혁신적인 아이디어를 제시하십시오. - 열정 표현: 네이버에 대한 열정과 조직에 기여하고자 하는 의지를 보여주십시오. 기타 유용한 팁 - 네트워킹 참여: 네이버 직원과 네트워킹 행사에 참석하여 정보를 수집하고 인맥을 구축하십시오. - 채용 정보 확인: 네이버 채용 웹사이트와 소셜 미디어 계정을 정기적으로 확인하여 최신 채용 정보를 파악하십시오. - 온라인 테스트 및 과제 준비: 지원 절차가 온라인 테스트나 과제를 포함할 수 있음을 인지하고 미리 준비하십시오. - 긍정적인 태도 유지: 지원 과정 내내 긍정적인 태도를 유지하고 자신감을 갖추십시오.네이버 채용 꿀팁 1네이버에 지원하려면 몇 가지 중요한 꿀팁이 있습니다. 첫째, 네이버는 기술적인 면접을 매우 중시하기 때문에 기술적 기반을 탄탄히 다지세요. 둘째, 행동 면접에 대비하세요. 네이버는 문화적 적합성을 중요하게 생각하므로 회사 문화에 잘 맞는지 보여주는 예시를 준비하세요. 셋째, 네이버의 영어 능력 요구 사항을 반드시 충족하세요. 네이버는 글로벌 기업이므로 영어 구사 능력이 필수적입니다. 넷째, 네이버의 채용 과정은 경쟁이 치열합니다. 포기하지 말고 꾸준히 노력하세요.네이버 채용 꿀팁기술적 기반 탄탄히 다지기행동 면접에 대비하기영어 능력 요구 사항 충족하기포기하지 않고 꾸준히 노력하기1. 네이버 채용 꿀팁실력 준비- 기본기부터 꼼꼼히 复习 - 과거 개발 경험 및 프로젝트 소개서 작성에 注力 - 시험 문제 연습을 통해 문제 유형 파악정보 수집- 네이버 채용 공고 페이지 정기적으로 조회 - 네이버 채용 홈피 및 기업 블로그 확인 - 인사이드 네이버 채용자 인터뷰 기사 참고자기 소개서 작성- 개인 특징, 기술, 경험을 구체적 사례로 제시 - 네이버의 비전과 가치관에 부합하도록 표현 - 자신에게만 있는 고유한 장점 강조면접 대비- 기본 礼儀와 태도 중시 - 자기 소개서를 정확히 설명할 수 있는 준비 - 기술적 질문에 대한 대비와 문제 해결 능력 발휘네트워킹- 채용 담당자나 현직 직원과 연결 - 네이버 관련 행사 및 워크샵 참여 - 업계 네트워크를 통해 정보 교환지원 이후- 결과 통보까지 참을성 있는 기다림 - 결과가 불합격이라도 피드백을 요청 - 성공을 위해 지속적인 노력과 개발네이버 채용 꿀팁 2네이버 채용에 성공하는 데에는 여러 가지 꿀팁이 있습니다. 가장 우선적으로 고려해야 할 점은 이력서와 자기소개서를 완벽하게 작성하는 것입니다. 깔끔하고 간결하게 작성된 이력서와 자기소개서는 채용 담당자에게 귀하의 자격을 빠르게 파악할 수 있도록 도울 것입니다. 또한 네이버 기업 문화에 대해 잘 알고 있는 것도 중요합니다. 공감대를 형성하기 위해 회사의 가치관과 비전을 조사하세요. 이렇게 하면 합면 가능성이 높아집니다. 네이버 채용에 성공하려면 인내심을 갖는 것도 중요합니다. 채용 과정은 시간이 많이 걸릴 수 있습니다. 그러나 포기하지 마세요. 계속 지원하고 네트워킹을 통해 기회를 찾으세요. 마지막으로 자신감을 갖는 것이 중요합니다. 귀하의 자격에 대해 자신감을 갖고 인터뷰에 임하면 채용 담당자에게 긍정적인 인상을 줄 수 있습니다. 그러나 자만하지 않고 항상 겸손한 자세를 유지하세요.<tr style=""background-color: lightblue; </body>1. 네이버 채용 자세히 알아보기채용 분야엔지니어링마케팅디자인제품 관리운영인사기타채용 절차이력서 및 자기소개서 제출전화 면접대면 면접과제 수행건강 검진복리 후생경쟁력 있는 급여주식 옵션의료 보험연금휴가교육 지원네이버 문화혁신 중심협업적 환경사용자 지향성장 및 학습 기회인재 채용 기준업무 관련 기술 및 경험문제 해결 능력팀워크 및 협업 능력의사 소통 능력열정과 성장 의지네이버 채용에 대해 자세히 알아보기 네이버는 한국에서 가장 큰 검색 엔진과 포털 사이트로, 여러 분야에서 뛰어난 인재를 채용하고 있습니다. 네이버 채용에 관심이 있으시면 공식 홈페이지를 방문해 자세한 정보를 확인하세요. 네이버는 다양한 직무를 제공하며, 귀하의 기술과 경험에 적합한 기회를 찾을 수 있습니다. 또한 네이버는 직원에게 뛰어난 혜택과 개발 기회를 제공하여 직원들이 성장하고 성공할 수 있는 환경을 조성합니다. 네이버 채용에 지원하시면 혁신적이고 동적인 환경에서 일할 수 있는 기회를 얻게 됩니다. 네이버는 귀하의 경력에 도전과 성장의 기회를 제공합니다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//goodman710012-1.tistory.com/reaction';window.ReactionReqBody = {    entryId: 36}공유하기게시글 관리팁앤테크 - 생활 팁과 기술 블로그저작자표시 비영리 변경금지  네이버, 채용 loadedComments[36]=true;findFragmentAndHighlight(36);var sortComment=""Comment-asc"";if(""comment-desc""==sortComment){var sortCommentcss="".post-reply .tt-list-reply { display: flex; flex-direction: column-reverse; }.post-reply .tt-list-reply li.tt-item-reply:first-child {order:1}.post-reply .tt-list-reply li.tt-item-reply.rp_general:first-child {order:0}"",styleElement=document.createElement(""style"");styleElement.innerHTML=sortCommentcss;document.head.appendChild(styleElement)}var writeCommentPosotion=""write-Comment-top"";""write-Comment-top""==writeCommentPosotion&&(sortCommentcss="".post-reply .tt-comment-cont{ display: flex; flex-direction: column-reverse; } .post-reply .tt-box-total {order:1;}"",styleElement=document.createElement(""style""),styleElement.innerHTML=sortCommentcss,document.head.appendChild(styleElement));    var contentContainer=document.querySelector("".e-content.post-content"");if(contentContainer){var tocSpace=document.createElement(""div"");tocSpace.classList.add(""toc-space"");contentContainer.insertBefore(tocSpace,contentContainer.firstChild);var headings=contentContainer.querySelectorAll(""h2, h3"");if(headings.length>0){var tocContainer=document.createElement(""div"");tocContainer.classList.add(""toc-wrap"");var ulContainer=document.createElement(""ul"");ulContainer.classList.add(""toc"");headings.forEach(function(heading,index){var tocItem=document.createElement(""li"");tocItem.classList.add(""toc-item"");var tocLink=document.createElement(""a"");tocLink.href=""#section-""+index;tocLink.textContent=heading.textContent;if(heading.tagName===""H2"")tocItem.classList.add(""h2"");else if(heading.tagName===""H3"")tocItem.classList.add(""h3"");tocItem.appendChild(tocLink);ulContainer.appendChild(tocItem);heading.id=""section-""+index;tocLink.addEventListener(""click"",function(event){event.preventDefault();var target=document.querySelector(tocLink.getAttribute(""href""));if(target){var scrollOffset= (window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth) >= 450 ? 120 : 80;var targetPosition=target.offsetTop+scrollOffset;window.scrollTo({top:targetPosition,behavior:""smooth""})}})});var tocTitle=document.createElement(""strong"");tocTitle.textContent=""\ubaa9\ucc28"";var tocIcon = document.createElement(""div"");tocIcon.classList.add(""toc-icon"");var tocTitleContainer=document.createElement(""div"");tocTitleContainer.classList.add(""toc-title"");tocTitleContainer.appendChild(tocIcon);tocTitleContainer.appendChild(tocTitle);tocContainer.appendChild(tocTitleContainer);tocContainer.appendChild(ulContainer);tocSpace.appendChild(tocContainer)}};document.addEventListener(""DOMContentLoaded"",function(){var g=document.querySelectorAll("".e-content.post-content img"");g.forEach(function(a,b){var l=a.getAttribute(""alt""),h=a.getAttribute(""data-filename"");l||a.setAttribute(""alt"",h?h:""etc-image-""+b)});if(0<g.length){var k=function(){if(0<window.pageYOffset){var a=blockedStylesheets.find(function(b){return b.href.includes(""lightbox"")});a&&loadStylesheet(a.href);(a=blockedScripts.find(function(b){return b.src.includes(""lightbox"")}))&&loadScript(a.src).then(function(){var b=lightbox;b.options.fadeDuration=200;b.options.resizeDuration=200;b.options.wrapAround=!1;b.options.albumLabel=""%1 / %2""})[""catch""](function(){});window.removeEventListener(""scroll"",k)}};window.addEventListener(""scroll"",k,{passive:!0})}var c=document.getElementById(""widen-btn""),d=document.getElementById(""original-btn""),e=document.querySelector(""#container #main #sidebar""),f=document.querySelector("".h-entry .content-width"");c&&d&&e&&f&&(c.addEventListener(""click"",function(a){a.preventDefault();e.style.display=""none"";c.style.display=""none"";d.style.display=""inline-block"";f.classList.add(""wide"")}),d.addEventListener(""click"",function(a){a.preventDefault();e.style.display=""block"";d.style.display=""none"";c.style.display=""inline-block"";f.classList.remove(""wide"")}))});공지사항전체 카테고리  분류 전체보기 (37) 최근 글머리가띵하고어지러워요 자세히 알아보기치핵 2기 자세히 알아보기itq한글시험일정 자세히 알아보기공무원 블로그 수익 자세히 알아보기네이버 채용 자세히 알아보기인기 글충북 진천 출렁다리 자세히 알아보기24년 예비군 원격교육 자세히 알아보기머리가띵하고어지러워요 자세히 알아보기itq한글시험일정 자세히 알아보기저돌적 뜻 자세히 알아보기최근 댓글마곡통 - 마곡 부동산정보 06.17 잘~읽고　가요~~ 좋은 하루되세요 태그#아이오닉7#GV90#itq한글시험일정#애사비#머리가띵하고어지러워요#자세히#kmo시험#네오룬#세부여행계획#송진가루전체 방문자오늘7어제2전체289Copyright © 쭈미로운 생활 All rights reserved.Designed by JJuumdocument.addEventListener(""DOMContentLoaded"",function(){function m(a,b){if(a.isIntersecting){if(a.target.classList.contains(""post-reply"")){var c=blockedStylesheets.find(function(d){return d.href.includes(""comment"")});c&&loadStylesheet(c.href);(c=blockedScripts.find(function(d){return d.src.includes(""comment"")}))&&loadScript(c.src).then(function(){var d=new Event(""load"");window.dispatchEvent(d)})[""catch""](function(){})}else a.target.classList.contains(""container_postbtn"")?g||((c=blockedStylesheets.find(function(d){return d.href.includes(""postBtn"")}))&&loadStylesheet(c.href),(c=blockedScripts.find(function(d){return d.src.includes(""reaction-button-container"")}))&&loadScript(c.src),a.target.style.visibility=""visible"",g=!0):""PRE""!==a.target.parentElement.tagName||""CODE""!==a.target.tagName||h||(loadStylesheet(""//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/vs2015.min.css""),loadScript(""//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"").then(function(){hljs.highlightAll();loadScript(""//cdnjs.cloudflare.com/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"").then(function(){hljs.initLineNumbersOnLoad()})[""catch""](function(){})})[""catch""](function(){}),h=!0);b.unobserve(a.target)}}function k(){if(0<window.pageYOffset){var a=blockedScripts.find(function(b){return b.src.includes(""googletagmanager.com/gtag/js?id"")});a&&loadScript(a.src).then(function(){var b=document.createElement(""script"");b.innerHTML=blockedScriptContents[0].textContent;document.head.appendChild(b)})[""catch""](function(){});window.removeEventListener(""scroll"",k)}}mutationObserver.disconnect();var h=!1,g=!1,l=!1,e=document.querySelectorAll("".post-reply, .container_postbtn, pre code""),n=new IntersectionObserver(function(a,b){a.forEach(function(c){m(c,b)})},{root:null,rootMargin:""200px"",threshold:.2});e.forEach(function(a){n.observe(a)});window.addEventListener(""scroll"",function(){var a=(document.body.scrollTop||document.documentElement.scrollTop)/(document.documentElement.scrollHeight-document.documentElement.clientHeight)*100,b=document.getElementById(""progress"");b&&(b.style.width=a+""%"")},{passive:!0});var f=document.getElementById(""header_wrap"");f&&window.addEventListener(""scroll"",function(){50<window.scrollY?f.classList.add(""shrink""):f.classList.remove(""shrink"")},{passive:!0});(e=document.querySelector("".btn_topMenu""))&&e.addEventListener(""click"",function(a){a.stopPropagation();if(a=document.querySelector("".dropdown-content"")){if(!l){var b=blockedScripts.find(function(c){return c.src.includes(""menubar.min"")});b&&loadScript(b.src);if(b=document.querySelector("".dropdown-profile_bg img""))b.src=b.dataset.src,b.style.display=""block"",b.removeAttribute(""data-src"");l=!0}a.classList.toggle(""dropdown-content-toggle"")}});(e=document.querySelector("".btn_close""))&&e.addEventListener(""click"",function(a){a.stopPropagation();(a=document.querySelector("".dropdown-content""))&&a.classList.remove(""dropdown-content-toggle"")});document.querySelectorAll("".post_category_name"").forEach(function(a){var b=a.textContent.trim().split(""/"")[1];b&&(a.textContent=b.trim())});document.querySelectorAll("".p-category"").forEach(function(a){var b=a.textContent.split(""/"")[1];b&&(a.textContent=b.trim())});document.querySelectorAll(""iframe"").forEach(function(a){var b=a.getAttribute(""name"");a.setAttribute(""title"",b||""inner iframe"")});(e=document.getElementById(""content""))&&e.classList.add(""show"");window.addEventListener(""scroll"",k,{passive:!0})});티스토리툴바document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""6950785-36"",""customProps"":{""userId"":""0"",""blogId"":""6950785"",""entryId"":""36"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""36"",""entryTitle"":""네이버 채용 자세히 알아보기"",""entryType"":""POST"",""categoryName"":""카테고리 없음"",""categoryId"":""0"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""6598754"",""authorNickname"":""쿠첸"",""blogNmae"":""팁앤테크 - 생활 팁과 기술 블로그"",""image"":""kage@LccEs/btsIeko89Yr/d6img91hkvXqXg4lJeXanK"",""plink"":""/entry/%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%B1%84%EC%9A%A9-%EC%9E%90%EC%84%B8%ED%9E%88-%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0"",""tags"":[""네이버"",""채용""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
61,https://sexybill.tistory.com/78,공공기관 면접 1분 자기소개 예시,"합격한 면접 1분 자기소개 예시 - 공공기관 편2020.11.06 17:58빌하임의 생산성 라이프글 작성자: 빌하임     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }      (adsbygoogle = window.adsbygoogle || []).push({}); 합격한 면접 1분 자기소개 예시 - 공공기관 편공공기관 면접 1분 자기소개 예시안녕하세요. 빌하임입니다. 이번 글은 실제로 합격을 이뤄낸 면접 1분 자기소개 예시를 다룹니다. 저처럼 합격하기까지 시행착오를 겪지 않고, 1분 자기소개에서 면접관의 질문과 좋은 반응을 얻고 싶은 분들은 아래를 참고하세요.      (adsbygoogle = window.adsbygoogle || []).push({}); 저는 공공기관에 들어가기 위해 일대일, 일대다, 다대다 면접부터 토론/토의면접, 인성면접, AI면접, 영어면접, 프레젠테이션 면접, 롤플레잉 면접 등 산전수전 다 겪었습니다.  공기업의 경우 서류와 필기시험은 강의를 수강하고 철저히 준비하여 떨어진 적이 거의 없었기 때문에 면접 경험만큼은 그 누구보다 많다고 자신할 수 있습니다. 실무면접, 임원면접까지 포함하면 지금까지 경험한 면접만 10차례가 넘는데요, 대략 기억나는 것만 적어보면 다음과 같습니다. 공무원 면접 2회 (경력경쟁채용 포함), 한국공항공사면접 3회, 인천국제공항공사 면접 2회, 한국전력공사 면접 1회, 지방 공단면접 3회 등  이렇게 경험이 많다보니 굳이 학원을 다닐 필요 없이 면접을 준비할 수 있다고 생각하며 준비했지만, 스터디를 하더라도 정작 저는 떨어지고 남들은 붙여주는 괴현상을 겪어보며 마음을 바꾸게 되었습니다. 그렇게 면접학원과 스터디를 전전하며 결국 면접을 통과하는 자기소개는 따로 있다는 것을 알게 되었습니다. 아무리 스펙과 말빨이 뛰어나도 나머지 1%를 채우기 위해서는 아래와 같은 전문가의 지도를 받은 1분 자기소개가 필요하다는 것을 말입니다.       (adsbygoogle = window.adsbygoogle || []).push({}); 덕분에 위에 서술한 기관 중 한 곳에 합격할 수 있었습니다. 물론 표정과 몸짓까지 알려주는 면접 전문가만큼은 아니지만, 그들로부터 배운 맞춤형 1분 자기소개 예시를 알려드리겠습니다. 면접 1분 자기소개 예시 - 작성법1분 자기소개는 자기 분석부터자기소개는 역시 먼저 자신의 성향 분석하는 것에서 시작됩니다. 강점과 장점만 강조하려 욕심을 부리다가 자기소개가 안드로메다로 갈 수 있습니다. 떨어지지 않고 싶으시다면 아래를 참고하세요.       (adsbygoogle = window.adsbygoogle || []).push({}); 자신이 작성한 자소서를 바탕으로 AI가 자기 분석을 도와주는 도구가 있습니다. 아래 사진은 채용사이트인 ‘사람인’에서 자신의 성격을 분석하는 방법을 설명합니다. 사람인 AI 역량 분석 : 작성한 자기소개서를 이력서에 입력 후 역량분석을 한다. 위에서 보시듯 저의 성향은 ‘실용적, 생산적, 도구다루기, 순응, 말이 적음, 공정, 신뢰, 진솔, 양심적, 정직’이 키워드인 것을 알 수 있습니다. 아래는 이를 바탕으로 작성한 블라인드 면접 1분 자기소개 예시입니다.안녕하십니까! OO지역 OO 직무에 지원한 지원자 #번입니다. 저는 (직무와 연관된 경험)으로부터 신재생에너지의 사업성을 알게 되었고, OO기업의 (원하는 부서 구체적으로)에서 근무하고 싶다는 꿈을 갖게 되었습니다. 그래서 먼저 (직무와 연관된 기업, 아르바이트 경험)을 하였습니다. 그곳에서 (직무경험#1)과 (직무경험#2)을 해보았지만 고객에 대한 이해는 끝이 없었습니다. 몇 번의 실패가 있었지만, 그런 실패가 고객을 진정으로 이해하는 계기를 마련해 주었고, 결국 팀원과 함께 (실패를 극복한 성공경험)을 해냈습니다. 이처럼 전공이 달라도(전공이 다른 경우) 노력으로 극복할 수 있으며, (성공경험으로 부터 배운 점)으로 OO에서도 조직에 기여하는 신입사원이 되겠습니다. 감사합니다. 면접관 사진 앞에서 하면 더욱 효과적 1분 자기소개 예시는 40초 내외의 분량으로 길이도 적절하며, 면접관이 알고 싶어 하는 모든 것이 드러나 있습니다. 1. 지원동기2. 직무관련 경험3. 어려움을 극복한 경험 (장·단점 및 업무상 강점)4. 전공 등 부족해 보이는 스펙에 대한 보강 설명5. 조직을 대하는 자세 이처럼 면접 1분 자기소개 예시에서 보시다시피, 자기소개는 단순하지 않고 철저히 전략적으로 세워야 함을 알 수 있습니다. 이것을 혼자하시기 어렵다면 경험상 차라리 면접학원을 가시는 것을 추천 드립니다.       (adsbygoogle = window.adsbygoogle || []).push({}); 또한 이미 아시는 바와 같이 사기업은 이윤창출이 목적인만큼, 공공기관의 1분 자기소개는 사기업과 다르게 조직의 특성을 고려하셔야 합니다. 그 반대도 마찬가지겠죠? 다음에는 AI면접, 영어면접, 토론면접, 롤플레잉면접에 대한 포스팅으로 돌아오겠습니다.  AI 면접의 모든 것 (feat. 꿀팁과 후기)AI 면접의 모든 것 (feat. 꿀팁과 후기) # AI 면접이란? 안녕하세요. 빌하임입니다. 이번 글은 AI 면접을 다룹니다. 공기업의 AI면접 후기를 바탕으로 작성한 정보입니다. 만약 공기업이 아니거나, 이sexybill.tistory.com  합격한 자소서 지원동기 예시 - 공기업 및 사기업합격한 자소서 지원동기 예시 - 공기업 및 사기업 자소서 지원동기 예시 안녕하세요. 빌하임입니다. 이 글은 합격한 자소서 지원동기 예시를 다룹니다. 공기업과 사기업의 유형에 따라 자소서sexybill.tistory.com이상 생산성1번지 빌하임이었습니다.읽어주셔서 감사합니다.       (adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//sexybill.tistory.com/reaction';window.ReactionReqBody = {    entryId: 78}공유하기게시글 관리빌하임의 생산성 1번지저작자표시 비영리 변경금지 생산성댓글공유하기다른 글댓글이 댓글의 메뉴 토글    setInitialEntryComments(78, 1723618752)방문자 정보이름암호운영자에게만 공개작성하기loadedComments[78]=true;findFragmentAndHighlight(78);이 글 공유하기구독하기구독하기카카오톡카카오톡라인라인트위터트위터FacebookFacebook카카오스토리카카오스토리밴드밴드네이버 블로그네이버 블로그PocketPocketEvernoteEvernote다른 글썩지않는 깐마늘 보관법썩지않는 깐마늘 보관법2020.11.12AI 면접의 모든 것 (feat. 꿀팁과 후기)AI 면접의 모든 것 (feat. 꿀팁과 후기)2020.11.08굴밥 만드는법 - 백종원 레시피 응용굴밥 만드는법 - 백종원 레시피 응용2020.11.02담배 끊는법 (부제:자면서 3400만원 버는 법)담배 끊는법 (부제:자면서 3400만원 버는 법)2020.10.30다른 글 더 둘러보기let generalThumb=""https://blog.kakaocdn.net/dn/dbGiuN/btqMMjsmR8j/jujrFMvtyZ3RzJzgKEG4S1/img.jpg"";"
62,https://jpub.tistory.com/1147,'도서 소개' Related Articles,"도서 소개파이썬으로 시작하는 캐글: 입문에서 컴피티션까지 제이펍2021. 4. 14. 09:43튜토리얼 형태의 캐글 & 머신러닝 입문서! 우승 경험이 있는 전업 캐글러 콤비가 설명하는 안정되고 알기 쉬운 지식! 캐글에서 승리하는 경험을 쌓기 위한 최고의 디딤돌!  도서 구매 사이트(가나다순)  [교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]    출판사 제이펍저작권사 講談社원서명 PythonではじめるKaggleスタートブック(ISBN 9784065190067)저자명 이시하라 쇼타로, 무라타 히데키역자명 윤인성출판일 2021년 4월 19일페이지 184쪽시리즈 아이러브 A.I. 30(I♥A.I. 30)판  형 46배판변형(188*245*10.5)제  본 무선(soft cover)정  가 18,000원ISBN 979-11-90665-84-1 (93000)키워드 캐글 / Kaggle / Kaggler / 머신러닝 / A.I / 머신러닝 / 딥러닝 / 인공지능 / 기계학습 / 파이썬 / python / competition / titanic / notebook분야 파이썬 / 머신러닝 관련 사이트■ 캐글 사이트 ■ 아마존 도서소개 페이지 관련 포스트■ 2021/4/1 - [출간전 책소식] - 캐글 Competition에서 승리를 쟁취할 사람은 바로 당신입니다! 관련 시리즈 ■ I♥A.I.(아이러브 인공지능) 시리즈 관련 도서 ■ I♥A.I.(아이러브 인공지능) 시리즈 참고 관련 파일 다운로드■ 예제 코드 다운로드   강의보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음의 자료를 보내드리겠습니다.)■ 본문의 그림과 표 샘플 PDF(차례, 옮긴이 머리말, 이 책에 대하여, 베타리더 후기, 1장 '캐글 개요' 일부, 2장 'Titanic 문제' 일부, 3장 'Titanic에서 더 나아가기' 일부, 4장 '더 공부하려면' 일부)sample_파이썬으로시작하는캐글.pdf1.68MB 정오표 페이지■ (등록되는 대로 링크를 걸어드리겠습니다) 도서 구매 사이트(가나다순)  [교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]   도서 소개튜토리얼 형태의 캐글 & 머신러닝 입문서! 우승 경험이 있는 전업 캐글러 콤비가 설명하는 안정되고 알기 쉬운 지식! 캐글에서 승리하는 경험을 쌓기 위한 최고의 디딤돌! 이 책은 파이썬 언어를 사용해서 ‘캐글(Kaggle)’이라는 머신러닝 Competition(대회)에 참여할 수 있도록 해주는 입문서입니다. ‘Titanic: Machine Learning from Disaster’라는 초보자 튜토리얼을 주제로 캐글의 기초를 다룹니다. 단순하게 Titanic(타이타닉) 문제를 푸는 방법만 알려주는 것이 아니라, 스스로의 힘으로 다른 Competition에 참여할 때 필요한 지식을 함께 설명하므로 아직 미숙하여 체계적으로 정리된 지식을 필요로 하는 초심자에게 매우 적합합니다. 이 책의 특징 저자 모두 캐글 마스터이자 메달 수상 경험이 있어, 캐글 입문에 특화된 튜토리얼 형식으로 작성주제가 장과 절 단위로 확실하게 구분되어 여러 지식을 단계적으로 습득 가능이후 다른 Competition에 참가할 수 있도록 테이블 데이터, 이미지 데이터, 텍스트 데이터를 다루는 방법도 설명중간중간 저자들의 대화를 수록하여 캐글과 관련된 생생한 경험 제공프로그래밍과 파이썬 초보자를 위한 자세한 설명과 샘플 코드 완비 이 책의 대상 독자 캐글에 흥미가 있지만 어디부터 시작해야 할지 잘 모르겠다는 분파이썬, 머신러닝을 간단하게 살펴본 상태에서 캐글에 도전하고 싶은 분머신러닝을 직접 실습하면서 깊게 공부하고 싶은 분파이썬과 머신러닝에 대해서 어느 정도 알지만 캐글은 처음이신 분지은이 소개이시하라 쇼타로 石原 祥太郎 (u++) 동경대 공학부 시스템 창성학과 졸업캐글 마스터(https://kaggle.com/sishihara)2019년 3월에 공개한 Qiita의 캐글 입문 글에 1,600개 이상의 ‘좋아요’ 달성2019년 4월에 ‘PetFinder.my Adoption Prediction’ Competition에서 우승 2019년 12월에 ‘Kaggle Days Tokyo’에서 Competition 개최 현재 일본경제신문사에서 데이터 분석가로 근무 중 무라타 히데키 村田 秀樹 (카레) 홋카이도대학 이학부 교학과 졸업캐글 마스터(kaggle.com/currypurin)2019년 6월에 ‘LANL Earthquake Prediction’ Competition에서 3위 수상 2018년 8월에 ‘Santander Value Prediction Challenge’ Competition에서 솔로 금메달 획득(8위) 캐글 입문자를 위한 동인지 《캐글 튜토리얼》이 2,500부 이상 판매됨 현재 전업 캐글러로 활약 중 옮긴이 소개윤인성 출근하는 게 싫어서 책을 집필하기 시작했다. 현재 직업 특성상 집에서 나갈 이유가 별로 없다는 것에 굉장히 만족하는 성격이기도 하다. 홍차와 커피를 좋아하며, 기타, 가야금, 그림 그리기, 스컬핑 등이 취미다. 책의 머리말을 작성하는 시점을 기준으로 이번이 59번째 책이다. 차례제1장 캐글 개요 1 1.1 캐글이란? 2 1.2 캐글에서 사용하는 머신러닝 5 1.3 캐글 계정 만들기 8 1.4 Competitions 페이지 개요 10 1.5 환경 구축을 따로 하지 않아도 되는 ‘Notebooks’의 사용 방법 14 1.6 1장 정리 19더보기제2장 Titanic 문제 23 2.1 일단 submit해 보기! 25 2.2 전체적인 흐름 파악하기: submit까지의 처리 흐름 살펴보기 33 2.3 탐색적 데이터 분석해 보기 40 2.4 가설을 기반으로 새로운 특징량 만들기 56 2.5 다양한 머신러닝 알고리즘 사용해 보기 61 2.6 하이퍼파라미터 조정하기 68 2.7 ‘Cross Validation’의 중요성 74 2.8 앙상블 학습해 보기 85 2.9 2장 정리 91 제3장 Titanic에서 더 나아가기 93 3.1 여러 테이블 다루기 94 3.2 이미지 데이터 다루기 99 3.3 텍스트 데이터 다루기 108 3.4 3장 정리 116 제4장 더 공부하려면 117 4.1 참가할 Competition을 선택하는 방법 118 4.2 초보자를 위한 도전 방법 121 4.3 분석 환경 선택 방법 127 4.4 4장 정리 130 부록 샘플 코드에 대한 자세한 설명 133 A.1 2장 Titanic 문제 134 A.2 3장 Titanic에서 더 나아가자 152 마지막으로 162제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)  네이버 책 포스트 유튜브 인스타그램 트위터 페이스북  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1147}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글주머니 속의 머신러닝: 파이썬으로 구조적 데이터 다루기  (0)2021.04.28효율적 개발로 이끄는 파이썬 실천 기술  (0)2021.04.20돈이 되는 IT 트렌드  (0)2021.04.12맥 쓰는 사람들을 위한 macOS 완전 정복  (0)2021.03.26실무에 바로 적용하는 안드로이드 프로그래밍(제4판)  (0)2021.03.22'도서 소개' Related Articles주머니 속의 머신러닝: 파이썬으로 구조적 데이터 다루기효율적 개발로 이끄는 파이썬 실천 기술돈이 되는 IT 트렌드맥 쓰는 사람들을 위한 macOS 완전 정복Secret댓글달기loadedComments[1147]=true;findFragmentAndHighlight(1147);"
63,https://pt1000.tistory.com/67,SNS(소셜 미디어) 데이터,"4차산업혁명빅데이터(Big Data) 정의, 5가지 특징, 적용사례, 직업_총정리by 부매경2021. 5. 3.728x90(adsbygoogle = window.adsbygoogle || []).push({});안녕하십니까, 부매경입니다.  오늘은 4차 산업 혁명의 기반인 빅데이터(Big Data)에 대해서 알아보겠습니다. 빅데이터란 무엇인가? 적용사례는 무엇인지, 관련 직업은 어떤 것이 있는지 한번 알아보겠습니다. 빅데이터(Big Data)란? 빅데이터 정의컴퓨터, 모바일, 센서 등을 통해 생성되는 방대한 데이터, 정보의 바다기존의 데이터 수집, 관리, 처리해주는 데이터베이스를 초과 : 제타바이트급디지털로 기록할 수 있는 SNS, 사물인터넷, 센서, 내비게이션, 카메라 등 모든 전자기기에서 생성4차 산업혁명에서의 빅데이터 핵심 정의는 정보의 바다에서 가치 있는 데이터를 분석 이해하고, 새로운 가치를 창조해 내는 것이해를 돕기 위한 예 유튜브에서 내가 검색한 기록은 데이터가 되고 유튜브는 내가 만들어낸 데이터를 바탕으로 나의 취향을 분석분석된 결과로 나에게 내가 좋아할 만한 영상을 제공 빅데이터(Big Data) 생성 방식빅데이터는 크게 정형 및 비정형 테이터로 구분하여 생성되는데, 생성 출처는 크게 3가지 정도로 구분할 수 있습니다. SNS(소셜 미디어) 데이터소셜 미디어를 통한 동영상, 이미지, 게시글, 댓글 등의 Data 생성불특정 다수의 Data로 트렌드에 민감함2023년까지 약 27억 명이 소셜 미디어 데이터 사용 전망출처 : 부매경 티스토리 캡쳐머신 데이터사물인터넷(IoT) 기기와 기기(자동차, 비행기, 드론 등)의 센서로 데이터 생성기업, 국가 중심으로 머신 데이터가 급증하고 있음데이터가 가장 많이 생성되는 곳으로 2025년까지 40억 이상 생성 전망출처 : 이코노믹 리뷰, 스마트카 센서로 데이터 기록거래 데이터 구매 및 금융 거래 등을 통한 데이터 생성코로나로 인해 비대면 거래 증가로 데이터 생성 급증함 최근 댓글, 후기 등을 통해 문자, 이미지, 동영상 등 다양한 데이터 생성빅데이터 특징기존 빅데이터 특징(3V) 출처 : 위키미디어Volume 볼륨데이터의 양이 제타바이트 급으로 증가, 데이터를 안전하게 저장, 관리 방법 요구Velocity 속도빠른 속도로 생성되는 데이터데이터 처리, 분석을 빠른 시간 내에 수행 실시간으로 데이터 생성 및 분석/처리를 통해 가치 창출Variety 다양성정형화 + 비정형화 Data의 결합 기존의 정형화된 Data는 빅데이터의 가치가 없음 예를 들어 SNS에서좋아요 클릭은 정형화된 Data + 댓글의 개인적인 의견은 비 정형화된 Data기업의 재무제표는 정형화된 Data + 기업의 재무제표 평가 댓글은 비 정형화된 Data새로운 빅데이터 특정(2V)Veracity 진실성많은 양의 데이터를 수집할수록 중요성 대두정형화된 Data는 단순 오타나, 오류가 진실성의 판단 기준비 정형화된 Data는 개인의 거짓 정보, 성향 및 데이터의 출처 등이 판단 기준Value 가치빅데이터를 활용하는 궁극적인 목적은 새로운 가치를 창출빅데이터의 분석을 통해 인사이트 제공빅데이터와 머신러닝 기존 AI 관련 포스팅을 통해 언급한 바와 같이 머신러닝은 오래된 기술입니다. 하지만 빅데이터란 개념이 없는 시절에는 크게 인정받지 못 했습니다. 지금 머신러닝은 빅데이터가 제공해주는 정보로 데이터 내 패던을 분석의사결정을 내릴 수 있는 정보를 제공하고, 이러한 프로세스를 자동화합니다. 결국 양질의 빅데이터와 머신러닝 기술이 결합하여 기업의 가치를 창출하는 구조가현재 잘 나가는 회사들의 기본 플랫폼입니다.  인공지능(AI) 1편_인공지능의 역사 (tistory.com) 인공지능(AI) 1편_인공지능의 역사안녕하십니까, 부매경입니다. 미래 사회의 가장 핵심적이고 무서운 기술 중에 하나가 바로 인공지능(AI)입니다. 머스크 형도 인공지능에 대한 우려를 지속적으로 표명하였습니다. 인공지능은 악pt1000.tistory.com빅데이터 활용 분야 빅데이터의 활용은 사실 모든 분야에 적용됩니다. 활용범위는 무한대에 가까울 정도로 앞으로 그 시장이 성장할 것으로 보고 있습니다. 재무금융 서비스에 빅데이터 활용도는 매우 높습니다.  금융거래 부정행위 조사 및 감시금융상품의 리스크 분석 및 자동 추천고객의 투자분석, 제품 추천, 피트백운송 및 물류빅데이터 분석을 통해 경로 계획, 적재 통합쿠팡, 마켓 컬리 등의 당일 배송 서비스가 대표적이 예임의료빅데이터 분석을 통해 정확하고 신뢰성 있는 진단 빅데이터를 분석을 통한 신약, 백신 개발농업식물, 가축 등의 최적의 조건에서 성장할 수 있도록 분석유통, 운송, 판매 프로세스 최적화  빅데이터(Big Data) 직업빅데이터는 크게 데이터를 수집, 저장, 관리, 처리하는 플랫폼플랫폼의 데이터를 통해 분석, 그리고 가치를 창출하여 활용하는 3가지로 나눌 수 있습니다.  데이터 플랫폼 관련 전문가빅데이터를 수집, 저장, 관리, 처리하는 플랫폼을 만들거나, 관리하는 전문가들오라클 전문가, 인공지능 전문가, 플랫폼 개발 전문가, 클라우드 전무가필요역량으로 기초 프로그래밍, 데이터베이스 기초, 멀티 플랫폼 서비스 개발, 데이터 분석 및 시각화, 빅데이터 기반 서비스 구현빅데이터 분석가빅데이터 관련 직업에 핵심 직군으로 말 그대로 데이터 플랫폼에서 제공받은 데이터를 분석하는 직업4차 산업혁명에 핵심 직군으로 생각되며 기본적으로 위에서 언급한 역량은 기본적으로 요구핵심 역량으로 통계학, 비즈니스 컨설팅, 데이터 분석 프로그래밍, 머신러닝(AI) 등이 필요함의사 결정자 빅데이터 분석가가 제시한 의견에 대한 최종 결정자 빅데이터 분석가의 역량은 기본적(원리)으로 이해는 해야 함 기본적으로 4차 산업혁명에 필요한 기술에 대한 역량은 유사하며, 기존 포스팅 한 내용과 같이 C 그룹으로 수렴되는 것 같습니다. (상세 내용은 아래 참고^^)미래의 인재상_4차산업혁명 그리고 그 후 (tistory.com) 미래의 인재상_4차산업혁명 그리고 그 후안녕하십니까, 부경매입니다. 오늘은 4차 산업혁명, 지금 우리가 살고 앞으로 우리 집 어린 XY염색체가 살아가야 할 사회에 필요한 인재상에 대해 고민해 보았습니다. 집에서 열심히 유튜브 보거pt1000.tistory.com이상입니다. 다음에는 더 좋은 정보로 찾아뵙겠습니다. 감사합니다.          (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//pt1000.tistory.com/reaction';window.ReactionReqBody = {    entryId: 67}공유하기게시글 관리부자는 매일아침 뭘 할까? '4차산업혁명' 카테고리의 다른 글UAM 도심항공교통 정의 및 총 정리_UAM 2파전 승자는? 현대자동차 vs 한화시스템  (26)2021.05.06미래 직업_미래 유망 직업 25가지_총 정리  (15)2021.05.04신재생에너지 정의 및 종류_대표 5가지 에너지  (6)2021.04.29스마트팜_교육, 창업, 현실_2027년까지 3800억 지원  (7)2021.04.27MZ세대 뜻? 특징_프로 N잡러 시대  (9)2021.04.24태그big data, 빅데이터, 빅데이터 분석가, 빅데이터 정의, 빅데이터 직업, 빅데이터 특징, 빅데이터란관련글UAM 도심항공교통 정의 및 총 정리_UAM 2파전 승자는? 현대자동차 vs 한화시스템미래 직업_미래 유망 직업 25가지_총 정리신재생에너지 정의 및 종류_대표 5가지 에너지스마트팜_교육, 창업, 현실_2027년까지 3800억 지원loadedComments[67]=true;findFragmentAndHighlight(67);"
64,https://linkareer.com/activity/160548,스타트업,채용 시 마감 (D170)[피플펀드컴퍼니] 머신러닝(ML) 소프트웨어 엔지니어2030피플펀드컴퍼니기업형태스타트업접수기간시작일2023.11.28마감일모집 시 마감채용형태신입모집직무IT/인터넷근무지역서울 서초구홈페이지https://www.peoplefund.co.kr/공유하기홈페이지 지원스크랩0스크랩한 사용자 전체보기 (0명)피플펀드컴퍼니 채팅방88명채팅방 참여하기상세내용합격자료HOT담당자Q&A 상세내용머신러닝(ML) 소프트웨어 엔지니어[담당업무]고객에게 혁신적인 금융 상품을 제공할 수 있는 적합한 모델을 실험하고 고도화 합니다.금융 데이터를 활용한 설계 및 가공을 주도합니다.[접수기간]채용시 마감[채용공고]지원서 다운로드'지원서 파일 없음'이 활동에 관심을 가지는 사용자 (0명)합격스펙 & 합격자소서더보기오른쪽 화살표최종합격후기더보기오른쪽 화살표인기 활동 리스트 보러가기오른쪽 화살표담당자 Q&A (0)등록담당자가 인증된 공고입니다. 댓글을 달면 담당자가 직접 답변해 드립니다.이 공고 조회자가 많이 본 공고
65,https://jpub.tistory.com/208,태그,"전자책제이펍이 펴낸 전자책 모음 제이펍2012. 3. 12. 17:04저희 제이펍에서 펴내는 전자책 리스트를 한눈에 볼 수 있는 페이지입니다. 계속해서 등록 날짜별로 도서 리스트를 공유해 드리겠습니다.참고로 말씀드리자면, 전자책은 종이책 출간 후 대략 2~3개월 후에 발매됩니다.또한 오라일리 출판사의 번역서는 유통 플랫폼 이슈가 있어서 전자책 제작을 하지 않고 있으니 이 점 양해 바랍니다.(취소선이 그어진 건 절판입니다) 18차_2024년 6월 14일 출간(12종)파이썬과 비교하며 배우는 러스트 프로그래밍  아이패드로 시작하는 디지털 문방구 실전 SQL 퀵스타트  러스트 서버, 서비스, 앱 만들기 실무에 바로 쓰는 일잘러의 UiPath 업무 자동화 자바 잘 읽는 법 실전 스벨트 & 스벨트킷 입문 퀴즈로 배우는 디자인 초자동화 시대가 온다 클라우드 네이티브 스프링 인 액션 고도 엔진 4 게임 개발 프로젝트(제2판)데이터 분석을 위한 줄리아17차_2024년 3월 15일 출간(17종) 누구나 쉽게 캔바로 끝내는 콘텐츠 디자인 누구나 할 수 있는 유튜브 돈 벌기 첫걸음 러스트 프로그래밍 공식 가이드(제2판) 제로부터 시작하는 러스트 백엔드 프로그래밍 키워드로 완성하는 AI 아트 테크닉 with 미드저니, 니지저니 코딩도 하고, 사장도 합니다 Go 언어로 배우는 웹 애플리케이션 개발 혼란유발자들 사이버 보안의 공격과 방어 머신러닝 시스템 구축 실전 가이드 프런트엔드 개발을 위한 보안 입문 숏폼으로 성공하는 마케팅 원칙 100 실무에 바로 쓰는 일잘러의 협업 도구 컨설팅 내 맘대로 그리는 캐릭터 이모티콘 with 프로크리에이트 모니터링의 새로운 미래 관측 가능성 Plotly로 시작하는 인터랙티브 데이터 시각화 in R & 파이썬 자바 트러블슈팅 16차_2023년 12월 14일(15종) Let’s 주짓수 챗GPT로 만드는 주식 & 암호화폐 자동매매 시스템 프롬프트 엔지니어링으로 인공지능 제대로 일 시키기그림으로 배우는 구글 클라우드 101 웹 개발 새로고침 실무에 바로 쓰는 일잘러의 마이크로카피 작성법 객체지향 파이썬 나의 첫 HTML & CSS 웹 디자인 줄리아 머신러닝, 딥러닝, 강화학습 인간 vs. AI 정규표현식 문제 풀이 대결 핵심만 골라 배우는 SwiftUI 기반의 iOS 프로그래밍(개정증보판) 오늘부터 프로듀서! 아이패드로 나만의 음악 만들기 with 개러지밴드 실전 스프링 부트 시바테이블 자동화 실무 사례로 배우는 구글 앱스 스크립트  15차_2023년 9월 15일(10종) 컴퓨팅의 정수(판매 중지됨)API 해킹의 모든 것 러브드 프런트엔드 개발자를 위한 테스트 가이드진짜 쓰는 프리미어 프로 영상 편집로블록스 게임 스크립트로 코딩 입문하기 초보 해커를 위한 칼리 리눅스 입문디자인 패턴의 아름다움ARM Cortex-M 기반의 아두이노 프로그래밍누구나 쉽게 3단계 드로잉 14차_2023년 6월 15일(12종)자바와 파이썬으로 만드는 빅데이터 시스템나는 네이버 프런트엔드 개발자입니다실무에 바로 쓰는 일잘러의 엑셀 입문백엔드 프로그래밍을 위한 PHP & MySQL아트 오브 셸 원라이너 160제이펙티브 소프트웨어 테스팅인공지능 소프트웨어 품질 보증을 위한 테스트 기법개발자를 위한 시프트-레프트 테스트파이썬을 이용한 퀀트 투자 포트폴리오 만들기그림으로 배우는 StatQuest 머신러닝 강의진짜 쓰는 일러스트레이터 진짜 쓰는 윈도우 11 13차_2023년 3월 10일(16종) 대한민국 소프트웨어 성공 방정식 <== 무료 리얼월드 암호학레트로 게임 개발 바이블실무에 바로 쓰는 Go 언어 핸즈온 가이드NestJS로 배우는 백엔드 프로그래밍핵심만 골라 배우는 젯팩 컴포즈라즈베리파이 피코, 마이크로파이썬을 만나다웹3.0과 메타버스가 만드는 디지털 혁명웹 디자인, 이렇게 하면 되나요?Go 언어를 활용한 분산 서비스 개발실무에 바로 쓰는 일잘러의 기획서 작성법세상에 하나뿐인 디자인 굿즈 만들기기초 탄탄 UX/UI 디자인을 위한 Adobe XD진짜 쓰는 포토샵 & 일러스트레이터유튜브 채널 운영을 위한 포토샵 디자인기초 탄탄 오토캐드 AutoCAD LT 도면 작성 강의12차_2022년 12월 9일(14종)개발자를 위한 PL/SQL 프로그래밍 <== 무료 업무와 일상을 정리하는 새로운 방법 노션 Notion(개정2판) 실무에 바로 쓰는 일잘러의 엑셀 데이터 분석 유니티로 배우는 게임 디자인 패턴(제2판) 제로 트러스트 구글 엔지니어는 아무도 믿지 않는다 네트워크 운용 및 유지 보수의 모든 것 코딩 인터뷰를 위한 알고리즘 치트시트 누구나 할 수 있는 유니티 2D 게임 제작 삐뽀삐뽀 보안 119 예제로 배우는 파이썬 머신러닝(제3판) 모두를 위한 클라우드 컴퓨팅 인어별에서 온 하비 프레젠테이션 디자인, 이렇게 하면 되나요? 송쌤의 엔트리 인공지능 학교11차_2022년 9월 27일(15종)디자이너의 포토샵 테크닉 141 전문가를 위한 파이썬 프로그래밍(제4판) 그림으로 공부하는 마이크로서비스 구조 딥러닝을 위한 수학 파이썬 자동화 교과서 Fusion 360으로 디자인하는 나만의 굿즈 3D 프린팅 세상에 없던 금융, 디파이(심화편) AWS로 시작하는 인프라 구축의 정석 행복을 그리는 시간, 아이패드 드로잉 with 어도비 프레스코 좋은 코드, 나쁜 코드 비전공자를 위한 인공지능 교과서 진짜 쓰는 실무 엑셀 사물인터넷을 품은 라즈베리 파이(개정판) 사물인터넷을 위한 리눅스 프로그래밍 with 라즈베리 파이(전면개정판) 서버/인프라를 지탱하는 기술너 오랫동안 이런 걸 원하고 있었구나 10차_2022년 6월 22일(19종)네트워크 이해 및 설계 가이드(개정판) 쏙쏙 들어오는 함수형 코딩 실무에 바로 적용하는 파이썬 코드 레시피 302 마스터링 자기주권신원 효율성이 배가되는 WSL2 가이드북 Apache Airflow 기반의 데이터 파이프라인 알 스웨이가트의 파이썬 프로젝트 세상에 없던 금융, 디파이(입문편) 단단한 심층강화학습 파이썬 머신러닝 실무 테크닉 100 코드로 배우는 인공지능 가볍게 떠먹는 데이터 분석 프로젝트 유튜브 영상 편집을 위한 파이널 컷 프로 X 디자인, 이렇게 하면 되나요? 돈이 되는 IT 트렌드 실무에 바로 쓰는 일잘러의 보고서 작성법 프로그래머를 위한 파이썬 임베디드 엔지니어 교과서 IT에 몸담은 이들을 위한 지적 생산 기술 9차_2022년 3월 23일(12종)Go 언어를 활용한 네트워크 프로그래밍 프로그래머의 뇌 머신러닝 엔지니어링 도커, 컨테이너 빌드업! DNS 실전 교과서 그림으로 공부하는 TCP/IP 구조 임파워드실전에서 바로 쓰는 시계열 데이터 처리와 분석 in R 엑셀과 비교하며 배우는 파이썬 데이터 분석 쏙쏙 들어오는 인공지능 알고리즘 다양한 예제로 배우는 CSS 설계 실전 가이드 웹 개발자를 위한 대규모 서비스를 지탱하는 기술 8차_2021년 12월 20일(15종)유저가 모이는 모바일 RPG 기획 작법서 인공지능(제4판) 2 인공지능(제4판) 1 21개의 작고 재미난 파이썬 프로젝트 블록체인 인 액션 실무 예제로 배우는 데이터 공학 핵심만 골라 배우는 안드로이드 스튜디오 Arctic Fox & 프로그래밍 세상에서 제일 쉬운 키네마스터 영상 편집 파이썬으로 배우는 게임 개발 실전편 파이썬으로 배우는 게임 개발 입문편 검색을 위한 딥러닝 인스타그램 마케팅을 위한 상품 사진의 비밀 37 케라스 창시자의 딥러닝 with R 리액트 인 액션 모두를 위한 리눅스 프로그래밍 7차_2021년 7월 26일(14종)논쟁적 UX <== 무료파이썬 챌린지어도비 스케치 앱으로 기록하는 스마트폰 & 아이패드 드로잉PM 인터뷰의 모든 것해커의 기쁨 백설공주 거울과 인공지능 이야기허교수의 ARM Mbed 프로그래밍 입문아마존 웹 서비스 부하 테스트 입문실무에 바로 적용하는 안드로이드 프로그래밍(제4판)그림으로 공부하는 오라클 구조(개정판)오픈스택 기반의 프라이빗 클라우드 서비스효율적 개발로 이끄는 파이썬 실천 기술업무와 일상을 정리하는 새로운 방법 노션 Notion(개정판)이베이 & 아마존 해외 역직구 셀링 6차_2021년 4월 15일(12종)C포자를 위한 본격 C 언어 프로그래밍 <== 무료자바 개발자를 위한 97가지 제안 그림으로 공부하는 IT 인프라 구조(개정판) 심층 강화학습 인 액션 실무에 바로 적용하는 자바스크립트 코드 레시피 278 15단계로 배우는 도커와 쿠버네티스 데이터 과학자와 데이터 엔지니어를 위한 인터뷰 문답집 핵심만 골라 배우는 SwiftUI 기반의 iOS 프로그래밍 네트워크 쉽게, 더 쉽게(제4판) 빅데이터를 지탱하는 기술 자바 기반의 마이크로서비스 이해와 아키텍처 구축하기 TCP/IP 쉽게, 더 쉽게 5차_2020년 12월 16일(13종)통계의 아름다움한 권으로 끝내는 블록체인 교과서송쌤의 엔트리 콘텐츠 작품집자기주권 신원증명 구조 분석서객체지향 사고 프로세스(제5판)구글에서 배운 직장인 실무 컴퓨터 활용 45창업부터 운영까지 단계별로 실천하는 SNS 마케팅똥손 탈출 100일 100 드로잉파이썬으로 배우는 자연어 처리 인 액션실습으로 완성하는 구글 클라우드 플랫폼 인 액션알파고를 분석하며 배우는 인공지능따라하며 배우는 데이터 과학인공지능, 인간을 유혹하다 <== 무료 4차_2020년 09월 03일(12종)키워드로 정리하는 정보보안 119스프링 인 액션(제5판)단단한 강화학습딥러닝 인 더 브라우저송쌤의 스크래치 코딩 학교송쌤의 엔트리 게임 코딩 학교모던 C++로 배우는 동시성 프로그래밍몽고디비 인 액션(제2판)송쌤의 엔트리 코딩 학교Go 인 액션Flask 기반의 파이썬 웹 프로그래밍벤츠 타는 프로그래머 <== 무료 3차_2020년 06월 03일(12종)단단한 머신러닝알파제로를 분석하며 배우는 인공지능머신러닝 도감러스트 프로그래밍 공식 가이드카이젠 저니빅 너드 랜치의 코틀린 프로그래밍하이퍼레저 패브릭으로 배우는 블록체인알고리즘 도감처음 만나는 알고리즘실리콘밸리 견문록 <== 무료아두이노 상상을 스케치하다코드로 알아보는 ARM 리눅스 커널 2차_2020년 04월 09일(11종)함수형 언어 산책프로페셔널 안드로이드(제4판)오렌지노의 영상 편집을 위한 유튜브 배경음악고양이도 할 수 있는 Vue.js파이토치 첫걸음앤디 필드의 유쾌한 R 통계학빅데이터 분석과 활용심층 학습R로 배우는 실무 데이터 과학클린 소프트웨어세븐 데이터베이스 1차_ 2020년 01월 02일(12종)업무와 일상을 정리하는 새로운 방법 Notion 코딩 강화 파이썬신경망과 심층학습브레인 이미테이션 개발자도 궁금한 IT 인프라코드로 알아보는 ARM 리눅스 커널(제2판)스프링 부트로 배우는 자바 웹 개발인스파이어드(개정증보판)한 권으로 배우는 파이썬 기초 & 알고리즘 사고법어서 와, 컴퓨터 없는 코딩은 처음이지?2D/3D 멀티 플랫폼 게임을 위한 유니티 2018코어 이더리움 프로그래밍 <== 무료===============================================================출판사의 사정으로 인해 당분간 전자책을 판매하지 않기로 하였습니다. 추후 적당한 시기에 새로운 형태의 전자책을 준비하여 다시 선보이도록 하겠습니다. 지금까지 전자책을 이용해주신 분들께 감사의 말씀을 드립니다. 이 포스트는 제이펍에서 출간하는 전자책(앱북) 전체 리스트를 보여주는 포스트입니다. 앞으로 추가될 때마다 별도의 소개 포스트를 작성하지 않고 이 포스트에 추가하도록 하겠습니다. 현재는 아이패드용 앱북 형태로만 준비되어 있어 앱스토어에서만 구매하실 수 있음을 알려드립니다. 다른 버전(안드로이드나 PC용 등)으로 제작되면 추후 다시 안내해드리겠습니다. 앱북 제작업체: 두나무현재 판매 중인 전자책 아론 힐리가스의 오브젝티브-C 프로그래밍  도서소개: http://jpub.tistory.com/223판매가: 12.99$  핵심만 골라 배우는 iOS 프로그래밍   도서소개: http://jpub.tistory.com/184판매가: 14.99$    제로데이   도서소개: http://jpub.tistory.com/191판매가: 7.99$핵심만 골라 배우는 오브젝티브-C 프로그래밍  도서소개: http://jpub.tistory.com/179판매가: 11.99$       window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 208}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기저작자표시 비영리 변경금지 태그두나무, 앱북, 전자책, 제이펍이전 댓글 더보기    setInitialEntryComments(208, 1723627670)Secret댓글달기loadedComments[208]=true;findFragmentAndHighlight(208);"
66,https://jpub.tistory.com/1014,태그,"도서 소개단단한 머신러닝: 머신러닝 기본 개념을 제대로 정리한 인공지능 교과서 제이펍2020. 2. 26. 14:56간결한 설명과 최소한의 수학적 지식을 통해 체계적으로 정리한 머신러닝 입문서!도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]출판사 제이펍저작권사 清华大学出版社원서명 机器学习(원서 ISBN: 9787302423287)저자명 조우쯔화역자명 김태헌출판일 2020년 2월 28일페이지 536쪽시리즈 I♥A.I. 24(아이러브 인공지능 24)판 형 188*245*26제 본 무선(soft cover)정 가 30,000원ISBN 979-11-88621-98-9(93000)키워드 머신러닝 / 딥러닝 / 인공지능 / 신경망 / 베이지안 / 강화학습 / 기계학습 / 심층학습 / 준지도학습 / 클러스터링 / 서포트 벡터 머신 / 앙상블 학습분야 인공지능 / 머신러닝관련 사이트■ 저작권사 도서 소개 페이지■ dangdang 도서 소개 페이지■ 역자 도서 A/S 블로그관련 포스트■ 2020/02/14 - [출간전 책소식] - 50만 부가 판매된 중국의 인공지능 서적!관련 시리즈■ I♥A.I 시리즈관련 도서■ (관련 시리즈 참고) 강의보조자료 다운로드교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표관련 파일 다운로드■ 한국어 버전 연습문제 해답(이 자료는 저작권사로부터 제공받지 못한 자료입니다. 역자께서 개인적으로 시간과 노력을 들여 준비하고 있으며, 순차적으로 등록될 예정임을 안내해 드립니다)■ 중국어 버전 연습문제 해답(이 자료는 저작권사로부터 공식적으로 인정받은 자료는 아님을 밝힙니다)샘플 PDF(차례, 추천사, 옮긴이 머리말, 머리말, 이 책의 사용법, 베타리더 후기, 주요 기호표, 1장 '서론' 전체, 2장 '모델 평가 및 선택' 일부, 3장 '선형 모델' 일부, 16장 '강화 학습' 일부) 단단한머신러닝_sample.pdf정오표 페이지■ https://jpub.tistory.com/1028도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]도서 소개간결한 설명과 최소한의 수학적 지식을 통해 체계적으로 정리한 머신러닝 입문서!출간 3개월 만에 3만 부 판매!(중국 기준)누적 50만 부 돌파!(2020년 2월 중국 기준)중국 주요서점 장기 베스트셀러(중국 기준)이 책은 인공지능 분야의 명예의 전당이라는 AAAI의 펠로우로 선정된 저자가 머신러닝을 처음 접하는 독자를 위해 2년간 정성을 다해 집필한 책입니다. 이공계 고학년과 대학원의 16주 머신러닝 강의에 맞춰 각 장이 30페이지가 넘지 않는 16개의 장과 수준 있는 연습문제로 구성하였으며, 최대한 다양한 독자에게 머신러닝을 소개하기 위해 최소한의 수학적 지식만을 사용하였습니다.이 책의 주요 목적은 독자들에게 나무와 숲을 함께 볼 수 있는 ‘초급 지도’를 제공해 머신러닝 입문자들이 올바른 방향으로 나갈 수 있도록 도와주는 것입니다. 다양한 머신러닝 알고리즘을 이해하기 쉽도록 이론뿐만 아니라 내부 처리 로직까지 설명하고 있어서 실제 머신러닝 기법의 개념과 원리를 탄탄하게 배울 수 있습니다.아울러 체계적이고 간결한 내용 전개는 학부나 대학원의 교재뿐만 아니라 독학을 위한 자습서나 연구 참고용 도서로도 좋습니다.지은이 소개조우쯔화(Zhou Zhihua)난징대학교 컴퓨터과학과 교수미국 컴퓨터학회(ACM) 선정 우수과학자AAAI, IEEE, IAPR, IET/IEE 펠로우국가 우수청년장학금 수상자Chang Jiang Scholars 특별 초청 교수현) 중국 인공지능학회 머신러닝 전문위원회 회장, 중국 컴퓨터학회 인공지능 및 패턴인식 전문위원회 부회장, IEEE 컴퓨터학회 난징지부 의장옮긴이 소개김태헌하나금융융합기술원에서 데이터 과학자로 일하면서 로보어드바이저, 신용평가 시스템 개발 등의 프로젝트에 참여하고 있다. 중학생 시절부터 10여년간을 중국에서 보냈으며, 베이징 대학교를 졸업하고 미국 캘리포니아 대학교 샌디에이고 캠퍼스에서 국제경제 석사 학위를 받았다.차례CHAPTER 01 서론 11.1 들어가며 11.2 머신러닝의 기본 용어 21.3 가설 공간 51.4 귀납적 편향 81.5 발전 과정 131.6 응용 현황 181.7 더 읽을거리 22연습문제 25 참고문헌 26 머신러닝 쉼터 28더보기접기CHAPTER 02 모델 평가 및 선택 292.1 경험 오차 및 과적합 292.2 평가 방법 312.3 모델 성능 측정 372.4 비교 검증 472.5 편향과 분산 572.6 더 읽을거리 59연습문제 61 참고문헌 62 머신러닝 쉼터 64CHAPTER 03 선형 모델 653.1 기본 형식 653.2 선형 회귀 663.3 로지스틱 회귀 703.4 선형 판별분석 733.5 다중 분류 학습 773.6 클래스 불균형 문제 803.7 더 읽을거리 83연습문제 85 참고문헌 86 머신러닝 쉼터 88CHAPTER 04 의사결정 트리 894.1 기본 프로세스 894.2 분할 선택 924.3 가지치기 984.4 연속값과 결측값 1034.5 다변량 의사결정 트리 1104.6 더 읽을거리 113연습문제 115 참고문헌 117 머신러닝 쉼터 118CHAPTER 05 신경망 1195.1 뉴런 모델 1195.2 퍼셉트론과 다층 네트워크 1215.3 오차 역전파 알고리즘 1245.4 글로벌 미니멈과 로컬 미니멈 1305.5 기타 신경망 1335.6 딥러닝 1395.7 더 읽을거리 142연습문제 144 참고문헌 145 머신러닝 쉼터 148CHAPTER 06 서포트 벡터 머신 1496.1 마진과 서포트 벡터 1496.2 쌍대문제 1516.3 커널 함수 1556.4 소프트 마진과 정규화 1586.5 서포터 벡터 회귀 1636.6 커널 기법 1676.7 더 읽을거리 170연습문제 172 참고문헌 173 머신러닝 쉼터 175CHAPTER 07 베이지안 분류기 1777.1 베이지안 결정 이론 1777.2 최대 우도 추정 1797.3 나이브 베이즈 분류기 1817.4 세미 나이브 베이즈 분류기 1867.5 베이지안 네트워크 1887.6 EM 알고리즘 1957.7 더 읽을거리 197연습문제 199 참고문헌 200 머신러닝 쉼터 202CHAPTER 08 앙상블 학습 2038.1 객체와 앙상블 2038.2 부스팅 2068.3 배깅과 랜덤 포레스트 2118.4 결합 전략 2158.5 다양성 2218.6 더 읽을거리 227연습문제 229 참고문헌 231 머신러닝 쉼터 234CHAPTER 09 클러스터링 2359.1 클러스터링 학습 문제 2359.2 성능 척도 2369.3 거리 계산법 2389.4 프로토타입 클러스터링 2419.5 밀도 클러스터링 2529.6 계층 클러스터링 2559.7 더 읽을거리 259연습문제 262 참고문헌 264 머신러닝 쉼터 266CHAPTER 10 차원 축소와 척도 학습 26710.1 k-최근접 이웃 기법 26710.2 임베딩 26910.3 주성분 분석 27310.4 커널 선형 차원 축소 27510.5 매니폴드 학습 27810.6 척도 학습 28210.7 더 읽을거리 285연습문제 287 참고문헌 288 머신러닝 쉼터 290CHAPTER 11 특성 선택과 희소 학습 29111.1 부분집합 탐색과 평가 29111.2 필터식 선택 29411.3 포괄식 선택 29611.4 임베딩식 선택과 L1 정규화 29811.5 희소 표현과 사전 학습 30111.6 압축 센싱 30411.7 더 읽을거리 308연습문제 310 참고문헌 311 머신러닝 쉼터 314CHAPTER 12 계산 학습 이론 31512.1 기초 지식 31512.2 PAC 학습 31712.3 유한 가설 공간 31912.4 VC 차원 32312.5 라데마허 복잡도 32912.6 안정성 33512.7 더 읽을거리 339연습문제 341 참고문헌 342 머신러닝 쉼터 343CHAPTER 13 준지도 학습 34513.1 언레이블된 데이터 34513.2 생성적 방법 34813.3 준지도 SVM 35213.4 그래프 준지도 학습 35513.5 불일치에 기반한 방법 35913.6 준지도 클러스터링 36313.7 더 읽을거리 368연습문제 370 참고문헌 372 머신러닝 쉼터 374CHAPTER 14 확률 그래피컬 모델 37514.1 은닉 마르코프 모델 37514.2 마르코프 랜덤 필드 37914.3 조건 랜덤 필드 38314.4 학습과 추론 38614.5 근사추론 39014.6 토픽 모델 39714.7 더 읽을거리 400연습문제 403 참고문헌 404 머신러닝 쉼터 406CHAPTER 15 규칙 학습 40715.1 기본 개념 40715.2 순차적 커버링 41015.3 가지치기 최적화 41415.4 일차 규칙 학습 41615.5 귀납 논리 프로그래밍 42015.6 더 읽을거리 428연습문제 431 참고문헌 432 머신러닝 쉼터 434CHAPTER 16 강화 학습 43516.1 과업과 보상 43516.2 K-암드 밴딧 43816.3 모델 기반 학습 44316.4 모델-프리 학습 45016.5 가치 함수 근사 45716.6 이미테이션 러닝 46016.7 더 읽을거리 462연습문제 464 참고문헌 465 머신러닝 쉼터 467APPENDIX A 행렬 469A.1 기본 연산 469A.2 도함수 470A.3 특잇값 분해 472APPENDIX B 최적화 474B.1 라그랑주 승수법 474B.2 이차 프로그래밍 477B.3 반정형 프로그래밍 478B.4 경사하강법 479B.5 좌표하강법 480APPENDIX C 확률 분포 482C.1 자주 사용하는 확률 분포 482C.2 켤레 분포 487C.3 KL 발산 488에필로그 489찾아보기 494접기제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!) 네이버 책  포스트  유튜브  인스타그램  트위터  페이스북window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1014}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글파이썬으로 배우는 자연어 처리 인 액션  (0)2020.03.02인스타그램 마케팅을 위한 상품 사진의 비밀 37  (0)2020.02.26딥러닝 인 더 브라우저: 자바스크립트 프레임워크를 이용한 딥러닝 웹 개발  (0)2020.02.18유튜브 영상 편집을 위한 프리미어 프로  (10)2020.01.15풍부한 그림과 사진으로 배우는 네트워크 쉽게 더 쉽게(제4판)  (0)2020.01.10태그Machine Learning, 강화학습, 기계학습, 김태헌, 딥러닝, 머신러닝, 베이지안, 신경망, 심층학습, 아이러브인공지능, 인공지능, 제이펍, 조우쯔화, 중국책'도서 소개' Related Articles파이썬으로 배우는 자연어 처리 인 액션인스타그램 마케팅을 위한 상품 사진의 비밀 37딥러닝 인 더 브라우저: 자바스크립트 프레임워크를 이용한 딥러닝 웹 개발유튜브 영상 편집을 위한 프리미어 프로Secret댓글달기loadedComments[1014]=true;findFragmentAndHighlight(1014);"
67,https://linkareer.com/activity/80722,스타트업,"접수기간 (D804)Data팀 Data/Machine Learning Engineer 채용 (신입)2980플리토기업형태스타트업접수기간시작일2022.03.04마감일상시모집채용형태신입모집직무IT/인터넷, 기타근무지역서울 강남구홈페이지https://www.flitto.com/language/translation/text공유하기홈페이지 지원스크랩3스크랩한 사용자 전체보기 (3명)플리토 채팅방347명채팅방 참여하기상세내용합격자료HOT담당자Q&A 상세내용Data팀 Data/Machine Learning Engineer 채용 (신입)지원분야모집부문Data팀 Data/Machine Learning Engineer 채용 (신입)업무내용- 다양한 언어쌍의 코퍼스 신규 구축 및 관리- 자연어 처리(Natural Language Processing)를 이용한 코퍼스 정제 및 품질 분석- 기업 고객사를 위한 맞춤형 데이터 구축(텍스트, 이미지, 음성 등)에 필요한 개발 업무 지원- 코퍼스 주제 분류, 개인정보 비식별화, 불량 코퍼스 필터링 등 다양한 ML 프로젝트 (예정)고용형태신입수습기간3개월모집인원0명지원 자격학력학력무관전공전공무관직무관련- Julia / Python / R 중에서 자신 있는 프로그래밍 언어가 있는 분- 하나의 데이터도 놓치지 않고 꼼꼼하게 관리할 수 있는 성격우대사항- 외국어를 잘하지 않아도 언어 자체에 관심이 있는 분- 공개된 데이터셋을 이용해 개발한 경험- 머신러닝 프레임워크(PyTorch, TensorFlow 등)를 이용한 개발 경험지원서접수지원방법[채용진행]· 입사지원 : 상시채용▶홈페이지 지원 : https://flitto.recruiter.co.kr/app/jobnotice/view?systemKindCode=MRS2&jobnoticeSn=84264· 전형진행 : 서류전형 → test전형(코딩과제) → 면접전형 → 입사협의 → 입사※ 빠른 채용 진행을 위해 면접전형시 경력/소득 증빙자료를 요청합니다.- 전형 결과에 상관없이 결과 확정시 개별 메일로 안내드립니다.접수기간상시채용문의처+82-70-4235-3201    jobs@flitto.com   전형절차서류전형 - test전형 - 면접전형 - 입사추가 정보복리후생- 문화 : 직급없는 “님” 호칭 및 경어 사용, 완전 자율 복장: 수평적 소통 문화(대표실 없음, 누구든 자유롭게 아이디어 및 의견 제시 가능): 자유로운 연차 사용, 사생활에 대한 존중과 배려- 복지 : 연봉 外 중식대 별도 제공 (앱 활용): 경조휴가 및 경조비지원, 생일/결혼기념일 휴가, 명절 상여 등: (근속기간에 따른) 사내대출, 자기개발비, 건강검진 등\- 개발환경 : 맥북 + 4K 모니터 + 개발장비 지원비(최초 입사시 15만원)* 맥북 外 노트북 선택 가능기타정보- 근무지 : 플리토 서울 본사 (2호선 역삼역 도보 5분 거리 위치)- 근로계약 : 정규직 (수습기간 3개월)- 근무시간 : 10시~19시 기본. 금요일은 플렉서블 근무(8~11시 출근 선택)Data/Machine Learning Engineer 채용 (신입)"" 강한 책임감을 가지고 동료들과 소통하는 동료를 찾습니다! ""플리토는 2012년에 설립된 언어 데이터 전문 기업으로 집단지성, 아케이드 등자체 플랫폼을 통해 텍스트, 이미지, 음성 데이터를 수집하며, 기업의 요구사항에맞춰 데이터를 수집 및 가공해 판매하고 있습니다.Data/Machine Learning Engineer는 이렇게 만들어진 데이터를 다루는데 필요한 개발을 담당합니다.[주요업무]  - 다양한 언어쌍의 코퍼스 신규 구축 및 관리  - 자연어 처리(Natural Language Processing)를 이용한 코퍼스 정제 및 품질 분석  - 기업 고객사를 위한 맞춤형 데이터 구축(텍스트, 이미지, 음성 등)에 필요한 개발 업무 지원  - 코퍼스 주제 분류, 개인정보 비식별화, 불량 코퍼스 필터링 등 다양한 ML 프로젝트 (예정)[자격요건]  - Julia / Python / R 중에서 자신 있는 프로그래밍 언어가 있는 분  - 하나의 데이터도 놓치지 않고 꼼꼼하게 관리할 수 있는 성격[우대사항]  - 외국어를 잘하지 않아도 언어 자체에 관심이 있는 분  - 공개된 데이터셋을 이용해 개발한 경험  - 머신러닝 프레임워크(PyTorch, TensorFlow 등)를 이용한 개발 경험[기타사항]  - 근무지 : 플리토 서울 본사 (2호선 역삼역 도보 5분 거리 위치)  - 근로계약 : 정규직 (수습기간 3개월)  - 근무시간 : 10시~19시 기본. 금요일은 플렉서블 근무(8~11시 출근 선택)  - 문화 : 직급없는 “님” 호칭 및 경어 사용, 완전 자율 복장            : 수평적 소통 문화(대표실 없음, 누구든 자유롭게 아이디어 및 의견 제시 가능)            : 자유로운 연차 사용, 사생활에 대한 존중과 배려  - 복지 : 연봉 外 중식대 별도 제공 (앱 활용)            : 경조휴가 및 경조비지원, 생일/결혼기념일 휴가, 명절 상여 등            : (근속기간에 따른) 사내대출, 자기개발비, 건강검진 등  - 개발환경 : 맥북 + 4K 모니터 + 개발장비 지원비(최초 입사시 15만원)                    * 맥북 外 노트북 선택 가능[채용진행]  · 입사지원 : 상시채용  · 전형진행 : 서류전형 → test전형(코딩과제) → 면접전형 → 입사협의 → 입사     ※ 전형 결과에 상관없이 결과 확정시 개별 메일로 안내드립니다.지원서 다운로드'지원서 파일 없음'이 활동에 관심을 가지는 사용자 (3명)합격스펙 & 합격자소서더보기오른쪽 화살표최종합격후기더보기오른쪽 화살표인기 활동 리스트 보러가기오른쪽 화살표담당자 Q&A (0)등록담당자가 인증된 공고입니다. 댓글을 달면 담당자가 직접 답변해 드립니다.이 공고 조회자가 많이 본 공고"
68,https://sages.tistory.com/374,댓글을 달아 주세요 ,"세이지의 노트notice / tag/ localog / media/ guestbook / admin 이직 오답 노트: 국내사에서 외국계 취업 성공기 - 임상 PM (크몽 전자책) [전격 할인]!from 임상시험/관련 직종 2022. 1. 24. 19:50<!--google_ad_client = ""pub-5923543165714951"";/* up1 */google_ad_slot = ""1010606164"";google_ad_width = 250;google_ad_height = 250;//-->     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});이번에 이직 관련해서 아래와 같이 글을 올렸었다.세이지의 노트 :: 이직인 듯 이직 아닌 이직 같은 이직 (tistory.com) 이전에 말했던 것처럼, 이번에 70여 페이지의 전자책을 썼었다고 했었는데 당시는 크몽에서 승인을 기다리고 있는 상태였다. 원래는 승인에 시일이 꽤 걸린다고 했었지만 크몽에서 승인이 꽤 빠르게 되었다. https://kmong.com/gig/362663 이직 오답 노트-국내사→외국계 임상 PM 취업 성공기 드립니다. | 30000원부터 시작 가능한 총 평점1개 총 작업 개수 완료한 총 평점 0점인 세이지C의 취업·입시, 취업·이직 전자책 서비스를 0개의 리뷰와 함께 확인해 보세요. 취업·입시, 취업·이직 전자책 제공 등 30000원부터 시작 가능한 서비kmong.com  전자책 분량이 꽤 많긴 한데 이걸 꼭 다 보기 보다는 필요한 부분을 중심으로 검토하는 것이 좋을 것 같다. 그리고 책과 함께 약간의 메시지 상담 서비스도 추가했다. 주중에는 업무 때문에 아무래도 진행이 어려울 것 같고 되도록이면 주말에 메시지 상담이 가능할 것 같다.  지난 6개월 동안 일반적으로 어느 정도로 생각되든 간에 나는 개인적으로 매우 힘든 시간을 가졌었다. 부디 이 책을 읽는 사람들은 나만큼 힘들지 않기를 바란다.  추가로 크몽에 있는 글 요약 관련 사항을 추가해 보았다.   인사말 1  이직 전 분석 이직의 목적이 무엇인가 이직 전 본인 상황 분석하기2  이직 전 필요 사항 정리 본인의 목표 설정 및 회사별 특성 확인 이력서 등 필요 문서 작성3  직접 지원하기 채용 공고를 확인할 수 있는 곳과 작은 팁 회사 평판 및 연봉 수준 미리 확인 메일로 지원 시 실제 회사의 글로벌 사이트를 통해 지원 후 체크 시 참고 사항 계약직 지원 및 데디 지원 시 유의점 직접 지원 시 장점4  헤드헌터를 통해 지원하기 헤드헌터를 통해야 하는 이유 좋은 헤드헌터를 고르는 방법 커뮤니케이션 시 기본 예의5  면접 준비 및 실제 면접 지원 로그 만들기 및 필자의 실제 지원 및 당락 결과 일반적인 면접 절차의 구성 면접 질문 리스트 면접 최종 준비6  면접 이후 면접 후기: 좋은 회사, 나쁜 회사, 이상한 회사? 탈락 전화 시 자세 합격 후기7  약간의 별책 부록 영어 실력 급하게 올리는 방법 이직에 대한 마음 가짐 합격 이후의 현재 생활과 느낀 점 마치며 나름 깔끔하게 만들어 보려고 했으나 크몽 표지에는 그다지 예쁘지 않은 것 같다.목차 별로 모두 링크가 걸려 있어 바로 클릭 가능하다.돈 때문에 시작했다는 내용을 또 썼다.. 후회는 없지만 마음에 은근히 남은 모양이다.일단 나부터 분석했다.이것보다 더 자세한 팁이 많으므로 잘 고민해서 구입하시길! [기간 한정] 선착순 10명만 전자책 만 원에 판매 예정이니 많은 관심 부탁 드립니다! STANDARD 10,000원: 전자책만 판매 DELUXE 20,000원: 전자책 및 상담 1회 제공PREMIUM 30,000원: 전자책 및 CV 1회 검토 후 상담 1회 제공 ※ STANDARD 구입 후에 상담 서비스가 필요할 경우전자책만 구매 후 1회 상담이 필요한 경우 10,000원 추가,CV 1회 검토 후 상담 1회가 필요할 경우 20,000 추가 시 가능합니다.  :)반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//sages.tistory.com/reaction';window.ReactionReqBody = {    entryId: 374}공유하기게시글 관리세이지의 노트저작자표시 비영리 변경금지 '임상시험 > 관련 직종' 카테고리의 다른 글새로 발견한, 특히 CRA 관련 블로그: 제약 임상 Career & Life  (0)2022.01.24CRC에서 CRA가 되면 다른 점  (1)2020.03.03Medical Writer는 무슨 일을 하는가  (79)2015.05.04실제적인 CRC 업무 - 사소한 팁 모음  (10)2011.06.20실제적인 CRC 업무  (16)2011.05.06/* 세이지 하단 */aladdin_ttb_key = 'ttbstarstaring1715001';aladdin_ttb_channel = '755';aladdin_ttb_width = '503';aladdin_ttb_height = '244';, 댓글 0개가 달렸습니다.댓글을 달아 주세요  : secret  : name  : password  : homepage loadedComments[374]=true;findFragmentAndHighlight(374);Category노트 목차 (251)요즈음 공지 (25)쓰고 듣고 (151)플레이리스트 (32)한단설에서 (0)에세이 (13)만화경 (19)다시보기 (83)전광판 (4)영어 (31)TOEIC S & W (10)리더스 다이제스트 (20)임상시험 (44)관련 직종 (11)직장생활백서 (17)용어 및 정보 (13)웹진 해석 (3)Recent Post 크몽 첫 수익금 중 일부 기부 완료- 플레이리스트 31 플레이리스트 30 JLPT N1 준비 (3) - 일본어 학원 & 실제 시험 후기 및⋯ JLPT N1 준비 (2) - 일본어 공부 앱 / 팟캐스트 등 JLPT N1 준비 (1) - 일본어 공부 스케줄 및 교재 리스트1 어쨌든 JLPT 준비: 일드 추천 80편 (2) 어쨌든 JLPT 준비: 일드 추천 80편 (1) 직장에서 가지고 있으면 좋은 여성 패션 아이템 20가지 이직 오답 노트: 국내사에서 외국계 취업 성공기 - 임상 PM (⋯Recent Comment늦깎이 취준생이라 라이팅 시험을 보긴 봐야 되는데 뭐부터 해야할지⋯.  ㄴㄴ 12.17선생님 안녕하세요. 늘 많은 도움 받고 있습니다!한 가지 질문이⋯.  ㅎㅎㅎ 12.13어려워요 대화를 하자고 해서 대꾸한건데 본인생각과 다르다고 꼰대⋯.  김경원 2023포스팅 잘 읽고 갑니다 :).  baundy 2022정말 좋은 글 감사히 잘 읽고 갑니다!.  GW 2022Recent TrackbackCalendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Archive2023/12 (1)2023/08 (1)2023/01 (1)2022/12 (3)2022/10 (2)Link Admin write 1 Admin write 2WAU_colored('u1h769vp', 'ffffff808285')T23 Y35 T627,553 / Subscribe to RSS 세이지's Blog is powered by  / Designed by seevaavar gaJsHost = ((""https:"" == document.location.protocol) ? ""https://ssl."" : ""http://www."");document.write(unescape(""%3Cscript src='"" + gaJsHost + ""google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E""));try {var pageTracker = _gat._getTracker(""UA-4838616-1"");pageTracker._trackPageview();} catch(err) {}티스토리툴바세이지의 노트구독하기                    (function () {                         var blogTitle = '세이지의 노트';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()if(!wcs_add) var wcs_add = {};   wcs_add[""wa""] = encodeURI(""19d18bd6ffcc3e"");   wcs_do();document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""31078-374"",""customProps"":{""userId"":""0"",""blogId"":""31078"",""entryId"":""374"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""374"",""entryTitle"":""이직 오답 노트: 국내사에서 외국계 취업 성공기 - 임상 PM (크몽 전자책) [전격 할인]!"",""entryType"":""POST"",""categoryName"":""임상시험/관련 직종"",""categoryId"":""601589"",""serviceCategoryName"":""경영·직장"",""serviceCategoryId"":606,""author"":""36219"",""authorNickname"":""세이지"",""blogNmae"":""세이지의 노트"",""image"":""kage@deZPg3/btrrpmxqm8n/ZErKfG9lHWBDViSs7yKWo1"",""plink"":""/374"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
69,https://210306.tistory.com/20,글을 시작하며,"대학원 준비/국내대학원[국내 대학원] 3-3. 학업계획서 - 연구계획 작성by EARL_2021. 10. 2.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({}); [국내 대학원] 공대 대학원 준비하기최근 들어 부쩍 대학원에 관련된 멘토링 또는 컨설팅 요청이 자주 들어온다. 9월이 끝나고 10월이 시작하는 시기에 많은 대학원이 원서모집을 시작해서 그런 것 같다. 많은 사람들이 대학원 입학210306.tistory.com*글을 읽기 전 이전 글 또는 아래에 해당되는 분들을 위한 글임을 말씀드립니다.1. 공대 대학원 준비 중인 학생2. 석사 지원생3. 석사를 지원하는 이유가 취업이 메인인 분들4. 위의 링크에 국내 공대 대학원 관련글들 링크가 전부 업데이트 되어 있습니다.글을 시작하며이번 글에서는 계속해서 이어 학업계획서 작성에 대해 이야기하겠습니다. 기존 자기소개 및 지원동기 작성은 기존 글을 참고 부탁드립니다. 이번에는 연구계획에 대해서 작성해보겠습니다. 연구계획은 많은 분들이 작성하기 어려워하는 부분입니다. 학부과정에서 다뤄본 적도 없으며 사실 앞으로 무엇을 연구할지 정확히 정해져 있지 않기 때문입니다.  연구계획 얼마나 정확하게 써야하나?많은 분들이 이 부분에 대해 정말 고민하셨습니다. 본인은 이제 막 학부를 졸업했거나 4학년이며 공부는 하고자 하지만 정확히 어떤 주제로 연구를 해야 될지 모르겠다고 하십니다. 당연한 이야기입니다. 특히 석사과정 지원자들의 경우 특별한 경우가 아니라면 구체적인 계획이 없습니다. 교수님들도 그 부분은 잘 알고 계십니다. 그렇기 때문에 디테일하게 쓰실 필요 없으며 대략적인 방향만 제시하셔도 됩니다. 다만 교수님 별로 학과별로 차이는 있을 수 있습니다. 가령 특수학과(융합학과, 특정 산업 관련학과)들의 경우는 디테일하게 쓰실 필요가 있습니다. 연구 방향 설정연구 방향은 석사과정 중에서도 계속해서 바뀔 수 있습니다. 하지만 이 부분은 석사지원단계에서 걱정하실 부분은 아닙니다. 또한 추후에 방향을 바꾼다 한들 불이익은 크게 없습니다. 그럼 본론으로 돌아와서 연구계획을 작성하기 전 가장 먼저 생각해야 할 연구방향입니다.  이 부분에 대해서는 3-1 자소서 작성에서도 다루었으나 다시 한번 언급하고자 합니다. 바로 지원하고자 하는 연구실의 논문들 아웃풋을 통해서 정하는 방법입니다. 교수님들 또는 그 연구실 박사생들의 논문들을 대략적으로 확인해보시고 그와 비슷한 방향만 잡으시는게 중요합니다. 가령 AI베이스의 생산기술을 연구하는데 본인이 전통적인 방식의 생산기술 개선에 대해 연구하고자 한다고 적을 수는 없기 때문입니다. 또 다른 방법은 사전 컨택으로 정할 수 있습니다. 만약 컨택이 성공할 경우 높은 확률로 교수님과 사전 미팅을 하게 됩니다. 이때의 미팅은 면접이 아닌 연구실 및 연구방향 소개를 해주는 경우가 많이 있습니다. 이러한 내용을 참고하여 작성을 시작하시면 됩니다.지원 동기 작성의 연장 방향도 정했으니 나머지는 금방 작성하실 수 있습니다. 먼저 말씀드렸다시피 석사지원생의 연구계획서는 절대로 디테일하게 나올 수 없습니다. 따라서 교수님이 보시기에 방향이 맞는 것 같다, 이러한 연구를 같이 해볼 수 있을 것 같다 정도의 인식을 드릴 수 있으면 됩니다.  앞의 글에서 소개해드린 지원 동기에서 본인이 하였던 프로젝트를 논문의 형식처럼 분석하시라고 언급하였습니다. 이처럼 프로젝트를 통해 본인이 생각하는 기존 방식에 대한 문제점 또는 개선점을 언급하고 이에 맞게 글을 쓰시면 됩니다. 이 부분에서 본인이 정말 할 수 있냐 없냐는 중요하지 않습니다.  반응형(adsbygoogle = window.adsbygoogle || []).push({});연구계획서 구성그럼 실질적인 연구계획서의 구성에 대해 말해보고자 합니다. 늘 말씀드리지만 저의 주관적인 작성 방법이며 참고만 부탁드립니다.  1. 기존 논문들의 보완점을 읽어보고 그에 대한 의견을 적어본다논문들의 결론을 보시면 본인들의 결론과 동시에 앞으로의 보완점 역시 명시되어있습니다. 이러한 부분들을 잘 정리하여 아래와 같은 순서로 작성하시면 됩니다. Step 1. xx 전공에서는 xx 문제와 관련된 많은 논문들이 있음Step 2. 대다수의 논문이 xx와 같은 결과를 냄Step 3. 하지만 xx의 문제가 항상 존재함Step 4. 저는 이러한 문제를 해결할 수 있는, 오차를 줄일 수 있는 연구를 하고 싶다 2. 본인의 프로젝트 기반으로 연구계획을 작성이전 글에서 말씀드린 프로젝트를 논문의 형식처럼 쪼개 보시면 역시 비슷하게 본인의 프로젝트 결과의 보완점 및 문제점 또한 알 수 있습니다. 이러한 부분에 대해서 이론적인 대체방법 또는 이론이나 현실의 한계에 대해 생각해보시고 아래와 같은 순서로 작성하시면 됩니다. Step 1. xx와 관련된 프로젝트를 성공적으로 수행하였음Step 2. 하지만 xx부문에서 부족하다는 것을 알았음Step 3. 조사해본 결과 xx이론을 적용하면 더욱 좋은 결과를 가진다는 것을 알았음Step 4. 이와 관련된 연구를 통해 기존의 xx한 결과를 개선시킬 수 있는 연구를 해보고 싶다. 3. 순수 본인이 관심이 있고 좋아하는 부문에 대한 접근가장 어렵게 작성하는 방식이지만 동시에 실력만 있다면 가장 좋은 방법이라고 생각합니다. 하지만 이렇게 작성하실 경우 확실한 사전조사 및 공부가 필요합니다. Step 1. 본인이 공부를 하며 관심을 가진, 또는 의문을 가진 부분을 제시Step 2. xx한 방법론들이 많이 제시되었으나 본인은 다른 방식들도 많을 거라 생각Step 3. 아직 정확하겐 알 수없지만 이러한 부분에 대한 연구를 해보고자 함 글을 마무리하며이번 글에서는 연구계획서 작성에 대한 생각을 적어보았습니다. 사실 연구계획서는 전공에 따라 양식도 내용도 크게 차이가 납니다. 전공별 영역별 추구하는 결과가 다르기 때문입니다. 저는 기계공학 및 고급생산기술 관련 학과를 전공하였기에 위와 같은 전개 예시를 들었습니다. 참고만 하시고 본인 전공 및 결과에 맞는 계획서를 작성하시기 바랍니다. 기타 상담대학원 입시 및 준비와 관련하여 전반적인 컨설팅을 진행하고 있습니다. 대학원 입시를 처음 시작하시는 분부터, 자기소개서 및 학업계획서 작성 중 이신 분까지 전체적인 대학원 지원과 관련하여 컨설팅 및 멘토링 진행합니다.  관심 있으시면 아래 오픈 채팅 또는 숨고 링크를 통하여 견적 요청 남겨주세요.  국내/해외 대학원 준비 / 자소서, 학업계획서 첨삭#대학원 #자소서 #학업계획서open.kakao.com 반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//210306.tistory.com/reaction';window.ReactionReqBody = {    entryId: 20}공유하기게시글 관리평범한 직장인의 관심사 '대학원 준비 > 국내대학원' 카테고리의 다른 글[국내 대학원] 4-2. 대학원 면접 준비 - 전공 질문, 전공 관련 면접  (0)2021.10.02[국내 대학원] 4-1. 대학원 면접 준비 - 자기소개 및 인성면접 관련 질문예시  (0)2021.10.02[국내 대학원] 3-2. 학업계획서 - 지원동기 작성  (0)2021.10.02[국내 대학원] 3-1. 대학원 학업계획서(연구계획서) - 자기소개서 작성하기  (0)2021.10.02[국내 대학원] 2-2. 대학원 컨택 메일 작성하기 및 컨택 시기 정하기  (0)2021.10.02태그공대대학원, 대학원, 대학원 입시, 대학원 입시 컨설팅, 대학원입시, 수학계획서, 연구계획서, 학업계획서관련글[국내 대학원] 4-2. 대학원 면접 준비 - 전공 질문, 전공 관련 면접[국내 대학원] 4-1. 대학원 면접 준비 - 자기소개 및 인성면접 관련 질문예시[국내 대학원] 3-2. 학업계획서 - 지원동기 작성[국내 대학원] 3-1. 대학원 학업계획서(연구계획서) - 자기소개서 작성하기댓글0비밀글등록loadedComments[20]=true;findFragmentAndHighlight(20);"
70,https://jpub.tistory.com/662,태그,"도서 소개엑셀로 배우는 인공지능 제이펍2017. 3. 3. 10:39 이 책은 현재 절판입니다. 그간 읽어주신 분들께 감사드립니다.  인공지능을 배우는 학생은 물론, 비전공자나 일반인까지인공지능 입문자를 위한 최적의 가이드!   출판사 제이펍 원출판사 SHOEISHA 원서명 はじめての人工知能 Excelで体験しながら学ぶAI(원서 ISBN: 9784798144658) 저자명 아사이 노보루 역자명 우영운 출판일 2017년 2월 28일 페이지 264쪽 시리즈 I♥A.I. 03 판  형 크라운판 변형(170*225*13) 제  본 무선(soft cover) 정  가 18,000원 ISBN 979-11-85890-74-6 (93000) 키워드 인공지능 / AI / 머신러닝 / 딥러닝 / 신경망 / 퍼지 / 유전자 알고리즘 / 탐색법 / 게임 전략 / 지식 표현 / 전문가 시스템 / 에이전트 / Lisp / Prolog 분야 컴퓨터 공학 / 인공지능    관련 사이트 ■ 아마존재팬 도서 소개 페이지 ■ 원출판사 도서 소개 페이지   관련 포스트 ■ 2017/02/22 - [출간전 책소식] - 인공지능을 엑셀로 배우자!   관련 시리즈 ■ I♥A.I 시리즈   관련 도서 ■ 알고리즘 중심의 머신러닝 가이드(제2판)  ■ 딥러닝 제대로 시작하기 ■ 머신러닝 인 액션: 기계 학습 알고리즘으로 데이터 마이닝하기 ■ 인공지능 1: 현대적 접근 방식(제3판) ■ 인공지능 2: 현대적 접근 방식(제3판)   관련 파일 다운로드 ■ 엑셀 시뮬레이션 프로그램LearnAIwithExcel-master.zip다운로드깃헙에서 받기(깃헙 페이지에 접속하시면 가운데 우측 부분에  버튼이 있습니다. 이 버튼을 누른 후 우측 하단에 있는 'Download ZIP'을 클릭하시면 파일을 다운로드하실 수 있습니다)        강의보조 자료 교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com ■ 본문의 그림과 표 ■ 강의교안(ppt)(17년 8월 제공 예정)   샘플 PDF(차례, 옮긴이 머리말, 베타리더 후기, 3장 '인간의 애매함을 기계로 처리하기 = 퍼지')  엑셀로배우는인공지능_sample.pdf다운로드  정오표 페이지 ■ http://jpub.tistory.com/715   도서구매 사이트(가나다순)  [강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]    도서 소개 인공지능을 배우는 학생은 물론, 비전공자나 일반인까지 인공지능 입문자를 위한 최적의 가이드!   이 책은 앞으로 점점 더 발전할 것으로 예상되는 인공지능을 처음 배우고자 하는 분들을 위한 책이다. 머신러닝을 시작으로 신경망, 유전 알고리즘, 문제 해결, 게임 전략, 지식 표현 등 인공지능을 지탱하는 다양한 분야의 기초를 파악할 수 있다.   인공지능은 독특하면서도 고도의 기술이 많이 사용되는 분야이긴 하지만, 간단한 입력과 클릭만으로도 실행되는 엑셀 프로그램을 통해 실행 과정과 결과를 눈으로 바로 확인할 수 있도록 하였다. 아이디어가 돋보이는 엑셀 프로그램을 직접 조작하면서 인공지능에 대한 이해를 한층 높일 수 있을 것이다.   이 책에서 다루는 엑셀 프로그램 ■ 삐뚤어진 문자 인식하기 ■ ‘약간 높은 듯/약간 낮은 듯’하게 에어컨 제어하기 ■ 효율적으로 재산 분배하기 ■ 선교사가 식인종에 잡혀 먹히지 않고 강을 건널 수 있을까? ■ 최소 비용으로 산의 정상까지 오르는 경로 탐색하기 ■ 간단한 카드 게임으로 컴퓨터에 도전하기 ■ 인공지능에 단어의 의미 가르치기 ■ 병원에 가기 전에 인공지능에 물어보기 ■ 범인을 잡아라!   저자 소개 아사이 노보루(淺井 登) 1972년 나고야대학교 이학부를 졸업한 이후로 34년간 후지쯔에서 컴퓨터 언어 처리 시스템 및 인공지능 관련 기본 소프트웨어 개발에 힘썼다. 2000년부터 누마즈공업고등전문학교 전자제어공학과의 비상근 강사(인공지능)로 근무하다 지금은 오스카테크놀로지에 소속되어 있으면서 누마즈공업고등전문학교의 객원 교수를 겸하고 있다.   역자 소개 우영운  1997년 연세대학교 전자공학과에서 박사 학위를 취득한 이후 줄곧 동의 대학교 교수로 재직 중이다. 컴퓨터 프로그래밍과 인공지능 관련 과목을 주로 강의하고 있다. 지식 표현, 패턴 인식, 퍼지 기법, 딥러닝 등 인공지능 분야에 관심을 가지고 연구하고 있으며, 한국정보통신학회와 한국지능정보시스템학회에서 활동하고 있다.   차례 CHAPTER 1 꿈으로 가득 찬 인공지능 1 1.1 인공지능이 인간을 능가할 수 있을까? 2 1.2 인공지능의 연구 주제 29 1.3 인공지능 기술의 초보적 고찰 34 더보기 CHAPTER 2 인간의 뇌를 모방하는 기계 = 신경망 43 체험해봅시다: 인공지능이라면 약간 비뚤어진 문자를 정확히 인식할 수 있다 45 체험해봅시다: 인공지능이라면 더욱 비뚤어진 문자라도 정확히 인식할 수 있다 49 2.1 뇌의 모델과 신경망의 개념 52 2.2 퍼셉트론 56 2.3 홉필드 네트워크 61 2.4 기타 신경망 65   CHAPTER 3 인간의 애매함을 기계로 처리하기 = 퍼지 71 체험해봅시다: ‘약간 높은 듯/약간 낮은 듯’하게 에어컨 제어하기 73 체험해봅시다: 애매한 조건으로 목푯값 유지하기 76 3.1 퍼지의 개념 79 3.2 퍼지 추론 85 3.3 퍼지 제어 89 3.4 퍼지 관계 91   CHAPTER 4 좋은 것이 남는 진화의 법칙 = 유전 알고리즘 97 체험해봅시다: 효율적으로 재산 분배하기 99 4.1 유전 알고리즘이란? 104 4.2 유전 알고리즘의 구체적 예 108 4.3 유전 알고리즘의 응용 111   CHAPTER 5 우리 주변의 문제 잘 해결하기 = 문제 해결 117 체험해봅시다: 선교사가 ‘식인종’에 잡혀 먹히지 않고 강을 건널 수 있을까? 119 5.1 모델화 123 5.2 상태 전이 124 5.3 문제 해결의 구체적 예 126   CHAPTER 6 가장 효율적인 경로를 어떻게 선택할까? = 탐색법 131 체험해봅시다: 최소 비용으로 산의 정상까지 오르는 경로 탐색 133 6.1 탐색법의 분류 136 6.2 체계적 탐색 137 6.3 휴리스틱 탐색 140 6.4 탐색법 정리 144   CHAPTER 7 상대가 있을 경우의 대처 방법 = 게임 전략 147 체험해봅시다: 간단한 카드 게임으로 컴퓨터에 도전! 149 7.1 Min-Max 전략 153 7.2 αβ 전략 154   CHAPTER 8 인간이 학습하는 과정을 기계로 모방하기 = 머신 러닝 157 체험해봅시다: 인공지능에 단어의 의미 가르치기 159 8.1 머신 러닝의 기본적 개념 162 8.2 버전 공간법 165   CHAPTER 9 인간의 지식을 기계상에 표현하여 인간을 대신 = 지식 표현과 전문가 시스템 169 체험해봅시다: 병원에 가기 전에 인공지능에 물어보기 171 9.1 지식 표현 174 9.2 전문가 시스템 181   CHAPTER 10 기계에 인간의 자율성 부여하기 = 에이전트 185 체험해봅시다: 범인을 잡아라! 187 10.1 에이전트의 고전적 문제 191 10.2 에이전트의 개념 195 10.3 멀티에이전트 197   CHAPTER 11 인공지능을 개척한 컴퓨터 언어 = Lisp 201 11.1 리스트 처리 203 11.2 람다 계산 208 11.3 스코프와 익스텐트 213 11.4 쓰레기 수집 215   CHAPTER 12 사물의 관계를 서술하는 컴퓨터 언어 = Prolog 219 12.1 명제 논리 221 12.2 술어 논리 227 12.3 혼 절 231 12.4 단일화와 백트랙 234 12.5 WAM과 추상 명령 236   참고문헌 241 찾아보기 244  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 662}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글서버/인프라 엔지니어를 위한 DevOps  (0)2017.03.23안드로이드 게임 개발의 정석  (2)2017.03.13처음 만나는 자바스크립트  (8)2017.02.27자바스크립트와 Node.js를 이용한 웹 크롤링 테크닉  (12)2017.01.04알고리즘 중심의 머신러닝 가이드(제2판)  (6)2016.12.28태그ai, Artificial Intelligence, lisp, prolog, 게임전략, 딥러닝, 머신러닝, 신경망, 에이전트, 우영운, 유전자 알고리즘, 인공지능, 제이펍, 탐색법, 퍼지'도서 소개' Related Articles서버/인프라 엔지니어를 위한 DevOps안드로이드 게임 개발의 정석처음 만나는 자바스크립트자바스크립트와 Node.js를 이용한 웹 크롤링 테크닉Secret댓글달기loadedComments[662]=true;findFragmentAndHighlight(662);"
71,https://riedel.tistory.com/477,1. 금융 전략을 위한 머신러닝 - 금융과 머신러닝의 완벽한 만남,"var cnt = 0;var layoutKey = """";var slot = """";if(window.innerWidth > 767) {slot = ""7193229854"";layoutKey = ""-et+p-3e-92+ta"";} else {slot = ""4567066517"";layoutKey = ""-gm+k-2q-7a+nn"";}if(cnt != 0 && cnt%2 == 0) {document.write('<ul><li><ins class=""adsbygoogle"" style=""display:block"" data-ad-format=""fluid"" data-ad-layout-key=""'+layoutKey+'"" data-ad-client=""ca-pub-3458530807780778"" data-ad-slot=""'+slot+'""></ins></li></ul>');adPush();}cnt += 1;북로그/독서 기록비트코인 차트를 머신러닝으로 예측하는 방법(feat. 금융 전략을 위한 머신러닝 Machine Learning and Data Science Blueprints for Finance 후기)동사힐2022. 2. 14.if($(window).width() < 710) {$('#ad-top-left').remove();} else {adPush();}adPush();안녕하세요~  동사힐입니다. 😊오늘은 비트코린 차트를 머신러닝으로 예측하는 방법을 알 수 있는 책인 금융 전략을 위한 머신러닝 후기를 적어보고자 합니다.한빛미디어 <나는 리뷰어다> 활동을 위해서 책을 제공받아 작성된 서평이니, 참고 바랍니다. 1. 금융 전략을 위한 머신러닝 - 금융과 머신러닝의 완벽한 만남금융 전략을 위한 머신러닝 책 표지금융 전략을 위한 머신러닝의 원제목은 Machine Learning and Data Science Blueprints for Finance입니다. 책을 소개하는데 영어 원제목을 먼저 설명하는 이유는 영어 제목이 이 책의 특성을 온전하게 설명해주기 때문인데요. 실제로 이 책은 금융에 활용할 수 있는 머신러닝과 데이터 과학의 청사진을 구체적으로 제시하는 책입니다. 단순히 금융과 관련된 사례나 코드 예제만 제공하는 것이 아니라 머신러닝과 데이터 과학과 관련된 다양한 학습 모델을 제공하고 있고, 다양한 모델을 7단계 문제 접근 방법 툴을 활용해서 공통적으로 적용해볼 수 있도록 설명하고 있습니다. 그뿐만 아니라 기존의 머신러닝 & 데이터과학 책에서는 주로 예제를 사이킷런 등에 포함되어 있는 기본 예제로 설명하는 경우가 대다수인데, 이 책은 캐글(https://www.kaggle.com/)의 다양한 예제 등을 활용하고 있습니다. 실제 예제의 파일들은 주로 FRED(Federal Reserve Economic Data, 미 연방 준비 은행 경제 데이터)나 야후 파이낸스, 비트스탬프 등 실제 미국의 주요 경제 지표를 확인할 수 있는 실질 데이터를 가지고 분석합니다. 이러한 예제만 보더라도, 실무에서 충분히 활용 가능한 예제임을 알 수 있습니다. 이 책에서 예측하는 독자층은 헤지 펀드, 투자 및 소매 은행, 핀테크 회사에서 일하는 데이터 과학자, 데이터 엔지니어 퀀트 연구원, 머신러닝 설계자 또는 소프트웨어 엔지니이업니다. 역으로 말하면 이러한 금융 핀테크 기업에서 데이터 전문가 직무를 갖기 원하는 주니어 개발자에게 실무 예제를 경험해볼 수 있는 책이라고 볼 수 있습니다.    https://docs.google.com/spreadsheets/d/1zpLFAPZ8NA6V09JUUU66g_lvpVra24B_ZTDHunM2O8c/edit?usp=sharing  [한빛미디어] 머신러닝·딥러닝 도서 선택 가이드(update 21-12-27)딥러닝/머신러닝(21-11-25) 분류,알고리즘,알고리즘,알고리즘 주 활용 분야 학습 방법,지도학습,지도학습,지도학습 입력의 규칙성(문제?),회귀,회귀,회귀 특징 추론/확률,추론/확률,추론/확률 선행docs.google.com다만, 이 책의 난이도는 상당히 높습니다. 한빛미디어에서 제작한 '[한빛미디어] 머신러닝·딥러닝 도서 선택 가이드'를 보면 이 책의 난이도는 무려 7입니다. 위 도서선택가이드에서 머신러닝, 딥러닝 관련 책이 총 61권인데, 이중 난이도 7이상의 책은 13권뿐입니다. 이 정도면 상당한 난이도라고 할 수 있습니다. 하지만 난이도에 겁먹을 필요는 없습니다. 적어도 파이썬을 어느 정도 다뤄본 독자라면 충분히 이해하고 파악할 수 있습니다. 만약 파이썬을 다뤄보지 않았더라도, R 등을 활용해서 데이터 분석을 해본 독자도 충분히 접근 가능합니다. 저는 오히려 이 책을 제대로 활용하기 위해서 필요한 지식은 컴퓨터 언어 관련 지식은 아니라고 생각합니다. 솔직히 말씀드리면 이 책에서는 아나콘다를 설치하여 주피터 노트북으로 코드를 실행하라고 나와 있는데, 예제 코드를 보고 주피터 노트툭보다 구글 코랩을 활용하면 훨씬 수월하게 예제 코드를 모두 실행할 수 있습니다. 구글 코랩은 기본 세팅이 이미 다 되어 있고, 구글의 GPU를 활용하여 연산하기 때문에 노트북으로도 충분히 머신러닝을 할 수 있는 좋은 프로그램입니다. 구글 코랩에서 데이터를 불러오기만 할 수 있으면 프로그래밍 언어적으로 필요한 능력은 모두 끝났다고 생각합니다.그것보다 더 요구되는 역량은 바로 머신러닝과 관련된 지도 학습, 비지도 학습, 강화 학습 등의 모델링과 알고리즘에 대한 이해도입니다. 예를 들어 이 책에서 지도 학습과 관련하여 선형 회귀부터 정규화 회귀, 로지스틱 회귀, 서포트 벡터 머신, K-최근접 이웃, 선형 판별 분석, 분류 트리, 회귀 트리, 앙상블 모델 등 다양한 모델을 소개하고, 실제로 데이터로 분석을 합니다. 이런 개념들을 이해하고, 어떻게 분석하고 효과성을 판별하는지에 대해서 정확히 알아야, 실제로 책에서 비트코인 거래 전략 알고리즘에서 다양한 모델 중에서 앙상블 모델의 랜덤 포레스트 모델을 선정했는지 이해할 수 있습니다. 이는 앞에서 말씀 드린 이 책의 기본 구조가 7단계 문제 접근 방식으로 인해 두드러지는 특징인데요. 예제 연습이나 실무에서도 바로 활용할 수 있도록 하기 위함인데요, 특히 모델 평가와 모델 튜닝 구조는 머신러닝에서 매우 필수적으로 학습해야 할 부분이며, 이 책이 지닌 가장 큰 매력이라고 생각합니다.  또한 머신러닝, 딥러닝에 관심이 많은 독자분이라면 '[한빛미디어] 머신러닝·딥러닝 도서 선택 가이드'를 참고하시면 학습하는데 큰 도움이 될 것입니다. 그러면 구체적으로 이 책의 특징을 살펴보겠습니다.  2. 독자 맞춤형 예제 소스 제공 https://gitlab.com/inspro9/hanbit_mlfi Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com먼저 이 책의 보물이라고 할 수 있는 예제 소스와 설명이 담긴 깃입니다. 저는 처음의 예제 소스를 책에서 못 찾아서 한빛미디어 담당자에게 메일까지 보냈었는데요. 메일 보내고 30분도 안되어서 바로 친절하게 답해주셔서 정말 감사한 마음이었습니다. 사실 이 예제 소스 주소는 책 표지 뒷면에 나와 있음에도 불구하고, 저의 주의 부족으로 찾지를 못했었죠.책 표지 뒷면에 나와 있는 예제 소스 주소이 예제들과 함께 책의 주요 내용을 학습해야 합니다. 특히 예제 소스만 덩그러니 나와 있는 것이 아니라, 책과 상호 연결되도록 구체적인 설명을 함께 제시하고 있어서 독자의 이해를 돕습니다. 다만, 깃 문서는 전부 영어로 작성되어 있기에, 어느 정도 영어 실력은 필요로 합니다. 그런데 이런 예제 소스는 사실 다른 머신러닝 책에서도 기본으로 제공하는 것이라 특별할 것 없다고 생각할 수 있는데, 저에게 가장 인상 깊었던 것은 바로 다음입니다. Notebooks by Application in Finance1. Trading Strategies and Algorithmic TradingBitcoin Trading Strategy using classificationBitcoin Trading Enhancing Speed and Accuracy using dimensionality reductionClustering for Pairs Trading StrategyReinforcement Learning based Trading StrategyNLP and Sentiments Analysis based Trading Strategy2. Portfolio Management and robo-advisorsInvestor Risk Tolerance and Robo-advisors - using supervised regressionRobo-Advisor Dashboard-powdered by MLPortfolio Management - Eigen Portfolio - using dimensionality reductionPortfolio Management - Clustering InvestorsHierarchial Risk Parity - using clusteringPortfolio Allocation - using reinforcement learning3. Derivatives Pricing and HedgingDerivative Pricing - using supervised regressionDerivatives Hedging - using reinforcement learning4. Asset Price PredictionStock Price Prediction - using regression and time seriesYield Curve Prediction - using regression and time seriesYield Curve Construction and Interest Rate Modeling - using dimensionality reduction5. Fraud DetectionFraud Detection - using classification6. Loan Default probability predictionLoan Default Probability - using classification7. Chatbot and automationDigital Assistant-chat-bots - using NLPDocuments Summarization - using NLP   Notebooks by Machine Learning Types1. Supervised Learning- Regression and Time series ModelsStock Price Prediction Derivative PricingInvestor Risk Tolerance and Robo-advisorsYield Curve Prediction2. Supervised Learning- Classification ModelsFraud DetectionLoan Default ProbabilityBitcoin Trading Strategy3. Unsupervised Learning- Dimensionality Reduction ModelsPortfolio Management - Eigen PortfolioYield Curve Construction and Interest Rate ModelingBitcoin Trading - Enhancing Speed and accuracy4. Unsupervised Learning- ClusteringClustering for Pairs TradingPortfolio Management - Clustering InvestorsHierarchial Risk Parity5. Reinforcement LearningReinforcement Learning based Trading StrategyDerivatives HedgingPortfolio Allocation6. Natural Language ProcessingNLP and Sentiments Analysis based Trading StrategyDigital Assistant-chat-botsDocuments Summarization  https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/index.ipynb index.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com 모두 인덱스에 제시된 내용인데요, 바로 동일한 예제를 금융 전략 관점과 머신러닝 타입에 따라서 분류를 해놓은 것입니다. 이 책은 금융 분야와 머신러닝 분야가 융합되어 있고, 따라서 두 분야의 독자들을 위해서 적절하게 나눠놓은 것입니다. 이러한 전문적인 내용을 상세하게 분류할 수 있는 이유는 이 책을 옮긴 김한상님의 뛰어난 역량이 있었기에 가능하다고 생각합니다.  실제로 이 책을 옮긴 김한상님은 현재 실리콘밸리에서 자율주행차를 연구하는 머신러닝, 데이터 전문가인데 금융 포트폴리오 관리 분야의 데이터 기반 의사 결정에도 깊은 관심을 갖다보니 자연스럽게 이 책을 번역도 하고, 이렇게 독자들을 위한 예제 소스도 직접 만드셨습니다. 김한상님의 노력이 없었다면, 이 책이 한국에 소개되기는 쉽지 않았으리라고 봅니다.  3. 7단계 문제 접근방법 템플릿 제공이 책은 파이썬을 사용하여 실전에 활용 가능한 문제를 제시하고 풀어 나갑니다. 또한 7단계 문제 접근방법(문제 정의 - 데이터 불러오기 - 데이터 분석 - 데이터 준비 - 모델 평가 - 모델 튜닝 - 모델 확정)의 템플릿을 제시합니다. 이 템플릿을 이용하여 새로운 머신러닝 문제에 쉽게 접근할 수 있습니다. -금융 전략을 위한 머신러닝 5쪽금융 전략을 위한 머신러닝은 파이썬을 기반으로 실무에서 바로 활용할 수 있는 여러 사례들을 다양한 머신러닝 모델을 활용하여 풀어나갑니다. 특히 7단계 문제 접근 방법을 제시하고, 이를 19가지 사례 전부에 적용합니다. 이를 통해 독자로 하여금 실무에 쉽게 응용할 수 있도록 만들고 있습니다. 특히 모델 평가와 모델 튜닝 부분은 머신러닝을 학습하는 주니어 개발자나 실무에서 일하는 현직 전문가에 큰 인사이트를 줄 것이라고 생각합니다. 그만큼 매우 활용도가 높으면서 깊이 있는 내용을 다루고 있습니다. 4. 비트코인, 주가 예측 그리고 챗봇까지 금융의 전 분야를 아우르는 19가지 사례 제공코로나19 팬데믹 이후 디지털 트랜스포메이션과 AI 트랜스포메이션 바람이 기업에 불면서 동시에 머신러닝과 딥러닝 또한 혹독한 겨울을 지나 지금 다양한 영역에서 활용되고 있습니다. 이에 따라서 많은 실무자나 주니어 개발자들이 머신러닝과 딥러닝을 학습하고 있는데요. 머신러닝을 다른 산업군보다 빠르게 활용했던 영역이 바로 금융입니다. 굳이 미국의 켄쇼를 언급하지 않아도, 국내에서도 상당수의 증권나 펀드 운용사에서 인공지능 AI를 활용해서 운용하는 펀드가 많습니다. 그뿐만 아니라 챗봇도 많이 운용하고 있구요.금융 분야에서 머신러닝을 많이 활용할 수 있는 가장 큰 이유는 바로 방대한 데이터를 엄청나게 빠른 속도로 만들어내고, 또 신속하게 의사결정을 내려서 흔들림없이 내린 결정을 지속해 가야 하기 때문입니다. 이런 금융 분야에서 구체적으로 활용할 수 있는 금융 사기 탐지, 비트코인, 주가 변화 예측, 포트폴리오 구성, 챗봇 시스템까지 머신러닝을 통해 활용할 수 있는 다양한 사례를 금융 전략을 위한 머신러닝에서는 사례로 제시하고 실제로 구현합니다. 그뿐만 아니라 각 장의 끝에는 이와 비슷한 사례의 연습 문제를 제시하여 독자로 하여금 스스로 고민하고 응용할 수 있도록 구체적이고 실질적인 아이디어를 함께 제시합니다.  금융, 핀테크 분야 전문가로서 머신러닝을 학습하고 싶은 독자머신러닝 학습자로서 보다 실질적인 구체적인 사례를 연습하고 싶은 독자금융 기업의 데이터 전문가로 취업을 준비하는 독자자신의 머신러닝, 데이터 과학 관련 분야를 금융 분야와 연결시켜 확장시키고 싶은 독자 이러한 독자들에게는 매우 소중한 책이 될 것이라고 생각합니다. 5. 비트코인 차트 예측 예제https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/Ch6_SLC/CS3BTS/BitcoinTradingStrategy.ipynb Ch6_SLC/CS3BTS/BitcoinTradingStrategy.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com금융 전략을 위한 머신러닝 책 본문 216쪽부터 나와 있는 실전 문제 비트코인 거래 전략의 코드 중 제가 실행한 일부 코드만 공유하고자 합니다. 금융 전략을 위한 머신러닝을 학습하는 독자들에게 조금이나마 도움이 되었으면 합니다.from google.colab import drivedrive.mount('/content/drive')# load datasetdataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv')먼저 저는 구글 코랩을 활용해서 코드를 실행했습니다. 위 코드는 저의 구글드라이브를 구글 코랩에 가상으로 마운트하는 명령어이구요. #은 주석이고, 그 다음줄은 데이터를 읽어내는 명령어입니다. 아무 생각없이 예제 소스를 그대로 복붙하면 실행이 안됩니다. 구글 코랩에서 파일의 폴더 모양을 클릭하신 후에 구글드라이브에 원하는 데이터의 경로 복사 기능을 활용해서 경로를 복사해주시면 데이터 파일을 읽어냅니다. 구글 코랩을 처음 활용하던 제가 처음에 많이 헤매던 부분이어서, 저처럼 파이썬을 잘 모르는 분들도 구글 코랩에서 경로 복사 기능만 이해하셔도 충분히 예제 소스를 이상없이 테스트해볼 수 있습니다.import matplotlib.pyplot as plt 처음에 matplotlib을 plt로 지정한 후에 다음의 메서드로 비트코인 그래프를 그렸습니다.dataset[['Weighted_Price']].plot(grid=True)plt.show()코드 실행 결과 등장한 차트 히스토그램도 다음 코드로 구현했습니다.# histogramsdataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,12))plt.show()코드 실행 결과 등장한 히스토그램 제시된 알고리즘 및 모델을 평가하기 위해서 먼저 데이터넷을 훈련하고, k-겹 교차 검증(k-folds cross validation)을 수행했습니다.results = []names = []for name, model in models:    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)    results.append(cv_results)    names.append(name)    msg = ""%s: %f (%f)"" % (name, cv_results.mean(), cv_results.std())    print(msg)k-겹 교차 검증에 무려 26분이 소요다음과 같은 결과가 나왔습니다. 앙상블 모델 중에서는 랜덤 포레스트가 최고의 성능을 보이는 것을 눈으로 확인할 수 있었습니다. 다만 구글 코랩으로 구글의 GPU를 사용했음에도 불구하고 무려 26분이나 시간이 걸렸습니다. 데이터가 무려 317메가바이트이기도 하고, 무려 9개의 모델을 비교 검증하는 것이다보니까 시간이 상당히 걸립니다. 제가 처음에는 아나콘다를 노트북에 설치해서 주피터 노트북으로 구동을 했는데, 노트북에 GPU가 없다보니 시간이 너무 오래 걸렸고, 결국 구글 코랩으로 옮기게 된 직접적인 이유이기도 합니다. # compare algorithmsfig = plt.figure()fig.suptitle('Algorithm Comparison')ax = fig.add_subplot(111)plt.boxplot(results)ax.set_xticklabels(names)fig.set_size_inches(15,8)plt.show()알고리즘 비교 결과를 시각화알고리즘 비교 결과를 matplotlib으로 시각화한 자료입니다. 한 눈에 각 모델의 수치를 비교할 수 있습니다.이 실전 문제(비트코인 거래 전략)는 머신러닝으로 금융 문제를 해결할 때 문제를 구조화하는 것이 핵심 단계라는 것을 시연해 보였다. 이 과정에서 투자 목표에 따라 레이블을 변환하고 특성 엔지니어링을 수행하는 것이 거래 전략을 위해 필요하다는 것을 확인했다. 가격 움직임의 추세 및 모멘텀과 관련된 직관적인 특성을 사용하는 것이 효율적임을 입증했다. 이것은 모델의 예측력을 높이는 데 유용했다. (중략)이 장에 제시된 파이썬, 머신러닝, 금융의 개념은 금융의 다른 분류 기반 문제에 대한 청사진으로 사용할 수 있다.-금융 전략을 위한 머신러닝 책 본문 229쪽책에서 언급된 위의 내용에서처럼 금융과 관련된 개념을 비트코인 차트 분석과 같은 금융 사례를 통해 제시함으로써 금융 관련 실무를 수행하는데 있어서 발생하는 다양한 문제들을 해결하는데 큰 도움이 될 것입니다.이 장의 마지막에서는 다음의 연습 문제를 제공함으로써 독자로 하여금 더욱 깊이 있는 사례 연구를 해볼 수 있도록 돕습니다.금융 전략을 위한 머신러닝 230쪽 연습 문제 6. 신용카드 거래 사기 탐지 예제https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/Ch6_SLC/CS1FD/FraudDetection.ipynb Ch6_SLC/CS1FD/FraudDetection.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com사기 탐지와 관련된 예제 중에서 가장 인상 깊었던 부분은 모델 튜닝이었습니다. 원하는 수준의 모델의 정확도를 얻을 때까지 지속적으로 개선하는 점은 저에게도 큰 도움이 되었습니다.# Grid Search: GradientBoosting Tuning'''n_estimators : int (default=100)    The number of boosting stages to perform.     Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.max_depth : integer, optional (default=3)    maximum depth of the individual regression estimators.     The maximum depth limits the number of nodes in the tree.     Tune this parameter for best performance; the best value depends on the interaction of the input variables.''' n_estimators = [20,180,1000]max_depth= [2, 3,5]param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)model = GradientBoostingClassifier()kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)grid_result = grid.fit(X_train_new, Y_train_new)#Print Resultsprint(""Best: %f using %s"" % (grid_result.best_score_, grid_result.best_params_))means = grid_result.cv_results_['mean_test_score']stds = grid_result.cv_results_['std_test_score']params = grid_result.cv_results_['params']ranks = grid_result.cv_results_['rank_test_score']for mean, stdev, param, rank in zip(means, stds, params, ranks):    print(""#%d %f (%f) with: %r"" % (rank, mean, stdev, param))격자 탐색 결과 신용카드 거래 사기 탐지는 신용카드 거래 불이행 비율을 발견하는 모델로 다양한 머신러닝 모델을 사용해보고, 적절한 평가 메트릭을 선택하고 불균형한 데이터를 어떻게 처리하는지를 시연하는지를 선보이고 있습니다. 7. NLP를 사용한 문서 요약 예제https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/Ch10_NLP/CS3DS/DocumentSummarization.ipynb Ch10_NLP/CS3DS/DocumentSummarization.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com오늘 리뷰에서 마지막으로 살펴볼 예제는 NLP를 사용한 문서 요약 예제입니다. 금융 관련 문서를 자연어 처리를 통해서 핵심을 요약하여 요점을 빠르게 파악할 수 있도록 돕는 프로세스입니다. 사이킷런의 LDA로 문서 요약을 연습해보겠습니다.#Libraries for pdf conversionfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreterfrom pdfminer.converter import TextConverterfrom pdfminer.layout import LAParamsfrom pdfminer.pdfpage import PDFPageimport re from io import StringIO#Libraries for feature extraction and topic modelingfrom sklearn.feature_extraction.text import CountVectorizerfrom sklearn.decomposition import LatentDirichletAllocation#Other librariesimport numpy as npimport pandas as pdpdf 변환 라이브러리, 특성 추출 및 주제 모델링 라이브러리, 기타 라이브러리를 불렀습니다. import mglearntopics = mglearn.tools.print_topics(topics=range(1,6), feature_names=features,sorting=array, topics_per_chunk=5, n_words=10)mglearn 출력 결과mglearn으로 5가지 주제에서 상위 10개의 단어를 추출했습니다. 다음으로는 주제 시각화를 해보았습니다. plt.figure(figsize=(16,13))plt.imshow(wc, interpolation='bilinear')plt.axis(""off"")plt.figure()#plt.imshow(raw_pic, cmap=plt.cm.gray, interpolation='bilinear')plt.axis(""off"")plt.show()워드 클라우드 생성 결과 8. 금융 전략을 위한 머신러닝(Machine Learning and Data Science Blueprints for Finance) 리뷰를 마치며2주 동안 금융 전략을 위한 머신러닝(Machine Learning and Data Science Blueprints for Finance)에 빠져 있었습니다. 왜 이 책의 원제에 Blueprints(청사진)이 들어 있을까? 생각을 많이 했는데, 다음의 이유에서 금융을 위한 머신러닝 청사진이 맞다고 생각했습니다.7단계 문제 접근방법 템플릿금융 분야의 핵심적인 19가지 사례심도 있는 연습문제이를 통해서 금융 분야의 머신러닝 전문가로 성장할 수 있는 구체적이고 완벽한 청사진을 제공하는 책입니다. 이 책을 모두 읽고 나니 금융 분야에서 실무자가 겪게될 대부분의 문제를 간접적으로 경험할 수 있었고, 문제를 해결하는 솔루션까지 학습할 수 있었습니다. 누구나 쉽게 접근할 수 있는 책은 아니지만, 머신러닝을 통해 금융 투자 전문가로 성장하고자 하는 독자 혹은 데이터 전문가로서 자신의 영역을 확장시키고자 하는 독자 모두에게 최고의 청사진을 제공하는 사례연구서입니다. 이 책을 통해서 대한민국의 금융 분야에도 머신러닝과 데이터 과학이 더욱 큰 기여를 하였으면 하는 바람입니다.  감사합니다.  어떠셨나요? 도움이 되셨나요?그러면 다음에도 더욱 좋은 글로 돌아오겠습니다.궁금한 사항 있으시면 댓글로 남겨주세요.도움이 필요하시다면 사연을 적어서 이메일을 보내주세요.dongsahill@gmail.com그리고 도움이 되셨다면 공감과 구독 부탁드려요.이상으로 동사힐이었습니다!읽어주셔서 감사합니다. 😊  반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//riedel.tistory.com/reaction';window.ReactionReqBody = {    entryId: 477}공유하기게시글 관리별감 아카이빙저작자표시 비영리 변경금지 '북로그 > 독서 기록' 카테고리의 다른 글삼국지 관우는 왜 조선에서 전쟁의 신이 되었을까?(feat. 만화로 배우는 조선 왕실의 신화 리뷰)  (0)2022.02.24데이터를 분석하고 시각화하는 아주 쉬운 방법(feat. 혼자 공부하는 R 데이터분석 리뷰)  (0)2022.02.16저는 주식투자가 처음인데요 리뷰(feat. 투자전략편을 읽고)  (0)2022.02.03아직도 주식 투자를 해보지 않았다면? (feat. 이 책부터 읽어보자.)  (0)2022.01.26왜 지금 슈퍼 석세스를 읽어야 할까?(feat. 신년을 준비하며 다시 읽는 슈퍼 석세스)  (0)2022.01.04볼 만한 글adPush();adPush();if($(window).width() < 710) {$('#ad-bottom-right').remove();} else {adPush();}댓글2비밀글등록    setInitialEntryComments(477, 1723627680)loadedComments[477]=true;findFragmentAndHighlight(477);💲 추천 글if(!checkMainPage()) {var mainAds = $('.main-ads');if(mainAds.prev().prop('tagName') == 'H2') {mainAds.prev().remove();}mainAds.remove();} else {adPush();}"
72,https://benn.tistory.com/35,Tag,"                                                  Bee's 데이터 과학                              홈태그방명록Data Science | AI/머신러닝 및 딥러닝[인공지능 자격증] 마이크로소프트 AI Fundamentals 자격증 (AI-900) 취득 후기Letter_B2021. 10. 22. 16:55728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});시험에 대해서마이크로소프트 시험최근에 링크드인 피드에 마이크로소프트 자격증을 따고 후기를 남기는 사람들이 눈이 띄었다. 그래서 나도 관심을 가지고 알아보기 시작했다. 마이크로소프트에서는 다양한 자격증을 취득할 수 있다. 모든 자격증은 마이크로소프트에서 제공하는 서비스 위주이며 역할 기반인 인증 시험들은 각 분야의 개념도 알아야 한다.예를 들면, AI 엔지니어 인증시험은 AI 관련 마이크로소프트 서비스도 자세히 알아야하지만 AI (머신러닝, 딥러닝) 관련 개념도 어느 정도 꽤 알아야 한다.  자격증 레벨에는 초급 > 중급 > 고급으로 나뉘지만 기본 사항 (Fundamentals), 역할 기반 (Role-based), 전문 (specialty)로 나뉘기도 한다.  그중 출발점으로 좋은 초급 + 기본 사항 (Fundamentals) 인증은 아래와 같다.Fundamentals Certifications (출처: Microsoft Learn) 여기서 애저 (Azure) 관련 초급시험은 세 가지가 있다.[AZ-900] 초급/애저: Azure Fundamentals - 클라우드 개념 + 애저 서비스 ✓[AI-900] 초급/애저/AI 엔지니어: Azure AI Fundamentals - ML/AI 개념 + 애저 서비스 ✓[DP-900] 초급/애저/데이터 엔지니어: Azure Data Fundamentals - 데이터 개념 + 애저 서비스 AI-900 시험AI-900 시험은 정말 기본적인 AI (머신러닝/딥러닝) 개념과 마이크로소프트에서 제공하는 AI 서비스만 알면 쉽게 딸 수 있는 자격증이다. 완전 입문자가 아니라면 살짝 비추하고 싶은 시험이다.어느정도 AI를 아는 사람이라면 이 위에 역할 기반 인증인 AI-102를 추천하고 싶다.  마이크로소프트 AI-900 웹사이트  시험 내용 공부 방법 & 자료총 10시간 정도 공부를 하고 시험을 봤다. 학습 경로 (3시간) → 온라인 워크숍 (3시간) → 덤프 문제 (2시간) → 덤프 다시 훑어보고 마인드맵 (1시간 반) → 시험마이크로소프트 학습경로마이크로소프트에서 제공하는 무료 학습 경로. AZ-900 공부할때도 학습경로+덤프 콤보로 충분했기에 이번에도 학습경로 1 회독으로 공부를 시작했다.마이크로소프트에서 제공하는 학습 경로는 아래와 같이 거의 글을 읽는게 다이기 때문에 조금 지루하다.. 마이크로소프트 학습 경로 중 일부 학습 경로는 정말 가볍게 읽어 보고 애저 portal을 통해 애저 서비스를 사용해보는 부분은 건너뛰었다.대학원 과목에서 애저를 (아주 살짝) 건들어본 경험도 있고 읽는것만으로 충분하다고 생각했다. 애저 Machine Learning에서 분류 모델 정말 그림이 안 그려지는 경우 유튜브에서 사용법을 찾아보기도 했다.이렇게 따라서 하는 부분이 꽤 많아서 학습경로 예상시간인 10시간보다 훨씬 짧은 3시간 안에 완독 했다..!  온라인 워크숍 참여링크드인에서 광고하던 AI-900 온라인 워크숍을 참여했다. 한국시간으로 아침 10시부터 6시까지였는데 인터넷이 계속 끊겨 첫 3시간만 들었다 (끊기고 나가면 초대해줄때까지 기다려야함. 두번째 튕겼을때는 너무 방해가 되는거 같아 그냥 혼자 공부했다).그래도 이 워크샵을 통해 AI-900 시험 바우처, 정리된 노트와 덤프 문제를 pdf 파일로 받았다. (공유는 안된다고 한다)  덤프 웹사이트난 워크숍에서 받은 문제를 써서 풀어봤지만 아래 웹사이트에서 다 나오는 문제였다. (근데 심지어 답을 안 줌..?)(문제 119개) https://www.examtopics.com/exams/microsoft/ai-900/ - 페이지 넘어갈 때마다 캡챠 풀어야 해서 매우 불편.. 대략 100 문제를 2시간에 걸쳐 풀어보았다. 다른 시험 (AZ-900) 덤프 풀 때는 많이 틀렸는데 이 시험은 첫판부터 거의 100% 맞았다.   시험 전 날시험 전날에는 덤프 문제를 토픽들로 나눠서 간단히 마인드맵을 그려봤다. (1시간 반 정도)마인드맵을 그려보면 큰 그림이 그려져 좀 더 정리가 잘된다. AI-900 마인드맵 시험 후기시험 예약마이크로소프트 시험 페이지에서 Pearson VUE를 통해 온라인 시험을 예약했다. 이때 원하는 날짜대와 시간을 정할 수 있고 시험 언어와 감독관 언어 (영어 또는 일본어)를 택할 수 있다. Pearson VUE 시험 예약  시험 당일저번에 AZ-900 시험을 봤을 때 이미 시험 프로그램 OnVUE를 받아놓고 시스템 체크를 했었다.시험은 시작 시간 30분 전부터 체크인을 할 수 있는데 이때 얼굴 사진 + 신분증 사진 + 방 사진을 찍은 후 감독관이 확인할 때까지 기다려야 한다 (길어야 1분?).감독관이 전화를 하거나 채팅을 걸 수도 있다고 되어있는데 난 기다렸다가 자동으로 시험 페이지로 넘어갔다. 이때 시험 시작 시간까지 안 기다려도 된다. 난 오후 1시 시험이었는데 12시 반에 체크인하고 시스템 체크, 설문조사를 풀고 바로 시험을 시작해서 오후 12시 49분에 모든 게 끝이 났다.  시험 문제시험 문제 개수는 랜덤인데 난 37문제가 나왔다. 주어진 시간은 45분이고 1000점 만점에서 700점이 넘어야 통과!생각보다 간단한 문제에 8분 안에 시험을 끝냈다. 점수는 970점!답을 보여주지 않지만 분야마다 막대그래프로 능력치?를 보여주는데 컴퓨터 비전에서 한 두 문제를 틀린 거 같다. 워크숍 (덤프) 문제가 90% 나왔다. 이렇게 나의 두 번째 마이크로소프트 배지를 획득했다..!!계속 모으게 싶어지는 나의 콜렉터 기질... 나의 마이크로소프트 디지털 배지 이번 시험을 마지막으로 이제 중급 시험으로 넘어갈 생각이다.  (생각 중인 자격증은 DP-100, DA-100, AI-102)일단 11월의 목표는 AI-102과 AWS SAA이다.나 파이팅! 728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//benn.tistory.com/reaction';window.ReactionReqBody = {    entryId: 35}공유하기게시글 관리Bee's 데이터 과학저작자표시 'Data Science | AI > 머신러닝 및 딥러닝' 카테고리의 다른 글[머신러닝/딥러닝] Foundation Model이란?  (0)2024.05.28AI/머신러닝 논문 사이트 추천  (1)2023.02.23[EPIC GAMES] 머신러닝 게임 ""While True: Learn()"" 리뷰  (0)2021.12.08[데이터 분석] 혼동행렬 Confusion Matrix (R과 Python 코드)  (0)2021.06.09[머신러닝] 머신러닝이란? (Feat. 지도학습 & 비지도학습)  (1)2021.03.16TagAI, AI-900, 덤프, 마이크로소프트 자격증, 인공지능'Data Science | AI/머신러닝 및 딥러닝'의 다른글이전글[데이터 분석] 혼동행렬 Confusion Matrix (R과 Python 코드)현재글[인공지능 자격증] 마이크로소프트 AI Fundamentals 자격증 (AI-900) 취득 후기다음글[EPIC GAMES] 머신러닝 게임 ""While True: Learn()"" 리뷰관련글AI/머신러닝 논문 사이트 추천2023.02.23[EPIC GAMES] 머신러닝 게임 ""While True: Learn()"" 리뷰2021.12.08[데이터 분석] 혼동행렬 Confusion Matrix (R과 Python 코드)2021.06.09[머신러닝] 머신러닝이란? (Feat. 지도학습 & 비지도학습)2021.03.16댓글 15    setInitialEntryComments(35, 1723607788)댓글비밀글등록loadedComments[35]=true;findFragmentAndHighlight(35);반응형(adsbygoogle = window.adsbygoogle || []).push({});👋  저는 시드니에서 거주하는 데이터 과학자입니다. 현재 컴퓨터 비전 관련 일을 하고 있습니다. 분류 전체보기 (54)  Data Science | AI (44)  머신러닝 및 딥러닝 (8)  논문 리뷰 (0)  통계, 수학 (5)  Python (17)  R (5)  SQL (4)  클라우드 (2)  데이터 시각화 (3)  Web development (7)  웹 분석 (1)  알고리즘 (1)  Career Journal (3)  TIL (0) Tag파이썬,sql,통계,데이터 시각화,CSS,통계학,설치,라이브러리,머신러닝,pandas,딥러닝,판다스,다운로드,머신러닝 논문,데이터 분석,PYTHON,R,데이터분석,데이터과학,데이터 과학,최근글과 인기글최근글인기글[머신러닝] 생성적 적대 신경망 Generative Adversarial Network (GAN) 정리2024.06.27 15:55머신러닝/딥러닝 논문 읽는 방법 (앤드류 응 교수님법)2024.06.21 10:58[딥러닝 / 수학] 코사인 유사도 cosine similarity 이해하기2024.06.21 09:10[Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인2021.06.17 12:16비주얼 스튜디오 테마 추천 및 변경하기2023.02.16 11:36비주얼 스튜디오 코드 폰트 바꾸기, 크기 바꾸기 + 코딩용 폰트 추천!2023.02.17 08:56최근댓글안녕하세요!저도 OMSA 시작할 때 파이썬 완전 초보였어요! 지원 당시, 본문에 언⋯ Letter_B안녕하세요!OMSA을 알고나서 관심을 가지고 서치하다가 들어왔습니다. 자세한 후기 감사드⋯ Sophia잘~ 보고갑니다 김도훈공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/062024/052024/012023/082023/062023/042023/022022/112022/102022/08Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total435,663Today : 149Yesterday : 502블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트티스토리툴바Bee's 데이터 과학구독하기                    (function () {                         var blogTitle = 'Bee\'s 데이터 과학';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4565392-35"",""customProps"":{""userId"":""0"",""blogId"":""4565392"",""entryId"":""35"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""35"",""entryTitle"":""[인공지능 자격증] 마이크로소프트 AI Fundamentals 자격증 (AI-900) 취득 후기"",""entryType"":""POST"",""categoryName"":""Data Science | AI/머신러닝 및 딥러닝"",""categoryId"":""463938"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4648833"",""authorNickname"":""Letter_B"",""blogNmae"":""Bee's 데이터 과학"",""image"":""kage@bitKcR/btrh5Zweg6t/Z1Kvv3g5TIEXrhpFPY1ejK"",""plink"":""/35"",""tags"":[""AI"",""AI-900"",""덤프"",""마이크로소프트 자격증"",""인공지능""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
73,https://yaun.tistory.com/265,Convolutional Neural Networks (합성곱 신경망),"                                                  야 언데드 하지마                              코딩일지/Machine Learning실전 머신러닝 적용 4주차 정리야언2022. 10. 12. 19:52이번 주 배울것다양한 신경망 구조전이학습 출처: https://www.cnblogs.com/wangxiaocvpr/p/6247424.html신경망을 구성하는 방법은 정말 여러가지가 있는데요,이 중 가장 많이 쓰이는 합성곱 신경망(CNN),순환 신경망(RNN),생성적 적대 신경망(GAN)에 대해 알아보겠습니다!특히 이미지처리에서 많이 쓰이는 CNN에 대해서는 조금 더 자세히 알아보고 실습도 해볼 거예요 🙂   Convolutional Neural Networks (합성곱 신경망) 합성곱과 합성곱 신경망합성곱(Convolution)은 예전부터 컴퓨터 비전(Computer Vision, CV) 분야에서 많이 쓰이는 이미지 처리 방식으로 계산하는 방식은 아래와 같습니다. 입력데이터와 필터의 각각의 요소를 서로 곱한 후 다 더하면 출력값이 됩니다.출처: https://ce-notepad.tistory.com/14딥러닝 연구원들은 이 합성곱을 어떻게 딥러닝에 활용할 수 있을까 고민하다가, 1998년에 Yann LeCun 교수님이 엄청난 논문을 발표하게 됩니다.르쿤 교수님은 합성곱을 이용한 이 신경망 디자인을 합성곱 신경망(CNN)이라고 명칭하였고 이미지 처리에서 엄청난 성능을 보이는 것을 증명했는데요. CNN의 발견 이후 딥러닝은 전성기를 이루었다고 볼 수 있습니다. 이후 CNN은 얼굴 인식, 사물 인식 등에 널리 사용되며 현재도 이미지 처리에서 가장 보편적으로 사용되는 네트워크 구조입니다.  Filter, Strides and Padding합성곱 신경망에서 가장 중요한 합성곱 계층(Convolution layer)에 대해 알아봅시다!아래와 같이 5x5 크기의 입력이 주어졌을 때, 3x3짜리 필터를 사용하여 합성곱을 하면 3x3 크기의 특성맵(Feature map)을 뽑아낼 수 있습니다. 필터(Filter 또는 Kernel)를 한 칸씩 오른쪽으로 움직이며 합성곱 연산을 하는데요, 이 때 이동하는 간격을 스트라이드(Stride)라고 합니다.출처: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1그런데 이렇게 연산을 하게 되면 합성곱 연산의 특성상 출력값인 특성 맵의 크기가 줄어듭니다. 이런 현상을 방지하기 위해서 우리는 패딩(Padding 또는 Margin)을 주어, 스트라이드가 1일 때 입력값과 특성 맵의 크기를 같게 만들 수 있습니다.출처: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1위에서는 1개의 필터를 사용하여 연산을 하였지만 여러개의 필터를 이용하여 합성곱 신경망의 성능을 높일 수 있습니다. 그리고 이미지는 3차원(가로, 세로, 채널)이므로 아래와 같은 모양이 됩니다. 이 그림에서 각각의 입력과 출력은 다음과 같습니다:입력 이미지 크기: (10, 10, 3)필터의 크기: (4, 4, 3)필터의 개수 :2출력 특성 맵의 크기: (10, 10, 2)출처: https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n  CNN의 구성 CNN의 구성합성곱 신경망은 합성곱 계층(Convolution layer)과 완전연결 계층(Dense layer)을 함께 사용합니다.출처: https://teknoloji.org/cnn-convolutional-neural-networks-nedir/합성곱 계층 + 활성화 함수 + 풀링을 반복하며 점점 작아지지만 핵심적인 특성들을 뽑아 내는데요. 여기서 풀링 계층(Pooling layer)은 특성 맵의 중요부분을 추출하여 저장하는 역할을 합니다. 아래의 이미지는 Max pooling의 예시입니다. 2x2 크기의 풀 사이즈(Pool size)로 스트라이드 2의 Max pooling 계층을 통과할 경우 2x2 크기의 특성 맵에서 가장 큰 값들을 추출합니다.출처: https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks아래는 Average pooling의 예시입니다. Max pooling에서는 2x2 크기의 특성 맵에서 최대 값을 추출했다면 Average pooling은 2x2 크기의 특성 맵에서 평균 값을 추출하는 방식입니다.출처: https://www.kaggle.com/questions-and-answers/59502Max pooling과 Average pooling의 결과를 비교해보면 이렇게 되겠죠?출처: https://towardsdatascience.com/beginners-guide-to-understanding-convolutional-neural-networks-ae9ed58bb17d다시 이 그림으로 돌아와서 두 번째 풀링 계층을 지나면 완전연결 계층과 연결이 되어야 하는데 풀링을 통과한 특성 맵은 2차원이고 완전연결 계층은 1차원이므로 연산이 불가능합니다.출처: https://teknoloji.org/cnn-convolutional-neural-networks-nedir/따라서 우리는 평탄화 계층(Flatten layer)를 사용해서 2차원을 1차원으로 펼치는 작업을 하게 됩니다. 아래는 간단하게 평탄화 계층의 동작을 설명한 그림입니다.출처: https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening평탄화 계층을 통과하게 되면 우리는 완전연결 계층에서 행렬 곱셈을 할 수 있게되고 마찬가지로 완전연결 계층(=Dense=Fully connected) + 활성화 함수의 반복을 통해 점점 노드의 개수를 축소시키다가 마지막에 Softmax 활성화 함수를 통과하고 출력층으로 결과를 출력하게 됩니다. CNN의 활용 예컴퓨터 비전에서 필요한 기본 기능물체 인식(Object Detection)출처: https://arxiv.org/abs/1612.04402v1Object detection은 사진 이미지에서 정확히 물체를 인식하는 것을 뜻하며 컴퓨터비전에서 가장 중요한 기술입니다. 각각의 객체를 정확하게 인식하는 것부터 Computer Vision이 시작하기 때문입니다.핸드폰 카메라 셀카 모드에서 얼굴 영역을 자동으로 찾아주는 것도 object detection이라고 할 수 있겠죠? YOLO (You Only Look Once)   ※ 이번 프로젝트에 쓰일듯현재 V5까지 나왔으며 속도가 빠르다는 강점을 가졌고 다른 real-time detection에 비해 정확도가 높아 유명한 Computer Vision 알고리즘입니다.   이미지 분할(Segmentation) Segmentation은 각각의 오브젝트에 속한 픽셀들을 분리하는 것을 나타냅니다.나누는 기준이 디테일 할수록 정교화된 성능을 가져야 하고 처리속도 또한 문제가 될 수 있습니다.Segmentation의 Class를 동물로 분리할 수 있고, 강아지와 고양이로 분리할 수 있습니다. 더욱 더 세분화해서 분류를 하게 된다면 강아지 중에서도 웰시코기, 비숑, 진돗개로도 분리를 할 수 있습니다. 인물과 배경을 Segmentation하여 배경은 흐릿하게 처리해서 인물을 Focus하는 기술입니다.의료영상에서도, 양성/음성부분을 파악하고 악성인 부분을 Segmentation하여 인식할 수 있도록 도와줍니다.  활용 예자율주행 물체인식자세 인식(Pose Detection)화질개선(Super Resolution)Style Transfer사진 색 복원(Colorization)   다양한 CNN 종류 AlexNet (2012)출처: https://paperswithcode.com/method/alexnet컴퓨터 비전 분야의 ‘올림픽’이라 할 수 있는 ILSVRC(ImageNet Large-Scale Visual Recognition Challenge)의 2012년 대회에서 제프리 힌튼 교수팀의 AlexNet이 Top 5 test error 기준 15.4%를 기록해 2위(26.2%)를 큰 폭으로 따돌리고 1위를 차지했습니다.여기서 top 5 test error란 모델이 예측한 최상위 5개 클래스 가운데 정답이 없는 경우의 오류율을 나타냅니다. 당시 ILSVRC 데이터셋(Image은 1000개 범주 예측 문제였습니다. 어쨌든 AlexNet 덕분에 딥러닝, 특히 CNN이 세간의 주목을 받게 됐습니다.AlexNet은 의미있는 성능을 낸 첫 번째 합성곱 신경망이고, Dropout과 Image augmentation 기법을 효과적으로 적용하여 딥러닝에 많은 기여를 했기 때문입니다.  VGGNet (2014)출처: https://medium.com/deep-learning-g/cnn-architectures-vggnet-e09d7fe79c45VGGNet은 큰 특징은 없는데 엄청 Deep한 모델(파라미터의 개수가 많고 모델의 깊이가 깊습니다)로 잘 알려져 있습니다. 또한 요즘에도 딥러닝 엔지니어들이 처음 모델을 설계할 때 전이 학습 등을 통해서 가장 먼저 테스트하는 모델이기도 하죠. 간단한 방법론으로 좋은 성적을 내서 유명해졌습니다.  GoogLeNet(=Inception V3) (2015) 합성곱 신경망의 아버지 르쿤 교수님이 구글에서 개발한 합성곱 신경망 구조입니다. AlexNet 이후 층을 더 깊게 쌓아 성능을 높이려는 시도들이 계속되었는데, 바로 VGGNet(2014), GoogLeNet(2015) 이 대표적인 사례입니다. GoogLeNet은 VGGNet보다 구조가 복잡해 널리 쓰이진 않았지만 구조 면에서 주목을 받았습니다.GoogLeNet 연구진들은 한 가지의 필터를 적용한 합성곱 계층을 단순히 깊게 쌓는 방법도 있지만, 하나의 계층에서도 다양한 종류의 필터, 풀링을 도입함으로써 개별 계층를 두텁게 확장시킬 수 있다는 창조적인 아이디어로 후배 연구자들에게 많은 영감을 주었습니다. 이들이 제안한 구조가 바로 Inception module (인셉션 모듈)입니다.출처: https://tariq-hasan.github.io/concepts/computer-vision-cnn-architectures/인셉션 모듈에서 주의깊게 보아야할 점은 차원(채널) 축소를 위한 1x1 합성곱 계층 아이디어입니다. 또한 여러 계층을 사용하여 분할하고 합치는 아이디어는, 갈림길이 생김으로써 조금 더 다양한 특성을 모델이 찾을 수 있게하고, 인공지능이 사람이 보는 것과 비슷한 구조로 볼 수 있게 합니다. 이러한 구조로 인해 VGGNet 보다 신경망이 깊어졌음에도, 사용된 파라미터는 절반 이하로 줄었습니다.  **ResNet (2015)AlexNet이 처음 제안된 이후로 합성곱 신경망의 계층은 점점 더 깊어졌습니다. AlexNet이 불과 5개 계층에 불과한 반면 VGGNet은 19개 계층, GoogleNet은 22개 계층에 달합니다. 하지만 층이 깊어질 수록 역전파의 기울기가 점점 사라져서 학습이 잘 되지 않는 문제(Gradient vanishing)가 발생했습니다. ResNet 저자들이 제시한 아래 학습그래프를 보면 이같은 문제가 뚜렷이 나타납니다.출처: https://neurohive.io/en/popular-networks/resnet/따라서 ResNet 연구진은 Residual block을 제안합니다. 그래디언트가 잘 흐를 수 있도록 일종의 지름길(Shortcut=Skip connection)을 만들어주는 방법입니다.출처: https://neurohive.io/en/popular-networks/resnet/위의 그림에서 알 수 있듯 y = F(x) + x 를 다시 쓰면 F(x) = y - x 로 표현할 수 있고, Residual block은 입력과 출력 간의 차이를 학습하도록 설계되어 있습니다.ResNet의 Residual block은 합성곱 신경망 역사에서 큰 영향을 끼쳤고 아직도 가장 많이 사용되는 구조 중에 하나입니다. 많은 사람들이 Residual block을 사용하면 대부분의 경우 모델의 성능이 좋아진다라고 얘기하고 있습니다.    Transfer Learning (전이 학습) 전이 학습전이 학습이라는 개념은 인간이 학습하는 방법을 모사하여 만들어졌습니다. 만약 여러분들이 영어를 배워서 영어를 완벽하게 말할 수 있게 되었다고 가정합시다. 그러면 여러분이 프랑스어를 배울 때는 영어를 배울 때 사용한 지식과 방법을 사용하여 더욱 빠르게 습득할 수 있겠죠!이렇게 과거에 문제를 해결하면서 축적된 경험을 토대로 그것과 유사한 문제를 해결하도록 신경망을 학습시키는 방법을 전이 학습이라고 합니다. 전이 학습은 비교적 학습 속도가 빠르고 (빠른 수렴), 더 정확하고, 상대적으로 적은 데이터셋으로 좋은 결과를 낼 수 있기 때문에 실무에서도 자주 사용하는 방법입니다.출처: https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a전이학습은 위에서 소개한 유명한 네트워크들과 같이 미리 학습시킨 모델(pretrained models)을 가져와 새로운 데이터셋에 대해 다시 학습시키는 방법입니다. 흥미로운 점은, 꽤나 다른 형태의 데이터셋에 대해서도 효과를 보인다는 것인데요! 예를 들어, 1000개의 동물/사물을 분류하는 ImageNet이라는 대회에서 학습한 모델들을 가져와 얼굴 인식 데이터셋에 학습시켜도 좋은 결과를 얻을 수 있습니다. 이런 특징 덕분에 전이 학습은 딥러닝에서 더욱 중요해지게 되었죠! Recurrent Neural Networks (순환 신경망) Recurrent Neural Networks (RNN)자연어 처리 등 다양한 분야에 활용되는 RNN에 대해 배워봅시다!RNN은 은닉층이 순차적으로 연결되어 순환구조를 이루는 인공신경망의 한 종류입니다. 음성, 문자 등 순차적으로 등장하는 데이터 처리에 적합한 모델로 알려져 있는데요. 합성곱 신경망과 더불어 최근 들어 각광 받고 있는 신경망 구조입니다.길이에 관계없이 입력과 출력을 받아들일 수 있는 구조이기 때문에 필요에 따라 다양하고 유연하게 구조를 만들 수 있다는 점이 RNN의 가장 큰 장점입니다.출처: https://ratsgo.github.io/natural language processing/2017/03/09/rnnlstm/우리가 소설을 지어내는 인공지능을 만든다고 할 때, hell 이라는 입력을 받으면 ello 라는 출력을 만들어내게 해서 결과적으로 hello 라는 순차적인 문자열을 만들어 낼 수 있게 하는 아주 좋은 구조입니다.출처: https://ratsgo.github.io/natural language processing/2017/03/09/rnnlstm/이외에도 주식이나 암호화폐의 시세를 예측한다던지, 사람과 대화하는 챗봇을 만드는 등의 다양한 모델을 만들 수 있습니다.  Generative Adversarial Network (생성적 적대 신경망) Generative Adversarial Network (GAN)서로 적대(Adversarial)하는 관계의 2가지 모델(생성 모델과 판별 모델)을 동시에 사용하는 기술입니다. 최근 딥러닝 학계에서 굉장히 핫한 분야입니다GAN은 위조지폐범과 이를 보고 적발하는 경찰의 관계로 설명할 수 있습니다.생성모델 (위조지폐범): 경찰도 구분 못하는 진짜같은 위조지폐를 만들자!판별모델 (경찰): 진짜 지폐와 위조 지폐를 잘 구분해내자!이와같이 계속 진행되면 위조지폐범은 더욱 더 정교하게, 경찰은 더욱 더 판별을 잘하면서 서로 발전의 관계가 되어 원본과 구별이 어려운 가짜 이미지가 만들어지게 됩니다. GAN이 어떻게 작용하는지 살펴보기GAN에 대해 Input data와 Output data를 파악하고 위조지폐범과 경찰에 입장에서 한번 생각해보겠습니다.AnimalGAN이라는 머신이 어떻게 잡음으로부터 동물 이미지를 만드는지 봄으로써 GAN의 작동방식을 이해해봅시다! 이 머신에게 주어진 문제는 다음과 같습니다.Input Data : 랜덤으로 생성된 잡음Output Data : 0~1 사이의 값( 0은 가짜, 1은 진짜)이때 대립하는 두 모델은 다음과 같습니다.Generator(위조지폐범): 이미지가 진짜(1)로 판별될수록 좋겠죠? 보다 정교하게 모델을 만들려고 노력하며 Target은 1로 나오도록 해야합니다. 가짜를 진짜인 1처럼 만들기 위하여 타깃인 1과 예측의 차이인 손실을 줄이기 위하여 Backpropagation을 이용한 weight를 조정할 것입니다.Discriminator(경찰): 진짜 이미지는 1로, 가짜 이미지는 0으로 판별할 수 있어야합니다. 생성된 모델에서 Fake와 Real 이미지 둘다를 학습하여 예측과 타깃의 차이인 손실을 줄여야합니다.이렇게 두 모델이 대립하면서(Adversarial) 발전해 에폭(Epoch)이 지날 때마다 랜덤 이미지가 점점 동물을 정교하게 생성해 내는 것(Generative)을 볼 수 있습니다. GAN을 사용한 예시들CycleGAN StarGAN CartoonGAN출처: https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/2205.pdf DeepFakehttp://www.aitimes.com/news/articleView.html?idxno=132830삼성 AI랩이 선보인 이미지를 동영상으로 만드는 기술.마릴린 먼로, 모나리자, 아인슈타인 등 과거 인물의 사진을 AI로 학습시켜 가상의 영상을 생성했다.이 기술 역시 딥페이크를 기반으로 한 이미지·영상 합성이다. /유튜브 캡처 BeautyGAN Toonify Yourself출처: https://youtu.be/84EqhSY-n6c  CNN, 전이학습 실습 CNN 학습해보기데이터셋 다운로드필요한 패키지 임포트하기데이터셋 로드하기라벨 분포 확인하기전처리하기입력과 출력 나누기데이터 미리보기one-hot 인코딩하기일반화하기네트워크 구성하기모델 학습시키기 이미지 증강기법 이용해보기학습 데이터 증강하기train_image_datagen = ImageDataGenerator(  rescale=1./255, # 일반화  rotation_range=10,  # 랜덤하게 이미지를 회전 (단위: 도, 0-180)  zoom_range=0.1, # 랜덤하게 이미지 확대 (%)  width_shift_range=0.1,  # 랜덤하게 이미지를 수평으로 이동 (%)  height_shift_range=0.1,  # 랜덤하게 이미지를 수직으로 이동 (%))train_datagen = train_image_datagen.flow(    x=x_train,    y=y_train,    batch_size=256,    shuffle=True)검증 데이터 일반화하기test_image_datagen = ImageDataGenerator(  rescale=1./255)test_datagen = test_image_datagen.flow(    x=x_test,    y=y_test,    batch_size=256,    shuffle=False)이미지 확인하기네트워크 구성하기모델 학습시키기 전이학습 실습해보기데이터셋 다운로드필요한 패키지 임포트하기전처리하기 - 폴더에서 직접 데이터 가져와서 증강기법까지 써보기train_datagen = ImageDataGenerator(  rescale=1./255, # 일반화  rotation_range=10, # 랜덤하게 이미지를 회전 (단위: 도, 0-180)  zoom_range=0.1, # 랜덤하게 이미지 확대 (%)  width_shift_range=0.1,  # 랜덤하게 이미지를 수평으로 이동 (%)  height_shift_range=0.1,  # 랜덤하게 이미지를 수직으로 이동 (%)  horizontal_flip=True # 랜덤하게 이미지를 수평으로 뒤집기)test_datagen = ImageDataGenerator(  rescale=1./255 # 일반화)train_gen = train_datagen.flow_from_directory(  'fruits-360/Training',  target_size=(224, 224), # (height, width)  batch_size=32,  seed=2021,  class_mode='categorical',  shuffle=True)test_gen = test_datagen.flow_from_directory(  'fruits-360/Test',  target_size=(224, 224), # (height, width)  batch_size=32,  seed=2021,  class_mode='categorical',  shuffle=False)데이터 확인하기전이학습 - 모델 가져와서 수정하기from tensorflow.keras.applications.inception_v3 import InceptionV3input = Input(shape=(224, 224, 3))base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=input, pooling='max')x = base_model.outputx = Dropout(rate=0.25)(x)x = Dense(256, activation='relu')(x)output = Dense(131, activation='softmax')(x)model = Model(inputs=base_model.input, outputs=output)model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['acc'])모델 학습시키기  ** ModelCheckpoint로 정확도 높은 모델 저장from tensorflow.keras.callbacks import ModelCheckpointhistory = model.fit(    train_gen,    validation_data=test_gen, # 검증 데이터를 넣어주면 한 epoch이 끝날때마다 자동으로 검증    epochs=20, # epochs 복수형으로 쓰기!    callbacks=[      ModelCheckpoint('model.h5', monitor='val_acc', verbose=1, save_best_only=True)    ])학습된 모델 로딩하기from tensorflow.keras.models import load_modelmodel = load_model('model.h5')결과 확인하기test_imgs, test_labels = test_gen.__getitem__(100)y_pred = model.predict(test_imgs)classes = dict((v, k) for k, v in test_gen.class_indices.items())fig, axes = plt.subplots(4, 8, figsize=(20, 12))for img, test_label, pred_label, ax in zip(test_imgs, test_labels, y_pred, axes.flatten()):  test_label = classes[np.argmax(test_label)]  pred_label = classes[np.argmax(pred_label)]  ax.set_title('GT:%s\nPR:%s' % (test_label, pred_label))  ax.imshow(img)    4주차까지 완강하며 머신러닝의 기본 개념과 사용방법을 단계별로 공부해 보았다.  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//yaun.tistory.com/reaction';window.ReactionReqBody = {    entryId: 265}공유하기게시글 관리야 언데드 하지마 '코딩일지/Machine Learning'의 다른글이전글실전 머신러닝 적용 3주차 정리현재글실전 머신러닝 적용 4주차 정리관련글실전 머신러닝 적용 3주차 정리2022.10.12실전 머신러닝 적용 2주차 정리2022.10.12실전 머신러닝 적용 1주차 정리2022.10.12loadedComments[265]=true;findFragmentAndHighlight(265);야 언데드 하지마이젠 안구려그래도 하지마야 언데드 하지마구독하기글쓰기블로그 관리 분류 전체보기 (267)  코딩일지 (218)  TIL: Today I Learned (84)  WIL: Weekly I Learned (17)  python 백준 알고리즘 (81)  내일배움캠프 과제 (5)  파이썬 (7)  자료구조, 알고리즘 (4)  내배캠 타임어택 테스트 (3)  Machine Learning (4)  Node.js (5)  sql (5)  취미 (40)  비즈아트 (13)  music (20)  게임 (3)  피아노 | 연습할것 (4) Tag최근글과 인기글최근글인기글あいみょん - 君はロックを聴かない2024.05.02 02:14프로그래머스 코딩테스트 연습 - 다리를 지나는 트럭2023.04.05 01:25프로그래머스 코딩테스트 연습 - 완주하지 못한 선수2023.04.05 00:06ChatGPT API를 활용한 웹 서비스 만들기 - 3일차(프론트, 백엔드 배포)2023.03.28 22:06ChatGPT API를 활용한 웹 서비스 만들기 - 2일차2023.03.27 22:06Node.js에서 환경 변수 다루기2023.03.27 20:50최근댓글포스팅 잘 읽었습니다 ㅎㅎget_time파이팅!!야언머찌다 파이팅! 미스티_공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/052023/042023/032023/012022/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total11,055Today : 8Yesterday : 4블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트　m의 하루티스토리툴바                    (function () {                         var blogTitle = '야 언데드 하지마';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""358481-265"",""customProps"":{""userId"":""0"",""blogId"":""358481"",""entryId"":""265"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""265"",""entryTitle"":""실전 머신러닝 적용 4주차 정리"",""entryType"":""POST"",""categoryName"":""코딩일지/Machine Learning"",""categoryId"":""1090641"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""339754"",""authorNickname"":""야언"",""blogNmae"":""야 언데드 하지마"",""image"":""kage@bm8JrN/btrOqzm4Z5l/Hqqe8vKyxeJLECXvPx4KE0"",""plink"":""/265"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
74,https://jpub.tistory.com/992,태그,"도서 소개머신러닝 도감: 그림으로 공부하는 머신러닝 알고리즘 17 제이펍2019. 12. 18. 09:42 이 책은 현재 절판입니다. 그간 읽어주신 독자들께 감사드립니다.전자책은 계속 판매하고 있습니다. 알고리즘 중심의 머신러닝을 배우고 싶은 분에게 추천합니다!복잡한 머신러닝 알고리즘을 풍부한 컬러 그림으로 배웁니다! 도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크] 출판사 제이펍저작권사 쇼에이샤(翔泳社)원서명 機械学習図鑑(원서 ISBN: 9784798155654)저자명 아키바 신야, 스기야마 아세이, 데라다 마나부역자명 이중민출판일 2019년 12월 19일페이지 260쪽시리즈 I♥A.I. 21(아이러브 인공지능 21)판 형 170*225*13.1제 본 무선(soft cover)정 가 26,000원ISBN 979-11-88621-84-2(93000)키워드 머신러닝 / 인공지능 / 기계학습 / 머신러닝 알고리즘 / 지도학습 / 비지도학습 / 데이터 처리 / 파이썬 / 사이킷런분야 인공지능 / 머신러닝 관련 사이트■ 저작권사 도서소개 페이지■ 아마존 도서소개 페이지 관련 포스트■ 2019/12/05 - [출간전 책소식] - 머신러닝 핵심 알고리즘을 파이썬 코드와 그래프로 배운다! 관련 시리즈■ I♥A.I 시리즈 관련 도서■ 패턴 인식과 머신 러닝 ■ 그림과 수식으로 배우는 통통 머신러닝 ■ 머신러닝 인 액션 ■ 알고리즘 중심의 머신 러닝가이드 관련 파일 다운로드■ 예제 코드■ 구글 Colaboratory 예제 실행 방법 안내   강의보조 자료 다운로드교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표 샘플 PDF(차례, 옮긴이 머리말, 머리말, 이 책에 대하여, 베타리더 후기, 1장 '머신러닝 기초' 일부, 2장 '지도학습' 일부, 3장 '비지도 학습' 일부)머신러닝도감_sample.pdf다운로드  정오표 페이지■ https://jpub.tistory.com/1005 도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크] 도서 소개알고리즘 중심의 머신러닝을 배우고 싶은 분에게 추천합니다!복잡한 머신러닝 알고리즘을 풍부한 컬러 그림으로 배웁니다! 이 책은 복잡한 머신러닝 알고리즘을 그림과 함께 하나하나 살펴보는 입문서입니다. 전문가가 아닌 사람도 머신러닝을 이해할 수 있도록 지도 학습과 비지도 학습에 해당하는 17가지 알고리즘을 설명합니다. 또한, 사이킷런 기반의 파이썬 예제 코드를 구글 콜랩 등에서 바로 실행하며 읽을 수 있습니다. 이 책의 특징복잡한 머신러닝 알고리즘 구조를 한 권으로 배운다컬러 그림을 풍부하게 수록하였다알고리즘마다 사이킷런을 사용한 코드를 제공하므로 보면서 직접 실행할 수 있다구조뿐만 아니라 실제 사용법과 주의점을 알 수 있다 이 책의 대상 독자머신러닝에 흥미를 느껴 공부를 시작한 분좀 더 다양한 머신러닝 알고리즘을 알고 싶은 분수식이 부담스러워서 머신러닝 관련 책을 읽기 어려워하는 분문제에 따라 적절한 머신러닝 알고리즘을 선택하고 싶은 분 책에서 소개하는 알고리즘 1701 선형 회귀02 정규화03 로지스틱 회귀04 서포트 벡터 머신05 서포트 벡터 머신(커널 기법)06 나이브 베이즈 분류07 랜덤 포레스트08 신경망09 kNN(k-최근접 이웃 알고리즘)10 PCA(주성분 분석)11 LSA(잠재 의미 분석)12 NMF(음수 미포함 행렬 분해)13 LDA(잠재 디리클레 할당)14 k-means(k-평균 알고리즘)15 가우시안 혼합 모델16 LLE(국소 선형 임베딩)17 t-SNE(t-분포 확률적 임베딩) 지은이 소개아키바 신야(秋庭 伸也)2012년에 와세다대학교 기간이공학부를 졸업하고, 2015년에 와세다대학교 이공학술원 기간이공학연구과 기계과학전공 석사 과정을 수료했습니다. 지금은 리크루트 통신의 기술 리드로 근무하고 있습니다.@ak1niwa 스기야마 아세이(杉山 阿聖)제조업체의 IT 자회사에서 3년간 iOS 앱을, 2년간 채팅 봇을 개발했습니다. 현재는 SENSY의 연구원으로 머신러닝을 이용한 개발 업무를 담당하고 있습니다. 엔지니어 대상의 스터디 그룹에 참가하거나 다른 개발자와 지식 나누기를 좋아합니다.@K_Ryuichirou 데라다 마나부(寺田 学)파이썬 웹과 관련된 컨설팅 및 구축 업무를 하고 있습니다. 2010년부터 일본 파이썬 커뮤니티에서 적극적으로 활동하면서 ‘파이콘 일본’ 콘퍼런스 개최에 도움을 주고 있으며, 2013년 3월부터는 파이콘 일본의 대표이사를 맡고 있습니다. 또한, 다른 오픈 소스 소프트웨어 관련 커뮤니티를 주관하거나 멤버로 활동하기도 합니다. 아울러 파이썬 엔지니어 육성 추진 협회의 고문이사로 활동하면서 파이썬의 매력을 전달하는 교육 활동에도 많은 관심을 두고 있습니다. 최근에는 파이썬과 머신러닝 입문자를 대상으로 강의를 시작했습니다.《파이썬으로 배우는 새로운 데이터 분석의 교과서(쇼에이샤, 2018년 9월)를 함께 썼으며, 《거침없이 이해하는 파이썬》(쇼에이샤, 2017년 8월)을 감수했습니다.@terapyon 옮긴이 소개이중민‘지속 가능한 삶이 무엇인가?’라는 고민으로 디지털 노마드가 되어 다양한 IT 기술을 탐구하고 이를 콘텐츠로 만드는 방법을 공부하고 있습니다. PC 및 하드웨어 전문 리뷰 사이트인 pcBee에서 테크니컬 라이터로 활동하면서 다양한 하드웨어 및 소프트웨어 환경을 분석하고 기사를 작성하면서 전문 지식을 쌓았고, 이후 프리랜서 웹 마스터로 다양한 웹 사이트 개발을 경험했습니다. 지금은 IT 개발과 관련한 인사이트를 넓히기 위해 애쓰고 있습니다.《PC 조립 관리 수리 길라잡이 2002: 세상에 단 하나뿐인 내 PC 만들기》(정보문화사, 2002)를 함께 썼고, 《처음 배우는 블록체인》(한빛미디어, 2018), 《이토록 쉬운 딥러닝을 위한 기초 수학 with 파이썬》(루비페이퍼, 2019)을 옮겼습니다. 차례CHAPTER 1 머신러닝 기초 11.1 머신러닝 소개 3    머신러닝 3    머신러닝의 유형 4    머신러닝의 활용 101.2 머신러닝 준비하기 11    데이터의 중요성 11    지도 학습(분류)의 예 14    구현 방법 17    비지도 학습의 예 19    시각화 23    그래프의 종류와 표현 방법: matplotlib을 이용한 그래프 출력 29    판다스를 이용해 데이터를 이해하고 다루기 38    마치며 45 더보기CHAPTER 2 지도 학습 4701 선형회귀 49    기본 개념 49    알고리즘 50    더 나아가기 5302 정규화 58    기본 개념 58    알고리즘 61    더 나아가기 6403 로지스틱 회귀 67    기본 개념 67    알고리즘 69    더 나아가기 7104 서포트 벡터 머신 74    기본 개념 74    알고리즘 75    더 나아가기 7705 커널 기법을 적용한 서포트 벡터 머신 80    기본 개념 81    알고리즘 81    더 나아가기 8306 나이브 베이즈 분류 86    기본 개념 86    알고리즘 89    더 나아가기 9307 랜덤 포레스트 94    기본 개념 94    알고리즘 95    더 나아가기 9908 신경망 101    기본 개념 101    알고리즘 104    더 나아가기 10809 k-최근접 이웃 알고리즘(kNN) 110    기본 개념 110    알고리즘 112    더 나아가기 113 CHAPTER 3 비지도 학습 11710 주성분 분석 119    기본 개념 119    알고리즘 121    더 나아가기 12411 잠재 의미 분석 125    기본 개념 125    알고리즘 127    더 나아가기 13112 음수 미포함 행렬 분해 132    기본 개념 132    알고리즘 134    더 나아가기 13613 잠재 디리클레 할당 139    기본 개념 139    알고리즘 141    더 나아가기 14314 k-평균 알고리즘 146    기본 개념 146    알고리즘 147    더 나아가기 14915 가우시안 혼합 모델 151    기본 개념 151    알고리즘 152    더 나아가기 15616 국소 선형 임베딩 157    기본 개념 157    알고리즘 158    더 나아가기 16117 t-분포 확률적 임베딩 163    기본 개념 163    알고리즘 164    더 나아가기 168 CHAPTER 4 평가 방법과 여러 가지 데이터 처리 1714.1 평가 방법 173    지도 학습의 평가 173    분류 문제의 평가 방법 174    회귀 문제의 평가 방법 183    평균제곱오차와 결정계수의 차이 188    다른 알고리즘을 이용할 때와 비교 188    하이퍼 파라미터 설정 190    모델의 과적합 191    과적합을 막는 방법 192    학습 데이터와 검정 데이터 나누기 193    교차 검증 196    하이퍼 파라미터 탐색하기 1984.2 문서 데이터의 전처리 202    단어 빈도 수를 이용한 변환 202    TF-IDF를 이용한 변환 203    머신러닝 모델에 적용 2044.3 이미지 데이터 변환하기 207    픽셀 밝기 값 활용하기 207    변환한 벡터 데이터로 머신러닝 모델 만들기 209 CHAPTER 5 파이썬 개발 환경 2115.1 파이썬 3 설치 213    윈도우 10 213    macOS 214    리눅스 215    아나콘다를 윈도우 10에 설치 2165.2 가상 환경 218    표준 개발 환경에서 가상 환경 설정하기 218    아나콘다 2205.3 외부 라이브러리 설치 221    외부 라이브러리 221    외부 라이브러리 설치 221 참고문헌 223 APPENDIX 부록 225    읽으면 도움 되는 수학 개념 몇 가지 226    이 책의 주요 용어 230 찾아보기 237 제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)네이버 책  포스트  유튜브  인스타그램  트위터  페이스북  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 992}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글알파제로를 분석하며 배우는 인공지능  (2)2019.12.30자바 트러블슈팅: scouter를 활용한 시스템 장애 진단 및 해결 노하우  (0)2019.12.27함수형 언어 산책: 도커 기반의 함수형 언어 실습에서 빅 데이터 처리 프레임워크까지  (0)2019.12.06러스트 프로그래밍 공식 가이드  (0)2019.11.27포토샵 사전  (0)2019.11.27태그기계학습, 딥러닝, 머신러닝, 머신러닝알고리즘, 심층학습, 이중민, 인공지능, 제이펍'도서 소개' Related Articles알파제로를 분석하며 배우는 인공지능자바 트러블슈팅: scouter를 활용한 시스템 장애 진단 및 해결 노하우함수형 언어 산책: 도커 기반의 함수형 언어 실습에서 빅 데이터 처리 프레임워크까지러스트 프로그래밍 공식 가이드Secret댓글달기loadedComments[992]=true;findFragmentAndHighlight(992);"
75,https://jpub.tistory.com/662,태그,"도서 소개엑셀로 배우는 인공지능 제이펍2017. 3. 3. 10:39 이 책은 현재 절판입니다. 그간 읽어주신 분들께 감사드립니다.  인공지능을 배우는 학생은 물론, 비전공자나 일반인까지인공지능 입문자를 위한 최적의 가이드!   출판사 제이펍 원출판사 SHOEISHA 원서명 はじめての人工知能 Excelで体験しながら学ぶAI(원서 ISBN: 9784798144658) 저자명 아사이 노보루 역자명 우영운 출판일 2017년 2월 28일 페이지 264쪽 시리즈 I♥A.I. 03 판  형 크라운판 변형(170*225*13) 제  본 무선(soft cover) 정  가 18,000원 ISBN 979-11-85890-74-6 (93000) 키워드 인공지능 / AI / 머신러닝 / 딥러닝 / 신경망 / 퍼지 / 유전자 알고리즘 / 탐색법 / 게임 전략 / 지식 표현 / 전문가 시스템 / 에이전트 / Lisp / Prolog 분야 컴퓨터 공학 / 인공지능    관련 사이트 ■ 아마존재팬 도서 소개 페이지 ■ 원출판사 도서 소개 페이지   관련 포스트 ■ 2017/02/22 - [출간전 책소식] - 인공지능을 엑셀로 배우자!   관련 시리즈 ■ I♥A.I 시리즈   관련 도서 ■ 알고리즘 중심의 머신러닝 가이드(제2판)  ■ 딥러닝 제대로 시작하기 ■ 머신러닝 인 액션: 기계 학습 알고리즘으로 데이터 마이닝하기 ■ 인공지능 1: 현대적 접근 방식(제3판) ■ 인공지능 2: 현대적 접근 방식(제3판)   관련 파일 다운로드 ■ 엑셀 시뮬레이션 프로그램LearnAIwithExcel-master.zip다운로드깃헙에서 받기(깃헙 페이지에 접속하시면 가운데 우측 부분에  버튼이 있습니다. 이 버튼을 누른 후 우측 하단에 있는 'Download ZIP'을 클릭하시면 파일을 다운로드하실 수 있습니다)        강의보조 자료 교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com ■ 본문의 그림과 표 ■ 강의교안(ppt)(17년 8월 제공 예정)   샘플 PDF(차례, 옮긴이 머리말, 베타리더 후기, 3장 '인간의 애매함을 기계로 처리하기 = 퍼지')  엑셀로배우는인공지능_sample.pdf다운로드  정오표 페이지 ■ http://jpub.tistory.com/715   도서구매 사이트(가나다순)  [강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]    도서 소개 인공지능을 배우는 학생은 물론, 비전공자나 일반인까지 인공지능 입문자를 위한 최적의 가이드!   이 책은 앞으로 점점 더 발전할 것으로 예상되는 인공지능을 처음 배우고자 하는 분들을 위한 책이다. 머신러닝을 시작으로 신경망, 유전 알고리즘, 문제 해결, 게임 전략, 지식 표현 등 인공지능을 지탱하는 다양한 분야의 기초를 파악할 수 있다.   인공지능은 독특하면서도 고도의 기술이 많이 사용되는 분야이긴 하지만, 간단한 입력과 클릭만으로도 실행되는 엑셀 프로그램을 통해 실행 과정과 결과를 눈으로 바로 확인할 수 있도록 하였다. 아이디어가 돋보이는 엑셀 프로그램을 직접 조작하면서 인공지능에 대한 이해를 한층 높일 수 있을 것이다.   이 책에서 다루는 엑셀 프로그램 ■ 삐뚤어진 문자 인식하기 ■ ‘약간 높은 듯/약간 낮은 듯’하게 에어컨 제어하기 ■ 효율적으로 재산 분배하기 ■ 선교사가 식인종에 잡혀 먹히지 않고 강을 건널 수 있을까? ■ 최소 비용으로 산의 정상까지 오르는 경로 탐색하기 ■ 간단한 카드 게임으로 컴퓨터에 도전하기 ■ 인공지능에 단어의 의미 가르치기 ■ 병원에 가기 전에 인공지능에 물어보기 ■ 범인을 잡아라!   저자 소개 아사이 노보루(淺井 登) 1972년 나고야대학교 이학부를 졸업한 이후로 34년간 후지쯔에서 컴퓨터 언어 처리 시스템 및 인공지능 관련 기본 소프트웨어 개발에 힘썼다. 2000년부터 누마즈공업고등전문학교 전자제어공학과의 비상근 강사(인공지능)로 근무하다 지금은 오스카테크놀로지에 소속되어 있으면서 누마즈공업고등전문학교의 객원 교수를 겸하고 있다.   역자 소개 우영운  1997년 연세대학교 전자공학과에서 박사 학위를 취득한 이후 줄곧 동의 대학교 교수로 재직 중이다. 컴퓨터 프로그래밍과 인공지능 관련 과목을 주로 강의하고 있다. 지식 표현, 패턴 인식, 퍼지 기법, 딥러닝 등 인공지능 분야에 관심을 가지고 연구하고 있으며, 한국정보통신학회와 한국지능정보시스템학회에서 활동하고 있다.   차례 CHAPTER 1 꿈으로 가득 찬 인공지능 1 1.1 인공지능이 인간을 능가할 수 있을까? 2 1.2 인공지능의 연구 주제 29 1.3 인공지능 기술의 초보적 고찰 34 더보기 CHAPTER 2 인간의 뇌를 모방하는 기계 = 신경망 43 체험해봅시다: 인공지능이라면 약간 비뚤어진 문자를 정확히 인식할 수 있다 45 체험해봅시다: 인공지능이라면 더욱 비뚤어진 문자라도 정확히 인식할 수 있다 49 2.1 뇌의 모델과 신경망의 개념 52 2.2 퍼셉트론 56 2.3 홉필드 네트워크 61 2.4 기타 신경망 65   CHAPTER 3 인간의 애매함을 기계로 처리하기 = 퍼지 71 체험해봅시다: ‘약간 높은 듯/약간 낮은 듯’하게 에어컨 제어하기 73 체험해봅시다: 애매한 조건으로 목푯값 유지하기 76 3.1 퍼지의 개념 79 3.2 퍼지 추론 85 3.3 퍼지 제어 89 3.4 퍼지 관계 91   CHAPTER 4 좋은 것이 남는 진화의 법칙 = 유전 알고리즘 97 체험해봅시다: 효율적으로 재산 분배하기 99 4.1 유전 알고리즘이란? 104 4.2 유전 알고리즘의 구체적 예 108 4.3 유전 알고리즘의 응용 111   CHAPTER 5 우리 주변의 문제 잘 해결하기 = 문제 해결 117 체험해봅시다: 선교사가 ‘식인종’에 잡혀 먹히지 않고 강을 건널 수 있을까? 119 5.1 모델화 123 5.2 상태 전이 124 5.3 문제 해결의 구체적 예 126   CHAPTER 6 가장 효율적인 경로를 어떻게 선택할까? = 탐색법 131 체험해봅시다: 최소 비용으로 산의 정상까지 오르는 경로 탐색 133 6.1 탐색법의 분류 136 6.2 체계적 탐색 137 6.3 휴리스틱 탐색 140 6.4 탐색법 정리 144   CHAPTER 7 상대가 있을 경우의 대처 방법 = 게임 전략 147 체험해봅시다: 간단한 카드 게임으로 컴퓨터에 도전! 149 7.1 Min-Max 전략 153 7.2 αβ 전략 154   CHAPTER 8 인간이 학습하는 과정을 기계로 모방하기 = 머신 러닝 157 체험해봅시다: 인공지능에 단어의 의미 가르치기 159 8.1 머신 러닝의 기본적 개념 162 8.2 버전 공간법 165   CHAPTER 9 인간의 지식을 기계상에 표현하여 인간을 대신 = 지식 표현과 전문가 시스템 169 체험해봅시다: 병원에 가기 전에 인공지능에 물어보기 171 9.1 지식 표현 174 9.2 전문가 시스템 181   CHAPTER 10 기계에 인간의 자율성 부여하기 = 에이전트 185 체험해봅시다: 범인을 잡아라! 187 10.1 에이전트의 고전적 문제 191 10.2 에이전트의 개념 195 10.3 멀티에이전트 197   CHAPTER 11 인공지능을 개척한 컴퓨터 언어 = Lisp 201 11.1 리스트 처리 203 11.2 람다 계산 208 11.3 스코프와 익스텐트 213 11.4 쓰레기 수집 215   CHAPTER 12 사물의 관계를 서술하는 컴퓨터 언어 = Prolog 219 12.1 명제 논리 221 12.2 술어 논리 227 12.3 혼 절 231 12.4 단일화와 백트랙 234 12.5 WAM과 추상 명령 236   참고문헌 241 찾아보기 244  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 662}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글서버/인프라 엔지니어를 위한 DevOps  (0)2017.03.23안드로이드 게임 개발의 정석  (2)2017.03.13처음 만나는 자바스크립트  (8)2017.02.27자바스크립트와 Node.js를 이용한 웹 크롤링 테크닉  (12)2017.01.04알고리즘 중심의 머신러닝 가이드(제2판)  (6)2016.12.28태그ai, Artificial Intelligence, lisp, prolog, 게임전략, 딥러닝, 머신러닝, 신경망, 에이전트, 우영운, 유전자 알고리즘, 인공지능, 제이펍, 탐색법, 퍼지'도서 소개' Related Articles서버/인프라 엔지니어를 위한 DevOps안드로이드 게임 개발의 정석처음 만나는 자바스크립트자바스크립트와 Node.js를 이용한 웹 크롤링 테크닉Secret댓글달기loadedComments[662]=true;findFragmentAndHighlight(662);"
76,https://riedel.tistory.com/477,1. 금융 전략을 위한 머신러닝 - 금융과 머신러닝의 완벽한 만남,"var cnt = 0;var layoutKey = """";var slot = """";if(window.innerWidth > 767) {slot = ""7193229854"";layoutKey = ""-et+p-3e-92+ta"";} else {slot = ""4567066517"";layoutKey = ""-gm+k-2q-7a+nn"";}if(cnt != 0 && cnt%2 == 0) {document.write('<ul><li><ins class=""adsbygoogle"" style=""display:block"" data-ad-format=""fluid"" data-ad-layout-key=""'+layoutKey+'"" data-ad-client=""ca-pub-3458530807780778"" data-ad-slot=""'+slot+'""></ins></li></ul>');adPush();}cnt += 1;북로그/독서 기록비트코인 차트를 머신러닝으로 예측하는 방법(feat. 금융 전략을 위한 머신러닝 Machine Learning and Data Science Blueprints for Finance 후기)동사힐2022. 2. 14.if($(window).width() < 710) {$('#ad-top-left').remove();} else {adPush();}adPush();     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }안녕하세요~  동사힐입니다. 😊오늘은 비트코린 차트를 머신러닝으로 예측하는 방법을 알 수 있는 책인 금융 전략을 위한 머신러닝 후기를 적어보고자 합니다.한빛미디어 <나는 리뷰어다> 활동을 위해서 책을 제공받아 작성된 서평이니, 참고 바랍니다. 1. 금융 전략을 위한 머신러닝 - 금융과 머신러닝의 완벽한 만남금융 전략을 위한 머신러닝 책 표지금융 전략을 위한 머신러닝의 원제목은 Machine Learning and Data Science Blueprints for Finance입니다. 책을 소개하는데 영어 원제목을 먼저 설명하는 이유는 영어 제목이 이 책의 특성을 온전하게 설명해주기 때문인데요. 실제로 이 책은 금융에 활용할 수 있는 머신러닝과 데이터 과학의 청사진을 구체적으로 제시하는 책입니다. 단순히 금융과 관련된 사례나 코드 예제만 제공하는 것이 아니라 머신러닝과 데이터 과학과 관련된 다양한 학습 모델을 제공하고 있고, 다양한 모델을 7단계 문제 접근 방법 툴을 활용해서 공통적으로 적용해볼 수 있도록 설명하고 있습니다. 그뿐만 아니라 기존의 머신러닝 & 데이터과학 책에서는 주로 예제를 사이킷런 등에 포함되어 있는 기본 예제로 설명하는 경우가 대다수인데, 이 책은 캐글(https://www.kaggle.com/)의 다양한 예제 등을 활용하고 있습니다. 실제 예제의 파일들은 주로 FRED(Federal Reserve Economic Data, 미 연방 준비 은행 경제 데이터)나 야후 파이낸스, 비트스탬프 등 실제 미국의 주요 경제 지표를 확인할 수 있는 실질 데이터를 가지고 분석합니다. 이러한 예제만 보더라도, 실무에서 충분히 활용 가능한 예제임을 알 수 있습니다. 이 책에서 예측하는 독자층은 헤지 펀드, 투자 및 소매 은행, 핀테크 회사에서 일하는 데이터 과학자, 데이터 엔지니어 퀀트 연구원, 머신러닝 설계자 또는 소프트웨어 엔지니이업니다. 역으로 말하면 이러한 금융 핀테크 기업에서 데이터 전문가 직무를 갖기 원하는 주니어 개발자에게 실무 예제를 경험해볼 수 있는 책이라고 볼 수 있습니다.    https://docs.google.com/spreadsheets/d/1zpLFAPZ8NA6V09JUUU66g_lvpVra24B_ZTDHunM2O8c/edit?usp=sharing  [한빛미디어] 머신러닝·딥러닝 도서 선택 가이드(update 21-12-27)딥러닝/머신러닝(21-11-25) 분류,알고리즘,알고리즘,알고리즘 주 활용 분야 학습 방법,지도학습,지도학습,지도학습 입력의 규칙성(문제?),회귀,회귀,회귀 특징 추론/확률,추론/확률,추론/확률 선행docs.google.com다만, 이 책의 난이도는 상당히 높습니다. 한빛미디어에서 제작한 '[한빛미디어] 머신러닝·딥러닝 도서 선택 가이드'를 보면 이 책의 난이도는 무려 7입니다. 위 도서선택가이드에서 머신러닝, 딥러닝 관련 책이 총 61권인데, 이중 난이도 7이상의 책은 13권뿐입니다. 이 정도면 상당한 난이도라고 할 수 있습니다. 하지만 난이도에 겁먹을 필요는 없습니다. 적어도 파이썬을 어느 정도 다뤄본 독자라면 충분히 이해하고 파악할 수 있습니다. 만약 파이썬을 다뤄보지 않았더라도, R 등을 활용해서 데이터 분석을 해본 독자도 충분히 접근 가능합니다. 저는 오히려 이 책을 제대로 활용하기 위해서 필요한 지식은 컴퓨터 언어 관련 지식은 아니라고 생각합니다. 솔직히 말씀드리면 이 책에서는 아나콘다를 설치하여 주피터 노트북으로 코드를 실행하라고 나와 있는데, 예제 코드를 보고 주피터 노트툭보다 구글 코랩을 활용하면 훨씬 수월하게 예제 코드를 모두 실행할 수 있습니다. 구글 코랩은 기본 세팅이 이미 다 되어 있고, 구글의 GPU를 활용하여 연산하기 때문에 노트북으로도 충분히 머신러닝을 할 수 있는 좋은 프로그램입니다. 구글 코랩에서 데이터를 불러오기만 할 수 있으면 프로그래밍 언어적으로 필요한 능력은 모두 끝났다고 생각합니다.그것보다 더 요구되는 역량은 바로 머신러닝과 관련된 지도 학습, 비지도 학습, 강화 학습 등의 모델링과 알고리즘에 대한 이해도입니다. 예를 들어 이 책에서 지도 학습과 관련하여 선형 회귀부터 정규화 회귀, 로지스틱 회귀, 서포트 벡터 머신, K-최근접 이웃, 선형 판별 분석, 분류 트리, 회귀 트리, 앙상블 모델 등 다양한 모델을 소개하고, 실제로 데이터로 분석을 합니다. 이런 개념들을 이해하고, 어떻게 분석하고 효과성을 판별하는지에 대해서 정확히 알아야, 실제로 책에서 비트코인 거래 전략 알고리즘에서 다양한 모델 중에서 앙상블 모델의 랜덤 포레스트 모델을 선정했는지 이해할 수 있습니다. 이는 앞에서 말씀 드린 이 책의 기본 구조가 7단계 문제 접근 방식으로 인해 두드러지는 특징인데요. 예제 연습이나 실무에서도 바로 활용할 수 있도록 하기 위함인데요, 특히 모델 평가와 모델 튜닝 구조는 머신러닝에서 매우 필수적으로 학습해야 할 부분이며, 이 책이 지닌 가장 큰 매력이라고 생각합니다.  또한 머신러닝, 딥러닝에 관심이 많은 독자분이라면 '[한빛미디어] 머신러닝·딥러닝 도서 선택 가이드'를 참고하시면 학습하는데 큰 도움이 될 것입니다. 그러면 구체적으로 이 책의 특징을 살펴보겠습니다.  2. 독자 맞춤형 예제 소스 제공 https://gitlab.com/inspro9/hanbit_mlfi Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com먼저 이 책의 보물이라고 할 수 있는 예제 소스와 설명이 담긴 깃입니다. 저는 처음의 예제 소스를 책에서 못 찾아서 한빛미디어 담당자에게 메일까지 보냈었는데요. 메일 보내고 30분도 안되어서 바로 친절하게 답해주셔서 정말 감사한 마음이었습니다. 사실 이 예제 소스 주소는 책 표지 뒷면에 나와 있음에도 불구하고, 저의 주의 부족으로 찾지를 못했었죠.책 표지 뒷면에 나와 있는 예제 소스 주소이 예제들과 함께 책의 주요 내용을 학습해야 합니다. 특히 예제 소스만 덩그러니 나와 있는 것이 아니라, 책과 상호 연결되도록 구체적인 설명을 함께 제시하고 있어서 독자의 이해를 돕습니다. 다만, 깃 문서는 전부 영어로 작성되어 있기에, 어느 정도 영어 실력은 필요로 합니다. 그런데 이런 예제 소스는 사실 다른 머신러닝 책에서도 기본으로 제공하는 것이라 특별할 것 없다고 생각할 수 있는데, 저에게 가장 인상 깊었던 것은 바로 다음입니다. Notebooks by Application in Finance1. Trading Strategies and Algorithmic TradingBitcoin Trading Strategy using classificationBitcoin Trading Enhancing Speed and Accuracy using dimensionality reductionClustering for Pairs Trading StrategyReinforcement Learning based Trading StrategyNLP and Sentiments Analysis based Trading Strategy2. Portfolio Management and robo-advisorsInvestor Risk Tolerance and Robo-advisors - using supervised regressionRobo-Advisor Dashboard-powdered by MLPortfolio Management - Eigen Portfolio - using dimensionality reductionPortfolio Management - Clustering InvestorsHierarchial Risk Parity - using clusteringPortfolio Allocation - using reinforcement learning3. Derivatives Pricing and HedgingDerivative Pricing - using supervised regressionDerivatives Hedging - using reinforcement learning4. Asset Price PredictionStock Price Prediction - using regression and time seriesYield Curve Prediction - using regression and time seriesYield Curve Construction and Interest Rate Modeling - using dimensionality reduction5. Fraud DetectionFraud Detection - using classification6. Loan Default probability predictionLoan Default Probability - using classification7. Chatbot and automationDigital Assistant-chat-bots - using NLPDocuments Summarization - using NLP   Notebooks by Machine Learning Types1. Supervised Learning- Regression and Time series ModelsStock Price Prediction Derivative PricingInvestor Risk Tolerance and Robo-advisorsYield Curve Prediction2. Supervised Learning- Classification ModelsFraud DetectionLoan Default ProbabilityBitcoin Trading Strategy3. Unsupervised Learning- Dimensionality Reduction ModelsPortfolio Management - Eigen PortfolioYield Curve Construction and Interest Rate ModelingBitcoin Trading - Enhancing Speed and accuracy4. Unsupervised Learning- ClusteringClustering for Pairs TradingPortfolio Management - Clustering InvestorsHierarchial Risk Parity5. Reinforcement LearningReinforcement Learning based Trading StrategyDerivatives HedgingPortfolio Allocation6. Natural Language ProcessingNLP and Sentiments Analysis based Trading StrategyDigital Assistant-chat-botsDocuments Summarization  https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/index.ipynb index.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com 모두 인덱스에 제시된 내용인데요, 바로 동일한 예제를 금융 전략 관점과 머신러닝 타입에 따라서 분류를 해놓은 것입니다. 이 책은 금융 분야와 머신러닝 분야가 융합되어 있고, 따라서 두 분야의 독자들을 위해서 적절하게 나눠놓은 것입니다. 이러한 전문적인 내용을 상세하게 분류할 수 있는 이유는 이 책을 옮긴 김한상님의 뛰어난 역량이 있었기에 가능하다고 생각합니다.  실제로 이 책을 옮긴 김한상님은 현재 실리콘밸리에서 자율주행차를 연구하는 머신러닝, 데이터 전문가인데 금융 포트폴리오 관리 분야의 데이터 기반 의사 결정에도 깊은 관심을 갖다보니 자연스럽게 이 책을 번역도 하고, 이렇게 독자들을 위한 예제 소스도 직접 만드셨습니다. 김한상님의 노력이 없었다면, 이 책이 한국에 소개되기는 쉽지 않았으리라고 봅니다.  3. 7단계 문제 접근방법 템플릿 제공이 책은 파이썬을 사용하여 실전에 활용 가능한 문제를 제시하고 풀어 나갑니다. 또한 7단계 문제 접근방법(문제 정의 - 데이터 불러오기 - 데이터 분석 - 데이터 준비 - 모델 평가 - 모델 튜닝 - 모델 확정)의 템플릿을 제시합니다. 이 템플릿을 이용하여 새로운 머신러닝 문제에 쉽게 접근할 수 있습니다. -금융 전략을 위한 머신러닝 5쪽금융 전략을 위한 머신러닝은 파이썬을 기반으로 실무에서 바로 활용할 수 있는 여러 사례들을 다양한 머신러닝 모델을 활용하여 풀어나갑니다. 특히 7단계 문제 접근 방법을 제시하고, 이를 19가지 사례 전부에 적용합니다. 이를 통해 독자로 하여금 실무에 쉽게 응용할 수 있도록 만들고 있습니다. 특히 모델 평가와 모델 튜닝 부분은 머신러닝을 학습하는 주니어 개발자나 실무에서 일하는 현직 전문가에 큰 인사이트를 줄 것이라고 생각합니다. 그만큼 매우 활용도가 높으면서 깊이 있는 내용을 다루고 있습니다. 4. 비트코인, 주가 예측 그리고 챗봇까지 금융의 전 분야를 아우르는 19가지 사례 제공코로나19 팬데믹 이후 디지털 트랜스포메이션과 AI 트랜스포메이션 바람이 기업에 불면서 동시에 머신러닝과 딥러닝 또한 혹독한 겨울을 지나 지금 다양한 영역에서 활용되고 있습니다. 이에 따라서 많은 실무자나 주니어 개발자들이 머신러닝과 딥러닝을 학습하고 있는데요. 머신러닝을 다른 산업군보다 빠르게 활용했던 영역이 바로 금융입니다. 굳이 미국의 켄쇼를 언급하지 않아도, 국내에서도 상당수의 증권나 펀드 운용사에서 인공지능 AI를 활용해서 운용하는 펀드가 많습니다. 그뿐만 아니라 챗봇도 많이 운용하고 있구요.금융 분야에서 머신러닝을 많이 활용할 수 있는 가장 큰 이유는 바로 방대한 데이터를 엄청나게 빠른 속도로 만들어내고, 또 신속하게 의사결정을 내려서 흔들림없이 내린 결정을 지속해 가야 하기 때문입니다. 이런 금융 분야에서 구체적으로 활용할 수 있는 금융 사기 탐지, 비트코인, 주가 변화 예측, 포트폴리오 구성, 챗봇 시스템까지 머신러닝을 통해 활용할 수 있는 다양한 사례를 금융 전략을 위한 머신러닝에서는 사례로 제시하고 실제로 구현합니다. 그뿐만 아니라 각 장의 끝에는 이와 비슷한 사례의 연습 문제를 제시하여 독자로 하여금 스스로 고민하고 응용할 수 있도록 구체적이고 실질적인 아이디어를 함께 제시합니다.  금융, 핀테크 분야 전문가로서 머신러닝을 학습하고 싶은 독자머신러닝 학습자로서 보다 실질적인 구체적인 사례를 연습하고 싶은 독자금융 기업의 데이터 전문가로 취업을 준비하는 독자자신의 머신러닝, 데이터 과학 관련 분야를 금융 분야와 연결시켜 확장시키고 싶은 독자 이러한 독자들에게는 매우 소중한 책이 될 것이라고 생각합니다. 5. 비트코인 차트 예측 예제https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/Ch6_SLC/CS3BTS/BitcoinTradingStrategy.ipynb Ch6_SLC/CS3BTS/BitcoinTradingStrategy.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com금융 전략을 위한 머신러닝 책 본문 216쪽부터 나와 있는 실전 문제 비트코인 거래 전략의 코드 중 제가 실행한 일부 코드만 공유하고자 합니다. 금융 전략을 위한 머신러닝을 학습하는 독자들에게 조금이나마 도움이 되었으면 합니다.from google.colab import drivedrive.mount('/content/drive')# load datasetdataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv')먼저 저는 구글 코랩을 활용해서 코드를 실행했습니다. 위 코드는 저의 구글드라이브를 구글 코랩에 가상으로 마운트하는 명령어이구요. #은 주석이고, 그 다음줄은 데이터를 읽어내는 명령어입니다. 아무 생각없이 예제 소스를 그대로 복붙하면 실행이 안됩니다. 구글 코랩에서 파일의 폴더 모양을 클릭하신 후에 구글드라이브에 원하는 데이터의 경로 복사 기능을 활용해서 경로를 복사해주시면 데이터 파일을 읽어냅니다. 구글 코랩을 처음 활용하던 제가 처음에 많이 헤매던 부분이어서, 저처럼 파이썬을 잘 모르는 분들도 구글 코랩에서 경로 복사 기능만 이해하셔도 충분히 예제 소스를 이상없이 테스트해볼 수 있습니다.import matplotlib.pyplot as plt 처음에 matplotlib을 plt로 지정한 후에 다음의 메서드로 비트코인 그래프를 그렸습니다.dataset[['Weighted_Price']].plot(grid=True)plt.show()코드 실행 결과 등장한 차트 히스토그램도 다음 코드로 구현했습니다.# histogramsdataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,12))plt.show()코드 실행 결과 등장한 히스토그램 제시된 알고리즘 및 모델을 평가하기 위해서 먼저 데이터넷을 훈련하고, k-겹 교차 검증(k-folds cross validation)을 수행했습니다.results = []names = []for name, model in models:    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)    results.append(cv_results)    names.append(name)    msg = ""%s: %f (%f)"" % (name, cv_results.mean(), cv_results.std())    print(msg)k-겹 교차 검증에 무려 26분이 소요다음과 같은 결과가 나왔습니다. 앙상블 모델 중에서는 랜덤 포레스트가 최고의 성능을 보이는 것을 눈으로 확인할 수 있었습니다. 다만 구글 코랩으로 구글의 GPU를 사용했음에도 불구하고 무려 26분이나 시간이 걸렸습니다. 데이터가 무려 317메가바이트이기도 하고, 무려 9개의 모델을 비교 검증하는 것이다보니까 시간이 상당히 걸립니다. 제가 처음에는 아나콘다를 노트북에 설치해서 주피터 노트북으로 구동을 했는데, 노트북에 GPU가 없다보니 시간이 너무 오래 걸렸고, 결국 구글 코랩으로 옮기게 된 직접적인 이유이기도 합니다. # compare algorithmsfig = plt.figure()fig.suptitle('Algorithm Comparison')ax = fig.add_subplot(111)plt.boxplot(results)ax.set_xticklabels(names)fig.set_size_inches(15,8)plt.show()알고리즘 비교 결과를 시각화알고리즘 비교 결과를 matplotlib으로 시각화한 자료입니다. 한 눈에 각 모델의 수치를 비교할 수 있습니다.이 실전 문제(비트코인 거래 전략)는 머신러닝으로 금융 문제를 해결할 때 문제를 구조화하는 것이 핵심 단계라는 것을 시연해 보였다. 이 과정에서 투자 목표에 따라 레이블을 변환하고 특성 엔지니어링을 수행하는 것이 거래 전략을 위해 필요하다는 것을 확인했다. 가격 움직임의 추세 및 모멘텀과 관련된 직관적인 특성을 사용하는 것이 효율적임을 입증했다. 이것은 모델의 예측력을 높이는 데 유용했다. (중략)이 장에 제시된 파이썬, 머신러닝, 금융의 개념은 금융의 다른 분류 기반 문제에 대한 청사진으로 사용할 수 있다.-금융 전략을 위한 머신러닝 책 본문 229쪽책에서 언급된 위의 내용에서처럼 금융과 관련된 개념을 비트코인 차트 분석과 같은 금융 사례를 통해 제시함으로써 금융 관련 실무를 수행하는데 있어서 발생하는 다양한 문제들을 해결하는데 큰 도움이 될 것입니다.이 장의 마지막에서는 다음의 연습 문제를 제공함으로써 독자로 하여금 더욱 깊이 있는 사례 연구를 해볼 수 있도록 돕습니다.금융 전략을 위한 머신러닝 230쪽 연습 문제 6. 신용카드 거래 사기 탐지 예제https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/Ch6_SLC/CS1FD/FraudDetection.ipynb Ch6_SLC/CS1FD/FraudDetection.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com사기 탐지와 관련된 예제 중에서 가장 인상 깊었던 부분은 모델 튜닝이었습니다. 원하는 수준의 모델의 정확도를 얻을 때까지 지속적으로 개선하는 점은 저에게도 큰 도움이 되었습니다.# Grid Search: GradientBoosting Tuning'''n_estimators : int (default=100)    The number of boosting stages to perform.     Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.max_depth : integer, optional (default=3)    maximum depth of the individual regression estimators.     The maximum depth limits the number of nodes in the tree.     Tune this parameter for best performance; the best value depends on the interaction of the input variables.''' n_estimators = [20,180,1000]max_depth= [2, 3,5]param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)model = GradientBoostingClassifier()kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)grid_result = grid.fit(X_train_new, Y_train_new)#Print Resultsprint(""Best: %f using %s"" % (grid_result.best_score_, grid_result.best_params_))means = grid_result.cv_results_['mean_test_score']stds = grid_result.cv_results_['std_test_score']params = grid_result.cv_results_['params']ranks = grid_result.cv_results_['rank_test_score']for mean, stdev, param, rank in zip(means, stds, params, ranks):    print(""#%d %f (%f) with: %r"" % (rank, mean, stdev, param))격자 탐색 결과 신용카드 거래 사기 탐지는 신용카드 거래 불이행 비율을 발견하는 모델로 다양한 머신러닝 모델을 사용해보고, 적절한 평가 메트릭을 선택하고 불균형한 데이터를 어떻게 처리하는지를 시연하는지를 선보이고 있습니다. 7. NLP를 사용한 문서 요약 예제https://gitlab.com/inspro9/hanbit_mlfi/-/blob/main/Ch10_NLP/CS3DS/DocumentSummarization.ipynb Ch10_NLP/CS3DS/DocumentSummarization.ipynb · main · Hahnsang Kim / hanbit_mlfiGitLab.comgitlab.com오늘 리뷰에서 마지막으로 살펴볼 예제는 NLP를 사용한 문서 요약 예제입니다. 금융 관련 문서를 자연어 처리를 통해서 핵심을 요약하여 요점을 빠르게 파악할 수 있도록 돕는 프로세스입니다. 사이킷런의 LDA로 문서 요약을 연습해보겠습니다.#Libraries for pdf conversionfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreterfrom pdfminer.converter import TextConverterfrom pdfminer.layout import LAParamsfrom pdfminer.pdfpage import PDFPageimport re from io import StringIO#Libraries for feature extraction and topic modelingfrom sklearn.feature_extraction.text import CountVectorizerfrom sklearn.decomposition import LatentDirichletAllocation#Other librariesimport numpy as npimport pandas as pdpdf 변환 라이브러리, 특성 추출 및 주제 모델링 라이브러리, 기타 라이브러리를 불렀습니다. import mglearntopics = mglearn.tools.print_topics(topics=range(1,6), feature_names=features,sorting=array, topics_per_chunk=5, n_words=10)mglearn 출력 결과mglearn으로 5가지 주제에서 상위 10개의 단어를 추출했습니다. 다음으로는 주제 시각화를 해보았습니다. plt.figure(figsize=(16,13))plt.imshow(wc, interpolation='bilinear')plt.axis(""off"")plt.figure()#plt.imshow(raw_pic, cmap=plt.cm.gray, interpolation='bilinear')plt.axis(""off"")plt.show()워드 클라우드 생성 결과 8. 금융 전략을 위한 머신러닝(Machine Learning and Data Science Blueprints for Finance) 리뷰를 마치며2주 동안 금융 전략을 위한 머신러닝(Machine Learning and Data Science Blueprints for Finance)에 빠져 있었습니다. 왜 이 책의 원제에 Blueprints(청사진)이 들어 있을까? 생각을 많이 했는데, 다음의 이유에서 금융을 위한 머신러닝 청사진이 맞다고 생각했습니다.7단계 문제 접근방법 템플릿금융 분야의 핵심적인 19가지 사례심도 있는 연습문제이를 통해서 금융 분야의 머신러닝 전문가로 성장할 수 있는 구체적이고 완벽한 청사진을 제공하는 책입니다. 이 책을 모두 읽고 나니 금융 분야에서 실무자가 겪게될 대부분의 문제를 간접적으로 경험할 수 있었고, 문제를 해결하는 솔루션까지 학습할 수 있었습니다. 누구나 쉽게 접근할 수 있는 책은 아니지만, 머신러닝을 통해 금융 투자 전문가로 성장하고자 하는 독자 혹은 데이터 전문가로서 자신의 영역을 확장시키고자 하는 독자 모두에게 최고의 청사진을 제공하는 사례연구서입니다. 이 책을 통해서 대한민국의 금융 분야에도 머신러닝과 데이터 과학이 더욱 큰 기여를 하였으면 하는 바람입니다.  감사합니다.  어떠셨나요? 도움이 되셨나요?그러면 다음에도 더욱 좋은 글로 돌아오겠습니다.궁금한 사항 있으시면 댓글로 남겨주세요.도움이 필요하시다면 사연을 적어서 이메일을 보내주세요.dongsahill@gmail.com그리고 도움이 되셨다면 공감과 구독 부탁드려요.이상으로 동사힐이었습니다!읽어주셔서 감사합니다. 😊  반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//riedel.tistory.com/reaction';window.ReactionReqBody = {    entryId: 477}공유하기게시글 관리별감 아카이빙저작자표시 비영리 변경금지 '북로그 > 독서 기록' 카테고리의 다른 글삼국지 관우는 왜 조선에서 전쟁의 신이 되었을까?(feat. 만화로 배우는 조선 왕실의 신화 리뷰)  (0)2022.02.24데이터를 분석하고 시각화하는 아주 쉬운 방법(feat. 혼자 공부하는 R 데이터분석 리뷰)  (0)2022.02.16저는 주식투자가 처음인데요 리뷰(feat. 투자전략편을 읽고)  (0)2022.02.03아직도 주식 투자를 해보지 않았다면? (feat. 이 책부터 읽어보자.)  (0)2022.01.26왜 지금 슈퍼 석세스를 읽어야 할까?(feat. 신년을 준비하며 다시 읽는 슈퍼 석세스)  (0)2022.01.04볼 만한 글adPush();adPush();if($(window).width() < 710) {$('#ad-bottom-right').remove();} else {adPush();}댓글2비밀글등록    setInitialEntryComments(477, 1723627680)loadedComments[477]=true;findFragmentAndHighlight(477);💲 추천 글if(!checkMainPage()) {var mainAds = $('.main-ads');if(mainAds.prev().prop('tagName') == 'H2') {mainAds.prev().remove();}mainAds.remove();} else {adPush();}"
77,https://benn.tistory.com/35,Tag,"                                                  Bee's 데이터 과학                              홈태그방명록Data Science | AI/머신러닝 및 딥러닝[인공지능 자격증] 마이크로소프트 AI Fundamentals 자격증 (AI-900) 취득 후기Letter_B2021. 10. 22. 16:55     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});시험에 대해서마이크로소프트 시험최근에 링크드인 피드에 마이크로소프트 자격증을 따고 후기를 남기는 사람들이 눈이 띄었다. 그래서 나도 관심을 가지고 알아보기 시작했다. 마이크로소프트에서는 다양한 자격증을 취득할 수 있다. 모든 자격증은 마이크로소프트에서 제공하는 서비스 위주이며 역할 기반인 인증 시험들은 각 분야의 개념도 알아야 한다.예를 들면, AI 엔지니어 인증시험은 AI 관련 마이크로소프트 서비스도 자세히 알아야하지만 AI (머신러닝, 딥러닝) 관련 개념도 어느 정도 꽤 알아야 한다.  자격증 레벨에는 초급 > 중급 > 고급으로 나뉘지만 기본 사항 (Fundamentals), 역할 기반 (Role-based), 전문 (specialty)로 나뉘기도 한다.  그중 출발점으로 좋은 초급 + 기본 사항 (Fundamentals) 인증은 아래와 같다.Fundamentals Certifications (출처: Microsoft Learn) 여기서 애저 (Azure) 관련 초급시험은 세 가지가 있다.[AZ-900] 초급/애저: Azure Fundamentals - 클라우드 개념 + 애저 서비스 ✓[AI-900] 초급/애저/AI 엔지니어: Azure AI Fundamentals - ML/AI 개념 + 애저 서비스 ✓[DP-900] 초급/애저/데이터 엔지니어: Azure Data Fundamentals - 데이터 개념 + 애저 서비스 AI-900 시험AI-900 시험은 정말 기본적인 AI (머신러닝/딥러닝) 개념과 마이크로소프트에서 제공하는 AI 서비스만 알면 쉽게 딸 수 있는 자격증이다. 완전 입문자가 아니라면 살짝 비추하고 싶은 시험이다.어느정도 AI를 아는 사람이라면 이 위에 역할 기반 인증인 AI-102를 추천하고 싶다.  마이크로소프트 AI-900 웹사이트  시험 내용 공부 방법 & 자료총 10시간 정도 공부를 하고 시험을 봤다. 학습 경로 (3시간) → 온라인 워크숍 (3시간) → 덤프 문제 (2시간) → 덤프 다시 훑어보고 마인드맵 (1시간 반) → 시험마이크로소프트 학습경로마이크로소프트에서 제공하는 무료 학습 경로. AZ-900 공부할때도 학습경로+덤프 콤보로 충분했기에 이번에도 학습경로 1 회독으로 공부를 시작했다.마이크로소프트에서 제공하는 학습 경로는 아래와 같이 거의 글을 읽는게 다이기 때문에 조금 지루하다.. 마이크로소프트 학습 경로 중 일부 학습 경로는 정말 가볍게 읽어 보고 애저 portal을 통해 애저 서비스를 사용해보는 부분은 건너뛰었다.대학원 과목에서 애저를 (아주 살짝) 건들어본 경험도 있고 읽는것만으로 충분하다고 생각했다. 애저 Machine Learning에서 분류 모델 정말 그림이 안 그려지는 경우 유튜브에서 사용법을 찾아보기도 했다.이렇게 따라서 하는 부분이 꽤 많아서 학습경로 예상시간인 10시간보다 훨씬 짧은 3시간 안에 완독 했다..!  온라인 워크숍 참여링크드인에서 광고하던 AI-900 온라인 워크숍을 참여했다. 한국시간으로 아침 10시부터 6시까지였는데 인터넷이 계속 끊겨 첫 3시간만 들었다 (끊기고 나가면 초대해줄때까지 기다려야함. 두번째 튕겼을때는 너무 방해가 되는거 같아 그냥 혼자 공부했다).그래도 이 워크샵을 통해 AI-900 시험 바우처, 정리된 노트와 덤프 문제를 pdf 파일로 받았다. (공유는 안된다고 한다)  덤프 웹사이트난 워크숍에서 받은 문제를 써서 풀어봤지만 아래 웹사이트에서 다 나오는 문제였다. (근데 심지어 답을 안 줌..?)(문제 119개) https://www.examtopics.com/exams/microsoft/ai-900/ - 페이지 넘어갈 때마다 캡챠 풀어야 해서 매우 불편.. 대략 100 문제를 2시간에 걸쳐 풀어보았다. 다른 시험 (AZ-900) 덤프 풀 때는 많이 틀렸는데 이 시험은 첫판부터 거의 100% 맞았다.   시험 전 날시험 전날에는 덤프 문제를 토픽들로 나눠서 간단히 마인드맵을 그려봤다. (1시간 반 정도)마인드맵을 그려보면 큰 그림이 그려져 좀 더 정리가 잘된다. AI-900 마인드맵 시험 후기시험 예약마이크로소프트 시험 페이지에서 Pearson VUE를 통해 온라인 시험을 예약했다. 이때 원하는 날짜대와 시간을 정할 수 있고 시험 언어와 감독관 언어 (영어 또는 일본어)를 택할 수 있다. Pearson VUE 시험 예약  시험 당일저번에 AZ-900 시험을 봤을 때 이미 시험 프로그램 OnVUE를 받아놓고 시스템 체크를 했었다.시험은 시작 시간 30분 전부터 체크인을 할 수 있는데 이때 얼굴 사진 + 신분증 사진 + 방 사진을 찍은 후 감독관이 확인할 때까지 기다려야 한다 (길어야 1분?).감독관이 전화를 하거나 채팅을 걸 수도 있다고 되어있는데 난 기다렸다가 자동으로 시험 페이지로 넘어갔다. 이때 시험 시작 시간까지 안 기다려도 된다. 난 오후 1시 시험이었는데 12시 반에 체크인하고 시스템 체크, 설문조사를 풀고 바로 시험을 시작해서 오후 12시 49분에 모든 게 끝이 났다.  시험 문제시험 문제 개수는 랜덤인데 난 37문제가 나왔다. 주어진 시간은 45분이고 1000점 만점에서 700점이 넘어야 통과!생각보다 간단한 문제에 8분 안에 시험을 끝냈다. 점수는 970점!답을 보여주지 않지만 분야마다 막대그래프로 능력치?를 보여주는데 컴퓨터 비전에서 한 두 문제를 틀린 거 같다. 워크숍 (덤프) 문제가 90% 나왔다. 이렇게 나의 두 번째 마이크로소프트 배지를 획득했다..!!계속 모으게 싶어지는 나의 콜렉터 기질... 나의 마이크로소프트 디지털 배지 이번 시험을 마지막으로 이제 중급 시험으로 넘어갈 생각이다.  (생각 중인 자격증은 DP-100, DA-100, AI-102)일단 11월의 목표는 AI-102과 AWS SAA이다.나 파이팅! 728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//benn.tistory.com/reaction';window.ReactionReqBody = {    entryId: 35}공유하기게시글 관리Bee's 데이터 과학저작자표시 'Data Science | AI > 머신러닝 및 딥러닝' 카테고리의 다른 글[머신러닝/딥러닝] Foundation Model이란?  (0)2024.05.28AI/머신러닝 논문 사이트 추천  (1)2023.02.23[EPIC GAMES] 머신러닝 게임 ""While True: Learn()"" 리뷰  (0)2021.12.08[데이터 분석] 혼동행렬 Confusion Matrix (R과 Python 코드)  (0)2021.06.09[머신러닝] 머신러닝이란? (Feat. 지도학습 & 비지도학습)  (1)2021.03.16TagAI, AI-900, 덤프, 마이크로소프트 자격증, 인공지능'Data Science | AI/머신러닝 및 딥러닝'의 다른글이전글[데이터 분석] 혼동행렬 Confusion Matrix (R과 Python 코드)현재글[인공지능 자격증] 마이크로소프트 AI Fundamentals 자격증 (AI-900) 취득 후기다음글[EPIC GAMES] 머신러닝 게임 ""While True: Learn()"" 리뷰관련글AI/머신러닝 논문 사이트 추천2023.02.23[EPIC GAMES] 머신러닝 게임 ""While True: Learn()"" 리뷰2021.12.08[데이터 분석] 혼동행렬 Confusion Matrix (R과 Python 코드)2021.06.09[머신러닝] 머신러닝이란? (Feat. 지도학습 & 비지도학습)2021.03.16댓글 15    setInitialEntryComments(35, 1723607788)댓글비밀글등록loadedComments[35]=true;findFragmentAndHighlight(35);반응형(adsbygoogle = window.adsbygoogle || []).push({});👋  저는 시드니에서 거주하는 데이터 과학자입니다. 현재 컴퓨터 비전 관련 일을 하고 있습니다. 분류 전체보기 (54)  Data Science | AI (44)  머신러닝 및 딥러닝 (8)  논문 리뷰 (0)  통계, 수학 (5)  Python (17)  R (5)  SQL (4)  클라우드 (2)  데이터 시각화 (3)  Web development (7)  웹 분석 (1)  알고리즘 (1)  Career Journal (3)  TIL (0) Tag파이썬,sql,통계,데이터 시각화,CSS,통계학,설치,라이브러리,머신러닝,pandas,딥러닝,판다스,다운로드,머신러닝 논문,데이터 분석,PYTHON,R,데이터분석,데이터과학,데이터 과학,최근글과 인기글최근글인기글[머신러닝] 생성적 적대 신경망 Generative Adversarial Network (GAN) 정리2024.06.27 15:55머신러닝/딥러닝 논문 읽는 방법 (앤드류 응 교수님법)2024.06.21 10:58[딥러닝 / 수학] 코사인 유사도 cosine similarity 이해하기2024.06.21 09:10[Python] 아나콘다 (Anaconda) 다운로드 및 설치하기 feat. 주피터 노트북, 파이썬/콘다 버전 확인2021.06.17 12:16비주얼 스튜디오 테마 추천 및 변경하기2023.02.16 11:36비주얼 스튜디오 코드 폰트 바꾸기, 크기 바꾸기 + 코딩용 폰트 추천!2023.02.17 08:56최근댓글안녕하세요!저도 OMSA 시작할 때 파이썬 완전 초보였어요! 지원 당시, 본문에 언⋯ Letter_B안녕하세요!OMSA을 알고나서 관심을 가지고 서치하다가 들어왔습니다. 자세한 후기 감사드⋯ Sophia잘~ 보고갑니다 김도훈공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/062024/052024/012023/082023/062023/042023/022022/112022/102022/08Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total435,663Today : 149Yesterday : 502블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트티스토리툴바Bee's 데이터 과학구독하기                    (function () {                         var blogTitle = 'Bee\'s 데이터 과학';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4565392-35"",""customProps"":{""userId"":""0"",""blogId"":""4565392"",""entryId"":""35"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""35"",""entryTitle"":""[인공지능 자격증] 마이크로소프트 AI Fundamentals 자격증 (AI-900) 취득 후기"",""entryType"":""POST"",""categoryName"":""Data Science | AI/머신러닝 및 딥러닝"",""categoryId"":""463938"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4648833"",""authorNickname"":""Letter_B"",""blogNmae"":""Bee's 데이터 과학"",""image"":""kage@bitKcR/btrh5Zweg6t/Z1Kvv3g5TIEXrhpFPY1ejK"",""plink"":""/35"",""tags"":[""AI"",""AI-900"",""덤프"",""마이크로소프트 자격증"",""인공지능""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
78,https://yaun.tistory.com/265,Convolutional Neural Networks (합성곱 신경망),"                                                  야 언데드 하지마                              코딩일지/Machine Learning실전 머신러닝 적용 4주차 정리야언2022. 10. 12. 19:52이번 주 배울것다양한 신경망 구조전이학습 출처: https://www.cnblogs.com/wangxiaocvpr/p/6247424.html신경망을 구성하는 방법은 정말 여러가지가 있는데요,이 중 가장 많이 쓰이는 합성곱 신경망(CNN),순환 신경망(RNN),생성적 적대 신경망(GAN)에 대해 알아보겠습니다!특히 이미지처리에서 많이 쓰이는 CNN에 대해서는 조금 더 자세히 알아보고 실습도 해볼 거예요 🙂   Convolutional Neural Networks (합성곱 신경망) 합성곱과 합성곱 신경망합성곱(Convolution)은 예전부터 컴퓨터 비전(Computer Vision, CV) 분야에서 많이 쓰이는 이미지 처리 방식으로 계산하는 방식은 아래와 같습니다. 입력데이터와 필터의 각각의 요소를 서로 곱한 후 다 더하면 출력값이 됩니다.출처: https://ce-notepad.tistory.com/14딥러닝 연구원들은 이 합성곱을 어떻게 딥러닝에 활용할 수 있을까 고민하다가, 1998년에 Yann LeCun 교수님이 엄청난 논문을 발표하게 됩니다.르쿤 교수님은 합성곱을 이용한 이 신경망 디자인을 합성곱 신경망(CNN)이라고 명칭하였고 이미지 처리에서 엄청난 성능을 보이는 것을 증명했는데요. CNN의 발견 이후 딥러닝은 전성기를 이루었다고 볼 수 있습니다. 이후 CNN은 얼굴 인식, 사물 인식 등에 널리 사용되며 현재도 이미지 처리에서 가장 보편적으로 사용되는 네트워크 구조입니다.  Filter, Strides and Padding합성곱 신경망에서 가장 중요한 합성곱 계층(Convolution layer)에 대해 알아봅시다!아래와 같이 5x5 크기의 입력이 주어졌을 때, 3x3짜리 필터를 사용하여 합성곱을 하면 3x3 크기의 특성맵(Feature map)을 뽑아낼 수 있습니다. 필터(Filter 또는 Kernel)를 한 칸씩 오른쪽으로 움직이며 합성곱 연산을 하는데요, 이 때 이동하는 간격을 스트라이드(Stride)라고 합니다.출처: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1그런데 이렇게 연산을 하게 되면 합성곱 연산의 특성상 출력값인 특성 맵의 크기가 줄어듭니다. 이런 현상을 방지하기 위해서 우리는 패딩(Padding 또는 Margin)을 주어, 스트라이드가 1일 때 입력값과 특성 맵의 크기를 같게 만들 수 있습니다.출처: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1위에서는 1개의 필터를 사용하여 연산을 하였지만 여러개의 필터를 이용하여 합성곱 신경망의 성능을 높일 수 있습니다. 그리고 이미지는 3차원(가로, 세로, 채널)이므로 아래와 같은 모양이 됩니다. 이 그림에서 각각의 입력과 출력은 다음과 같습니다:입력 이미지 크기: (10, 10, 3)필터의 크기: (4, 4, 3)필터의 개수 :2출력 특성 맵의 크기: (10, 10, 2)출처: https://stackoverflow.com/questions/42883547/intuitive-understanding-of-1d-2d-and-3d-convolutions-in-convolutional-neural-n  CNN의 구성 CNN의 구성합성곱 신경망은 합성곱 계층(Convolution layer)과 완전연결 계층(Dense layer)을 함께 사용합니다.출처: https://teknoloji.org/cnn-convolutional-neural-networks-nedir/합성곱 계층 + 활성화 함수 + 풀링을 반복하며 점점 작아지지만 핵심적인 특성들을 뽑아 내는데요. 여기서 풀링 계층(Pooling layer)은 특성 맵의 중요부분을 추출하여 저장하는 역할을 합니다. 아래의 이미지는 Max pooling의 예시입니다. 2x2 크기의 풀 사이즈(Pool size)로 스트라이드 2의 Max pooling 계층을 통과할 경우 2x2 크기의 특성 맵에서 가장 큰 값들을 추출합니다.출처: https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks아래는 Average pooling의 예시입니다. Max pooling에서는 2x2 크기의 특성 맵에서 최대 값을 추출했다면 Average pooling은 2x2 크기의 특성 맵에서 평균 값을 추출하는 방식입니다.출처: https://www.kaggle.com/questions-and-answers/59502Max pooling과 Average pooling의 결과를 비교해보면 이렇게 되겠죠?출처: https://towardsdatascience.com/beginners-guide-to-understanding-convolutional-neural-networks-ae9ed58bb17d다시 이 그림으로 돌아와서 두 번째 풀링 계층을 지나면 완전연결 계층과 연결이 되어야 하는데 풀링을 통과한 특성 맵은 2차원이고 완전연결 계층은 1차원이므로 연산이 불가능합니다.출처: https://teknoloji.org/cnn-convolutional-neural-networks-nedir/따라서 우리는 평탄화 계층(Flatten layer)를 사용해서 2차원을 1차원으로 펼치는 작업을 하게 됩니다. 아래는 간단하게 평탄화 계층의 동작을 설명한 그림입니다.출처: https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening평탄화 계층을 통과하게 되면 우리는 완전연결 계층에서 행렬 곱셈을 할 수 있게되고 마찬가지로 완전연결 계층(=Dense=Fully connected) + 활성화 함수의 반복을 통해 점점 노드의 개수를 축소시키다가 마지막에 Softmax 활성화 함수를 통과하고 출력층으로 결과를 출력하게 됩니다. CNN의 활용 예컴퓨터 비전에서 필요한 기본 기능물체 인식(Object Detection)출처: https://arxiv.org/abs/1612.04402v1Object detection은 사진 이미지에서 정확히 물체를 인식하는 것을 뜻하며 컴퓨터비전에서 가장 중요한 기술입니다. 각각의 객체를 정확하게 인식하는 것부터 Computer Vision이 시작하기 때문입니다.핸드폰 카메라 셀카 모드에서 얼굴 영역을 자동으로 찾아주는 것도 object detection이라고 할 수 있겠죠? YOLO (You Only Look Once)   ※ 이번 프로젝트에 쓰일듯현재 V5까지 나왔으며 속도가 빠르다는 강점을 가졌고 다른 real-time detection에 비해 정확도가 높아 유명한 Computer Vision 알고리즘입니다.   이미지 분할(Segmentation) Segmentation은 각각의 오브젝트에 속한 픽셀들을 분리하는 것을 나타냅니다.나누는 기준이 디테일 할수록 정교화된 성능을 가져야 하고 처리속도 또한 문제가 될 수 있습니다.Segmentation의 Class를 동물로 분리할 수 있고, 강아지와 고양이로 분리할 수 있습니다. 더욱 더 세분화해서 분류를 하게 된다면 강아지 중에서도 웰시코기, 비숑, 진돗개로도 분리를 할 수 있습니다. 인물과 배경을 Segmentation하여 배경은 흐릿하게 처리해서 인물을 Focus하는 기술입니다.의료영상에서도, 양성/음성부분을 파악하고 악성인 부분을 Segmentation하여 인식할 수 있도록 도와줍니다.  활용 예자율주행 물체인식자세 인식(Pose Detection)화질개선(Super Resolution)Style Transfer사진 색 복원(Colorization)   다양한 CNN 종류 AlexNet (2012)출처: https://paperswithcode.com/method/alexnet컴퓨터 비전 분야의 ‘올림픽’이라 할 수 있는 ILSVRC(ImageNet Large-Scale Visual Recognition Challenge)의 2012년 대회에서 제프리 힌튼 교수팀의 AlexNet이 Top 5 test error 기준 15.4%를 기록해 2위(26.2%)를 큰 폭으로 따돌리고 1위를 차지했습니다.여기서 top 5 test error란 모델이 예측한 최상위 5개 클래스 가운데 정답이 없는 경우의 오류율을 나타냅니다. 당시 ILSVRC 데이터셋(Image은 1000개 범주 예측 문제였습니다. 어쨌든 AlexNet 덕분에 딥러닝, 특히 CNN이 세간의 주목을 받게 됐습니다.AlexNet은 의미있는 성능을 낸 첫 번째 합성곱 신경망이고, Dropout과 Image augmentation 기법을 효과적으로 적용하여 딥러닝에 많은 기여를 했기 때문입니다.  VGGNet (2014)출처: https://medium.com/deep-learning-g/cnn-architectures-vggnet-e09d7fe79c45VGGNet은 큰 특징은 없는데 엄청 Deep한 모델(파라미터의 개수가 많고 모델의 깊이가 깊습니다)로 잘 알려져 있습니다. 또한 요즘에도 딥러닝 엔지니어들이 처음 모델을 설계할 때 전이 학습 등을 통해서 가장 먼저 테스트하는 모델이기도 하죠. 간단한 방법론으로 좋은 성적을 내서 유명해졌습니다.  GoogLeNet(=Inception V3) (2015) 합성곱 신경망의 아버지 르쿤 교수님이 구글에서 개발한 합성곱 신경망 구조입니다. AlexNet 이후 층을 더 깊게 쌓아 성능을 높이려는 시도들이 계속되었는데, 바로 VGGNet(2014), GoogLeNet(2015) 이 대표적인 사례입니다. GoogLeNet은 VGGNet보다 구조가 복잡해 널리 쓰이진 않았지만 구조 면에서 주목을 받았습니다.GoogLeNet 연구진들은 한 가지의 필터를 적용한 합성곱 계층을 단순히 깊게 쌓는 방법도 있지만, 하나의 계층에서도 다양한 종류의 필터, 풀링을 도입함으로써 개별 계층를 두텁게 확장시킬 수 있다는 창조적인 아이디어로 후배 연구자들에게 많은 영감을 주었습니다. 이들이 제안한 구조가 바로 Inception module (인셉션 모듈)입니다.출처: https://tariq-hasan.github.io/concepts/computer-vision-cnn-architectures/인셉션 모듈에서 주의깊게 보아야할 점은 차원(채널) 축소를 위한 1x1 합성곱 계층 아이디어입니다. 또한 여러 계층을 사용하여 분할하고 합치는 아이디어는, 갈림길이 생김으로써 조금 더 다양한 특성을 모델이 찾을 수 있게하고, 인공지능이 사람이 보는 것과 비슷한 구조로 볼 수 있게 합니다. 이러한 구조로 인해 VGGNet 보다 신경망이 깊어졌음에도, 사용된 파라미터는 절반 이하로 줄었습니다.  **ResNet (2015)AlexNet이 처음 제안된 이후로 합성곱 신경망의 계층은 점점 더 깊어졌습니다. AlexNet이 불과 5개 계층에 불과한 반면 VGGNet은 19개 계층, GoogleNet은 22개 계층에 달합니다. 하지만 층이 깊어질 수록 역전파의 기울기가 점점 사라져서 학습이 잘 되지 않는 문제(Gradient vanishing)가 발생했습니다. ResNet 저자들이 제시한 아래 학습그래프를 보면 이같은 문제가 뚜렷이 나타납니다.출처: https://neurohive.io/en/popular-networks/resnet/따라서 ResNet 연구진은 Residual block을 제안합니다. 그래디언트가 잘 흐를 수 있도록 일종의 지름길(Shortcut=Skip connection)을 만들어주는 방법입니다.출처: https://neurohive.io/en/popular-networks/resnet/위의 그림에서 알 수 있듯 y = F(x) + x 를 다시 쓰면 F(x) = y - x 로 표현할 수 있고, Residual block은 입력과 출력 간의 차이를 학습하도록 설계되어 있습니다.ResNet의 Residual block은 합성곱 신경망 역사에서 큰 영향을 끼쳤고 아직도 가장 많이 사용되는 구조 중에 하나입니다. 많은 사람들이 Residual block을 사용하면 대부분의 경우 모델의 성능이 좋아진다라고 얘기하고 있습니다.    Transfer Learning (전이 학습) 전이 학습전이 학습이라는 개념은 인간이 학습하는 방법을 모사하여 만들어졌습니다. 만약 여러분들이 영어를 배워서 영어를 완벽하게 말할 수 있게 되었다고 가정합시다. 그러면 여러분이 프랑스어를 배울 때는 영어를 배울 때 사용한 지식과 방법을 사용하여 더욱 빠르게 습득할 수 있겠죠!이렇게 과거에 문제를 해결하면서 축적된 경험을 토대로 그것과 유사한 문제를 해결하도록 신경망을 학습시키는 방법을 전이 학습이라고 합니다. 전이 학습은 비교적 학습 속도가 빠르고 (빠른 수렴), 더 정확하고, 상대적으로 적은 데이터셋으로 좋은 결과를 낼 수 있기 때문에 실무에서도 자주 사용하는 방법입니다.출처: https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a전이학습은 위에서 소개한 유명한 네트워크들과 같이 미리 학습시킨 모델(pretrained models)을 가져와 새로운 데이터셋에 대해 다시 학습시키는 방법입니다. 흥미로운 점은, 꽤나 다른 형태의 데이터셋에 대해서도 효과를 보인다는 것인데요! 예를 들어, 1000개의 동물/사물을 분류하는 ImageNet이라는 대회에서 학습한 모델들을 가져와 얼굴 인식 데이터셋에 학습시켜도 좋은 결과를 얻을 수 있습니다. 이런 특징 덕분에 전이 학습은 딥러닝에서 더욱 중요해지게 되었죠! Recurrent Neural Networks (순환 신경망) Recurrent Neural Networks (RNN)자연어 처리 등 다양한 분야에 활용되는 RNN에 대해 배워봅시다!RNN은 은닉층이 순차적으로 연결되어 순환구조를 이루는 인공신경망의 한 종류입니다. 음성, 문자 등 순차적으로 등장하는 데이터 처리에 적합한 모델로 알려져 있는데요. 합성곱 신경망과 더불어 최근 들어 각광 받고 있는 신경망 구조입니다.길이에 관계없이 입력과 출력을 받아들일 수 있는 구조이기 때문에 필요에 따라 다양하고 유연하게 구조를 만들 수 있다는 점이 RNN의 가장 큰 장점입니다.출처: https://ratsgo.github.io/natural language processing/2017/03/09/rnnlstm/우리가 소설을 지어내는 인공지능을 만든다고 할 때, hell 이라는 입력을 받으면 ello 라는 출력을 만들어내게 해서 결과적으로 hello 라는 순차적인 문자열을 만들어 낼 수 있게 하는 아주 좋은 구조입니다.출처: https://ratsgo.github.io/natural language processing/2017/03/09/rnnlstm/이외에도 주식이나 암호화폐의 시세를 예측한다던지, 사람과 대화하는 챗봇을 만드는 등의 다양한 모델을 만들 수 있습니다.  Generative Adversarial Network (생성적 적대 신경망) Generative Adversarial Network (GAN)서로 적대(Adversarial)하는 관계의 2가지 모델(생성 모델과 판별 모델)을 동시에 사용하는 기술입니다. 최근 딥러닝 학계에서 굉장히 핫한 분야입니다GAN은 위조지폐범과 이를 보고 적발하는 경찰의 관계로 설명할 수 있습니다.생성모델 (위조지폐범): 경찰도 구분 못하는 진짜같은 위조지폐를 만들자!판별모델 (경찰): 진짜 지폐와 위조 지폐를 잘 구분해내자!이와같이 계속 진행되면 위조지폐범은 더욱 더 정교하게, 경찰은 더욱 더 판별을 잘하면서 서로 발전의 관계가 되어 원본과 구별이 어려운 가짜 이미지가 만들어지게 됩니다. GAN이 어떻게 작용하는지 살펴보기GAN에 대해 Input data와 Output data를 파악하고 위조지폐범과 경찰에 입장에서 한번 생각해보겠습니다.AnimalGAN이라는 머신이 어떻게 잡음으로부터 동물 이미지를 만드는지 봄으로써 GAN의 작동방식을 이해해봅시다! 이 머신에게 주어진 문제는 다음과 같습니다.Input Data : 랜덤으로 생성된 잡음Output Data : 0~1 사이의 값( 0은 가짜, 1은 진짜)이때 대립하는 두 모델은 다음과 같습니다.Generator(위조지폐범): 이미지가 진짜(1)로 판별될수록 좋겠죠? 보다 정교하게 모델을 만들려고 노력하며 Target은 1로 나오도록 해야합니다. 가짜를 진짜인 1처럼 만들기 위하여 타깃인 1과 예측의 차이인 손실을 줄이기 위하여 Backpropagation을 이용한 weight를 조정할 것입니다.Discriminator(경찰): 진짜 이미지는 1로, 가짜 이미지는 0으로 판별할 수 있어야합니다. 생성된 모델에서 Fake와 Real 이미지 둘다를 학습하여 예측과 타깃의 차이인 손실을 줄여야합니다.이렇게 두 모델이 대립하면서(Adversarial) 발전해 에폭(Epoch)이 지날 때마다 랜덤 이미지가 점점 동물을 정교하게 생성해 내는 것(Generative)을 볼 수 있습니다. GAN을 사용한 예시들CycleGAN StarGAN CartoonGAN출처: https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/2205.pdf DeepFakehttp://www.aitimes.com/news/articleView.html?idxno=132830삼성 AI랩이 선보인 이미지를 동영상으로 만드는 기술.마릴린 먼로, 모나리자, 아인슈타인 등 과거 인물의 사진을 AI로 학습시켜 가상의 영상을 생성했다.이 기술 역시 딥페이크를 기반으로 한 이미지·영상 합성이다. /유튜브 캡처 BeautyGAN Toonify Yourself출처: https://youtu.be/84EqhSY-n6c  CNN, 전이학습 실습 CNN 학습해보기데이터셋 다운로드필요한 패키지 임포트하기데이터셋 로드하기라벨 분포 확인하기전처리하기입력과 출력 나누기데이터 미리보기one-hot 인코딩하기일반화하기네트워크 구성하기모델 학습시키기 이미지 증강기법 이용해보기학습 데이터 증강하기train_image_datagen = ImageDataGenerator(  rescale=1./255, # 일반화  rotation_range=10,  # 랜덤하게 이미지를 회전 (단위: 도, 0-180)  zoom_range=0.1, # 랜덤하게 이미지 확대 (%)  width_shift_range=0.1,  # 랜덤하게 이미지를 수평으로 이동 (%)  height_shift_range=0.1,  # 랜덤하게 이미지를 수직으로 이동 (%))train_datagen = train_image_datagen.flow(    x=x_train,    y=y_train,    batch_size=256,    shuffle=True)검증 데이터 일반화하기test_image_datagen = ImageDataGenerator(  rescale=1./255)test_datagen = test_image_datagen.flow(    x=x_test,    y=y_test,    batch_size=256,    shuffle=False)이미지 확인하기네트워크 구성하기모델 학습시키기 전이학습 실습해보기데이터셋 다운로드필요한 패키지 임포트하기전처리하기 - 폴더에서 직접 데이터 가져와서 증강기법까지 써보기train_datagen = ImageDataGenerator(  rescale=1./255, # 일반화  rotation_range=10, # 랜덤하게 이미지를 회전 (단위: 도, 0-180)  zoom_range=0.1, # 랜덤하게 이미지 확대 (%)  width_shift_range=0.1,  # 랜덤하게 이미지를 수평으로 이동 (%)  height_shift_range=0.1,  # 랜덤하게 이미지를 수직으로 이동 (%)  horizontal_flip=True # 랜덤하게 이미지를 수평으로 뒤집기)test_datagen = ImageDataGenerator(  rescale=1./255 # 일반화)train_gen = train_datagen.flow_from_directory(  'fruits-360/Training',  target_size=(224, 224), # (height, width)  batch_size=32,  seed=2021,  class_mode='categorical',  shuffle=True)test_gen = test_datagen.flow_from_directory(  'fruits-360/Test',  target_size=(224, 224), # (height, width)  batch_size=32,  seed=2021,  class_mode='categorical',  shuffle=False)데이터 확인하기전이학습 - 모델 가져와서 수정하기from tensorflow.keras.applications.inception_v3 import InceptionV3input = Input(shape=(224, 224, 3))base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=input, pooling='max')x = base_model.outputx = Dropout(rate=0.25)(x)x = Dense(256, activation='relu')(x)output = Dense(131, activation='softmax')(x)model = Model(inputs=base_model.input, outputs=output)model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['acc'])모델 학습시키기  ** ModelCheckpoint로 정확도 높은 모델 저장from tensorflow.keras.callbacks import ModelCheckpointhistory = model.fit(    train_gen,    validation_data=test_gen, # 검증 데이터를 넣어주면 한 epoch이 끝날때마다 자동으로 검증    epochs=20, # epochs 복수형으로 쓰기!    callbacks=[      ModelCheckpoint('model.h5', monitor='val_acc', verbose=1, save_best_only=True)    ])학습된 모델 로딩하기from tensorflow.keras.models import load_modelmodel = load_model('model.h5')결과 확인하기test_imgs, test_labels = test_gen.__getitem__(100)y_pred = model.predict(test_imgs)classes = dict((v, k) for k, v in test_gen.class_indices.items())fig, axes = plt.subplots(4, 8, figsize=(20, 12))for img, test_label, pred_label, ax in zip(test_imgs, test_labels, y_pred, axes.flatten()):  test_label = classes[np.argmax(test_label)]  pred_label = classes[np.argmax(pred_label)]  ax.set_title('GT:%s\nPR:%s' % (test_label, pred_label))  ax.imshow(img)    4주차까지 완강하며 머신러닝의 기본 개념과 사용방법을 단계별로 공부해 보았다.  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//yaun.tistory.com/reaction';window.ReactionReqBody = {    entryId: 265}공유하기게시글 관리야 언데드 하지마 '코딩일지/Machine Learning'의 다른글이전글실전 머신러닝 적용 3주차 정리현재글실전 머신러닝 적용 4주차 정리관련글실전 머신러닝 적용 3주차 정리2022.10.12실전 머신러닝 적용 2주차 정리2022.10.12실전 머신러닝 적용 1주차 정리2022.10.12loadedComments[265]=true;findFragmentAndHighlight(265);야 언데드 하지마이젠 안구려그래도 하지마야 언데드 하지마구독하기글쓰기블로그 관리 분류 전체보기 (267)  코딩일지 (218)  TIL: Today I Learned (84)  WIL: Weekly I Learned (17)  python 백준 알고리즘 (81)  내일배움캠프 과제 (5)  파이썬 (7)  자료구조, 알고리즘 (4)  내배캠 타임어택 테스트 (3)  Machine Learning (4)  Node.js (5)  sql (5)  취미 (40)  비즈아트 (13)  music (20)  게임 (3)  피아노 | 연습할것 (4) Tag최근글과 인기글최근글인기글あいみょん - 君はロックを聴かない2024.05.02 02:14프로그래머스 코딩테스트 연습 - 다리를 지나는 트럭2023.04.05 01:25프로그래머스 코딩테스트 연습 - 완주하지 못한 선수2023.04.05 00:06ChatGPT API를 활용한 웹 서비스 만들기 - 3일차(프론트, 백엔드 배포)2023.03.28 22:06ChatGPT API를 활용한 웹 서비스 만들기 - 2일차2023.03.27 22:06Node.js에서 환경 변수 다루기2023.03.27 20:50최근댓글포스팅 잘 읽었습니다 ㅎㅎget_time파이팅!!야언머찌다 파이팅! 미스티_공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/052023/042023/032023/012022/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total11,055Today : 8Yesterday : 4블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트　m의 하루티스토리툴바                    (function () {                         var blogTitle = '야 언데드 하지마';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""358481-265"",""customProps"":{""userId"":""0"",""blogId"":""358481"",""entryId"":""265"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""265"",""entryTitle"":""실전 머신러닝 적용 4주차 정리"",""entryType"":""POST"",""categoryName"":""코딩일지/Machine Learning"",""categoryId"":""1090641"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""339754"",""authorNickname"":""야언"",""blogNmae"":""야 언데드 하지마"",""image"":""kage@bm8JrN/btrOqzm4Z5l/Hqqe8vKyxeJLECXvPx4KE0"",""plink"":""/265"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
79,https://jpub.tistory.com/992,태그,"도서 소개머신러닝 도감: 그림으로 공부하는 머신러닝 알고리즘 17 제이펍2019. 12. 18. 09:42 이 책은 현재 절판입니다. 그간 읽어주신 독자들께 감사드립니다.전자책은 계속 판매하고 있습니다. 알고리즘 중심의 머신러닝을 배우고 싶은 분에게 추천합니다!복잡한 머신러닝 알고리즘을 풍부한 컬러 그림으로 배웁니다! 도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크] 출판사 제이펍저작권사 쇼에이샤(翔泳社)원서명 機械学習図鑑(원서 ISBN: 9784798155654)저자명 아키바 신야, 스기야마 아세이, 데라다 마나부역자명 이중민출판일 2019년 12월 19일페이지 260쪽시리즈 I♥A.I. 21(아이러브 인공지능 21)판 형 170*225*13.1제 본 무선(soft cover)정 가 26,000원ISBN 979-11-88621-84-2(93000)키워드 머신러닝 / 인공지능 / 기계학습 / 머신러닝 알고리즘 / 지도학습 / 비지도학습 / 데이터 처리 / 파이썬 / 사이킷런분야 인공지능 / 머신러닝 관련 사이트■ 저작권사 도서소개 페이지■ 아마존 도서소개 페이지 관련 포스트■ 2019/12/05 - [출간전 책소식] - 머신러닝 핵심 알고리즘을 파이썬 코드와 그래프로 배운다! 관련 시리즈■ I♥A.I 시리즈 관련 도서■ 패턴 인식과 머신 러닝 ■ 그림과 수식으로 배우는 통통 머신러닝 ■ 머신러닝 인 액션 ■ 알고리즘 중심의 머신 러닝가이드 관련 파일 다운로드■ 예제 코드■ 구글 Colaboratory 예제 실행 방법 안내   강의보조 자료 다운로드교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표 샘플 PDF(차례, 옮긴이 머리말, 머리말, 이 책에 대하여, 베타리더 후기, 1장 '머신러닝 기초' 일부, 2장 '지도학습' 일부, 3장 '비지도 학습' 일부)머신러닝도감_sample.pdf다운로드  정오표 페이지■ https://jpub.tistory.com/1005 도서구매 사이트(가나다순)[교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [영풍문고]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크] 도서 소개알고리즘 중심의 머신러닝을 배우고 싶은 분에게 추천합니다!복잡한 머신러닝 알고리즘을 풍부한 컬러 그림으로 배웁니다! 이 책은 복잡한 머신러닝 알고리즘을 그림과 함께 하나하나 살펴보는 입문서입니다. 전문가가 아닌 사람도 머신러닝을 이해할 수 있도록 지도 학습과 비지도 학습에 해당하는 17가지 알고리즘을 설명합니다. 또한, 사이킷런 기반의 파이썬 예제 코드를 구글 콜랩 등에서 바로 실행하며 읽을 수 있습니다. 이 책의 특징복잡한 머신러닝 알고리즘 구조를 한 권으로 배운다컬러 그림을 풍부하게 수록하였다알고리즘마다 사이킷런을 사용한 코드를 제공하므로 보면서 직접 실행할 수 있다구조뿐만 아니라 실제 사용법과 주의점을 알 수 있다 이 책의 대상 독자머신러닝에 흥미를 느껴 공부를 시작한 분좀 더 다양한 머신러닝 알고리즘을 알고 싶은 분수식이 부담스러워서 머신러닝 관련 책을 읽기 어려워하는 분문제에 따라 적절한 머신러닝 알고리즘을 선택하고 싶은 분 책에서 소개하는 알고리즘 1701 선형 회귀02 정규화03 로지스틱 회귀04 서포트 벡터 머신05 서포트 벡터 머신(커널 기법)06 나이브 베이즈 분류07 랜덤 포레스트08 신경망09 kNN(k-최근접 이웃 알고리즘)10 PCA(주성분 분석)11 LSA(잠재 의미 분석)12 NMF(음수 미포함 행렬 분해)13 LDA(잠재 디리클레 할당)14 k-means(k-평균 알고리즘)15 가우시안 혼합 모델16 LLE(국소 선형 임베딩)17 t-SNE(t-분포 확률적 임베딩) 지은이 소개아키바 신야(秋庭 伸也)2012년에 와세다대학교 기간이공학부를 졸업하고, 2015년에 와세다대학교 이공학술원 기간이공학연구과 기계과학전공 석사 과정을 수료했습니다. 지금은 리크루트 통신의 기술 리드로 근무하고 있습니다.@ak1niwa 스기야마 아세이(杉山 阿聖)제조업체의 IT 자회사에서 3년간 iOS 앱을, 2년간 채팅 봇을 개발했습니다. 현재는 SENSY의 연구원으로 머신러닝을 이용한 개발 업무를 담당하고 있습니다. 엔지니어 대상의 스터디 그룹에 참가하거나 다른 개발자와 지식 나누기를 좋아합니다.@K_Ryuichirou 데라다 마나부(寺田 学)파이썬 웹과 관련된 컨설팅 및 구축 업무를 하고 있습니다. 2010년부터 일본 파이썬 커뮤니티에서 적극적으로 활동하면서 ‘파이콘 일본’ 콘퍼런스 개최에 도움을 주고 있으며, 2013년 3월부터는 파이콘 일본의 대표이사를 맡고 있습니다. 또한, 다른 오픈 소스 소프트웨어 관련 커뮤니티를 주관하거나 멤버로 활동하기도 합니다. 아울러 파이썬 엔지니어 육성 추진 협회의 고문이사로 활동하면서 파이썬의 매력을 전달하는 교육 활동에도 많은 관심을 두고 있습니다. 최근에는 파이썬과 머신러닝 입문자를 대상으로 강의를 시작했습니다.《파이썬으로 배우는 새로운 데이터 분석의 교과서(쇼에이샤, 2018년 9월)를 함께 썼으며, 《거침없이 이해하는 파이썬》(쇼에이샤, 2017년 8월)을 감수했습니다.@terapyon 옮긴이 소개이중민‘지속 가능한 삶이 무엇인가?’라는 고민으로 디지털 노마드가 되어 다양한 IT 기술을 탐구하고 이를 콘텐츠로 만드는 방법을 공부하고 있습니다. PC 및 하드웨어 전문 리뷰 사이트인 pcBee에서 테크니컬 라이터로 활동하면서 다양한 하드웨어 및 소프트웨어 환경을 분석하고 기사를 작성하면서 전문 지식을 쌓았고, 이후 프리랜서 웹 마스터로 다양한 웹 사이트 개발을 경험했습니다. 지금은 IT 개발과 관련한 인사이트를 넓히기 위해 애쓰고 있습니다.《PC 조립 관리 수리 길라잡이 2002: 세상에 단 하나뿐인 내 PC 만들기》(정보문화사, 2002)를 함께 썼고, 《처음 배우는 블록체인》(한빛미디어, 2018), 《이토록 쉬운 딥러닝을 위한 기초 수학 with 파이썬》(루비페이퍼, 2019)을 옮겼습니다. 차례CHAPTER 1 머신러닝 기초 11.1 머신러닝 소개 3    머신러닝 3    머신러닝의 유형 4    머신러닝의 활용 101.2 머신러닝 준비하기 11    데이터의 중요성 11    지도 학습(분류)의 예 14    구현 방법 17    비지도 학습의 예 19    시각화 23    그래프의 종류와 표현 방법: matplotlib을 이용한 그래프 출력 29    판다스를 이용해 데이터를 이해하고 다루기 38    마치며 45 더보기CHAPTER 2 지도 학습 4701 선형회귀 49    기본 개념 49    알고리즘 50    더 나아가기 5302 정규화 58    기본 개념 58    알고리즘 61    더 나아가기 6403 로지스틱 회귀 67    기본 개념 67    알고리즘 69    더 나아가기 7104 서포트 벡터 머신 74    기본 개념 74    알고리즘 75    더 나아가기 7705 커널 기법을 적용한 서포트 벡터 머신 80    기본 개념 81    알고리즘 81    더 나아가기 8306 나이브 베이즈 분류 86    기본 개념 86    알고리즘 89    더 나아가기 9307 랜덤 포레스트 94    기본 개념 94    알고리즘 95    더 나아가기 9908 신경망 101    기본 개념 101    알고리즘 104    더 나아가기 10809 k-최근접 이웃 알고리즘(kNN) 110    기본 개념 110    알고리즘 112    더 나아가기 113 CHAPTER 3 비지도 학습 11710 주성분 분석 119    기본 개념 119    알고리즘 121    더 나아가기 12411 잠재 의미 분석 125    기본 개념 125    알고리즘 127    더 나아가기 13112 음수 미포함 행렬 분해 132    기본 개념 132    알고리즘 134    더 나아가기 13613 잠재 디리클레 할당 139    기본 개념 139    알고리즘 141    더 나아가기 14314 k-평균 알고리즘 146    기본 개념 146    알고리즘 147    더 나아가기 14915 가우시안 혼합 모델 151    기본 개념 151    알고리즘 152    더 나아가기 15616 국소 선형 임베딩 157    기본 개념 157    알고리즘 158    더 나아가기 16117 t-분포 확률적 임베딩 163    기본 개념 163    알고리즘 164    더 나아가기 168 CHAPTER 4 평가 방법과 여러 가지 데이터 처리 1714.1 평가 방법 173    지도 학습의 평가 173    분류 문제의 평가 방법 174    회귀 문제의 평가 방법 183    평균제곱오차와 결정계수의 차이 188    다른 알고리즘을 이용할 때와 비교 188    하이퍼 파라미터 설정 190    모델의 과적합 191    과적합을 막는 방법 192    학습 데이터와 검정 데이터 나누기 193    교차 검증 196    하이퍼 파라미터 탐색하기 1984.2 문서 데이터의 전처리 202    단어 빈도 수를 이용한 변환 202    TF-IDF를 이용한 변환 203    머신러닝 모델에 적용 2044.3 이미지 데이터 변환하기 207    픽셀 밝기 값 활용하기 207    변환한 벡터 데이터로 머신러닝 모델 만들기 209 CHAPTER 5 파이썬 개발 환경 2115.1 파이썬 3 설치 213    윈도우 10 213    macOS 214    리눅스 215    아나콘다를 윈도우 10에 설치 2165.2 가상 환경 218    표준 개발 환경에서 가상 환경 설정하기 218    아나콘다 2205.3 외부 라이브러리 설치 221    외부 라이브러리 221    외부 라이브러리 설치 221 참고문헌 223 APPENDIX 부록 225    읽으면 도움 되는 수학 개념 몇 가지 226    이 책의 주요 용어 230 찾아보기 237 제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)네이버 책  포스트  유튜브  인스타그램  트위터  페이스북  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 992}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글알파제로를 분석하며 배우는 인공지능  (2)2019.12.30자바 트러블슈팅: scouter를 활용한 시스템 장애 진단 및 해결 노하우  (0)2019.12.27함수형 언어 산책: 도커 기반의 함수형 언어 실습에서 빅 데이터 처리 프레임워크까지  (0)2019.12.06러스트 프로그래밍 공식 가이드  (0)2019.11.27포토샵 사전  (0)2019.11.27태그기계학습, 딥러닝, 머신러닝, 머신러닝알고리즘, 심층학습, 이중민, 인공지능, 제이펍'도서 소개' Related Articles알파제로를 분석하며 배우는 인공지능자바 트러블슈팅: scouter를 활용한 시스템 장애 진단 및 해결 노하우함수형 언어 산책: 도커 기반의 함수형 언어 실습에서 빅 데이터 처리 프레임워크까지러스트 프로그래밍 공식 가이드Secret댓글달기loadedComments[992]=true;findFragmentAndHighlight(992);"
80,https://jpub.tistory.com/1494,태그,"도서 소개모니터링의 새로운 미래 관측 가능성 제이펍2023. 11. 28. 10:38 마이크로서비스와 인공지능 사례 중심의 관측 가능성 실무 가이드 클라우드 네이티브 기술이 고도화되고 시스템이 복잡해질수록 근본 원인 분석을 위한 관측 가능성이 필수다. 이 책은 분산 서비스에서 빼놓을 수 없는 쿠버네티스를 기반으로 관측 가능성을 다룬다. 프로메테우스부터 그라파나, 오픈텔레메트리까지 다양하게 다루고 있어 관측 가능성에 대한 폭넓은 지식을 얻을 수 있다. 직접 실습할 수 있도록 Go 언어와 파이썬으로 개발한 마이크로서비스를 제공하며, 다양한 예제를 통해 시스템을 구축해보면서 근본 원인에 대한 분석 방법을 이해하도록 구성했다. 예제는 실무에 가깝게 구성되어 현장에서 바로 적용이 가능한 기술을 익힐 수 있다. 도서 구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  [교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사] 출판사 제이펍저작권사 제이펍원서명 (없음)도서명 모니터링의 새로운 미래 관측 가능성부제 프로메테우스, 그라파나, 오픈텔레메트리까지 마이크로서비스와 인공지능 중심의 옵저버빌리티 구현지은이 정현석, 진미란옮긴이 (없음)감수자 (없음)시리즈 (없음)출판일 2023. 12. 08페이지 468쪽판 형 46배판변형(188*245*22.7)제 본 무선(soft cover)정 가 38,000원ISBN 979-11-92987-57-6 (93000)키워드 observability, 옵저버빌리티, 관찰 가능성, AIOps, 쿠버네티스, 분산 서비스, 근본 원인 분석, 오픈서치, LGTM 스택, OpenTelemetry분 야 네트워크 / 빅데이터 관련 사이트■ 저자 기술 블로그 관련 시리즈■ (없음) 관련 포스트■ 2023.11.23 - [출간 전 책 소식] - 외부 신호로 내부 상태를 예측하는 관측 가능성 관련 도서■ (없음) 관련 파일 다운로드■ https://github.com/philllipjung/o11ybook 강의 보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음 자료를 보내드립니다.)■ 본문의 그림과 표 미리보기(차례, 추천사, 베타리더 후기, 머리말, 이 책에 대하여, 본문 일부) 정오표 페이지■ (등록되는 대로 링크를 걸겠습니다.) 도서 구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  [교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사] 도서 소개실습 애플리케이션을 이용해 직접 하면서 배우는 관측 가능성 날로 복잡해지는 기술에 따라 모니터링만으로 모든 현상을 분석하고 대비하기는 어려워졌다. 특히 클라우드 서비스를 많이 이용하여 내부 시스템을 들여다보는 것도 쉽지 않기 때문에 여러 가지 신호를 측정하여 발생 가능한 이벤트를 예측하는 것이 중요하다. 따라서 관측 가능성을 통해 발생하는 오류의 원인과 잠재적인 오류 가능성까지 살펴볼 필요가 있다. 이 책은 관측 가능성의 개념과 용어 정리부터 시작해서 프로메테우스, 그라파나, 오픈텔레메트리까지 다양한 관측 가능성 도구를 설명한다. Go 언어와 파이썬으로 개발한 마이크로서비스를 제공하며, 카오스 엔지니어링이 가능하도록 구성한 애플리케이션을 통해 실제와 유사한 환경으로 실습하도록 구성한 것이 특징이다. 분산 서비스에서 빼놓을 수 없는 쿠버네티스를 기반으로 실습하며, 그라파나 LGTM 스택 등 다양한 도구를 활용해 시스템을 구축하며 근본 원인 분석을 실시한다. 관측 가능성을 처음 접하는 사람도 쉽게 시작할 수 있도록 프로그램 설치 방법부터 대규모 서비스를 위한 클라우드 환경에서의 구축 방법까지 설명하여 실무에서 바로 적용할 수 있도록 하였다. 관측 가능성을 처음 접하는 개발자는 물론, AIOps와 운영 자동화 등 그라파나와 일래스틱서치를 운영 중인 운영자, 개발에 관심이 많은 데브옵스 개발자, 사이트 신뢰성 엔지니어(SRE)까지 도움이 될 내용이 가득 담겼다. 현장에서 바로 적용할 수 있는 다양한 실무 노하우가 가득 담긴 이 책이 한 단계 성장하는 발판이 되길 바란다. 주요 내용관측 가능성의 개념과 기반 기술프로메테우스 생태계 이해와 타노스 소개로키, 템포, 미미르를 이용한 그라파나 관측 가능성그라파나와 오픈서치 기반으로 개발된 예제 실습오픈텔레메트리를 활용한 관측 가능성AIOps와 운영 자동화 개념과 전망 지은이 소개정현석액센츄어(Accenture), IBM에서 소프트웨어 엔지니어로 근무했고, 현재 호주 시드니에 있는 맥쿼리그룹에서 SRE로 근무하고 있다. 비용 절감을 위해 다양한 관측 가능성 설루션을 하나로 통합하고 있으며, USED/RED 대시보드와 알람을 표준화해서 배포를 자동화했다. 실사용자 모니터링을 사용하여 프런트엔드부터 백엔드까지 관측 가능성을 적용하고, 비즈니스적인 가치를 찾고 기술적으로 구현하기 위해 지원하고 있다. 또한, 관측 가능성을 고도화해서 근본 원인 분석과 IT 운영 자동화를 이루고, 나아가 AIOps가 구현될 수 있도록 협업 중이다. 진미란클라우드 엔지니어로 근무하며 데이터, ML 분야의 여러 베스트 프랙티스를 경험했다. 머신러닝의 프로세스 자동화, 재현 가능성 및 지속성이 중요하다고 생각하고, 머신러닝 모델을 서비스화하여 UX에 도움을 주거나 수익을 창출하는 등의 실용성에 대해 고민하고 있다. 현재는 MLOps 엔지니어로 근무하며 관련 설루션을 개발하고 있다. 새로운 것에 도전하고 값진 경험으로 성장하기를 희망하는 미래의 나와, 실제로 그것을 해내야 하는 현실 속의 나 사이의 괴리로 인해 갈등하지만, ‘이것도 그냥 나인가 보다’ 하고 받아들이는 수행 과정에 있다. 차례 추천사 x베타리더 후기 xiii머리말 xv이 책에 대하여 xvii CHAPTER 1 관측 가능성의 개념과 방향성 11.1 관측 가능성의 세 가지 요소 2__1.1.1 모니터링과 차이점 2__1.1.2 관측 가능성 구성 요소 51.2 메트릭 6__1.2.1 가용성 6__1.2.2 구글의 골든 시그널 7__1.2.3 메트릭 유형 12__1.2.4 시계열 데이터 13__1.2.5 프로메테우스의 히스토그램 16__1.2.6 메트릭 관리 방안 211.3 추적 25__1.3.1 추적 구성 요소 25더보기__1.3.2 추적 데모 291.4 로그 37__1.4.1 로그 관리 37__1.4.2 로그 표준화 401.5 상관관계 44__1.5.1 상관관계의 필요성 44__1.5.2 상관관계 구현 방안 461.6 관측 가능성 데모 52__1.6.1 데모의 방향성 52__1.6.2 관측 가능성 데모 목록 541.7 관측 가능성 목표 59__1.7.1 레퍼런스 아키텍처 59__1.7.2 핵심 목표 601.8 관측 가능성 오픈소스 641.9 관측 가능성 방향성 65 CHAPTER 2 관측 가능성 기반 기술 692.1 트래픽 관리 69__2.1.1 단일 장애점 69__2.1.2 로드 밸런서 70__2.1.3 복원성 패턴 73__2.1.4 가시성 78__2.1.5 서비스 메시 792.2 쿠버네티스 오토스케일링 81__2.2.1 오토스케일링 오픈소스 85__2.2.2 메트릭 측정 90__2.2.3 메트릭 선정 912.3 관측 가능성 프로세스 96__2.3.1 관측 가능성 운영 프로세스 96__2.3.2 관측 가능성 장애 프로세스 972.4 수평 샤딩 992.5 마이크로서비스 102__2.5.1 마이크로서비스 개발 흐름 103__2.5.2 관측 가능성의 마이크로서비스 105__2.5.3 읽기와 쓰기를 분리하기 1062.6 일관된 해시 1082.7 관측 가능성 시각화 1132.8 키-값 저장소 1192.9 객체 스토리지 1202.10 안정적 데이터 관리 1212.11 시계열 데이터 집계 128 CHAPTER 3 관측 가능성의 시작, 프로메테우스 1313.1 프로메테우스 바이너리 구성 1313.2 프로메테우스 시계열 데이터베이스 138__3.2.1 데이터 형식 138__3.2.2 데이터 관리 139__3.2.3 블록 관리 1413.3 프로메테우스 쿠버네티스 구성 1443.4 프로메테우스 오퍼레이터 1463.5 프로메테우스 오토스케일링 154__3.5.1 프로메테우스 어댑터 154__3.5.2 KEDA 오토스케일 1593.6 프로메테우스 알람 1623.7 프로메테우스 운영 아키텍처 170__3.7.1 샤딩 아키텍처 170__3.7.2 페더레이션 아키텍처 1733.8 타노스 운영 175__3.8.1 타노스 아키텍처 175__3.8.2 타노스 사이드카 방식 178__3.8.3 타노스 리시버 방식 181__3.8.4 타노스 구성 183__3.8.5 타노스 테스트 186 CHAPTER 4 오픈소스 관측 가능성, 그라파나 1894.1 그라파나 관측 가능성 190__4.1.1 목적과 범위 190__4.1.2 인프라 구성 191__4.1.3 애플리케이션 구성 1934.2 로키 로그 관리 202__4.2.1 로키 기능 202__4.2.2 로키 바이너리 구성 213__4.2.3 프롬테일 쿠버네티스 구성 214__4.2.4 로키 쿠버네티스 구성 215__4.2.5 로키 테스트 2214.3 미미르 메트릭 관리 224__4.3.1 미미르 기능 224__4.3.2 미미르 구성 232__4.3.3 미미르 쿠버네티스 구성 236__4.3.4 미미르 업무 규칙 2384.4 템포 추적 관리 245__4.4.1 템포 기능 245__4.4.2 템포 바이너리 구성 249__4.4.3 템포 쿠버네티스 구성 250__4.4.4 템포 쿠버네티스 테스트 2524.5 예거 추적 관리 254__4.5.1 예거 쿠버네티스 구성 254__4.5.2 예거 데이터 모델 257 CHAPTER 5 그라파나 관측 가능성 데모 2595.1 상관관계 261__5.1.1 메트릭에서 추적으로 262__5.1.2 추적에서 메트릭으로 263__5.1.3 로그에서 추적으로 270__5.1.4 추적에서 로그로 271__5.1.5 메트릭에서 로그로 2725.2 뉴 스택 278__5.2.1 뉴 스택 소개 279__5.2.2 뉴 스택 구성 284__5.2.3 뉴 스택 상관관계 2875.3 라이드 온디맨드 294__5.3.1 시스템 설정 296__5.3.2 소스 설명 309__5.3.3 HotROD 개선 방향 3285.4 그라파나 관측 가능성 330__5.4.1 시스템 개요 330__5.4.2 소스 설명 333__5.4.3 시스템 구성 336__5.4.4 그라파나 데이터 소스 설정 341 CHAPTER 6 관측 가능성의 표준, 오픈텔레메트리 3436.1 오픈텔레메트리 소개 3446.2 오픈텔레메트리 컴포넌트 345__6.2.1 신호의 구성 요소 347__6.2.2 콘텍스트 전파 358__6.2.3 파이프라인 3596.3 추적 361__6.3.1 오픈텔레메트리 추적 소개 361__6.3.2 추적 파이프라인 구성 3676.4 메트릭 374__6.4.1 오픈텔레메트리 메트릭 소개 374__6.4.2 메트릭 파이프라인 구성 3786.5 로그 384__6.5.1 오픈텔레메트리 로그 소개 384__6.5.2 로그 파이프라인 구성 3916.6 컬렉터 397__6.6.1 오픈텔레메트리 컬렉터 소개 397__6.6.2 컬렉터 파이프라인 구성 4006.7 오픈텔레메트리 데모 404 CHAPTER 7 관측 가능성을 넘어 자동화로 4257.1 IT 운영 자동화 4257.2 AIOps의 발전 단계 427__7.2.1 지능형 경고 429__7.2.2 상관관계 429__7.2.3 이상 탐지 4307.3 AIOps의 기술들 4317.4 앞으로 더 배울 내용 433__7.4.1 다섯 가지 텔레메트리 433__7.4.2 이상 탐지 434__7.4.3 근본 원인 분석 435__7.4.4 데이터 파이프라인 436__7.4.5 오픈서치 관측 가능성 436__7.4.6 멀티 클러스터와 멀티 테넌트 437__7.4.7 자동 계측 439__7.4.8 SLO 규칙과 시각화 439 용어 설명 440찾아보기 445  제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)  포스트  유튜브  인스타그램  트위터  페이스북 window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1494}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기저작자표시 '도서 소개' 카테고리의 다른 글내 맘대로 그리는 캐릭터 이모티콘 with 프로크리에이트  (0)2023.12.01Plotly로 시작하는 인터랙티브 데이터 시각화 in R & 파이썬  (0)2023.12.01Let’s 주짓수  (0)2023.11.16챗GPT로 만드는 주식 & 암호화폐 자동매매 시스템  (0)2023.11.15그림으로 배우는 구글 클라우드 101  (0)2023.11.10태그AIOps, LGTM 스택, observability, opentelemetry, 관찰 가능성, 근본 원인 분석, 분산 서비스, 오픈서치, 옵저버빌리티, 쿠버네티스'도서 소개' Related Articles내 맘대로 그리는 캐릭터 이모티콘 with 프로크리에이트Plotly로 시작하는 인터랙티브 데이터 시각화 in R & 파이썬Let’s 주짓수챗GPT로 만드는 주식 & 암호화폐 자동매매 시스템Secret댓글달기loadedComments[1494]=true;findFragmentAndHighlight(1494);"
81,https://jpub.tistory.com/1238,'출간 전 책 소식' Related Articles,"출간 전 책 소식Apache Airflow에 대한 국내 최초 전문서! 제이펍2022. 3. 2. 17:16아파치 소프트웨어 재단의 최상위 프로젝트로서 오픈소스 워크플로 관리 플랫폼인 Airflow에 대한 국내 최초 전문서가 곧 출간됩니다.Airflow는 2014년 10월에 Airbnb의 자체 워크플로 솔루션으로 시작되어 2016년 3월에 아파치 인큐베이터 프로젝트가 되었고, 2019년 1월에 최상위 프로젝트로 승격하여 2022년 2월 말에 Airflow 2.2.4가 발표되었습니다.  현재 450여 개의 기업들이 이 플랫폼을 사용하고 있는데요(https://github.com/apache/airflow/blob/main/INTHEWILD.md), 이에 대해 국내에서도 상당한 관심을 보이고 있습니다.  이 책을 통해서 Apache Airflow를 현업에 적용하는 데브옵스 엔지니어, 데이터 엔지니어, 머신러닝 엔지니어, 그리고 시스템 관리자가 많아져서, 가뜩이나 배우고 익혀야 할 기술 종류가 많은 엔지니어가 복잡한 워크플로를 일일이 관리하는 수고로움에서 조금은 벗어날 수 있기를 바랍니다.책은 3월 16일에 출간될 예정인데, 관심 있는 분들은 아래의 미리보기 파일을 살펴보시기 바랍니다. ■ 미리보기(차례, 옮긴이 머리말, 번역서 추천사, 베타리더 후기, 원서 추천사, 저자 머리말, 1장 'Apache Airflow 살펴보기' 전체)ApacheAirflow기반의데이터파이프라인_Sample.pdf4.75MB ■ 도서구매 사이트(가나다순) [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡] ■ 제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)  네이버 책  포스트  유튜브  인스타그램  트위터  페이스북 window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1238}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '출간 전 책 소식' 카테고리의 다른 글온라인에서 내가 어떤 사람으로, 어떻게 인식될까?  (0)2022.03.15윈도우에서 리눅스 활용하기!  (0)2022.03.08성취감을 한껏 느끼며 익히는 파이썬 프로그래밍!  (0)2022.02.10엑셀 하나로 유튜브 50만 구독자가 모인 데는 다 이유가 있습니다!  (0)2022.02.03단단한 + deep + 강화학습...  (0)2022.01.28'출간 전 책 소식' Related Articles온라인에서 내가 어떤 사람으로, 어떻게 인식될까?윈도우에서 리눅스 활용하기!성취감을 한껏 느끼며 익히는 파이썬 프로그래밍!엑셀 하나로 유튜브 50만 구독자가 모인 데는 다 이유가 있습니다!Secret댓글달기loadedComments[1238]=true;findFragmentAndHighlight(1238);"
82,https://jpub.tistory.com/1466,태그,"도서 소개줄리아 머신러닝, 딥러닝, 강화학습 제이펍2023. 9. 27. 09:48 파이썬 너머의 AI 세상, 프로덕션 줄리아 준비 끝 강력한 줄리아 언어와 생태계를 활용해 전문가답게 인공지능 실무를 처리해보자. 이 책은 줄리아의 타입 시스템이나 메서드 특화 등 언어적 특성을 자세히 살펴보고, 이어서 데이터 분석, 머신러닝, 딥러닝, 강화학습 영역에서의 일반적인 작업들과 최신 알고리즘들을 줄리아로 우아하게 실습해본다. 줄리아를 프로덕션 레벨로 익히고 활용하고 싶다면, 이 책이 유일무이한 선택이다.  도서구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  [교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사] 출판사 제이펍저작권사 제이펍원서명 (없음)도서명 줄리아 머신러닝, 딥러닝, 강화학습부제 빠르고 우아하게 데이터 분석부터 강화학습까지 인공지능 실무 스킬업지은이 김태훈옮긴이 (없음)감수자 (없음)시리즈 I♥A.I. 43출판일 2023. 10. 06페이지 396쪽판 형 46배판변형(188*245*19.4)제 본 무선(soft cover)정 가 32,000원ISBN 979-11-92987-40-8 (93000)키워드 julia, 데이터분석, 데이터과학, 시각화, 메타프로그래밍, 병렬, 전처리, 플럭스, NLP, 알고리즘분 야 인공지능 / 딥러닝 / 파이썬 관련 사이트■ 깃허브 저장소 관련 시리즈■ I♥A.I. 관련 포스트■ 2023.09.21 - [출간 전 책 소식] - 경축 줄리아 TIOBE 인덱스 20위 진입 관련 도서■ (없음) 관련 파일 다운로드■ (없음) 강의 보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음 자료를 보내드립니다.)■ 본문의 그림과 표 미리보기(베타리더 후기, 이 책에 대하여, 1장 일부) 정오표 페이지■ https://jpub.tistory.com/1472 도서구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  [교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사] 도서 소개가장 빠르고 우아한 데이터 과학 최고의 언어를 만날 시간 줄리아는 파이썬 상위호환 언어로 평가받으면서 사용이 늘고 있다. 파이썬과 같이 동적 언어이면서도 C와 같은 정적 언어에 가까운 실행 속도를 보이며, 대부분의 라이브러리 역시 줄리아 코드로 작성되어 라이브러리의 코드를 수정하거나 디버깅하기가 매우 쉽다는 장점도 있다. 이 책은 줄리아의 우아한 언어 특성과 강력한 라이브러리 생태계를 활용해 전문가답게 인공지능 실무를 처리하는 방법을 알려준다. 언어 문법을 매뉴얼 형식으로 설명하는 대신, 타입 시스템, 다중 디스패치, 메서드 특화, 메타프로그래밍, 다차원 배열, 병렬 연산 등 실무 관점에서 알아야 할 줄리아의 코딩 스타일을 자세히 다룬다. 이어서 데이터 분석과 시각화에 쓰이는 라이브러리들(Tables.jl, DataFrames.jl, Query.jl, Plots.jl 등)과 환경 구성법을 살펴보고, 간단한 전처리 실습도 해본다. 특히 책 앞부분은 파이썬과 비교하는 예시로 파이썬 사용자의 줄리아 적응을 돕는다. 이후는 머신러닝, 딥러닝, 강화학습 영역의 일반적인 작업들에 대해 최신 알고리즘을 활용해 줄리아로 우아하게 실습해보는 시간이다. 줄리아의 과학적 타입이나 MLJ의 모델 합성을 활용하면 머신러닝 워크플로 자체가 얼마나 깔끔해지는지 체감할 수 있다. 플럭스를 사용하는 딥러닝 파트에서는 자동 미분과 함자를 설명한 다음, 컴퓨터 비전, 객체 탐지, NLP 등의 딥러닝 작업들을 실습한다. 파이토치나 텐서플로에 익숙한 독자가 쉽게 따라올 수 있게 구성했다. 끝으로 DQN, DDPG, SAC, A2C, PPO 등 강화학습 알고리즘을 줄리아로 구현해 카트폴 환경에서 결과를 확인해본다. 줄리아 문법 또는 인공지능 이론을 기초부터 하나씩 설명하는 책은 아니다. 그런 입문서들은 이미 시중에 있지만, 줄리아를 실제로 인공지능 실무에 활용해본 저자가 노하우를 담아 집필한 활용서는 이 책이 유일하다. 인공지능 실무에서 생산성을 높이고 싶다면 이 책이 가장 우아한 선택이 될 것이다. 주요 내용타입 시스템, 다중 디스패치, 메서드 특화, 메타프로그래밍, 병렬 연산 등 줄리아의 강력한 언어 특성Tables.jl, DataFrames.jl, Query.jl, Plots.jl 등 줄리아 패키지를 활용한 데이터 분석 및 시각화과학적 타입을 이용한 머신러닝 전처리, 학습, 예측, 평가, 튜닝 및 모델 합성 실무플럭스를 사용한 컴퓨터 비전, 객체 탐지, NLP 등 딥러닝 작업 실습DQN, DDPG, SAC, A2C, PPO 강화학습 알고리즘 구현지은이 소개김태훈서울대학교에서 경영학과 통계학을 전공했다. 상품선물을 거래하는 미국 헤지펀드에서 6년간 파이썬으로 데이터 분석을 했다. 2012년부터 국내 대표 사모운용사인 타임폴리오자산운용에서 전산 본부를 이끌고 있다. 주로 하는 업무는 주문 처리 자동화, 위험 관리 시스템 구축, 시장 데이터 분석 등이다. 서비스 구현 시에는 C#을 주로 사용하고, 데이터 분석 시에는 줄리아를 즐겨 사용한다. 러스트, F# 등 다양한 프로그래밍 언어를 업무에 도입해보는 것을 좋아하고, 여러 언어 중에서 줄리아로 작업할 때 가장 우아함을 느꼈다. 새벽에 일어나서 맑은 정신으로 코딩할 때 행복함을 많이 느낀다. 차례베타리더 후기 xii이 책에 대하여 xvi PART I 줄리아 언어 CHAPTER 1 기본 문법 31.1 변수 31.2 수치 타입 4__정수 4 / 부동소수점 수 51.3 자료구조 6__배열 6 / 튜플 6 / 명명된 튜플 7 / 딕셔너리 71.4 문자열 타입 71.5 복합 타입 91.6 기본 연산 101.7 함수 11__함수 정의 및 호출 11 / 인수 기본값 12 / 가변 인수와 키워드 인수 12 / 익명 함수와 do 블록 13 / 함수 합성과 파이핑 14 / 벡터화용 dot 연산자 14 / 인수 전달 방식 14 / 객체 호출 함수 151.8 제어 흐름 15__복합식 15 / 조건식 16 / 반복문 16 / 예외 처리 171.9 모듈 17더보기1.10 변수 영역 19__전역 변수 19 / 함수의 지역 변수 19 / for, while, try 문의 지역 변수 20 CHAPTER 2 타입 시스템 232.1 동적 타입 232.2 추상 타입과 구체 타입 25__줄리아 수 체계 25 / 추상 타입 27 / 원시 타입 27 / 복합 타입 28 / 변경 불가능성 30 / 행위의 상속 312.3 매개변수 타입 32__UnionAll 타입 34 / 무공변성 34 / 매개변수 추상 타입 362.4 그 외 타입들 36__싱글턴 타입 36 / Nothing 타입 37 / 함수 타입 37 / 튜플 타입 37 / 유니언 타입 382.5 타입 변환과 승격 38__타입 변환 39 / 승격 40 / 사용자 정의 수 타입 41 CHAPTER 3 함수와 메서드 453.1 다중 디스패치 46__다중 디스패치 작동 방식 47 / 다중 디스패치 내부 구현 49 / 인수 타입별로 최적화된 메서드 정의 503.2 메서드 특화 51__컴파일 단계 52 / 복합 타입 인수 메서드의 특화 55 / 타입 시스템과 메서드 특화 573.3 성능 좋은 코드를 작성하는 법 57__스크립트 대신 함수 작성 57 / 타입 명시된 전역 변수 활용 58 / 배열의 원소 타입은 구체 타입으로 58 / 복합 타입의 필드 타입은 구체 타입으로 59 / 타입 안정성 지키기 59 CHAPTER 4 메타프로그래밍 634.1 코드의 데이터 표현 63__표현식 63 / 심벌 64 / 평가(실행) 65 / 내삽 654.2 코드 생성 654.3 매크로 68__매크로 예제 68 / 이스케이핑 69 / 다시 가위바위보 70 / 유용한 매크로 72 CHAPTER 5 다차원 배열 755.1 다차원 배열의 특징 75__열 우선 75 / 벡터화 불필요 785.2 다차원 배열의 사용법 80__배열 리터럴 및 생성 80 / 인덱싱 및 할당 82 / 브로드캐스팅 83 / 뷰 845.3 사용자 정의 배열 타입 84 CHAPTER 6 병렬 연산 876.1 멀티스레딩 876.2 멀티프로세싱 906.3 분산 컴퓨팅 926.4 CUDA GPU 활용 96 PART II 데이터 분석 도구 CHAPTER 7 재현 가능 환경 1037.1 패키지 관리자 1037.2 프로젝트 환경 관리 1067.3 환경 재현 108 CHAPTER 8 상호작용 환경 1118.1 IJulia.jl 1118.2 Pluto.jl 1138.3 구글 코랩 1148.4 비주얼 스튜디오 코드 116 CHAPTER 9 데이터 처리 도구 1179.1 Tables.jl 1179.2 DataFrames.jl 118__데이터프레임 생성 118 / 인덱싱 120 / 열 선택 및 변환 122 / 분할, 적용, 결합 123 / 팬더스와의 비교 1249.3 Query.jl 126 CHAPTER 10 시각화 도구 12910.1 Plots.jl 129__기본 사용법 129 / 백엔드 변경 132 / StatsPlots.jl 13310.2 Makie.jl 134 CHAPTER 11 데이터 처리 실습 13911.1 변수명 정정 14011.2 결측치 채우기 14111.3 분포 변환 145 PART III MLJ를 이용한 머신러닝 CHAPTER 12 워크플로 15112.1 데이터 준비 152__과학적 타입 153 / 데이터셋 분할 155 / 전처리 15612.2 모델 준비 157__모델 검색 157 / 모델 코드 로딩 159 / 모델 타입 체계 16012.3 학습, 예측, 평가 161__학습 161 / 예측 164 / 평가 측도 165 / 교차검증 16612.4 하이퍼파라미터 튜닝 167__튜닝 예제 168 / 조기 종료 171 CHAPTER 13 모델 합성 17313.1 데이터셋 준비 17313.2 파이프라인(합성 모델) 175__파이프라인 튜닝 176 / 셀프튜닝 모델들의 파이프라인 178 / 타깃 변환 17913.3 파이프라인(학습 네트워크) 180__프로토타이핑 180 / 학습 네트워크 내보내기 18313.4 배깅 186__EnsembleModel 187 / 학습 네트워크 188 / RandomForest 18913.5 스태킹 190__스태킹 과정 191 / 학습 네트워크 194 CHAPTER 14 비정형 데이터 19714.1 이미지 분류 197__데이터 정형화 198 / 다양한 모델 적용 19914.2 텍스트 분석 205__텍스트 전처리 206 / 텍스트 데이터의 특성 추출 208 / 학습 및 예측 211 PART IV 플럭스를 이용한 딥러닝 CHAPTER 15 자동 미분 21715.1 미분 구하는 방법 21715.2 미분 구현 실습 220__구현 1: 손 미분 220 / 구현 2: 수치 미분 220 / 구현 3: 기호 미분 221 / 구현 4: 자동 미분 222 / 15.3 플럭스의 자동 미분 227__자이곳 사용법 227 / 소스 코드 변환 방식 229 CHAPTER 16 플럭스 사용법 23516.1 데이터 준비 23616.2 모델 생성 237__가중치 초기화 238 / 사용자 정의 타입과 함자 23816.3 학습 및 테스트 240__모델 학습 함수 240 / 모델 테스트 함수 24216.4 전체 실행 242__손실 함수 및 옵티마이저 지정 243 / 에폭별 실행 243 / 모델 저장 및 로딩 24516.5 관련 패키지 246 CHAPTER 17 컴퓨터 비전 24917.1 합성곱 신경망 249__패션 아이템 분류 249 / 숫자 손글씨 분류 25317.2 전이 학습 253__데이터셋 준비 254 / 학습 및 테스트 함수 255 / 모델 정의 255 / 학습 및 테스트 25617.3 가짜 이미지 생성 258__사용자 정의 데이터셋 258 / 생성자와 판별자 261 / 훈련 26217.4 객체 탐지 265__객체 탐지 266 / 탐지 결과 그리기 267 CHAPTER 18 자연어 처리 27118.1 순환 신경망 271__셀과 래퍼 271 / 계층 273 / 손실 함수 정의 27418.2 문자열 생성 275__데이터셋 생성 276 / 모델 및 손실 함수 278 / 학습 및 문자열 생성 27918.3 텍스트 분류 280__데이터셋 준비 281 / 학습 및 테스트 함수 282 / 임베딩층 283 / 어텐션층 283 / 모델 정의 284 / 사전 학습된 임베딩 286 / 최종 결과 28618.4 트랜스포머 288__데이터셋 준비 및 학습, 텍스트 함수 288 / 모델 정의 288 / 학습 결과 290 / 정규화 순서 바꾸기 29118.5 BERT 292__텍스트 토큰화 292 / 특성 추출 294 / 분류 모델 정의 및 학습 29518.6 허깅페이스 296__BERT 기반의 모델 298 / GPT-2 299 / BART 300 PART V 심층 강화학습CHAPTER 19 강화학습 환경 30519.1 환경 사용법 30519.2 카트폴 환경 30719.3 사용자 정의 환경 309 CHAPTER 20 가치 기반 알고리즘 31320.1 기본 개념 313__정책, 궤적, 이득 313 / 기대이득, 최적정책 314 / 가치 함수: (최적) 상태, (최적) 행동 314 / 어드밴티지 함수 315 / 시간차 학습 315 / 활성 정책 vs 비활성 정책 317 / 탐험과 활용 317 / 타깃 네트워크 318 / 행동자-비평자 31820.2 DQN 318__경험 재현 버퍼 319 / 하이퍼파라미터 321 / 모델 정의 323 / 전체 실행 함수 325 / 행동 선택 함수 328 / 모델 훈련 함수 328 / 손실 함수 반환 함수 330 / 카트폴 결과 33120.3 DDPG 333__코드 구현 334 / 카트폴 결과 33620.4 SAC 337__코드 구현 338 / 카트폴 결과 342 CHAPTER 21 정책 기반 알고리즘 34321.1 기본 개념 343__정책 경사 343 / GAE 34521.2 A2C 346__롤아웃 버퍼 346 / 이득 및 GAE 계산 349 / 하이퍼파라미터 350 / 모델 정의 352 / 전체 실행 함수 354 / 행동 선택 함수 356 / 모델 훈련 함수 359 / 손실 함수 반환 함수 360 / 카트폴 결과 36121.3 PPO 364__코드 구현 366 / 카트폴 결과 36721.4 가치 기반과 정책 기반 알고리즘 비교 368 맺음말 370찾아보기 373  제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)  포스트  유튜브  인스타그램  트위터  페이스북window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1466}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기저작자표시 '도서 소개' 카테고리의 다른 글객체지향 파이썬  (0)2023.10.05나의 첫 HTML & CSS 웹 디자인  (2)2023.09.27핵심만 골라 배우는 SwiftUI 기반의 iOS 프로그래밍(개정증보판)  (0)2023.09.22인간 vs. AI 정규표현식 문제 풀이 대결  (0)2023.09.21실전 스프링 부트  (4)2023.09.13태그julia, nlp, 데이터과학, 데이터분석, 메타프로그래밍, 병렬, 시각화, 알고리즘, 전처리, 플럭스'도서 소개' Related Articles객체지향 파이썬나의 첫 HTML & CSS 웹 디자인핵심만 골라 배우는 SwiftUI 기반의 iOS 프로그래밍(개정증보판)인간 vs. AI 정규표현식 문제 풀이 대결Secret댓글달기loadedComments[1466]=true;findFragmentAndHighlight(1466);"
83,https://easyprogramming.tistory.com/entry/%ED%95%A9%EC%84%B1%ED%95%A8%EC%88%98-%EC%8B%A4%EC%83%9D%ED%99%9C-%ED%99%9C%EC%9A%A9-%EC%82%AC%EB%A1%80-%EC%98%88%EC%8B%9C,함수의 기본 개념과 역할,"이지프 분류 전체보기 (69)  프로그래밍 (16)  수학 (37)  IT (7)  티스토리 (9) 글작성방명록환경설정메뉴 닫기【합성함수】 실생활 활용 사례(예시) 8가지수학 / AIdev / 2024. 2. 7. 18:08반응형(adsbygoogle = window.adsbygoogle || []).push({});합성함수는 수학에서 일반적으로 사용되는 개념입니다. 간단히 말해서, 합성함수는 두 함수가 결합해서 새로운 함수를 형성하는 것입니다. 그러나 이 개념은 순수한 수학 이상의 적용 범위를 가지고 있습니다. 이 글에서는 합성함수가 우리 일상생활에서 어떻게 적용되는지 여러 가지 사례를 통해 알아보겠습니다.    목차         (adsbygoogle = window.adsbygoogle || []).push({});      합성함수 간단히 이해하기  함수의 기본 개념과 역할 함수라는 것은 '입력'이 들어오면 정해진 규칙에 따라 '출력'을 내놓는 관계를 말합니다. 함수는 일종의 '기계'라고 생각해볼 수 있어요. 예를 들어, 자판기는 돈(입력)을 넣으면 음료수(출력)를 주는 기계입니다. 이런 함수를 사용해서 우리 주변의 여러 가지 상황을 설명할 수 있어요. 예를 들면, 집의 가격이 면적, 위치, 건축 년도 등에 따라 어떻게 달라지는지를 함수로 표현해 볼 수 있습니다.  합성함수의 의미와 중요성 합성함수는 두 개 이상의 함수를 합쳐서 새로운 함수를 만드는 것을 말합니다. 이를테면, '함수의 함수' 같은 개념입니다. 많은 일들은 하나의 원인이 결과를 바로 만들어내지 않고, 여러 단계를 거쳐서 결과를 만들어냅니다. 예를 들면, 아침에 일어나서 학교에 가기까지 우리는 눈을 뜨고, 이를 닦고, 옷을 입고, 아침을 먹고, 등등 여러 가지 단계를 거쳐 학교에 도착하게 됩니다. 이렇게 복잡한 관계를 설명하고 이해하는 데 합성함수는 중요한 도구입니다.    합성함수의 실생활 활용 사례/예  스포츠에서의 합성함수   스포츠에서도 합성함수를 발견할 수 있습니다. 예를 들어, 어떤 운동 선수의 훈련 프로그램에서 첫 번째 단계(함수 A)가 그 선수의 체력을 향상시키고, 그 결과가 다음 단계(함수 B)인 기술 훈련의 효율성을 높이는 경우, 이러한 두 단계의 결합은 합성 함수로 볼 수 있습니다.   경제에서의 합성함수 경제 분야에서의 함성함수의 예제로는 소득과 소비 패턴 분석을 들 수 있습니다. 예를 들어 첫번째 단계의 함수A는 개인 또는 가구의 소득 수준을 결정합니다. 두 번째 단계(함수 B)는 이 소득 수준(A함수의 결과를)바탕으로 개인이나 가구의 소비 패턴을 분석하는 단계입니다. 즉 함수 A의 결과가 함수 B의 입력이 되고 이 합성함수는 개인이나 가구의 소득 수준이 어떻게 소비 패턴에 직접적인 영향을 미치는지 보여주는 합성 함수의 개념을 사용하는 것입니다.    온도 변화로 인한 옷차림 변화 예측  일기 예보 앱을 만들고 있다고 가정해 볼까요. 이 앱은 두 가지 중요한 작업을 합니다: 첫 번째 단계 (함수 A): 현재의 날씨 정보를 바탕으로 내일의 온도를 예측합니다. 여기서 함수 A는 ""날씨 정보를 입력으로 받아 내일의 온도를 알려주는 함수""입니다. 두 번째 단계 (함수 B): 내일의 온도를 바탕으로 적절한 옷차림을 추천합니다. 예를 들어, 온도가 낮으면 따뜻한 옷을, 온도가 높으면 가벼운 옷을 추천하는 식입니다. 여기서 함수 B는 ""온도를 입력으로 받아 적절한 옷차림을 알려주는 함수""입니다. 합성 함수로서의 의미 이제, 이 두 함수를 합쳐서 ""오늘의 날씨 정보를 바탕으로 내일 무엇을 입을지 추천해주는 함수""를 만들 수 있습니다. 이것이 바로 합성함수 B∘A입니다. 여기서: 함수 A는 오늘의 날씨로부터 내일의 온도를 예측합니다. 함수 B는 그 온도를 바탕으로 적절한 옷차림을 추천합니다. 즉, 우리는 오늘의 날씨 정보를 함수 A에 넣고, 함수 A의 결과(내일의 온도)를 함수 B에 넣어, 최종적으로 내일 무엇을 입을지에 대한 추천을 받게 됩니다.   사과 나무 관리로 더 많은 사과 얻기  당신은 사과 농장을 가지고 있고, 올해는 사과를 정말 많이 수확하고 싶은 상황이라고 가정해보겠습니다. 수확량을 예측하기 위해서 두 가지 중요한 함수를 활용하기로 결정했습니다. 첫 번째 단계 (함수 A): 기온과 비올 확률을 바탕으로 특정 기간 동안의 최적 성장 조건을 계산합니다. 이 함수는 기온과 강수량 데이터를 입력으로 받아, 이상적인 성장 조건을 충족하는 기간을 예측합니다. 두 번째 단계 (함수 B): 이상적인 성장 조건을 충족하는 기간을 바탕으로, 예상 사과 수확량을 계산합니다. 이 함수는 최적 성장 조건을 충족하는 기간을 입력으로 받아, 그에 따른 사과 수확량을 예측합니다. 여기서 B∘A는 ""기온과 비올 확률 데이터를 바탕으로 예상 사과 수확량을 계산하는 합성함수""가 됩니다. 즉, 초기 기상 데이터를 사용하여 최종적으로 사과 수확량을 예측하는 과정을 나타냅니다. 이렇게 수정된 예시는 합성함수의 개념을 명확하게 반영하며, 하나의 결과가 다음 단계의 입력으로 직접적으로 사용되는 사례를 보여줍니다.  온도 상승에 따른 대기질 변화 예측  여름이 되어 점점 더워지고 있다고 합니다. 이런 기온 상승이 공기에 어떤 변화를 줄지 궁금한 상황입니다. 이걸 알아보기 위해 합성함수를 사용해 보겠습니다. 첫 번째 단계 (함수 A) - 온도 예측하기: 여기서 우리는 ""여름이 얼마나 더워질까?""를 예측해봅니다. 마치 날씨 앱이 내일 얼마나 더울지 알려주는 것처럼, 우리는 오래 전부터 지금까지의 날씨 데이터 등을 통해 여름이 얼마나 더울지 예측해볼 수 있어요. 두 번째 단계 (함수 B) - 온도가 공기에 미치는 영향 알아보기: 이제, ""더워진 여름이 공기질에 어떤 영향을 줄까?""를 생각해봅니다. 예를 들어, 여름이 더워지면 특정 오염 물질이 더 활발하게 반응하여 공기 중에 오존이 더 많아질 수 있어요. 오존이 많아지면 공기질이 나빠질 수 있죠. 합성함수로서의 의미 B∘A: 첫 번째로, 온도가 얼마나 더워질지 예측하고(함수 A), 그 다음에 그 더워진 온도가 공기질에 어떤 변화를 줄지 알아보는(함수 B) 과정을 합쳐, 우리는 ""여름이 더워지면 공기는 어떻게 달라질까?""를 예측하는 합성 함수를 만들어 볼 수 있습니다.   돼지 저금통과 투자 게임   돈을 두 번에 걸쳐 투자하는 게임을 하고 있다고 가정해보겠습니다. 첫 번째 과정은 돼지 저금통에 돈을 저금하는 거고, 두 번째 과정은 그 돈을 가지고 더 큰 돈을 벌 수 있는 게임에 투자하는 것입니다. 이 두 과정을 함수로 설정하고 첫 번째 함수의 결과를 두 번째 함수의 입력으로 사용하는 합성함수로서 활용한다고 가정합니다. 첫 번째 단계 (함수 A) - 돼지 저금통에 돈을 넣기: 여기서, 당신은 용돈을 받거나 작은 일을 해서 번 돈을 돼지 저금통에 넣습니다. 저금통에 돈을 넣는 것이 우리의 '함수 A'예요. 예를 들어, ""한 달 동안 저금한 돈""이 될 수 있어요. 두 번째 단계 (함수 B) - 저금통의 돈으로 투자하기: 저금통에서 돈을 꺼내서, 그 돈으로 더 큰 돈을 벌 수 있는 게임에 투자합니다. 이 게임이 잘 되면, 당신은 투자한 돈보다 더 많은 돈을 돌려받게 되죠. 이 투자 과정이 우리의 '함수 B'입니다. 합성함수로서의 의미 합성함수 B∘A: 매우 단순한 함수가 되겠지만 특정기간 동안 일정금액을 돼지 저금통에 돈을 넣고(함수 A), 그 다음에 그 돈으로 투자를 해서 특정 이익률을 낸다고 가정(함수 B)해 보겠습니다. 이 두 과정이 합쳐져서 더 큰 돈을 얻는 과정으로 이어지는 것이죠. 두 함수를 정밀하게 설정해서 합성함수로 사용할 수 있다면 두 단계를 거쳐 최종적으로 얼마나 돈을 벌 수 있는지를 정말하게 계산할 수 있는 합성함수가 탄생할 것입니다.    학습 성취도와 건강 상태의 연결  학교에서의 성적이나 학습 성취도는 단지 공부 시간에 의해서만 결정되는 것이 아닙니다. 공부 시간, 가정 환경, 학교에서의 친구 관계, 심지어 건강 상태까지 여러 가지가 복잡하게 얽혀 있죠. 이런 모든 것들이 학생 한 사람의 성취도에 영향을 미칩니다. 그럼 이런 모든 것들을 어떻게 이해할 수 있을까요? 바로 '합성함수'의 개념이 도움이 됩니다. 예를 들어 아래의 두 함수를 활용해서 건강상태가 학습 성취도에 미치는 영향을 '모델링'해볼 수 있습니다. 첫 번째 단계 (함수 A): 학생의 건강 상태가 학습에 할애할 수 있는 시간에 어떤 영향을 미치는지 나타내는 함수입니다. 예를 들어, 건강 상태가 좋지 않으면 공부할 수 있는 시간이 줄어듭니다. 두 번째 단계 (함수 B): 가능한 공부 시간이 학습 성취도에 어떻게 영향을 미치는지를 나타내는 함수입니다. 예를 들어, 공부할 수 있는 시간이 많을수록, 더 많은 내용을 학습할 수 있고, 이는 성적 향상으로 이어집니다. 이 경우, 건강 상태(함수 A의 결과)가 공부할 수 있는 시간(함수 B의 입력)에 영향을 미치고, 이는 최종적으로 학습 성취도에 영향을 미칩니다. 이 과정을 합성함수 B∘A로 표현할 수 있으며, 이는 ""건강 상태가 학습 성취도에 미치는 영향""을 모델링했다고 볼 수 있습니다. 물론 이 두 함수만으로는 정확한 예측이 어렵다는 건 이미 느끼셨겠죠? 하지만 이런 함수들을 정교하게 설계하고 합성함수로 이을 수 있다면 점점 더 정확한 예측이 가능해질 것입니다.   인공지능 및 머신러닝에서의 합성함수  컴퓨터가 사진을 보고 그 안에 무엇이 있는지 알아내거나, 사람의 목소리를 듣고 그 말을 이해하는 것과 같은 일들을 하기 위해서는 어떻게 해야 할까요? 그건 바로 '합성함수'를 이용하는 딥러닝, 즉 깊은 학습이라는 기술을 사용하면 가능합니다. 딥러닝에서는 '활성화 함수'라는 여러 개의 작은 함수들이 합쳐져서 하나의 큰 함수를 만드는데요. 이 큰 함수를 이용해서 컴퓨터는 사진 속에 무슨 물체가 있는지 알아내거나, 사람의 목소리를 텍스트로 바꾸는 등의 일을 할 수 있게 됩니다. 예를 들어, 사진을 보고 그 안에 고양이가 있는지 없는지 알아내려면 어떻게 해야 할까요? 이를 위해서는 사진의 각 픽셀(사진을 구성하는 가장 작은 점)의 색상 정보, 위치 정보, 주변 픽셀과의 관계 등을 모두 고려해야 합니다. 이런 것들을 각각 하나의 작은 함수로 생각하고, 이들을 합성함수로 연결하면 컴퓨터는 사진 속에 고양이가 있는지를 판단할 수 있는 큰 함수를 만들 수 있게 됩니다. 이런 방식으로 합성함수를 이용하면, 컴퓨터는 사람처럼 복잡한 판단을 할 수 있게 됩니다. 이런 기술은 인공지능이나 머신러닝에서 매우 중요한 역할을 하며, 우리의 일상생활을 훨씬 더 편리하게 만들어 줍니다.   합성함수의 활용을 통한 문제 해결 실생활에서 발생하는 많은 문제들은 단순한 원인과 결과의 관계로 설명되지 않습니다. 이들은 다양한 요인들이 복잡하게 얽혀 있어, 그 관계를 이해하고 예측하는 데 합성함수가 필요합니다. 예를 들어, 농작물의 수확량을 증가시키려면 기후, 토양 상태, 병충해의 발생 가능성 등 다양한 요인을 동시에 고려해야 합니다. 이들 요인들을 각각 함수로 표현하고 합성함수를 통해 수확량을 예측하는 모델을 만들면, 효과적인 농업 전략을 수립할 수 있습니다.   합성함수 활용의 한계와 대안 합성함수의 활용은 많은 문제를 해결하는 데 도움을 주지만, 그 자체로 모든 문제를 해결할 수는 없습니다. 일부 복잡한 시스템에서는 여러 요인들이 비선형적으로 상호작용하는 경우가 많으며, 이는 단순한 합성함수로는 설명이 어렵습니다. 이런 경우에는 머신러닝이나 딥러닝 같은 고급 기법을 사용하여 문제를 해결하는 시도가 이어지고 있습니다.         (adsbygoogle = window.adsbygoogle || []).push({});     마무리 합성함수는 우리 일상생활에서 많은 현상을 설명하고 예측하는 데 유용하게 사용됩니다. 따라서 합성함수는 우리가 미래를 예측하고, 문제를 해결하며, 효과적인 전략을 수립하는 데 중요한 도구입니다. 이 글이 합성함수의 중요성과 활용 가능성을 이해하는데 조금이라도 도움이 되었으면 좋겠네요. 읽어주셔서 감사합니다.         (adsbygoogle = window.adsbygoogle || []).push({});    함께 읽으면 좋은 글  일차함수: 실생활 활용 사례(예시) 10가지수학은 자주 공포나 애증의 대상이 되기도 하지만 현대 사회에서는 일상생활에서 꼭 필요한 지식입니다. '일차함수'는 특히 수학이 아름답고 유용하다는 것을 잘 보여줄 수 있는 예시 중 하나입mathway.tistory.com 【함수의 극한】 실생활 활용 사례 예시 정리수학에 대한 대화가 나오면 많은 사람들이 '그게 왜 필요해?'라는 질문을 하곤 합니다. 그런데 오늘 우리가 이야기할 '함수의 극한'은 우리 삶에서 중요한 역할을 하는 개념입니다. 이 글에서는easyprogramming.tistory.com 【삼각함수】 실생활 활용 사례 15가지:다양한 응용 사례 탐구삼각함수는 고대 그리스 시대부터 수학의 한 분야로 연구되어 왔지만 지금도 많은 분야에서 중요한 역할을 하고 있습니다. 이 글에서는 삼각함수가 실생활에서 여떻게 응용되고 있는지 다양한easyprogramming.tistory.com 【이차방정식, 이차함수】실생활에 활용되는 사례 총정리이차방정식과 이차함수는 가장 많이 접하는 수학 지식 중 하나입니다. 이런 지식이 실생활에서 어떻게 활용되는지 안다면 다른 눈으로 이차방정식과 이차함수를 볼 수 있습니다. 그럼 이차방정easyprogramming.tistory.com 【함수】 실생활 활용 사례 정리함수는 집합과 집합의 관계를 표현하는데 쓸 수 있는 식입니다. 함수의 종류는 매우 다양하고 매우 광범위하게 활용되고 있습니다. 여기서는 여러 함수들이 실생활에서는 어떻게 활용되고 있는easyprogramming.tistory.com 【지수・로그 함수】 실생활 활용 사례 총정리지수함수는 그 크기에 비례해서 값이 증가하는 함수입니다. 크면 클수록 더 빨리 증가하고 작으면 작을수록 더 느리게 줄어드는 특성이 있습니다. 한국어에는 '기하급수적'이라는 말이 있는데easyprogramming.tistory.com 【생명과학 속 함수】 생물학이나 예비 의대생에게 필요한 함수 지식은?　최근의 생물학자나 의료전문가들에게는 수학적 사고가 요구되고 있습니다. 이미 많은 분야에서 그래프를 분석해야 하고 양적 정보를 해석할 필요가 있기 때문입니다. 그리고 명확한 논리적 패easyprogramming.tistory.com 【삼각함수】 의학 현장 속 활용 사례 정리삼각함수는 여러 영역에서 매우 넓게 쓰이고 있는 수학 지식입니다. 그렇다면 의학 분야에서는 어떨까요? 여기서는 의학에서 삼각함수가 활용되는 사례를 소개합니다. 푸리에 변환과 삼각함수easyprogramming.tistory.com 반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//easyprogramming.tistory.com/reaction';window.ReactionReqBody = {    entryId: 77}공유하기게시글 관리이지프저작자표시 비영리 변경금지 '수학' 카테고리의 다른 글【수학적 귀납법】 실생활 활용 사례(예시) 5가지  (0)2023.06.23【사이클로이드 곡선】실생활 활용 사례(예시) 6가지  (0)2023.06.21【집합】 실생활 활용 사례(예시) 12가지  (0)2023.06.16【명제】 실생활 활용 사례(예시) 10가지  (1)2023.06.13【정규분포】 실생활 활용 사례(예시) 9가지  (0)2023.06.12  function shareKakaotalk() {    Kakao.Link.sendScrap( {      requestUrl: location.href    } );  };     (adsbygoogle = window.adsbygoogle || []).push({});수학 관련 글【수학적 귀납법】 실생활 활용 사례(예시) 5가지2023.06.23【사이클로이드 곡선】실생활 활용 사례(예시) 6가지2023.06.21【집합】 실생활 활용 사례(예시) 12가지2023.06.16【명제】 실생활 활용 사례(예시) 10가지2023.06.13글 더보기 4댓글을 달아 주세요비공개댓글을 남겨주세요TistoryWhaleSkin3.4"">댓글 등록    setInitialEntryComments(77, 1723607261)loadedComments[77]=true;findFragmentAndHighlight(77);공지사항전체 카테고리 분류 전체보기 (69)  프로그래밍 (16)  수학 (37)  IT (7)  티스토리 (9) 최근 글최근 댓글최근 글【합성함수】 실생활 활용 사례(예시) 8가지 4【수학적 귀납법】 실생활 활용 사례(예시) 5가지 【사이클로이드 곡선】실생활 활용 사례(예시) 6가지 【집합】 실생활 활용 사례(예시) 12가지 【명제】 실생활 활용 사례(예시) 10가지 1【정규분포】 실생활 활용 사례(예시) 9가지 【사잇값 정리】 실생활 활용 사례(예시) 6가지  |  중간값 정리 3【쌍곡선】 실생활 활용 사례(예시) 14가지 1【공학】 확률과 통계 실생활 활용  사례(예시)  12가지 【수학】 확률과 통계 실생활 활용 사례(예시) 15가지 2최근댓글 05.20음악과 수열에서 흰 건반을 차례로 치면 같은 간격으로 음이 증가한다고 하⋯ㄱㅇ 05.20출처 알 수 있을까요? 05.08물건 비용 구매 최소화에 혹시 일차방정식 아닌가용??ㅇㅇ 05.07ㅋ 04.11ㄱㅅㅌㅂ1029 12.18화학반응이 더이상 일어나지않는것이 맞나요?>궁금 12.01크로드2 사용하다 보면 한도가 다 되었다고 나오는데~~이것은 일일 할당 ⋯따유리 라이텟라이텟 11.05어마어마 하네요....... 10.24지구 표면의 온도 분포에대한 논문의 출처가 궁금합니다!escdaddy 08.27크롬우측상단의 점3개를 누르면 나오는 메뉴창에 데스크톱사이트 항목 자체가⋯반응형(adsbygoogle = window.adsbygoogle || []).push({});Powered by Privatenote Copyright © 이지프 All rights reserved.TistoryWhaleSkin3.4/* 모바일 스크롤 */$('#btn_scroll_up').click(function() {$(document).scrollTop($('body').offset().top);});$('#btn_scroll_down').click(function() {if ($("".sidebar-mobile-off"").length >= 1) {$(document).scrollTop($(document).height());} else {$(document).scrollTop($('#sidebar').offset().top);}});/* 카테고리 번호 */var sc = $(""#sidebar .c_cnt"");sc.length > 0 && sc.each(function() {$(this).html($(this).html().replace(/[()]/g, """"))})/* 댓글 */$(document).on('click', '.cmtbtn', function(e) {$(this).parent().children('.cmt_dropdown').fadeToggle(""middle"");if ($(this).parent().children('.cmt_dropdown').hasClass(""active"")) {$(this).parent().children('.cmt_dropdown').removeClass(""active"");} else {$(this).parent().children('.cmt_dropdown').addClass(""active"");}});$(document).on('click', '.cmt_dropdown li a', function(e) {$(this).parent().parent().fadeToggle(""middle"");});/* 메뉴  */$("".btn_topMenu"").on('click', function() {$(""#myDropdown"").fadeToggle('middle');if ($(window).width() <= 930) {$(""#tt-search"").attr(""style"", ""display:block !important"");}if ($(""#myDropdwon"").hasClass(""active"")) {$(""#myDropdown"").removeClass(""active"");} else {$(""#myDropdown"").addClass(""active"");}});$('body').on('click', function(e) {$('.cmt_dropdown').each(function() {if ($(this).hasClass(""active"")) {$(this).removeClass(""active"");$(this).fadeOut();}});});$('.closeBtn').click(function() {$('#myDropdown').fadeOut();if ($(window).width() <= 930) {$(""#tt-search"").css(""display"", ""none"");}});$(window).resize(function() { if($(window).width() > 930) {} });/* 사이드바 탭 분류 */$(""#recent-tab li"").click(function() {$(""#recent-tab > li"").removeClass(""active"");$(this).addClass(""active"");$("".tab-content .tab-pane"").removeClass(""active"");$($(this).attr(""id"")).addClass(""active"");});/* 복사 방지, 개발자 도구 방지 */$(document).keydown(function(event) {if (event.keyCode == 123) { // Prevent F12return false;} else if (event.ctrlKey && event.shiftKey && event.keyCode == 73) { // Prevent Ctrl+Shift+I        return false;} else if (event.ctrlKey && (event.keyCode === 67 ||event.keyCode === 86 ||event.keyCode === 85 ||event.keyCode === 117)) {return false;}});if(!wcs_add) var wcs_add = {};wcs_add[""wa""] = ""14f245dfd656450"";if(window.wcs) {  wcs_do();}$(function(){$(""#toc"").toc( {content: "".e-content"", headings: ""h2,h3"" , top: -90, isBlink : true, blinkColor : '#21B9DE' } )});티스토리툴바hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4965424-77"",""customProps"":{""userId"":""0"",""blogId"":""4965424"",""entryId"":""77"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""77"",""entryTitle"":""【합성함수】 실생활 활용 사례(예시) 8가지"",""entryType"":""POST"",""categoryName"":""수학"",""categoryId"":""1031833"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""3738615"",""authorNickname"":""AIdev"",""blogNmae"":""이지프"",""image"":""kage@dyKKJX/btskQP6z25B/RzaNhqnRUp0KC28q9G0fC1"",""plink"":""/entry/%ED%95%A9%EC%84%B1%ED%95%A8%EC%88%98-%EC%8B%A4%EC%83%9D%ED%99%9C-%ED%99%9C%EC%9A%A9-%EC%82%AC%EB%A1%80-%EC%98%88%EC%8B%9C"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
84,https://jpub.tistory.com/695,태그,"도서 소개텐서플로로 시작하는 딥러닝 제이펍2017. 7. 18. 18:44 이 책은 현재 절판입니다. 그간 읽어주신 독자들께 감사드립니다.텐서플로를 이용하여 ‘합성곱 신경망(CNN)’의 구조를 완벽히 이해한다! 출판사 제이펍원출판사 마이나비출판(マイナビ出版)원서명 TensorFlowで学ぶディープラーニング入門(원서 ISBN: 9784839960889) 저자명 나카이 에츠지역자명 진명조출판일 2017년 7월 12일페이지 256쪽시리즈 I♥A.I. 05판 형 46배판변형(188*245*13)제 본 무선(soft cover)정 가 24,000원ISBN 979-11-85890-87-6 (93000)키워드 인공지능 / 딥러닝 / 심층학습 / 머신러닝 / 신경망 / 텐서플로분야 컴퓨터공학 / 인공지능 관련 사이트■ 아마존재팬 도서 소개 페이지■ 원출판사 도서 소개 페이지■ 원서 도서 지원 페이지 관련 포스트■ 2017/06/30 - [출간전 책소식] - 인공지능, 데이터 분석 전문가가 아닌 분들을 위한 딥러닝 서적  관련 시리즈■ I♥A.I 시리즈 관련 도서■ 그림과 수식으로 배우는 통통 딥러닝■ 엑셀로 배우는 인공지능■ 알고리즘 중심의 머신러닝 가이드(제2판)■ 딥러닝 제대로 시작하기■ 머신러닝 인 액션: 기계 학습 알고리즘으로 데이터 마이닝하기■ 인공지능 1: 현대적 접근 방식(제3판)■ 인공지능 2: 현대적 접근 방식(제3판) 관련 파일 다운로드■ 예제 소스■ 텐서플로 최신 버전(v 1.2) 지원 가이드(pdf)   강의보조 자료교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표 샘플 PDF(차례, 머리말, 감사의 글, 이 책에 대하여, 베타리더 후기, 1장 1.1절 '딥러닝과 텐서플로') 텐서플로로시작하는딥러닝_sample.pdf 정오표 페이지■ (등록되는 대로 링크를 걸어드리겠습니다) 도서구매 사이트(가나다순)[강컴] [교보문고] [도서11번가] [반디앤루니스] [알라딘] [예스이십사] [인터파크] 도서 소개텐서플로를 이용하여 ‘합성곱 신경망(CNN)’의 구조를 완벽히 이해한다! 이 책은 머신러닝과 데이터 분석을 제대로 배운 적이 없는 개발자를 대상으로 한다. 딥러닝의 대표적 예인 ‘합성곱 신경망(CNN)’의 구조를 근본부터 이해하고, 텐서플로를 이용해 실제로 동작하는 코드를 작성하는 것이 이 책의 목표다. 그리고 다수의 뉴런이 여러 층 결합된 ‘다층 신경망’ 내에서 대체 무슨 일이 일어나는지, 딥러닝 알고리즘은 어떤 원리로 학습하는지를 알려 준다. 딥러닝의 밑바닥에는 머신러닝의 원리가 있는데, 간단한 행렬 계산과 기초적인 미분을 알면 그 구조를 이해하기가 그리 어렵지 않다. 이 책은 필기 문자를 인식하도록 처리하는 합성곱 신경망에 대해, 그리고 이를 구성하는 각 요소의 역할을 신중하게 설명한다. 또한, 딥러닝의 대표 라이브러리인 텐서플로를 이용해 실제로 동작하는 코드를 보여줌으로써 각 요소의 동작 원리를 확인할 수 있도록 구성되어 있다. 레고 블록을 끼워 맞추듯이 네트워크 구성 요소를 늘려 감으로써 인식 정확도가 향상되는 모습을 관찰할 수 있을 것이다. 부디 이 책을 통해 딥러닝의 근본 원리를 이해하고 텐서플로 코드 작성법을 학습하여 다음 단계로 도약하는 계기가 되길 바란다. 이 책의 대상 독자머신러닝, 데이터 분석 전문가는 아니지만 AI 기술에 관심이 있는 분딥러닝 알고리즘이 어떻게 구성되어 있는지 알고 싶은 분텐서플로 공식 예제 코드를 제대로 활용하기 어려운 분 저자 소개나카이 에츠지(中井 悦司)1971년 4월 오사카에서 태어났다. 노벨 물리학상을 타고 싶어서 이론물리학 연구에 몰두하며 학창시절을 보냈다. 그리고 대학 입시학원 강사 등 여러 직업을 거쳐 외국계 기업의 리눅스 엔지니어로서 유닉스/리눅스 서버와 인생을 함께하게 되었다. 리눅스 에반젤리스트를 거쳐 현재는 대형 검색 시스템 기업에서 클라우드 및 솔루션 아키텍터로 일하고 있다.휴일에는 사랑스러운 초등학생 딸과 스포츠 센터에 수영하러 다니는 ‘좋은 아빠’로 동네에서 유명하다. ‘세계 평화’를 위해 일찍 집에 들어가려고 애쓰면서도 가끔은 각별히 사랑하는 변두리 선술집에 자신도 모르게 들르기도 한다. 요즘에는 머신러닝 이론을 비롯한 데이터 활용 기술에 관한 기초 지식을 세상에 널리 알리기 위해 강연 활동 및 잡지 기고나 서적 집필에도 주력하고 있다. 역자 소개진명조현재 씨디네트웍스에 근무하고 있으며, 《서버/인프라 엔지니어를 위한 DevOps》, 《서버/인프라를 지탱하는 기술》, 《파이썬 더 쉽게, 더 깊게》, 《대규모 서비스를 지탱하는 기술》, 《클라우드의 충격》, 《인프라 엔지니어의 교과서: 시스템 구축과 관리편》을 포함하여 13종의 기술 서적을 번역하였다. IT 산업의 미시적인 영역과 거시적인 영역을 아우르는 통찰력을 갖게 되기를 꿈꾸고 있으며, 최근에는 머신러닝을 비롯한 인공지능(AI)의 대중화에 주목하고 있다. 차례CHAPTER 1 텐서플로 입문 11.1 딥러닝과 텐서플로 4 1.1.1 머신러닝의 개념 4 1.1.2 신경망의 필요성 7 1.1.3 딥러닝의 특징 13 1.1.4 텐서플로를 이용한 파라미터 최적화 161.2 환경 준비 24 1.2.1 CentOS 7에서의 준비 과정 25 1.2.2 주피터 사용법 281.3 텐서플로 훑어보기 33 1.3.1 다차원 배열을 이용한 모델 표현 33 1.3.2 텐서플로 코드를 이용한 표현 35 1.3.3 세션을 이용한 트레이닝 실행 39더보기CHAPTER 2 분류 알고리즘의 기초 472.1 로지스틱 회귀를 이용한 이항 분류기 49 2.1.1 확률을 이용한 오차 평가 49 2.1.2 텐서플로를 이용한 최우추정 실행 54 2.1.3 테스트 세트를 이용한 검증 652.2 소프트맥스 함수와 다항 분류기 69 2.2.1 선형 다항 분류기의 구조 69 2.2.2 소프트맥스 함수를 이용한 확률로의 변환 732.3 다항 분류기를 이용한 필기 문자 분류 76 2.3.1 MNIST 데이터 세트 이용 방법 76 2.3.2 이미지 데이터의 분류 알고리즘 79 2.3.3 텐서플로를 이용한 트레이닝 실행 84 2.3.4 미니 배치와 확률적 경사 하강법 90 CHAPTER 3 신경망을 이용한 분류 953.1 단층 신경망의 구조 97 3.1.1 단층 신경망을 이용한 이항 분류기 97 3.1.2 은닉 계층의 역할 100 3.1.3 노드 개수와 활성화 함수 변경에 따른 효과 1103.2 단층 신경망을 이용한 필기 문자 분류 113 3.2.1 단층 신경망을 이용한 다항 분류기 113 3.2.2 텐서보드를 이용한 네트워크 그래프 확인 1163.3 다층 신경망으로의 확장 124 3.3.1 다층 신경망의 효과 124 3.3.2 특징 변수에 기반한 분류 로직 128 3.3.3 보충: 파라미터가 극솟값으로 수렴하는 예 133 CHAPTER 4 합성곱 필터를 통한 이미지 특징 추출 1374.1 합성곱 필터의 기능 1394.1.1 합성곱 필터의 예 1394.1.2 텐서플로를 이용한 합성곱 필터 적용 1424.1.3 풀링 계층을 이용한 이미지 축소 1504.2 합성곱 필터를 이용한 이미지 분류 1534.2.1 특징 변수를 이용한 이미지 분류 1534.2.2 합성곱 필터의 동적인 학습 1594.3 합성곱 필터를 이용한 필기 문자 분류 1634.3.1 세션 정보의 저장 기능 1634.3.2 단층 CNN을 이용한 필기 문자 분류 1654.3.3 동적으로 학습된 필터 확인 171 CHAPTER 5 합성곱 필터의 다층화를 통한 성능 향상 1775.1 합성곱 신경망의 완성 179 5.1.1 다층형 합성곱 필터를 이용한 특징 추출 179 5.1.2 텐서플로를 이용한 다층 CNN 구현 184 5.1.3 필기 문자의 자동 인식 애플리케이션 1895.2 그 밖의 주제 195 5.2.1 CIFAR-10(컬러 사진 이미지) 분류를 위한 확장 195 5.2.2 ‘A Neural Network Playground’를 이용한 직감적 이해 199 5.2.3 보충: 오차 역전파법을 이용한 기울기 벡터 계산 204 APPENDIX 부록 213A 맥OS와 윈도우에서의 환경 준비 방법 214A.1 맥OS의 환경 준비 과정 214A.2 윈도우10의 환경 준비 과정 218 B 파이썬 2의 기본 문법 225B.1 Hello, World!와 자료형, 연산 225B.2 문자열 226B.3 리스트와 딕셔너리 228B.4 제어구문 230B.5 함수와 모듈 233C 수학 공식 235 찾아보기 237 window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 695}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글인프라/네트워크 엔지니어를 위한 네트워크 디자인 패턴 가이드  (0)2017.08.02인공지능 70: 재미있게 알아보는 AI 키워드  (0)2017.07.25개발자를 위한 PL/SQL 프로그래밍  (0)2017.07.04그림과 수식으로 배우는 통통 딥러닝  (0)2017.06.30논쟁적 UX: 아이폰 국내 출시 10년, 대한민국 UX를 되짚어 보다  (0)2017.06.13태그Artificial Intelligence, cnn, deep learning, Machine Learning, 기계학습, 니카이에츠지, 딥러닝, 머신러닝, 신경망, 심층학습, 아이러브인공지능, 인공지능, 제이펍, 진명조, 텐서플로'도서 소개' Related Articles인프라/네트워크 엔지니어를 위한 네트워크 디자인 패턴 가이드인공지능 70: 재미있게 알아보는 AI 키워드개발자를 위한 PL/SQL 프로그래밍그림과 수식으로 배우는 통통 딥러닝    setInitialEntryComments(695, 1723627687)Secret댓글달기loadedComments[695]=true;findFragmentAndHighlight(695);"
85,https://huidea.tistory.com/130,"1. 잠재디리클레할당(Latent Dirichlet Allocation, LDA)","Study/Machine learning[Machine learning] 잠재디리클레할당 (day3 / 201012)by 후이 (hui)2020. 10. 12.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});오늘의 질문 ! 텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? 거기서 어떤 장점이 발생했나요?다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요. Q. 텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요? 토픽 모델링을 해야한다. 토픽 모델링에는 다양한 기법이 있지만 그중 가장 기초적인 기법 부터 하나씩 살펴보자면 ~  1. 잠재디리클레할당(Latent Dirichlet Allocation, LDA): LDA는 문서들은 토픽들의 혼합으로 구성되어져 있으며, 토픽들은 확률 분포에 기반하여 단어들을 생성한다고 가정  데이터가 주어지면, LDA는 문서가 생성되던 과정을 역추적 (wikidocs.net/30708) 1.1 기본 개념 ex. 문서1 : 저는 사과랑 바나나를 먹어요문서2 : 우리는 귀여운 강아지가 좋아요문서3 : 저의 깜찍하고 귀여운 강아지가 바나나를 먹어요 --> LDA는 각 문서의 토픽 분포와 각 토픽 내의 단어 분포를 추정!  <각 문서의 토픽 분포>문서1 : 토픽 A 100%문서2 : 토픽 B 100%문서3 : 토픽 B 60%, 토픽 A 40% <각 토픽의 단어 분포> --> 토픽의 개수 유사도 혼란도를 기반으로 사람이 지정토픽A : 사과 20%, 바나나 40%, 먹어요 40%, 귀여운 0%, 강아지 0%, 깜찍하고 0%, 좋아요 0%토픽B : 사과 0%, 바나나 0%, 먹어요 0%, 귀여운 33%, 강아지 33%, 깜찍하고 16%, 좋아요 16%  사람이 임의로 토픽의 수를 정하고, LDA 는 문서 내의 토픽 분포 확률과 토픽 내의 단어 분포 확률을 추정( 이때 쓰는 분포가 디리클레 분포 )  1.2 학습 진행 방법 1) 토픽 4개라고 임의로 지정한다면, 2) 모든 문서에서 토큰을 끊고 토픽 네개로 랜덤하게 할당    "" I am a boy "" 첫문장이 이거였다면,  ""I"" ""am""  ""a""  ""boy"" 각각을 1,2,3,4 토픽으로 처음에 임의로 할당해버림 3) 이렇게 전체 단어를 특정 토픽에 임의로 할당해놓고 이터레이션을 돌리며 학습을 진행하는 것   3.1 ) 학습 방식은 ""am""  ""a""  ""boy"" 가 제대로  할당 되었다는 가정을 하고 ""I"" 가 어디에 할당 되면 좋을 지 추정 !      - p(topic t | document d) : 문서 d의 단어들 중 토픽 t에 해당하는 단어들의 비율     - p(word w | topic t) : 단어 w를 갖고 있는 모든 문서들 중 토픽 t가 할당된 비율 (1)  두 개의 문서 doc1과 doc2를. 여기서는 우리는 doc1의 세번째 단어 apple의 토픽을 결정하고자 함 (2) 우선 첫번째로 사용하는 기준은 문서 doc1의 단어들이 어떤 토픽에 해당하는지를 확인 ==> p(topic t | document d)doc1의 모든 단어들은 토픽 A와 토픽 B에 50 대 50의 비율로 할당되어져 있으므로, 이 기준에 따르면 단어 apple은 토픽 A 또는 토픽 B 둘 중 어디에도 속할 가능성이 있음 (3) 두번째 기준은 단어 apple이 전체 문서에서 어떤 토픽에 할당되어져 있는지 확인  ==> p(word w | topic t)       이 기준에 따르면 단어 apple은 토픽 B에 할당될 가능성이 높음    ==> 이러한 두 가지 기준을 참고하여 LDA는 doc1의 apple을 어떤 토픽에 할당할지 결정!!!  1.3 특징 !!!! (중요) 1) 잠재 디리클레 할당과, 잠재 의미 분석의 차이 (맨날 헷갈림) 잠재 디리클레 할당은 디리클레 확률로 문서중 토픽비율, 토픽중 단어 비율로 계산잠재 의미 분석은 DTM (document term matrix) 에  SVD 로 차원축소 한후 근접단어 토픽 묶기  2) 잠재 디리클레 할당은 단어의 순서와 상관이 없다. 단지 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하기 때문에  3) 디리클레 분포 추론 과정에서 깁스 샘플링을 이용하게 된다. (형이 거기서 왜나와?)techblog-history-younghunjo1.tistory.com/87 [ML] Topic Modeling(토픽 모델)인 LDA(Latent Dirichlet Allocation)※해당 게시물에 사용된 일부 자료는 순천향대학교 빅데이터공학과 정영섭 교수님의 머신러닝 전공수업 자료에 기반하였음을 알려드립니다. 이번 포스팅에서는 Clustering의 방법 중 하나이며 비techblog-history-younghunjo1.tistory.com  ==> 수식을 뜯어보면 결국     1) 우리는 사후확률(posterior) p(z,ϕ,θ|w)를 최대로 만드는 z,ϕ,θ를 찾아야 함.      2) 사후확률을 구하려면 결국 분모인  p(w)를 구해야함           ( 사후확률은 베이즈 정리에서 evidence 부분 즉, 잠재변수 z,ϕ,θ의 모든 경우의 수를 고려한 각 단어(w)의 등장 확률 )     3) 하지만 잠재변수 z,ϕ,θ를 모두 관찰하는 게 불가능 따라서 ==> 깁스 샘플링 사용.  자세한 내용은 ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/ Topic Modeling, LDA · ratsgo's blog이번 글에서는 말뭉치로부터 토픽을 추출하는 토픽모델링(Topic Modeling) 기법 가운데 하나인 잠재디리클레할당(Latent Dirichlet Allocation, LDA)에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강��ratsgo.github.io   참고한 내용 출처  :www.youtube.com/watch?v=noWKlkdcY6Awikidocs.net/30708 728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//huidea.tistory.com/reaction';window.ReactionReqBody = {    entryId: 130}공유하기게시글 관리데이터 분석가 후이저작자표시 'Study > Machine learning' 카테고리의 다른 글[Machine learning] ROC 와 ROC-AUC 평가 방법 (Confusion matrix, Recall, Precision, TPR, FPR, Threshold)  (0)2020.11.10[Machine learning] 나이브베이즈확률, 나이브베이즈모델 (day4 / 201013)  (0)2020.10.14[Machine learning] Markov Chain, Gibbs Sampling, 마르코프 체인, 깁스 샘플링 (day2 / 201010)  (0)2020.10.10[Machine learning] 차원축소, PCA, SVD, LSA, LDA, MF 간단정리 (day1 / 201009)  (0)2020.10.10[Machine learning] PCA(주성분분석), LDA(선형판별분석법), SVD (행렬분해) (쉽게 설명하는 차원 축소 기법들 총정리 part2)  (0)2020.08.06관련글[Machine learning] ROC 와 ROC-AUC 평가 방법 (Confusion matrix, Recall, Precision, TPR, FPR, Threshold)[Machine learning] 나이브베이즈확률, 나이브베이즈모델 (day4 / 201013)[Machine learning] Markov Chain, Gibbs Sampling, 마르코프 체인, 깁스 샘플링 (day2 / 201010)[Machine learning] 차원축소, PCA, SVD, LSA, LDA, MF 간단정리 (day1 / 201009)댓글0비밀글등록loadedComments[130]=true;findFragmentAndHighlight(130);"
86,https://cia-secu-lock.tistory.com/m/82,2/23 업무일지,"신입일기(웹툰예정)2/23 업무일지CIA_secu 2022. 2. 23. 09:11     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90SMALL오늘 할 일client 테스팅용 만들기 - openssl 적용 rsa와 정해진 패킷을 보내기, 오디오 파일 패킷 센드는 이후 구현하여도 될 듯client 파일이 언제 위치하는 것이 좋은지> 나중에라도 할 일 코드끼리의 연결성 정리하기신입 첫 직장 선택, 조언이 필요합니다...안녕하세요, 저는 비전공자에 얼마 전 부트캠프를 수료한 신입입니다.희망 직군은 머신러닝 엔지니어인데 머신러닝 쪽이 기본 석사부터 요구하는 곳이 많다 보니 일단은 백엔드도 가리지 않고 여러 회사에 지원을 하고 있었습니다. 그러던 중 얼마 전 지인이 회사 한 곳을 소개 시켜줘서 인터뷰를 보고 왔었네요.가보니 자체 서비스를 준비하면서 현재는 딥러닝 관련 정부 R&D 과제를 수행하고 있는 중소기업이더라고요. 면접 느낌보다도 거의 서로 편하게 소개하는 식으로 대화가 오갔고 대표분이 열심히 회사 비전을 설명해주기는 했는데 사실 크게 공감이 가지는 않았습니다;; 지인이 소개해 준 곳이었기에 가볍게 인터뷰 경험 쌓는다 생각하면서 있다가 나왔고, 그 뒤로 큰 기대는 하지 않고 있었습니다. 그런데 오늘 대표에게 연락이 와서 연봉 4,000에 같이 일할 생각이 없냐고 하네요. 제 스펙에 사실 높은 연봉을 기대하지 않고 있었고 지금까지 지원했던 회사들의 신입 연봉이 많아야 3,500 정도였기 때문에 제안을 듣고나니 솔직히 조금 혹 하면서 조건들을 다시 따져보게 됩니다...구직을 하면서 나름 세웠던 기준은 제대로 된 사수 밑에서 배우면서 성장할 수 있는 회사였는데, 이 곳은 아마 제가 가게 되면 저랑 거의 비슷한 수준의 동료 한 명 정도만 상시로 일하게 될 것 같습니다... 대신 주 2~3회씩만 출근하는 CTO와 기술 고문이 있고 이 분들이 실무를 어느 정도 같이 맡아서 진행하는데 지인의 말에 따르면 이 분들이 실력도 좋고 배울 수 있는 것들도 많을 거라고는 하네요.그리고 머신러닝 엔지니어 포지션이 대부분 경력 또는 고스펙을 요구하는데 제가 신입으로 일할 수 있다는 점도 매력적으로 느껴집니다. 머신러닝 엔지니어를 신입으로 뽑지 않는데에는 물론 이유가 있겠지만 그럼에도 커리어 시작을 제가 원하는 개발 분야에서 바로 할 수 있고 연봉도 높게 시작할 수 있다고 하니 다른 단점들이 잘 안 보이게 되는 것 같습니다...저를 소개시켜 준 지인도 파트 타임으로 그 곳에서 일하다가 나온 분인데, 그 분 말로는 작은 회사지만 사람들도 다 괜찮고 야근도 없다고 합니다. 다만 정부과제 위주로 회사가 운영되다 보니 아무래도 좀 불안정한 면이 있고 이직할 때 내세울만한 결과물을 기대하긴 어렵다보니 본인도 소개해주면서 고민을 했다고는 하네요. 선배 개발자님들이 객관적으로 보시기에는 어떤가요? 연봉은 조금 덜 받더라도 더 안정적이고 비전이 있는 곳을 첫 직장으로 갖는 것이 더 좋을까요? 정부과제를 주 업무로 하면서도 개발자로서의 능력을 키울 수 있을까요?이런 질문들 정말 많이 올라오겠지만 혼자 검색해보고 고민하는 걸로는 답이 안 나오고 제 상황에 딱 맞는 조언이 절실해서 글 올려봅니다. 의견 주시면 정말 감사하겠습니다ㅠㅠ왜 ML 직군이 고학력을 요구할까요? 이 질문에 대한 답변을 한번쯤 생각해보셨나요?제가 생각하는 답변은 이 직군은 연구직이기 때문입니다.대학원에서 이런저런 연구를 하면서 연구에 필요한 방법론, 경험 등을 쌓구요.물론, AI/ML이 다른 분야에 비해 요구하는 기반 지식도 많습니다.백엔드 국비 6개월도 택도 없는 기간인데 AI/ML을 6개월 정도의 과정으로 한다? 납득이 가지 않습니다.그리고 정부과제 위주로 돌아가는 스타트업... 이름만 스타트업이지 SI랑 다를게 없어요.당장 높아보이는 연봉에 혹해서 들어갔다가 이도저도 아닌 일만 하다가 나올 가능성이 커보입니다.백엔드 개발을 하면 사이드 프로젝트 + 업무 경력으로 어필이라도 될텐데이런 과정으로 쌓은 경력은 정말 아무런 의미가 없을 가능성이 높습니다.https://www.boannews.com/media/view.asp?idx=104907  암호화폐와 탈중앙화 금융이 부딪힌 벽, 의외로 높다금융 업계는 현재 변혁의 속도를 높여가는 중이다. 그러면서 계속해서 새로운 보안 위협들이 등장하고 있고, 새로운 보호의 방법들이 고안되는 상황이다. 그런 와중에 예전 해킹 기술들을 새로www.boannews.com핀테크 기술이 많은 관심을 받기 시작하면서 암호화폐나 탈중앙화 금융이 차세대 주류 금전 거래의 수단으로 자리를 잡을 수 있을 것인가에 대한 논란도 계속해서 나오고 있다. 지금 상태 그대로는 불가능해 보이는 것이 사실이지만 아직 초기 단계에 있기 때문에 단정하기는 힘들다.이번 달 미국 사법부는 2016년 비트피넥스(Bitfinex) 해킹 사건에 연루된 용의자들을 체포했다. 이들은 당시 수십억 달러에 해당하는 비트코인을 훔쳐냈던 것으로 알려져 있다. 올해 1월만 하더라도 8천만 달러 규모의 암호화폐가 큐빗 파이낸스(Qubit Finance)라는 탈중앙화 암호화폐 거래소에서 사라지기도 했었다. 게다가 양자 컴퓨터 기술이 발전하면 암호화폐와 블록체인을 안전하게 보호해 주는 암호화 기술을 단박에 무력화시킬 것이라는 예측도 나오고 있는 상황이다.그러니 암호화폐, 탈중앙화 금융 등 미래에 대세가 될지 모르는 화폐와 신기술들의 안전성에 대한 의문이 제기될 수밖에 없다. 하지만 이것이 핀테크와 암호화폐를 완전히 가치 없는 기술로 전락시키지도 않는다. 암호화폐나 기타 여러 가지 핀테크를 벌써부터 비판하고 포기할 필요는 없다.시장 조사 업체 포레스터(Forrester)의 수석 분석가인 안드라스 체르(Andras Cser)는 “양자 컴퓨터가 블록체인과 암호화폐를 근본부터 흔들 가능성은 이론적으로 충분해 보인다”고 말한다. “하지만 아직 양자 컴퓨터는 언제 나올지도 모르는 기술입니다. 벌써부터 걱정하기에는 일러도 한참 이릅니다. 공공 키 암호화 알고리즘를 실제로 무력화시킬 만한 양자 컴퓨터가 나오려면 몇 년 더 걸릴 겁니다.”그러면서 체르는 “현재 암호화폐들은 매우 불안정한 상태”라고 지적한다. “이 역시 암호화폐가 가지고 있는 가장 큰 문제 중 하나입니다. 아직까지 암호화폐를 적극적으로 도입하려는 정부는 하나도 없다고 봐도 무방하고, 그렇기 때문에 언제 사라져도 이상하지 않습니다. 게다가 실질적인 경제적 결과물을 산출하지도 못하고 있죠. 오히려 환경에도 심각한 손상을 주는 채굴 행위만 수반할 뿐이죠. 정부가 지원도 안 해, 환경에도 해악적이야, 경제적 가치도 0에 가까우니 사실 지금까지 유지되는 게 신기할 정도입니다.728x90LIST저작자표시 비영리 변경금지"
87,https://bcho.tistory.com/1177,파이프라인 개발 프로세스,"                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝머신러닝 시스템 프로세스와 아키텍쳐Terry Cho2017. 6. 10. 14:11Machine Learning Pipeline조대협 (http://bcho.tistory.com)대부분 모델 개발과 알고리즘에 집중머신러닝을 공부하고 나서는 주로 통계학이나, 모델 자체에 많은 공부를 하는 노력을 드렸었다. 선형대수나 미적분 그리고 방정식에 까지 기본으로 돌아가려고 노력을 했었고, 그 중간에 많은 한계에도 부딪혔지만, 김성훈 교수님의 모두를 위한 딥러닝 강의를 접하고 나서, 수학적인 지식도 중요하지만 수학적인 깊은 지식이 없어도 모델 자체를 이해하고 근래에 발전된 머신러닝 개발 프레임웍을 이용하면 모델 개발이 가능하다는 것을 깨달았다. 계속해서 모델을 공부하고, 머신러닝을 공부하는 분들을 관심있게 지켜보고 실제 머신러닝을 사용하는 업무들을 살펴보니 재미있는 점이 모두 모델 자체 개발에만 집중한다는 것이다. 커뮤니티에 올라오는 글의 대부분은 어떻게 모델을 구현하는지 어떤 알고리즘을 사용하는지에 대한 내용들이 많았고, 실 업무에 적용하는 분들을 보면 많은 곳들이 R을 이용하여 데이타를 분석하고 모델링을 하는데, 데이타를 CSV 파일 형태로 다운 받아서 정재하고 데이타를 분석하고 모델을 개발하는 곳이 많은 것을 보았다. 데이타의 수집 및 전처리 및 개발된 모델에 대한 서비스에 대해서는 상대적으로 많은 정보를 접하지 못했는데, 예상하기로 대부분 모델 개발에 집중하기 때문이 아닌가 싶다.  엔지니어 백그라운드를 가진 나로써는 CSV로 데이타를 끌어다가 정재하고 분석하는 것이 매우 불편해 보이고 이해가 되지 않았다. 빅데이타 분석 시스템에 바로 연결을 하면, CSV로 덤프 받고 업로드 하는 시간등에 대한 고민이 없을텐데.” 왜 그렇게 할까 ?”라는 의문이 계속 생기기 시작하였다. 미니 프로젝트를 시작하다이런 의문을 가지던중 CNN 네트워크 모델에 대한 대략적인 학습이 끝나고, 실제로 적용하면서 경험을 쌓아보기로 하였다. 그래서 얼굴 인식 모델 개발을 시작하였다. CNN 모델이라는 마법을 사용하면 쉽게 개발이 될줄 알았던 프로젝트가 벌써 몇달이 되어 간다. 학습용 데이타를 구하고, 이를 학습에 적절하도록 전처리 하는 과정에서 많은 실수가 있었고, 그 과정에서 많은 재시도가 있었다. (자세한 내용은 http://bcho.tistory.com/1174 , https://www.slideshare.net/Byungwook/ss-76098082 를 참조) 특히나 데이타 자체를 다시 처리해야 하는 일이 많았기 때문에, 데이타 전처리 코드를 지속적으로 개선하였고 개선된 코드를 이용하여 데이타를 지속적으로 다시 처리해서 데이타의 품질을 높여나갔는데, 처리 시간이 계속해서 많이 걸렸다. 자동화와 스케일링의 필요성특히 이미지 전처리 부분은 사진에서 얼굴이 하나만 있는 사진을 골라내고 얼굴의 각도와 선글라스 유무등을 확인한후 사용 가능한 사진에서 얼굴을 크롭핑하고 학습용 크기로 리사이즈 하는 코드였는데 (자세한 내용 http://bcho.tistory.com/1176) 싱글 쓰레드로 만들다 보니 아무래도 시간이 많이 걸렸다. 실제 운영환경에서는 멀티 쓰레드 또는 멀티 서버를 이용하여 스케일링을 할 필요가 있다고 느꼈다. 또한 이미지 수집에서 부터 필터링, 그리고 학습 및 학습된 모델의 배포와 서비스 까지 이 전 과정을 순차적으로 진행을 하되 반복적인 작업이기 때문에 자동화할 필요성이 있다고 생각했다. 아이 체중 예측 모델을 통한 파이프라인에 대한 이해그러던 중에 팀 동료로 부터 좋은 예제 하나를 전달 받게 되었다. 미국 아기들의 환경에 따른 출생 체중을 예측하는 간단한 선형 회귀 모델을 구현한 파이썬 노트북인데 (https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/babyweight/babyweight.ipynb) 하나의 노트북에 전체 단계를 모두 구현해놓았다.   데이타에 대한 분석을 통한 데이타 특성 추출, 추출된 특성을 통한 모델 개발, 모델 학습을 위한 데이타 전처리 그리고 학습 및 학습된 모델을 통한 예측 서비스 까지 모든 과정을 하나의 노트북에 구현해놓았다.(시간이 있으면 꼭 보기를 강력 추천한다.) 흥미로운 점이 데이타 전처리를 Apache Beam이라는 데이타 처리 플랫폼을 썼고, 그 전처리 코드를 파이썬 노트북에 하나로 다 정리한것이다. (실제로 수행은 로컬에서도 가능하지만, 클라우드에서도 실행이 가능해서 충분한 스케일링을 지원한다.) Apache Beam의 구글의 빅데이타 분석 프레임웍으로 Apache Spark 과 같은 프레임웍이라고 보면된다. Google Dataflow라는 이름으로 구글 클라우드에서 서비스가 되는데, Apache Beam이라는 오픈소스로 공개가 되었다. ( http://bcho.tistory.com/1123 http://bcho.tistory.com/1122 http://bcho.tistory.com/1124 ) 아 이렇게 하는구나 하는 생각이 들었고, 그즘 실무에서 이와 같은 흐름으로 실제로 머신러닝을 수행하는 것을 볼 기회가 있었다. 데이타 전처리를 스케일링하다.서비스가 가능한 수준의 전체 머신러닝 서비스 파이프라인을 만들어보고 싶어졌다. 마침 또 Apache Beam의 경우에는 예전에 Java 코드로 실시간 분석을 해본 경험이 있고 이번에 2.0 버전이 릴리즈 되서 이번에는 2.0에서 파이썬을 공부해보기로 하고 개발에 들어갔다. 특히 기존의 데이타 전처리 코드는 싱글 쓰레드로 돌기 때문에 스케일링에 문제가 있었지만, Apache Beam을 사용할 경우 멀티 쓰레드 뿐만 아니라 동시에 여러대의 머신에서 돌릴 수 있고 이러한 병렬성에 대해서는 크게 고민을 하지 않아도 Apache Beam이 이 기능을 다 제공해준다. 또한 이 데이타 전처리 코드를 돌릴 런타임도 별도 설치할 필요가 없이 커멘드 하나로 구글 클라우드에서 돌릴 수 가 있다. (직업 특성상 클라우드 자원을 비교적 자유롭게 사용할 수 있었다.) Apache Beam으로 전처리 코드를 컨버팅 한결과 기존 싱글 쓰레드 파이썬 코드가 400~500장의 이미지 전처리에 1~2시간이 걸렸던 반면, 전환후에 대략 15~17분이면 끝낼 수 있었다. 전처리 중에는 서버의 대수가 1대에서 시작해서 부하가 많아지자 자동으로 5대까지 늘어났다. 이제는 아무리 많은 데이타가 들어오더라도 서버의 대수만 단순하게 늘리면 수분~수십분내에 수십,수만장의 데이타 처리가 가능하게 되었다.<그림. Apache Beam 기반의 이미지 전처리 시스템 실행 화면 > Apache Beam 기반의 이미지 전처리 코드는 https://github.com/bwcho75/facerecognition/blob/master/Preprocess%2Bface%2Brecognition%2Bdata%2Band%2Bgenerate%2Btraining%2Bdata.ipynb 에 공개해 놨다.  머신러닝 파이프라인 아키텍쳐와 프로세스이번 과정을 통해서 머신러닝의 학습 및 예측 시스템 개발이 어느 정도 정형화된 프로세스화가 가능하고 시스템 역시 비슷한 패턴의 아키텍쳐를 사용할 수 있지 않을까 하는 생각이 들었고, 그 내용을 아래와 같이 정리한다. 파이프라인 개발 프로세스지금까지 경험한 머신러닝 개발 프로세스는 다음과 같다. 데이타 분석먼저 머신러닝에 사용할 전체 데이타셋을 분석한다. 그래프도 그려보고 각 변수간의 연관 관계나 분포도를 분석하여, 학습에 사용할 변수를 정의하고 어떤 모델을 사용할지 판단한다.모델 정의 분석된 데이타를 기반으로 모델을 정의하고, 일부 데이타를 샘플링하여 모델을 돌려보고 유효한 모델인지를 체크한다. 모델이 유효하지 않다면 변수와 모델을 바꿔 가면서 최적의 모델을 찾는다.데이타 추출 및 전처리유효한 모델이 개발이 되면, 일부 데이타가 아니라 전체 데이타를 가지고 학습을 한다. 전체 데이타를 추출해서 모델에 넣어서 학습을 하려면 데이타의 크기가 크면 매번 매뉴얼로 하기가 어렵기 때문에 데이타 추출 및 전처리 부분을 자동화 한다.   전체 데이타를 이용한 반복 학습 및 튜닝모델 자체가 유효하다고 하더라도 전체 데이타를 가지고 학습 및 검증을 한것이 아니기 때문에 의외의 데이타가 나오거나 전처리에 의해서 필터링되지 않은 데이타가 있을 수 있기 때문에 지속적으로 데이타 추출 및 전처리 모듈을 수정해야 하고, 마찬가지로 모델 역시 정확도를 높이기 위해서 지속적으로 튜닝을 한다. 이 과정에서 전체 데이타를 다루기 때문에 모델 역시 성능을 위해서 분산형 구조로 개선되어야 한다. 모델 배포학습 모델이 완성되었으면 학습된 모델을 가지고 예측을 할 수 있는 시스템을 개발하고 이를 배포한다. 파이프라인 연결 및 자동화머신러닝의 모델은 위의 과정을 통해서 만들었지만, 데이타가 앞으로도 지속적으로 들어올 것이고 지속적인 개선이 필요하기 때문에 이 전과정을 자동화 한다. 이때 중요한것은 데이타 전처리, 학습, 튜닝, 배포등의 각 과정을 물 흐르듯이 연결하고 자동화를 해야 하는데 이렇게 데이타를 흐르는 길을 데이타 플로우라고 한다. (흔히 Luigi, Rundeck, Airflow와 같은 데이타플로우 오케스트레이션 툴을 이용한다)  전체적인 프로세스에 대해서 좋은 영상이 있어서 공유한다.아키텍쳐 위의 프로세스를 기반으로한 머신러닝 파이프라인 아키텍쳐 는 다음과 같다.   Inputs머신 러닝 파이프라인의 가장 처음단은 데이타를 수집하고 이 수집된 데이타를 저장하는 부분이다.데이타 수집은 시간,일,주,월과 같이 주기적으로 데이타를 수집하는 배치 프로세싱과, 실시간으로 데이타를 수집하는 리얼타임 프로세싱 두가지로 나뉘어 진다. 이 두 파이프라인을 통해서 데이타 소스로 부터 데이타를 수집하고 필터링하고 정재하여, 데이타 레이크에 저장한다. 이 구조는 일반적인 빅데이타 분석 시스템의 구조와 유사하다. (참고 자료 http://bcho.tistory.com/984 http://bcho.tistory.com/671 ) 개인적으로 머신러닝을 위해서 중요한 부분 중 하나는 데이타 레이크를 얼마나 잘 구축하느냐이다. 데이타 레이크는 모든 데이타가 모여 있는 곳으로 보통 데이타 레이크를 구축할때는 많은 데이타를 모으는 데만 집중하는데, 데이타를 잘 모으는 것은 기본이고 가장 중요한 점은 이 모여 있는 데이타에 대한 접근성을 제공하는 것이다. 무슨 이야기인가 하면, 보통 머신러닝 학습을 위해서 학습 데이타를 받거나 또는 데이타에 대한 연관성 분석등을 하기 위해서는 데이타 레이크에서 데이타를 꺼내오는데, 데이타 레이크를 개발 운영 하는 사람과 데이타를 분석하고 머신러닝 모델을 만드는 사람은 보통 다르기 때문에, 모델을 만드는 사람이 데이타 레이크를 운영하는 사람에게 “무슨 무슨 데이타를 뽑아서 CSV로 전달해 주세요.” 라고 이야기 하는 것이 보통이다. 그런데 이 과정이 번거롭기도 하고 시간이 많이 걸린다. 가장 이상적인 방법은 데이타를 분석하고 모델링 하는 사람이 데이타 레이크 운영팀에 부탁하지 않고서도 손쉽고 빠르게 데이타에 접근해서 데이타를 읽어오고 분석을 할 수 있어야 한다. 직업 특성상 구글의 빅쿼리를 많이 접하게 되는데, 빅쿼리는 대용량 데이타를 저장할 수 있을 뿐만 아니라 파이썬 노트북이나 R 스튜디오 플러그인을 통해서 바로 데이타를 불러와서 분석할 수 있다.  <그림 INPUT 계층의 빅데이타 저장 분석 아키텍쳐>Pre processing & Asset creationPre processing은 수집한 데이타를 학습 시스템에 넣기 위해서 적절한 데이타만 필터링하고 맞는 포맷으로 바꾸는 작업을 한다. 작은 모델이나 개발등에서는 샘플링된 데이타를 로컬에서 내려 받아서 R이나 numpy/pandas등으로 작업이 가능하지만, 데이타가 수테라에서 수백테라이상이 되는 빅데이타라면 로컬에서는 작업이 불가능하기 때문에, 데이타 전처리 컴포넌트를 만들어야 한다.일반적으로 빅데이타 분석에서 사용되는 기술을 사용하면 되는데, 배치성 전처리는 하둡이나 스파크와 같은 기술이 보편적으로 사용되고 실시간 스트리밍 분석은 스파크 스트리밍등이 사용된다.Train학습은 전처리된 데이타를 시스템에 넣어서 모델을 학습 시키는 단계이다. 이 부분에서 생각해야 할점은 첫번째는 성능 두번째는 튜닝이다. 성능 부분에서는 GPU등을 이용하여 학습속도를 늘리고 여러대의 머신을 연결하여 학습을 할 수 있는 병렬성이 필요하다. 작은 모델의 경우에는 수시간에서 하루 이틀 정도 소요되겠지만 모델이 크면 한달 이상이 걸리기 때문에 고성능 하드웨어와 병렬 처리를 통해서 학습 시간을 줄이는 접근이 필요하다. 작은 모델의 경우에는 NVIDIA GPU를 데스크탑에 장착해놓고 로컬에서 돌리는 것이 가성비 적으로 유리하고, 큰 모델을 돌리거나 동시에 여러 모델을 학습하고자 할때는 클라우드를 사용하는 것이 절대 적으로 유리하다 특히 구글 클라우드의 경우에는  알파고에서 사용된 GPU의 다음 세대인 TPU (텐서플로우 전용 딥러닝 CPU)를 제공한다. https://cloud.google.com/tpu/ CPU나 GPU대비 최대 15~30배 정도의 성능 차이가 난다.  학습 단계에서는 세부 변수를 튜닝할 필요가 있는데, 예를 들어 학습 속도나 뉴럴 네트워크의 폭이나 깊이, 드롭 아웃의 수, 컨볼루셔널 필터의 크기등등이 있다. 이러한 변수들을 하이퍼 패러미터라고 하는데, 학습 과정에서 모델의 정확도를 높이기 위해서 이러한 변수들을 자동으로 튜닝할 수 있는 아키텍쳐를 가지는 것이 좋다.  텐서플로우등과 같은 머신러닝 전용 프레임웍을 사용하여 직접 모델을 구현하는 방법도 있지만, 모델의 난이도가 그리 높지 않다면 SparkML등과 같이 미리 구현된 모델의 런타임을 사용하는 방법도 있다. PredictPredict에서는 학습된 모델을 이용하여 예측 기능을 서비스 하는데, 텐서플로우에서는  Tensorflow Serv를 사용하면 되지만, Tensorflow Serv의 경우에는 bazel 빌드를 이용하여 환경을 구축해야 하고, 대규모 서비를 이용한 분산 환경 서비스를 따로 개발해야 한다. 거기다가 인터페이스가 gRPC이다. (귀찮다.) 구글 CloudML의 경우에는 별도의 빌드등도 필요 없고 텐서 플로우 모델만 배포하면 대규모 서비스를 할 수 있는 런타임이 바로 제공되고 무엇보다 gRPC 인터페이스뿐만 아니라 HTTP/REST 인터페이스를 제공한다. 만약에 Production에서 머신러닝 모델을 서비스하고자 한다면 구글 CloudML을 고려해보기를 권장한다. Dataflow Orchestration이 전과정을 서로 유기적으로 묶어 주는 것을 Dataflow Orchestration이라고 한다.예를 들어 하루에 한번씩 이 파이프라인을 실행하도록 하고, 파이프라인에서 데이타 전처리 과정을 수행하고, 이 과정이 끝나면 자동으로 학습을 진행하고 학습 정확도가 정해진 수준을 넘으면 자동으로 학습된 모델은 서비스 시스템에 배포하는 이 일련의 과정을 자동으로 순차적으로 수행할 수 있도록 엮어 주는 과정이다.airbnb에서 개발한 Airflow나 luigi 등의 솔루션을 사용하면 된다. 아직도 갈길은 멀다.얼굴 인식이라는 간단한 모델을 개발하고 있지만, 전체를 자동화 하고, 클라우드 컴퓨팅을 통해서 학습 시간을 단축 시키고 예측 서비스를 할 수 있는 컴포넌트를 개발해야 하고, 향후에는 하이퍼 패러미터 튜닝을 자동으로 할 수 있는 수준까지 가보려고 한다. 그 후에는 GAN을 통한 얼굴 합성들도 도전하려고 하는데, node.js 공부하는데도 1~2년을 투자한후에나 조금이나마 이해할 수 있게 되었는데, 머신러닝을 시작한지 이제 대략 8개월 정도. 길게 보고 해야 하겠다.   window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1177}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글얼굴 인식 모델을 만들어보자 #3 - 학습된 모델로 예측하기  (2)2017.06.19연예인 얼굴 인식 모델을 만들어보자 - #2. CNN 모델을 만들고 학습시켜 보자  (15)2017.06.15연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기  (6)2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서  (0)2017.05.11머신러닝 모델 개발 삽질기  (0)2017.04.24Tagapache, Beam, CNN, course, Deep learning, image, jupyter, Machine Learning, pipe line, pre proceccing, Processing, python notebook, tensorflow, Tutorial, 강좌, 기초, 딥러닝, 머신러닝, 얼굴 인식, 오랜만에 포스팅, 조대협, 텐서플로우, 튜토리얼'빅데이타 & 머신러닝/머신러닝'의 다른글이전글연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기현재글머신러닝 시스템 프로세스와 아키텍쳐다음글연예인 얼굴 인식 모델을 만들어보자 - #2. CNN 모델을 만들고 학습시켜 보자관련글얼굴 인식 모델을 만들어보자 #3 - 학습된 모델로 예측하기2017.06.19연예인 얼굴 인식 모델을 만들어보자 - #2. CNN 모델을 만들고 학습시켜 보자2017.06.15연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서2017.05.11loadedComments[1177]=true;findFragmentAndHighlight(1177);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag조대협,cloud,딥러닝,빅데이타,구글,node.js,튜토리얼,소개,Machine Learning,클라우드 컴퓨팅,google,텐서플로우,머신러닝,강좌,클라우드,Kubernetes,tensorflow,초보,Tutorial,쿠버네티스,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1177"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1177"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1177"",""entryTitle"":""머신러닝 시스템 프로세스와 아키텍쳐"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":""cfile24.uf@21431635593B7E921AC2CE.png"",""plink"":""/1177"",""tags"":[""apache"",""Beam"",""CNN"",""course"",""Deep learning"",""image"",""jupyter"",""Machine Learning"",""pipe line"",""pre proceccing"",""Processing"",""python notebook"",""tensorflow"",""Tutorial"",""강좌"",""기초"",""딥러닝"",""머신러닝"",""얼굴 인식"",""오랜만에 포스팅"",""조대협"",""텐서플로우"",""튜토리얼""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
88,https://gooopy.tistory.com/55,1. 렐루 함수의 생김새,"만년필잉크의 데이터 분석 지식 저장소  데이터 분석  R  설치 및 환경설정  Basic  시각화  Python  설치 및 환경설정  Basic  Pandas  Numpy  시각화  Machine Learning  Basic  ML_Algorithm  Deep Learning  TensorFlow  TensorBoard  분석에 필요한 배경 지식  결측값  이상치  Python으로 하는 기초 수학  행렬  Python으로 하는 기초통계학  기본 개념  여행기  나와 함께 떠나는 두 번째 자유여행 - 이탈리아편  기타  홈태그방명록 대학 다니면서 맨날 헷갈려서 싹 정주행 했는데 최고네요..절대 보존 해주⋯유익한 정보 감사합니다! 포스팅 잘보고 갑니다!딥러닝 공부하는 중인데 어려워서 찾다가 왔어요. 이해하기 쉬워요 감사합니⋯네 ㅎㅎ 맞구독 드렸습니다안녕하세요! 파이썬에 입문하여 새롭게 공부하게 된 뉴비입니다!공부하면서⋯422 /              108 /              874,025블로그 내 검색딥러닝-3.4. 활성화함수(5)-렐루 함수(ReLU)만년필잉크2021. 1. 27. 11:332021. 1. 27. 11:33activation, Python, ReLU, 기울기 소실, 렐루 함수, 렐루 함수의 한계점, 머신러닝, 활성화함수     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90반응형(adsbygoogle = window.adsbygoogle || []).push({}); 지금까지 계단 함수, 선형 함수, 시그모이드 함수, 소프트맥스 함수, 하이퍼볼릭 탄젠트 함수에 대해 다뤄보았다. 이들은 은닉층에서 사용해서는 안되거나, 사용할 수 있더라도 제한적으로 사용해야 하는 활성화 함수들이었다. 이번 포스트에서는 은닉층에서 많이 사용되는 렐루 함수에 대해 학습해 보겠다.   렐루 함수(Rectified Linear Unit, ReLU)렐루 함수는 딥러닝 역사에 있어 한 획을 그은 활성화 함수인데, 렐루 함수가 등장하기 이전엔 시그모이드 함수를 활성화 함수로 사용해서 딥러닝을 수행했다.그러나, 이전 포스트에서 언급했듯 시그모이드 함수는 출력하는 값의 범위가 0에서 1사이므로, 레이어를 거치면 거칠수록 값이 현저하게 작아지게 되어 기울기 소실(Vanishing gradient) 현상이 발생한다고 하였다.gooopy.tistory.com/52?category=824281 머신러닝-3.1. 활성화함수(2)-시그모이드 함수 지난 포스트에서 퍼셉트론의 가장 기본이 되는 활성화 함수인 계단 함수(Step Function)를 학습하였으며, 선형 함수(Linear Function)의 한계점에 대해서도 학습해보았다.  선형 함수는 층을 쌓는 것이gooopy.tistory.com이 문제는 1986년부터 2006년까지 해결되지 않았으나, 제프리 힌튼 교수가 제안한 렐루 함수로 인해, 시그모이드의 기울기 소실 문제가 해결되게 되었다.렐루 함수는 우리 말로, 정류된 선형 함수라고 하는데, 간단하게 말해서 +/-가 반복되는 신호에서 -흐름을 차단한다는 의미다.렐루 함수는 은닉층에서 굉장히 많이 사용되는데, 별생각 없이 다층 신경망을 쌓고, 은닉층에 어떤 활성화 함수를 써야 할지 모르겠다 싶으면, 그냥 렐루 함수를 쓰라고 할 정도로, 아주 많이 사용되는 활성화 함수이다(물론 신경망을 의도를 가지고 써보고 싶다면, 그래선 안된다.).    1. 렐루 함수의 생김새렐루 함수는 +신호는 그대로 -신호는 차단하는 함수라고 하였는데, 그 생김새는 아래와 같다.$$ h(x) = \begin{cases}  x \ \ \ (x>0) \\   0 \ \ \ (x\leq 0)  \end{cases} $$말 그대로, 양수면 자기 자신을 반환하고, 음수면 0을 반환한다.이번에는 이를 구현해보고, 어떻게 생겼는지 확인해보자.>>> import numpy as np# ReLU 함수를 구현해보자>>> def ReLU(x):    >>>     return np.maximum(0, x)단순하게 최댓값 함수를 사용하여 지금 들어온 값(원소별 연산이 된다!)이 0보다 크면 자기 자신을 반환하고, 그렇지 않으면, 최댓값인 0을 반환하는 함수를 이용해서 구현하였다.>>> import matplotlib.pyplot as plt>>> x = np.arange(-5.0, 5.0, 0.1)>>> y = ReLU(x)>>> fig = plt.figure(figsize=(8,6))>>> fig.set_facecolor('white')>>> plt.title(""ReLU"", fontsize=30)>>> plt.xlabel('x', fontsize = 15)>>> plt.ylabel('y', fontsize = 15, rotation = 0)>>> plt.axvline(0.0, color='gray', linestyle=""--"", alpha=0.8)>>> plt.axhline(0.0, color='gray', linestyle=""--"", alpha=0.8)>>> plt.plot(x, y)>>> plt.show()가장 많이 사용되는 활성화함수라기엔 지금까지 보아왔던 시그모이드, 소프트맥스, 하이퍼볼릭 탄젠트 등에 비해 너무 단순하게 생겼다는 생각이 들 것이다.그렇다면 왜 렐루 함수를 은닉층에서 많이 사용할까?    2. 렐루 함수를 은닉층에서 많이 사용하는 이유 기울기 소실(Vanishing Gradient) 문제가 발생하지 않는다.렐루 함수는 양수는 그대로, 음수는 0으로 반환하는데, 그러다 보니 특정 양수 값에 수렴하지 않는다. 즉, 출력값의 범위가 넓고, 양수인 경우 자기 자신을 그대로 반환하기 때문에, 심층 신경망인 딥러닝에서 시그모이드 함수를 활성화 함수로 사용해 발생한 문제였던 기울기 소실(Vanishing Gradient) 문제가 발생하지 않는다. 기존 활성화 함수에 비해 속도가 매우 빠르다동시에 렐루 함수의 공식은 음수면 0, 양수면 자기 자신을 반환하는 아주 단순한 공식이다 보니, 경사 하강 시 다른 활성화 함수에 비해 학습 속도가 매우 빠르다!확률적 경사하강법(SGD)을 쓴다고 할 때, 시그모이드 함수나 하이퍼볼릭 탄젠트 함수에 비해 수렴하는 속도가 약 6배 가까이 빠르다고 한다!ReLU가 나오기 전에는 활성화 함수가 부드러워야(Smooth) 가중치 업데이트가 잘된다고 생각하여 exp 연산이 들어간 시그모이드나, 하이퍼볼릭 탄젠트 함수를 사용하여쓰나, 활성화 함수가 부드러운(Smooth)한 구간에 도달하는 순간 가중치 업데이트 속도가 매우 느려진다.ReLU는 편미분(기울기) 시 1로 일정하므로, 가중치 업데이트 속도가 매우 빠르다.    3. 렐루 함수의 한계점렐루 함수의 그래프를 보면, 음수 값이 들어오는 경우 모두 0으로 반환하는 문제가 있다보니, 입력값이 음수인 경우 기울기도 모조리 0으로 나오게 된다.입력값이 음수인 경우에 한정되긴 하지만, 기울기가 0이 되어 가중치 업데이트가 안되는 현상이 발생할 수 있다.즉, 가중치가 업데이트 되는 과정에서 가중치 합이 음수가 되는 순간 ReLU는 0을 반환하기 때문에 해당 뉴런은 그 이후로 0만 반환하는 아무것도 변하지 않는 현상이 발생할 수 있다.이러한 죽은 뉴런(Dead Neuron)을 초래하는 현상을 죽어가는 렐루(Dying ReLU) 현상이라고 한다.또한 렐루 함수는 기울기 소실 문제 방지를 위해 사용하는 활성화 함수이기 때문에 은닉층에서만 사용하는 것을 추천한다.ReLU의 출력값은 0 또는 양수이며, ReLU의 기울기도 0 또는 1이므로, 둘 다 양수이다. 이로 인해 시그모이드 함수처럼 가중치 업데이트 시 지그제그로 최적의 가중치를 찾아가는 지그재그 현상이 발생한다.또, ReLU의 미분은 0 초과 시, 1 0은 0으로 끊긴다는 문제가 있다. 즉, ReLU는 0에서 미분이 불가능하다.(이에 대해 활성화 함수로는 미분 불가능 하다할지라도, 출력값 문제는 아니고, 0에 걸릴 확률이 적으니, 이를 무시하고 사용한다.)    지금까지 은닉층에서 주로 사용되는 활성화 함수인 렐루 함수에 대해 학습해보았다. 비록 렐루 함수가 입력값이 0일 때, 기울기가 0에 수렴해 가중치 업데이트가 안 되는 현상이 발생한다고는 하지만, 성능상 큰 문제가 없으며, 도리어 이를 해결하기 위해 만든 활성화 함수의 성능이 보다 안 나오는 경우도 있다고 한다. 때문에 기본적으로 은닉층에서는 렐루 함수를 사용하지만, 때에 따라 렐루 함수의 단점이 두드러지는 경우도 존재하므로, 렐루 함수의 한계점을 보완하기 위한 렐루 함수의 형제 함수들이 있다.  다음 포스트에서는 렐루 함수의 한계점을 극복하기 위해 만들어진 다양한 활성화 함수에 대해 학습해보도록 하곘다.728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//gooopy.tistory.com/reaction';window.ReactionReqBody = {    entryId: 55}공유하기게시글 관리만년필잉크의 데이터 분석 지식 저장소 저작자표시 비영리 동일조건 'Machine Learning > Deep Learning' 카테고리의 다른 글딥러닝-4.0. 인공신경망(1)-신경망 연산(SLP)  (0)2021.01.28딥러닝-3.5. 활성화함수(6)-ReLU Family  (0)2021.01.27딥러닝-3.3. 활성화함수(4)-하이퍼볼릭 탄젠트 함수(tanh)  (0)2021.01.26딥러닝-3.2. 활성화함수(3)-소프트맥스 함수(Softmax)  (0)2021.01.26딥러닝-3.1. 활성화함수(2)-시그모이드 함수(Sigmoid)  (3)2021.01.25loadedComments[55]=true;findFragmentAndHighlight(55);+ Recent postsPython-기초:3.2. 정규 표현식(3) - 메타 ⋯Python-기초:3.1. 정규 표현식(2) - Pyt⋯Python-기초:3.0. 정규 표현식(1) - 소개:⋯Pandas-데이터 프레임, 데이터 조회하기-3. Bo⋯Powered by Tistory, Designed by              wallelRss Feed and              Twitter,              Facebook,              Youtube,              Google+       $(document).ready(function () {      if ($('body').width() > ""960"") {        $(""#sidebar"").mCustomScrollbar({          theme: ""dark-thin"",          autoHideScrollbar: ""true""        });      };    });  티스토리툴바만년필잉크의 데이터 분석 지식 저장소구독하기                    (function () {                         var blogTitle = '만년필잉크의 데이터 분석 지식 저장소';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""3994521-55"",""customProps"":{""userId"":""0"",""blogId"":""3994521"",""entryId"":""55"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""55"",""entryTitle"":""딥러닝-3.4. 활성화함수(5)-렐루 함수(ReLU)"",""entryType"":""POST"",""categoryName"":""Machine Learning/Deep Learning"",""categoryId"":""824281"",""serviceCategoryName"":""과학"",""serviceCategoryId"":404,""author"":""4429291"",""authorNickname"":""만년필잉크"",""blogNmae"":""만년필잉크의 데이터 분석 지식 저장소"",""image"":""kage@bJebYZ/btqURufaeIp/mAvstcH7sJbprYFK4CVgJk"",""plink"":""/55"",""tags"":[""activation"",""Python"",""ReLU"",""기울기 소실"",""렐루 함수"",""렐루 함수의 한계점"",""머신러닝"",""활성화함수""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
89,https://huidea.tistory.com/130,"1. 잠재디리클레할당(Latent Dirichlet Allocation, LDA)","Study/Machine learning[Machine learning] 잠재디리클레할당 (day3 / 201012)by 후이 (hui)2020. 10. 12.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});오늘의 질문 ! 텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? 거기서 어떤 장점이 발생했나요?다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요. Q. 텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요? 토픽 모델링을 해야한다. 토픽 모델링에는 다양한 기법이 있지만 그중 가장 기초적인 기법 부터 하나씩 살펴보자면 ~  1. 잠재디리클레할당(Latent Dirichlet Allocation, LDA): LDA는 문서들은 토픽들의 혼합으로 구성되어져 있으며, 토픽들은 확률 분포에 기반하여 단어들을 생성한다고 가정  데이터가 주어지면, LDA는 문서가 생성되던 과정을 역추적 (wikidocs.net/30708) 1.1 기본 개념 ex. 문서1 : 저는 사과랑 바나나를 먹어요문서2 : 우리는 귀여운 강아지가 좋아요문서3 : 저의 깜찍하고 귀여운 강아지가 바나나를 먹어요 --> LDA는 각 문서의 토픽 분포와 각 토픽 내의 단어 분포를 추정!  <각 문서의 토픽 분포>문서1 : 토픽 A 100%문서2 : 토픽 B 100%문서3 : 토픽 B 60%, 토픽 A 40% <각 토픽의 단어 분포> --> 토픽의 개수 유사도 혼란도를 기반으로 사람이 지정토픽A : 사과 20%, 바나나 40%, 먹어요 40%, 귀여운 0%, 강아지 0%, 깜찍하고 0%, 좋아요 0%토픽B : 사과 0%, 바나나 0%, 먹어요 0%, 귀여운 33%, 강아지 33%, 깜찍하고 16%, 좋아요 16%  사람이 임의로 토픽의 수를 정하고, LDA 는 문서 내의 토픽 분포 확률과 토픽 내의 단어 분포 확률을 추정( 이때 쓰는 분포가 디리클레 분포 )  1.2 학습 진행 방법 1) 토픽 4개라고 임의로 지정한다면, 2) 모든 문서에서 토큰을 끊고 토픽 네개로 랜덤하게 할당    "" I am a boy "" 첫문장이 이거였다면,  ""I"" ""am""  ""a""  ""boy"" 각각을 1,2,3,4 토픽으로 처음에 임의로 할당해버림 3) 이렇게 전체 단어를 특정 토픽에 임의로 할당해놓고 이터레이션을 돌리며 학습을 진행하는 것   3.1 ) 학습 방식은 ""am""  ""a""  ""boy"" 가 제대로  할당 되었다는 가정을 하고 ""I"" 가 어디에 할당 되면 좋을 지 추정 !      - p(topic t | document d) : 문서 d의 단어들 중 토픽 t에 해당하는 단어들의 비율     - p(word w | topic t) : 단어 w를 갖고 있는 모든 문서들 중 토픽 t가 할당된 비율 (1)  두 개의 문서 doc1과 doc2를. 여기서는 우리는 doc1의 세번째 단어 apple의 토픽을 결정하고자 함 (2) 우선 첫번째로 사용하는 기준은 문서 doc1의 단어들이 어떤 토픽에 해당하는지를 확인 ==> p(topic t | document d)doc1의 모든 단어들은 토픽 A와 토픽 B에 50 대 50의 비율로 할당되어져 있으므로, 이 기준에 따르면 단어 apple은 토픽 A 또는 토픽 B 둘 중 어디에도 속할 가능성이 있음 (3) 두번째 기준은 단어 apple이 전체 문서에서 어떤 토픽에 할당되어져 있는지 확인  ==> p(word w | topic t)       이 기준에 따르면 단어 apple은 토픽 B에 할당될 가능성이 높음    ==> 이러한 두 가지 기준을 참고하여 LDA는 doc1의 apple을 어떤 토픽에 할당할지 결정!!!  1.3 특징 !!!! (중요) 1) 잠재 디리클레 할당과, 잠재 의미 분석의 차이 (맨날 헷갈림) 잠재 디리클레 할당은 디리클레 확률로 문서중 토픽비율, 토픽중 단어 비율로 계산잠재 의미 분석은 DTM (document term matrix) 에  SVD 로 차원축소 한후 근접단어 토픽 묶기  2) 잠재 디리클레 할당은 단어의 순서와 상관이 없다. 단지 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하기 때문에  3) 디리클레 분포 추론 과정에서 깁스 샘플링을 이용하게 된다. (형이 거기서 왜나와?)techblog-history-younghunjo1.tistory.com/87 [ML] Topic Modeling(토픽 모델)인 LDA(Latent Dirichlet Allocation)※해당 게시물에 사용된 일부 자료는 순천향대학교 빅데이터공학과 정영섭 교수님의 머신러닝 전공수업 자료에 기반하였음을 알려드립니다. 이번 포스팅에서는 Clustering의 방법 중 하나이며 비techblog-history-younghunjo1.tistory.com  ==> 수식을 뜯어보면 결국     1) 우리는 사후확률(posterior) p(z,ϕ,θ|w)를 최대로 만드는 z,ϕ,θ를 찾아야 함.      2) 사후확률을 구하려면 결국 분모인  p(w)를 구해야함           ( 사후확률은 베이즈 정리에서 evidence 부분 즉, 잠재변수 z,ϕ,θ의 모든 경우의 수를 고려한 각 단어(w)의 등장 확률 )     3) 하지만 잠재변수 z,ϕ,θ를 모두 관찰하는 게 불가능 따라서 ==> 깁스 샘플링 사용.  자세한 내용은 ratsgo.github.io/from%20frequency%20to%20semantics/2017/06/01/LDA/ Topic Modeling, LDA · ratsgo's blog이번 글에서는 말뭉치로부터 토픽을 추출하는 토픽모델링(Topic Modeling) 기법 가운데 하나인 잠재디리클레할당(Latent Dirichlet Allocation, LDA)에 대해 살펴보도록 하겠습니다. 이번 글 역시 고려대 강��ratsgo.github.io   참고한 내용 출처  :www.youtube.com/watch?v=noWKlkdcY6Awikidocs.net/30708 728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//huidea.tistory.com/reaction';window.ReactionReqBody = {    entryId: 130}공유하기게시글 관리데이터 분석가 후이저작자표시 'Study > Machine learning' 카테고리의 다른 글[Machine learning] ROC 와 ROC-AUC 평가 방법 (Confusion matrix, Recall, Precision, TPR, FPR, Threshold)  (0)2020.11.10[Machine learning] 나이브베이즈확률, 나이브베이즈모델 (day4 / 201013)  (0)2020.10.14[Machine learning] Markov Chain, Gibbs Sampling, 마르코프 체인, 깁스 샘플링 (day2 / 201010)  (0)2020.10.10[Machine learning] 차원축소, PCA, SVD, LSA, LDA, MF 간단정리 (day1 / 201009)  (0)2020.10.10[Machine learning] PCA(주성분분석), LDA(선형판별분석법), SVD (행렬분해) (쉽게 설명하는 차원 축소 기법들 총정리 part2)  (0)2020.08.06관련글[Machine learning] ROC 와 ROC-AUC 평가 방법 (Confusion matrix, Recall, Precision, TPR, FPR, Threshold)[Machine learning] 나이브베이즈확률, 나이브베이즈모델 (day4 / 201013)[Machine learning] Markov Chain, Gibbs Sampling, 마르코프 체인, 깁스 샘플링 (day2 / 201010)[Machine learning] 차원축소, PCA, SVD, LSA, LDA, MF 간단정리 (day1 / 201009)댓글0비밀글등록loadedComments[130]=true;findFragmentAndHighlight(130);"
90,https://cia-secu-lock.tistory.com/m/82,2/23 업무일지,"신입일기(웹툰예정)2/23 업무일지CIA_secu 2022. 2. 23. 09:11     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90SMALL오늘 할 일client 테스팅용 만들기 - openssl 적용 rsa와 정해진 패킷을 보내기, 오디오 파일 패킷 센드는 이후 구현하여도 될 듯client 파일이 언제 위치하는 것이 좋은지> 나중에라도 할 일 코드끼리의 연결성 정리하기신입 첫 직장 선택, 조언이 필요합니다...안녕하세요, 저는 비전공자에 얼마 전 부트캠프를 수료한 신입입니다.희망 직군은 머신러닝 엔지니어인데 머신러닝 쪽이 기본 석사부터 요구하는 곳이 많다 보니 일단은 백엔드도 가리지 않고 여러 회사에 지원을 하고 있었습니다. 그러던 중 얼마 전 지인이 회사 한 곳을 소개 시켜줘서 인터뷰를 보고 왔었네요.가보니 자체 서비스를 준비하면서 현재는 딥러닝 관련 정부 R&D 과제를 수행하고 있는 중소기업이더라고요. 면접 느낌보다도 거의 서로 편하게 소개하는 식으로 대화가 오갔고 대표분이 열심히 회사 비전을 설명해주기는 했는데 사실 크게 공감이 가지는 않았습니다;; 지인이 소개해 준 곳이었기에 가볍게 인터뷰 경험 쌓는다 생각하면서 있다가 나왔고, 그 뒤로 큰 기대는 하지 않고 있었습니다. 그런데 오늘 대표에게 연락이 와서 연봉 4,000에 같이 일할 생각이 없냐고 하네요. 제 스펙에 사실 높은 연봉을 기대하지 않고 있었고 지금까지 지원했던 회사들의 신입 연봉이 많아야 3,500 정도였기 때문에 제안을 듣고나니 솔직히 조금 혹 하면서 조건들을 다시 따져보게 됩니다...구직을 하면서 나름 세웠던 기준은 제대로 된 사수 밑에서 배우면서 성장할 수 있는 회사였는데, 이 곳은 아마 제가 가게 되면 저랑 거의 비슷한 수준의 동료 한 명 정도만 상시로 일하게 될 것 같습니다... 대신 주 2~3회씩만 출근하는 CTO와 기술 고문이 있고 이 분들이 실무를 어느 정도 같이 맡아서 진행하는데 지인의 말에 따르면 이 분들이 실력도 좋고 배울 수 있는 것들도 많을 거라고는 하네요.그리고 머신러닝 엔지니어 포지션이 대부분 경력 또는 고스펙을 요구하는데 제가 신입으로 일할 수 있다는 점도 매력적으로 느껴집니다. 머신러닝 엔지니어를 신입으로 뽑지 않는데에는 물론 이유가 있겠지만 그럼에도 커리어 시작을 제가 원하는 개발 분야에서 바로 할 수 있고 연봉도 높게 시작할 수 있다고 하니 다른 단점들이 잘 안 보이게 되는 것 같습니다...저를 소개시켜 준 지인도 파트 타임으로 그 곳에서 일하다가 나온 분인데, 그 분 말로는 작은 회사지만 사람들도 다 괜찮고 야근도 없다고 합니다. 다만 정부과제 위주로 회사가 운영되다 보니 아무래도 좀 불안정한 면이 있고 이직할 때 내세울만한 결과물을 기대하긴 어렵다보니 본인도 소개해주면서 고민을 했다고는 하네요. 선배 개발자님들이 객관적으로 보시기에는 어떤가요? 연봉은 조금 덜 받더라도 더 안정적이고 비전이 있는 곳을 첫 직장으로 갖는 것이 더 좋을까요? 정부과제를 주 업무로 하면서도 개발자로서의 능력을 키울 수 있을까요?이런 질문들 정말 많이 올라오겠지만 혼자 검색해보고 고민하는 걸로는 답이 안 나오고 제 상황에 딱 맞는 조언이 절실해서 글 올려봅니다. 의견 주시면 정말 감사하겠습니다ㅠㅠ왜 ML 직군이 고학력을 요구할까요? 이 질문에 대한 답변을 한번쯤 생각해보셨나요?제가 생각하는 답변은 이 직군은 연구직이기 때문입니다.대학원에서 이런저런 연구를 하면서 연구에 필요한 방법론, 경험 등을 쌓구요.물론, AI/ML이 다른 분야에 비해 요구하는 기반 지식도 많습니다.백엔드 국비 6개월도 택도 없는 기간인데 AI/ML을 6개월 정도의 과정으로 한다? 납득이 가지 않습니다.그리고 정부과제 위주로 돌아가는 스타트업... 이름만 스타트업이지 SI랑 다를게 없어요.당장 높아보이는 연봉에 혹해서 들어갔다가 이도저도 아닌 일만 하다가 나올 가능성이 커보입니다.백엔드 개발을 하면 사이드 프로젝트 + 업무 경력으로 어필이라도 될텐데이런 과정으로 쌓은 경력은 정말 아무런 의미가 없을 가능성이 높습니다.https://www.boannews.com/media/view.asp?idx=104907  암호화폐와 탈중앙화 금융이 부딪힌 벽, 의외로 높다금융 업계는 현재 변혁의 속도를 높여가는 중이다. 그러면서 계속해서 새로운 보안 위협들이 등장하고 있고, 새로운 보호의 방법들이 고안되는 상황이다. 그런 와중에 예전 해킹 기술들을 새로www.boannews.com핀테크 기술이 많은 관심을 받기 시작하면서 암호화폐나 탈중앙화 금융이 차세대 주류 금전 거래의 수단으로 자리를 잡을 수 있을 것인가에 대한 논란도 계속해서 나오고 있다. 지금 상태 그대로는 불가능해 보이는 것이 사실이지만 아직 초기 단계에 있기 때문에 단정하기는 힘들다.이번 달 미국 사법부는 2016년 비트피넥스(Bitfinex) 해킹 사건에 연루된 용의자들을 체포했다. 이들은 당시 수십억 달러에 해당하는 비트코인을 훔쳐냈던 것으로 알려져 있다. 올해 1월만 하더라도 8천만 달러 규모의 암호화폐가 큐빗 파이낸스(Qubit Finance)라는 탈중앙화 암호화폐 거래소에서 사라지기도 했었다. 게다가 양자 컴퓨터 기술이 발전하면 암호화폐와 블록체인을 안전하게 보호해 주는 암호화 기술을 단박에 무력화시킬 것이라는 예측도 나오고 있는 상황이다.그러니 암호화폐, 탈중앙화 금융 등 미래에 대세가 될지 모르는 화폐와 신기술들의 안전성에 대한 의문이 제기될 수밖에 없다. 하지만 이것이 핀테크와 암호화폐를 완전히 가치 없는 기술로 전락시키지도 않는다. 암호화폐나 기타 여러 가지 핀테크를 벌써부터 비판하고 포기할 필요는 없다.시장 조사 업체 포레스터(Forrester)의 수석 분석가인 안드라스 체르(Andras Cser)는 “양자 컴퓨터가 블록체인과 암호화폐를 근본부터 흔들 가능성은 이론적으로 충분해 보인다”고 말한다. “하지만 아직 양자 컴퓨터는 언제 나올지도 모르는 기술입니다. 벌써부터 걱정하기에는 일러도 한참 이릅니다. 공공 키 암호화 알고리즘를 실제로 무력화시킬 만한 양자 컴퓨터가 나오려면 몇 년 더 걸릴 겁니다.”그러면서 체르는 “현재 암호화폐들은 매우 불안정한 상태”라고 지적한다. “이 역시 암호화폐가 가지고 있는 가장 큰 문제 중 하나입니다. 아직까지 암호화폐를 적극적으로 도입하려는 정부는 하나도 없다고 봐도 무방하고, 그렇기 때문에 언제 사라져도 이상하지 않습니다. 게다가 실질적인 경제적 결과물을 산출하지도 못하고 있죠. 오히려 환경에도 심각한 손상을 주는 채굴 행위만 수반할 뿐이죠. 정부가 지원도 안 해, 환경에도 해악적이야, 경제적 가치도 0에 가까우니 사실 지금까지 유지되는 게 신기할 정도입니다.728x90LIST저작자표시 비영리 변경금지"
91,https://bcho.tistory.com/1177,파이프라인 개발 프로세스,"                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝머신러닝 시스템 프로세스와 아키텍쳐Terry Cho2017. 6. 10. 14:11Machine Learning Pipeline조대협 (http://bcho.tistory.com)대부분 모델 개발과 알고리즘에 집중머신러닝을 공부하고 나서는 주로 통계학이나, 모델 자체에 많은 공부를 하는 노력을 드렸었다. 선형대수나 미적분 그리고 방정식에 까지 기본으로 돌아가려고 노력을 했었고, 그 중간에 많은 한계에도 부딪혔지만, 김성훈 교수님의 모두를 위한 딥러닝 강의를 접하고 나서, 수학적인 지식도 중요하지만 수학적인 깊은 지식이 없어도 모델 자체를 이해하고 근래에 발전된 머신러닝 개발 프레임웍을 이용하면 모델 개발이 가능하다는 것을 깨달았다. 계속해서 모델을 공부하고, 머신러닝을 공부하는 분들을 관심있게 지켜보고 실제 머신러닝을 사용하는 업무들을 살펴보니 재미있는 점이 모두 모델 자체 개발에만 집중한다는 것이다. 커뮤니티에 올라오는 글의 대부분은 어떻게 모델을 구현하는지 어떤 알고리즘을 사용하는지에 대한 내용들이 많았고, 실 업무에 적용하는 분들을 보면 많은 곳들이 R을 이용하여 데이타를 분석하고 모델링을 하는데, 데이타를 CSV 파일 형태로 다운 받아서 정재하고 데이타를 분석하고 모델을 개발하는 곳이 많은 것을 보았다. 데이타의 수집 및 전처리 및 개발된 모델에 대한 서비스에 대해서는 상대적으로 많은 정보를 접하지 못했는데, 예상하기로 대부분 모델 개발에 집중하기 때문이 아닌가 싶다.  엔지니어 백그라운드를 가진 나로써는 CSV로 데이타를 끌어다가 정재하고 분석하는 것이 매우 불편해 보이고 이해가 되지 않았다. 빅데이타 분석 시스템에 바로 연결을 하면, CSV로 덤프 받고 업로드 하는 시간등에 대한 고민이 없을텐데.” 왜 그렇게 할까 ?”라는 의문이 계속 생기기 시작하였다. 미니 프로젝트를 시작하다이런 의문을 가지던중 CNN 네트워크 모델에 대한 대략적인 학습이 끝나고, 실제로 적용하면서 경험을 쌓아보기로 하였다. 그래서 얼굴 인식 모델 개발을 시작하였다. CNN 모델이라는 마법을 사용하면 쉽게 개발이 될줄 알았던 프로젝트가 벌써 몇달이 되어 간다. 학습용 데이타를 구하고, 이를 학습에 적절하도록 전처리 하는 과정에서 많은 실수가 있었고, 그 과정에서 많은 재시도가 있었다. (자세한 내용은 http://bcho.tistory.com/1174 , https://www.slideshare.net/Byungwook/ss-76098082 를 참조) 특히나 데이타 자체를 다시 처리해야 하는 일이 많았기 때문에, 데이타 전처리 코드를 지속적으로 개선하였고 개선된 코드를 이용하여 데이타를 지속적으로 다시 처리해서 데이타의 품질을 높여나갔는데, 처리 시간이 계속해서 많이 걸렸다. 자동화와 스케일링의 필요성특히 이미지 전처리 부분은 사진에서 얼굴이 하나만 있는 사진을 골라내고 얼굴의 각도와 선글라스 유무등을 확인한후 사용 가능한 사진에서 얼굴을 크롭핑하고 학습용 크기로 리사이즈 하는 코드였는데 (자세한 내용 http://bcho.tistory.com/1176) 싱글 쓰레드로 만들다 보니 아무래도 시간이 많이 걸렸다. 실제 운영환경에서는 멀티 쓰레드 또는 멀티 서버를 이용하여 스케일링을 할 필요가 있다고 느꼈다. 또한 이미지 수집에서 부터 필터링, 그리고 학습 및 학습된 모델의 배포와 서비스 까지 이 전 과정을 순차적으로 진행을 하되 반복적인 작업이기 때문에 자동화할 필요성이 있다고 생각했다. 아이 체중 예측 모델을 통한 파이프라인에 대한 이해그러던 중에 팀 동료로 부터 좋은 예제 하나를 전달 받게 되었다. 미국 아기들의 환경에 따른 출생 체중을 예측하는 간단한 선형 회귀 모델을 구현한 파이썬 노트북인데 (https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/blogs/babyweight/babyweight.ipynb) 하나의 노트북에 전체 단계를 모두 구현해놓았다.   데이타에 대한 분석을 통한 데이타 특성 추출, 추출된 특성을 통한 모델 개발, 모델 학습을 위한 데이타 전처리 그리고 학습 및 학습된 모델을 통한 예측 서비스 까지 모든 과정을 하나의 노트북에 구현해놓았다.(시간이 있으면 꼭 보기를 강력 추천한다.) 흥미로운 점이 데이타 전처리를 Apache Beam이라는 데이타 처리 플랫폼을 썼고, 그 전처리 코드를 파이썬 노트북에 하나로 다 정리한것이다. (실제로 수행은 로컬에서도 가능하지만, 클라우드에서도 실행이 가능해서 충분한 스케일링을 지원한다.) Apache Beam의 구글의 빅데이타 분석 프레임웍으로 Apache Spark 과 같은 프레임웍이라고 보면된다. Google Dataflow라는 이름으로 구글 클라우드에서 서비스가 되는데, Apache Beam이라는 오픈소스로 공개가 되었다. ( http://bcho.tistory.com/1123 http://bcho.tistory.com/1122 http://bcho.tistory.com/1124 ) 아 이렇게 하는구나 하는 생각이 들었고, 그즘 실무에서 이와 같은 흐름으로 실제로 머신러닝을 수행하는 것을 볼 기회가 있었다. 데이타 전처리를 스케일링하다.서비스가 가능한 수준의 전체 머신러닝 서비스 파이프라인을 만들어보고 싶어졌다. 마침 또 Apache Beam의 경우에는 예전에 Java 코드로 실시간 분석을 해본 경험이 있고 이번에 2.0 버전이 릴리즈 되서 이번에는 2.0에서 파이썬을 공부해보기로 하고 개발에 들어갔다. 특히 기존의 데이타 전처리 코드는 싱글 쓰레드로 돌기 때문에 스케일링에 문제가 있었지만, Apache Beam을 사용할 경우 멀티 쓰레드 뿐만 아니라 동시에 여러대의 머신에서 돌릴 수 있고 이러한 병렬성에 대해서는 크게 고민을 하지 않아도 Apache Beam이 이 기능을 다 제공해준다. 또한 이 데이타 전처리 코드를 돌릴 런타임도 별도 설치할 필요가 없이 커멘드 하나로 구글 클라우드에서 돌릴 수 가 있다. (직업 특성상 클라우드 자원을 비교적 자유롭게 사용할 수 있었다.) Apache Beam으로 전처리 코드를 컨버팅 한결과 기존 싱글 쓰레드 파이썬 코드가 400~500장의 이미지 전처리에 1~2시간이 걸렸던 반면, 전환후에 대략 15~17분이면 끝낼 수 있었다. 전처리 중에는 서버의 대수가 1대에서 시작해서 부하가 많아지자 자동으로 5대까지 늘어났다. 이제는 아무리 많은 데이타가 들어오더라도 서버의 대수만 단순하게 늘리면 수분~수십분내에 수십,수만장의 데이타 처리가 가능하게 되었다.<그림. Apache Beam 기반의 이미지 전처리 시스템 실행 화면 > Apache Beam 기반의 이미지 전처리 코드는 https://github.com/bwcho75/facerecognition/blob/master/Preprocess%2Bface%2Brecognition%2Bdata%2Band%2Bgenerate%2Btraining%2Bdata.ipynb 에 공개해 놨다.  머신러닝 파이프라인 아키텍쳐와 프로세스이번 과정을 통해서 머신러닝의 학습 및 예측 시스템 개발이 어느 정도 정형화된 프로세스화가 가능하고 시스템 역시 비슷한 패턴의 아키텍쳐를 사용할 수 있지 않을까 하는 생각이 들었고, 그 내용을 아래와 같이 정리한다. 파이프라인 개발 프로세스지금까지 경험한 머신러닝 개발 프로세스는 다음과 같다. 데이타 분석먼저 머신러닝에 사용할 전체 데이타셋을 분석한다. 그래프도 그려보고 각 변수간의 연관 관계나 분포도를 분석하여, 학습에 사용할 변수를 정의하고 어떤 모델을 사용할지 판단한다.모델 정의 분석된 데이타를 기반으로 모델을 정의하고, 일부 데이타를 샘플링하여 모델을 돌려보고 유효한 모델인지를 체크한다. 모델이 유효하지 않다면 변수와 모델을 바꿔 가면서 최적의 모델을 찾는다.데이타 추출 및 전처리유효한 모델이 개발이 되면, 일부 데이타가 아니라 전체 데이타를 가지고 학습을 한다. 전체 데이타를 추출해서 모델에 넣어서 학습을 하려면 데이타의 크기가 크면 매번 매뉴얼로 하기가 어렵기 때문에 데이타 추출 및 전처리 부분을 자동화 한다.   전체 데이타를 이용한 반복 학습 및 튜닝모델 자체가 유효하다고 하더라도 전체 데이타를 가지고 학습 및 검증을 한것이 아니기 때문에 의외의 데이타가 나오거나 전처리에 의해서 필터링되지 않은 데이타가 있을 수 있기 때문에 지속적으로 데이타 추출 및 전처리 모듈을 수정해야 하고, 마찬가지로 모델 역시 정확도를 높이기 위해서 지속적으로 튜닝을 한다. 이 과정에서 전체 데이타를 다루기 때문에 모델 역시 성능을 위해서 분산형 구조로 개선되어야 한다. 모델 배포학습 모델이 완성되었으면 학습된 모델을 가지고 예측을 할 수 있는 시스템을 개발하고 이를 배포한다. 파이프라인 연결 및 자동화머신러닝의 모델은 위의 과정을 통해서 만들었지만, 데이타가 앞으로도 지속적으로 들어올 것이고 지속적인 개선이 필요하기 때문에 이 전과정을 자동화 한다. 이때 중요한것은 데이타 전처리, 학습, 튜닝, 배포등의 각 과정을 물 흐르듯이 연결하고 자동화를 해야 하는데 이렇게 데이타를 흐르는 길을 데이타 플로우라고 한다. (흔히 Luigi, Rundeck, Airflow와 같은 데이타플로우 오케스트레이션 툴을 이용한다)  전체적인 프로세스에 대해서 좋은 영상이 있어서 공유한다.아키텍쳐 위의 프로세스를 기반으로한 머신러닝 파이프라인 아키텍쳐 는 다음과 같다.   Inputs머신 러닝 파이프라인의 가장 처음단은 데이타를 수집하고 이 수집된 데이타를 저장하는 부분이다.데이타 수집은 시간,일,주,월과 같이 주기적으로 데이타를 수집하는 배치 프로세싱과, 실시간으로 데이타를 수집하는 리얼타임 프로세싱 두가지로 나뉘어 진다. 이 두 파이프라인을 통해서 데이타 소스로 부터 데이타를 수집하고 필터링하고 정재하여, 데이타 레이크에 저장한다. 이 구조는 일반적인 빅데이타 분석 시스템의 구조와 유사하다. (참고 자료 http://bcho.tistory.com/984 http://bcho.tistory.com/671 ) 개인적으로 머신러닝을 위해서 중요한 부분 중 하나는 데이타 레이크를 얼마나 잘 구축하느냐이다. 데이타 레이크는 모든 데이타가 모여 있는 곳으로 보통 데이타 레이크를 구축할때는 많은 데이타를 모으는 데만 집중하는데, 데이타를 잘 모으는 것은 기본이고 가장 중요한 점은 이 모여 있는 데이타에 대한 접근성을 제공하는 것이다. 무슨 이야기인가 하면, 보통 머신러닝 학습을 위해서 학습 데이타를 받거나 또는 데이타에 대한 연관성 분석등을 하기 위해서는 데이타 레이크에서 데이타를 꺼내오는데, 데이타 레이크를 개발 운영 하는 사람과 데이타를 분석하고 머신러닝 모델을 만드는 사람은 보통 다르기 때문에, 모델을 만드는 사람이 데이타 레이크를 운영하는 사람에게 “무슨 무슨 데이타를 뽑아서 CSV로 전달해 주세요.” 라고 이야기 하는 것이 보통이다. 그런데 이 과정이 번거롭기도 하고 시간이 많이 걸린다. 가장 이상적인 방법은 데이타를 분석하고 모델링 하는 사람이 데이타 레이크 운영팀에 부탁하지 않고서도 손쉽고 빠르게 데이타에 접근해서 데이타를 읽어오고 분석을 할 수 있어야 한다. 직업 특성상 구글의 빅쿼리를 많이 접하게 되는데, 빅쿼리는 대용량 데이타를 저장할 수 있을 뿐만 아니라 파이썬 노트북이나 R 스튜디오 플러그인을 통해서 바로 데이타를 불러와서 분석할 수 있다.  <그림 INPUT 계층의 빅데이타 저장 분석 아키텍쳐>Pre processing & Asset creationPre processing은 수집한 데이타를 학습 시스템에 넣기 위해서 적절한 데이타만 필터링하고 맞는 포맷으로 바꾸는 작업을 한다. 작은 모델이나 개발등에서는 샘플링된 데이타를 로컬에서 내려 받아서 R이나 numpy/pandas등으로 작업이 가능하지만, 데이타가 수테라에서 수백테라이상이 되는 빅데이타라면 로컬에서는 작업이 불가능하기 때문에, 데이타 전처리 컴포넌트를 만들어야 한다.일반적으로 빅데이타 분석에서 사용되는 기술을 사용하면 되는데, 배치성 전처리는 하둡이나 스파크와 같은 기술이 보편적으로 사용되고 실시간 스트리밍 분석은 스파크 스트리밍등이 사용된다.Train학습은 전처리된 데이타를 시스템에 넣어서 모델을 학습 시키는 단계이다. 이 부분에서 생각해야 할점은 첫번째는 성능 두번째는 튜닝이다. 성능 부분에서는 GPU등을 이용하여 학습속도를 늘리고 여러대의 머신을 연결하여 학습을 할 수 있는 병렬성이 필요하다. 작은 모델의 경우에는 수시간에서 하루 이틀 정도 소요되겠지만 모델이 크면 한달 이상이 걸리기 때문에 고성능 하드웨어와 병렬 처리를 통해서 학습 시간을 줄이는 접근이 필요하다. 작은 모델의 경우에는 NVIDIA GPU를 데스크탑에 장착해놓고 로컬에서 돌리는 것이 가성비 적으로 유리하고, 큰 모델을 돌리거나 동시에 여러 모델을 학습하고자 할때는 클라우드를 사용하는 것이 절대 적으로 유리하다 특히 구글 클라우드의 경우에는  알파고에서 사용된 GPU의 다음 세대인 TPU (텐서플로우 전용 딥러닝 CPU)를 제공한다. https://cloud.google.com/tpu/ CPU나 GPU대비 최대 15~30배 정도의 성능 차이가 난다.  학습 단계에서는 세부 변수를 튜닝할 필요가 있는데, 예를 들어 학습 속도나 뉴럴 네트워크의 폭이나 깊이, 드롭 아웃의 수, 컨볼루셔널 필터의 크기등등이 있다. 이러한 변수들을 하이퍼 패러미터라고 하는데, 학습 과정에서 모델의 정확도를 높이기 위해서 이러한 변수들을 자동으로 튜닝할 수 있는 아키텍쳐를 가지는 것이 좋다.  텐서플로우등과 같은 머신러닝 전용 프레임웍을 사용하여 직접 모델을 구현하는 방법도 있지만, 모델의 난이도가 그리 높지 않다면 SparkML등과 같이 미리 구현된 모델의 런타임을 사용하는 방법도 있다. PredictPredict에서는 학습된 모델을 이용하여 예측 기능을 서비스 하는데, 텐서플로우에서는  Tensorflow Serv를 사용하면 되지만, Tensorflow Serv의 경우에는 bazel 빌드를 이용하여 환경을 구축해야 하고, 대규모 서비를 이용한 분산 환경 서비스를 따로 개발해야 한다. 거기다가 인터페이스가 gRPC이다. (귀찮다.) 구글 CloudML의 경우에는 별도의 빌드등도 필요 없고 텐서 플로우 모델만 배포하면 대규모 서비스를 할 수 있는 런타임이 바로 제공되고 무엇보다 gRPC 인터페이스뿐만 아니라 HTTP/REST 인터페이스를 제공한다. 만약에 Production에서 머신러닝 모델을 서비스하고자 한다면 구글 CloudML을 고려해보기를 권장한다. Dataflow Orchestration이 전과정을 서로 유기적으로 묶어 주는 것을 Dataflow Orchestration이라고 한다.예를 들어 하루에 한번씩 이 파이프라인을 실행하도록 하고, 파이프라인에서 데이타 전처리 과정을 수행하고, 이 과정이 끝나면 자동으로 학습을 진행하고 학습 정확도가 정해진 수준을 넘으면 자동으로 학습된 모델은 서비스 시스템에 배포하는 이 일련의 과정을 자동으로 순차적으로 수행할 수 있도록 엮어 주는 과정이다.airbnb에서 개발한 Airflow나 luigi 등의 솔루션을 사용하면 된다. 아직도 갈길은 멀다.얼굴 인식이라는 간단한 모델을 개발하고 있지만, 전체를 자동화 하고, 클라우드 컴퓨팅을 통해서 학습 시간을 단축 시키고 예측 서비스를 할 수 있는 컴포넌트를 개발해야 하고, 향후에는 하이퍼 패러미터 튜닝을 자동으로 할 수 있는 수준까지 가보려고 한다. 그 후에는 GAN을 통한 얼굴 합성들도 도전하려고 하는데, node.js 공부하는데도 1~2년을 투자한후에나 조금이나마 이해할 수 있게 되었는데, 머신러닝을 시작한지 이제 대략 8개월 정도. 길게 보고 해야 하겠다.   window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1177}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글얼굴 인식 모델을 만들어보자 #3 - 학습된 모델로 예측하기  (2)2017.06.19연예인 얼굴 인식 모델을 만들어보자 - #2. CNN 모델을 만들고 학습시켜 보자  (15)2017.06.15연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기  (6)2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서  (0)2017.05.11머신러닝 모델 개발 삽질기  (0)2017.04.24Tagapache, Beam, CNN, course, Deep learning, image, jupyter, Machine Learning, pipe line, pre proceccing, Processing, python notebook, tensorflow, Tutorial, 강좌, 기초, 딥러닝, 머신러닝, 얼굴 인식, 오랜만에 포스팅, 조대협, 텐서플로우, 튜토리얼'빅데이타 & 머신러닝/머신러닝'의 다른글이전글연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기현재글머신러닝 시스템 프로세스와 아키텍쳐다음글연예인 얼굴 인식 모델을 만들어보자 - #2. CNN 모델을 만들고 학습시켜 보자관련글얼굴 인식 모델을 만들어보자 #3 - 학습된 모델로 예측하기2017.06.19연예인 얼굴 인식 모델을 만들어보자 - #2. CNN 모델을 만들고 학습시켜 보자2017.06.15연예인 얼굴 인식 모델을 만들어보자 - #1. 학습 데이타 준비하기2017.05.16얼굴 인식 모델 - 학습용 데이타 처리에 대해서2017.05.11loadedComments[1177]=true;findFragmentAndHighlight(1177);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Tag조대협,cloud,딥러닝,빅데이타,구글,node.js,튜토리얼,소개,Machine Learning,클라우드 컴퓨팅,google,텐서플로우,머신러닝,강좌,클라우드,Kubernetes,tensorflow,초보,Tutorial,쿠버네티스,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1177"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1177"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1177"",""entryTitle"":""머신러닝 시스템 프로세스와 아키텍쳐"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":""cfile24.uf@21431635593B7E921AC2CE.png"",""plink"":""/1177"",""tags"":[""apache"",""Beam"",""CNN"",""course"",""Deep learning"",""image"",""jupyter"",""Machine Learning"",""pipe line"",""pre proceccing"",""Processing"",""python notebook"",""tensorflow"",""Tutorial"",""강좌"",""기초"",""딥러닝"",""머신러닝"",""얼굴 인식"",""오랜만에 포스팅"",""조대협"",""텐서플로우"",""튜토리얼""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
92,https://gooopy.tistory.com/55,1. 렐루 함수의 생김새,"만년필잉크의 데이터 분석 지식 저장소  데이터 분석  R  설치 및 환경설정  Basic  시각화  Python  설치 및 환경설정  Basic  Pandas  Numpy  시각화  Machine Learning  Basic  ML_Algorithm  Deep Learning  TensorFlow  TensorBoard  분석에 필요한 배경 지식  결측값  이상치  Python으로 하는 기초 수학  행렬  Python으로 하는 기초통계학  기본 개념  여행기  나와 함께 떠나는 두 번째 자유여행 - 이탈리아편  기타  홈태그방명록 대학 다니면서 맨날 헷갈려서 싹 정주행 했는데 최고네요..절대 보존 해주⋯유익한 정보 감사합니다! 포스팅 잘보고 갑니다!딥러닝 공부하는 중인데 어려워서 찾다가 왔어요. 이해하기 쉬워요 감사합니⋯네 ㅎㅎ 맞구독 드렸습니다안녕하세요! 파이썬에 입문하여 새롭게 공부하게 된 뉴비입니다!공부하면서⋯422 /              108 /              874,025블로그 내 검색딥러닝-3.4. 활성화함수(5)-렐루 함수(ReLU)만년필잉크2021. 1. 27. 11:332021. 1. 27. 11:33activation, Python, ReLU, 기울기 소실, 렐루 함수, 렐루 함수의 한계점, 머신러닝, 활성화함수728x90반응형(adsbygoogle = window.adsbygoogle || []).push({}); 지금까지 계단 함수, 선형 함수, 시그모이드 함수, 소프트맥스 함수, 하이퍼볼릭 탄젠트 함수에 대해 다뤄보았다. 이들은 은닉층에서 사용해서는 안되거나, 사용할 수 있더라도 제한적으로 사용해야 하는 활성화 함수들이었다. 이번 포스트에서는 은닉층에서 많이 사용되는 렐루 함수에 대해 학습해 보겠다.   렐루 함수(Rectified Linear Unit, ReLU)렐루 함수는 딥러닝 역사에 있어 한 획을 그은 활성화 함수인데, 렐루 함수가 등장하기 이전엔 시그모이드 함수를 활성화 함수로 사용해서 딥러닝을 수행했다.그러나, 이전 포스트에서 언급했듯 시그모이드 함수는 출력하는 값의 범위가 0에서 1사이므로, 레이어를 거치면 거칠수록 값이 현저하게 작아지게 되어 기울기 소실(Vanishing gradient) 현상이 발생한다고 하였다.gooopy.tistory.com/52?category=824281 머신러닝-3.1. 활성화함수(2)-시그모이드 함수 지난 포스트에서 퍼셉트론의 가장 기본이 되는 활성화 함수인 계단 함수(Step Function)를 학습하였으며, 선형 함수(Linear Function)의 한계점에 대해서도 학습해보았다.  선형 함수는 층을 쌓는 것이gooopy.tistory.com이 문제는 1986년부터 2006년까지 해결되지 않았으나, 제프리 힌튼 교수가 제안한 렐루 함수로 인해, 시그모이드의 기울기 소실 문제가 해결되게 되었다.렐루 함수는 우리 말로, 정류된 선형 함수라고 하는데, 간단하게 말해서 +/-가 반복되는 신호에서 -흐름을 차단한다는 의미다.렐루 함수는 은닉층에서 굉장히 많이 사용되는데, 별생각 없이 다층 신경망을 쌓고, 은닉층에 어떤 활성화 함수를 써야 할지 모르겠다 싶으면, 그냥 렐루 함수를 쓰라고 할 정도로, 아주 많이 사용되는 활성화 함수이다(물론 신경망을 의도를 가지고 써보고 싶다면, 그래선 안된다.).    1. 렐루 함수의 생김새렐루 함수는 +신호는 그대로 -신호는 차단하는 함수라고 하였는데, 그 생김새는 아래와 같다.$$ h(x) = \begin{cases}  x \ \ \ (x>0) \\   0 \ \ \ (x\leq 0)  \end{cases} $$말 그대로, 양수면 자기 자신을 반환하고, 음수면 0을 반환한다.이번에는 이를 구현해보고, 어떻게 생겼는지 확인해보자.>>> import numpy as np# ReLU 함수를 구현해보자>>> def ReLU(x):    >>>     return np.maximum(0, x)단순하게 최댓값 함수를 사용하여 지금 들어온 값(원소별 연산이 된다!)이 0보다 크면 자기 자신을 반환하고, 그렇지 않으면, 최댓값인 0을 반환하는 함수를 이용해서 구현하였다.>>> import matplotlib.pyplot as plt>>> x = np.arange(-5.0, 5.0, 0.1)>>> y = ReLU(x)>>> fig = plt.figure(figsize=(8,6))>>> fig.set_facecolor('white')>>> plt.title(""ReLU"", fontsize=30)>>> plt.xlabel('x', fontsize = 15)>>> plt.ylabel('y', fontsize = 15, rotation = 0)>>> plt.axvline(0.0, color='gray', linestyle=""--"", alpha=0.8)>>> plt.axhline(0.0, color='gray', linestyle=""--"", alpha=0.8)>>> plt.plot(x, y)>>> plt.show()가장 많이 사용되는 활성화함수라기엔 지금까지 보아왔던 시그모이드, 소프트맥스, 하이퍼볼릭 탄젠트 등에 비해 너무 단순하게 생겼다는 생각이 들 것이다.그렇다면 왜 렐루 함수를 은닉층에서 많이 사용할까?    2. 렐루 함수를 은닉층에서 많이 사용하는 이유 기울기 소실(Vanishing Gradient) 문제가 발생하지 않는다.렐루 함수는 양수는 그대로, 음수는 0으로 반환하는데, 그러다 보니 특정 양수 값에 수렴하지 않는다. 즉, 출력값의 범위가 넓고, 양수인 경우 자기 자신을 그대로 반환하기 때문에, 심층 신경망인 딥러닝에서 시그모이드 함수를 활성화 함수로 사용해 발생한 문제였던 기울기 소실(Vanishing Gradient) 문제가 발생하지 않는다. 기존 활성화 함수에 비해 속도가 매우 빠르다동시에 렐루 함수의 공식은 음수면 0, 양수면 자기 자신을 반환하는 아주 단순한 공식이다 보니, 경사 하강 시 다른 활성화 함수에 비해 학습 속도가 매우 빠르다!확률적 경사하강법(SGD)을 쓴다고 할 때, 시그모이드 함수나 하이퍼볼릭 탄젠트 함수에 비해 수렴하는 속도가 약 6배 가까이 빠르다고 한다!ReLU가 나오기 전에는 활성화 함수가 부드러워야(Smooth) 가중치 업데이트가 잘된다고 생각하여 exp 연산이 들어간 시그모이드나, 하이퍼볼릭 탄젠트 함수를 사용하여쓰나, 활성화 함수가 부드러운(Smooth)한 구간에 도달하는 순간 가중치 업데이트 속도가 매우 느려진다.ReLU는 편미분(기울기) 시 1로 일정하므로, 가중치 업데이트 속도가 매우 빠르다.    3. 렐루 함수의 한계점렐루 함수의 그래프를 보면, 음수 값이 들어오는 경우 모두 0으로 반환하는 문제가 있다보니, 입력값이 음수인 경우 기울기도 모조리 0으로 나오게 된다.입력값이 음수인 경우에 한정되긴 하지만, 기울기가 0이 되어 가중치 업데이트가 안되는 현상이 발생할 수 있다.즉, 가중치가 업데이트 되는 과정에서 가중치 합이 음수가 되는 순간 ReLU는 0을 반환하기 때문에 해당 뉴런은 그 이후로 0만 반환하는 아무것도 변하지 않는 현상이 발생할 수 있다.이러한 죽은 뉴런(Dead Neuron)을 초래하는 현상을 죽어가는 렐루(Dying ReLU) 현상이라고 한다.또한 렐루 함수는 기울기 소실 문제 방지를 위해 사용하는 활성화 함수이기 때문에 은닉층에서만 사용하는 것을 추천한다.ReLU의 출력값은 0 또는 양수이며, ReLU의 기울기도 0 또는 1이므로, 둘 다 양수이다. 이로 인해 시그모이드 함수처럼 가중치 업데이트 시 지그제그로 최적의 가중치를 찾아가는 지그재그 현상이 발생한다.또, ReLU의 미분은 0 초과 시, 1 0은 0으로 끊긴다는 문제가 있다. 즉, ReLU는 0에서 미분이 불가능하다.(이에 대해 활성화 함수로는 미분 불가능 하다할지라도, 출력값 문제는 아니고, 0에 걸릴 확률이 적으니, 이를 무시하고 사용한다.)    지금까지 은닉층에서 주로 사용되는 활성화 함수인 렐루 함수에 대해 학습해보았다. 비록 렐루 함수가 입력값이 0일 때, 기울기가 0에 수렴해 가중치 업데이트가 안 되는 현상이 발생한다고는 하지만, 성능상 큰 문제가 없으며, 도리어 이를 해결하기 위해 만든 활성화 함수의 성능이 보다 안 나오는 경우도 있다고 한다. 때문에 기본적으로 은닉층에서는 렐루 함수를 사용하지만, 때에 따라 렐루 함수의 단점이 두드러지는 경우도 존재하므로, 렐루 함수의 한계점을 보완하기 위한 렐루 함수의 형제 함수들이 있다.  다음 포스트에서는 렐루 함수의 한계점을 극복하기 위해 만들어진 다양한 활성화 함수에 대해 학습해보도록 하곘다.728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//gooopy.tistory.com/reaction';window.ReactionReqBody = {    entryId: 55}공유하기게시글 관리만년필잉크의 데이터 분석 지식 저장소 저작자표시 비영리 동일조건 'Machine Learning > Deep Learning' 카테고리의 다른 글딥러닝-4.0. 인공신경망(1)-신경망 연산(SLP)  (0)2021.01.28딥러닝-3.5. 활성화함수(6)-ReLU Family  (0)2021.01.27딥러닝-3.3. 활성화함수(4)-하이퍼볼릭 탄젠트 함수(tanh)  (0)2021.01.26딥러닝-3.2. 활성화함수(3)-소프트맥스 함수(Softmax)  (0)2021.01.26딥러닝-3.1. 활성화함수(2)-시그모이드 함수(Sigmoid)  (3)2021.01.25loadedComments[55]=true;findFragmentAndHighlight(55);+ Recent postsPython-기초:3.2. 정규 표현식(3) - 메타 ⋯Python-기초:3.1. 정규 표현식(2) - Pyt⋯Python-기초:3.0. 정규 표현식(1) - 소개:⋯Pandas-데이터 프레임, 데이터 조회하기-3. Bo⋯Powered by Tistory, Designed by              wallelRss Feed and              Twitter,              Facebook,              Youtube,              Google+       $(document).ready(function () {      if ($('body').width() > ""960"") {        $(""#sidebar"").mCustomScrollbar({          theme: ""dark-thin"",          autoHideScrollbar: ""true""        });      };    });  티스토리툴바만년필잉크의 데이터 분석 지식 저장소구독하기                    (function () {                         var blogTitle = '만년필잉크의 데이터 분석 지식 저장소';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""3994521-55"",""customProps"":{""userId"":""0"",""blogId"":""3994521"",""entryId"":""55"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""55"",""entryTitle"":""딥러닝-3.4. 활성화함수(5)-렐루 함수(ReLU)"",""entryType"":""POST"",""categoryName"":""Machine Learning/Deep Learning"",""categoryId"":""824281"",""serviceCategoryName"":""과학"",""serviceCategoryId"":404,""author"":""4429291"",""authorNickname"":""만년필잉크"",""blogNmae"":""만년필잉크의 데이터 분석 지식 저장소"",""image"":""kage@bJebYZ/btqURufaeIp/mAvstcH7sJbprYFK4CVgJk"",""plink"":""/55"",""tags"":[""activation"",""Python"",""ReLU"",""기울기 소실"",""렐루 함수"",""렐루 함수의 한계점"",""머신러닝"",""활성화함수""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
93,https://pt1000.tistory.com/45,4차 산업혁명 시대의 인재 무엇에 따라 달라질까?,"4차산업혁명4차 산업혁명 직업_4차 산업혁명 인재상by 부매경2021. 4. 10.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90(adsbygoogle = window.adsbygoogle || []).push({});반응형(adsbygoogle = window.adsbygoogle || []).push({});안녕하십니까, 부경매입니다.  오늘은 4차 산업혁명, 지금 우리가 살고 앞으로 우리 집 어린 XY염색체가 살아가야 할 사회에 필요한 인재상에 대해 고민해 보았습니다. 집에서 열심히 유튜브 보거나, 게임을 하는 어린 XY염색체가 이 글을 볼 날을 기대하며... 4차 산업혁명 시대의 인재 무엇에 따라 달라질까? 4차 산업혁명의 진행으로 세상은 많은 변화가 생길 것이며, 그에 따라 유망 직종, 직업, 직장이 달라질 것입니다. 멀리서 예를 찾을 필요도 없이, 제가 학교 다닐때 가장 인기 있는 과는 기계공학, 항공우주공항, 조선해양, 원자력공학, 토목과 일명 개과가 한창 유행하고 취직도 가장 잘되는 과였습니다. 하지만 그 후 20년.....사향 사업으로 접어든 기계산업에 아직 종사하고 있는 저는 MZ세대와 데모 세대(저희 팀장님이 항상 자기는 데모 세대라고^^) 중간에 끼여서 이것도 저것도 아닌 어중간한 세대가 되었습니다.  시대 별로 인재의 기준이 달라지고, 유망 직종/직업이 달라집니다. 그럼 그 기준은 무엇일까요?속물처럼 보이겠지만, 인재들은 부와 권력이 집중 된 곳으로 이동하게 됩니다. 저 역시 학과선택 시 기계공학이 취직이 잘되고, 돈을 많이 벌 수 있다는 생각으로 기계공학을 선택한 것과 같이 사람들은 부와 권력이 집중되는 곳으로 모입니다. 시대별 인재상 미래 사회 인재상 과연 어떤 덕목이 필요한지 알아보기 위해 각 시대별로 어떻게 변화했는지 보면 미래의 인재상 동일한 방법으로 예측이 가능하지 않을까?각 시대별 부와 권력이 집중되는 곳이 어디 있지 한번 알아보겠습니다.   1. 수렵시대 ^^ 너무 멀리왔나요? 그래도 한번 보겠습니다. 수렵시대에서는 가장 큰 부는 식(먹는 것)을 해결하는 것이 가장 중요한 부의 척도였습니다. 부의 쌓는다는 의미보다 생존의 의미가 더 컸을 겁니다. 즉 동물을 잡거나, 열매을 채집하여 생존율이 높았을 겁니다. 그럼 수렵 사회에서의 인재의 역량은 무엇일까요? 건강한 신체가 가장 우선시 되었을 겁니다. 여기에 도구를 사용할 수 있는 사람들은 더 많은 식량을 안전하게 확보할 수 있었을 겁니다. 자연스럽게 권려도 힘이 강한 사람 중심으로 소규모 단위로 무리 지어 살았을 겁니다.  수렵시대의 인재는 바로 신체 건강한 육체를 가진 사람이었습니다.    2. 농경시대농경시대에 접어들면서 곡식을 심고, 가축을 기르면서 사유재산이라는 개념이 생겨났습니다. 식량을 많이 가진사람이 권련을 가지게 되고, 곡식과 가축을 기를 수 있는 강 주변으로 사람들이 모여 살았습니다. 농경사회에서 가장 필요한 역량은 바로 곡식을 키우는 방법을 아는 사람, 가축을 키우는 방법을 아는 사람들이었습니다. 그리고 이 시기에 사람들의 여유가 생기기 시작하면서, 문자, 숫자를 발명하였고, 이러한 문자와 숫자를 보유한 사람들이 부와 권력을 가지게 되었습니다.  농경사회의 인재는 바로 곡식, 가축을 키우는 방법을 알고 문자와 숫자를 사용하는 사람이었습니다.    3. 산업시대산업시대는 영국 증기기관의 개발로 시작되었고 금융기술로 정점을 찍었습니다. 이 시대는 수렵사회와 농경사회에서 중요시된 사람의 힘은 크게 의미가 없어집니다. 사람보다 힘이 강한 기계의 도입으로 상품의 대량생산이 가능해졌습니다. 기존 왕이나, 귀족들만이 보유한 물건들이 대량 생산되면서 부와 권력이 상인들로 넘어가게 됩니다. 그리고 상품이 생산해 내는 기계에 필요한 에너지(석탄, 석유)가 새로운 부의 척도가 되었습니다. 즉, 기계를 만들거나, 사용하는 기술을 보유한 사람이 인재가 되었고, 에너지 생산기술을 보유한 사람이 인재가 되었습니다. 그리고 증가한 부를 관리(증가)하는 기술인 금융업이 발달하면서 금융지식을 가지고 있는 사람이 최고의 부를 얻게 되었습니다. 산업시대는 이러한 공장이나 금융기관을 중심을 도시가 형성, 권력이 생성되게 되었습니다.  산업사회의 인재는 바로 증기기관을 이용할 수 있고, 석탄/석유 에너지 생산, 판매하며 금융지식을 보유한 사람이었습니다.   4. 정보사회정보화사회는 컴퓨터와 인터넷 기반의 디지털 기술이 부의 척도가 되었습니다. 모든 생산은 이러한 디지털 기반의 로봇으로 제품을 자동화 설비에서 생산해 냅니다.정보의 증가로 인해 사람들의 생각의 수준이 향상되었고, 새로운 가상 인터넷 공간에서 정보 및 지식을 공유하게 됩니다.디지털 세상에서 생산된 정보는 자산의 가치로 인정받으면서 플랫폼 사업이 급성장하게됩니다. 산업시대는 대도시 중심으로 집단이 형성되어 권력의 중심이 되었지만, 정보사회에서는 디지털 가상세계에서 정보공유를 통해 권력이 형성됩니다정보사회에서는 디지털 정보의 창출, 관리, 거래 능력이 인재의 큰 역량으로 여겼습니다.  최근 프로그래머의 부족으로 국내 IT 기업에서 고급 프로그램머 이탈을 막기 위해 엄청난 연봉 인상을 한 뉴스를 보았습니다. 그리고 앱 개발자, IT 개발자, 시스템 엔지니어, 네트워크 관리자, DB 관리자, 개인정보 관리사 등 디지털 정보를 창출, 관리, 거래 능력을 보유한 사람이 인재로 여겨집니다.  디지털의 개념을 조금 더 확대 시키면, copy & paste가 가능한 모든 것을 이야기하는데 자동차, 핸드폰 등도 Copy 해서 3d 프린트로 제작 가능함으로 모든 제품들이 디지털이라고 할 수 있습니다. 결국 디지털은 사업의 전방위에서 적용되고 있으며, 모든 사업에 필요한 역량으로 여겨집니다.   5. 만능지능시대(?)  4차 산업혁명 또는 그 이후 시대를 뭐라고 부르는지는 아직 정확하게 정해지지 않았으나, 많은 곳에서 지능이란 단어는 기본적으로 포함되어 있어 일단 만능 지능 시대라고 적었습니다. 만능 지능 시대의 생산기반은 인공지능 로봇이며, 인간 두뇌는 인공지능으로 대체되어 자동화가 이루어질 겁니다. 기존의 제품생산에 자동화가 아닌 생각/지능의 자동화가 이루어집니다. 사람의 고유의 역할이라고 생각한 생각/지능도 필요가 없어지는 시대가 올까요? 인공지능의 발달로 지능은 폭발적인 증가할 것이고 사람의 자유의 시간과 생명의 증가는 세상의 많은 것을 변화시킬 것입니다.AI를 통한 생산관리, 창조, 거래 능력이 부를 급격하게 증가될 것이며, 권력은 AI 기술기반의 창의성 발휘로 세상을 혁신적으로 변화시키는 개인을 중심으로 형성될 것이다.  즉 만능지능시대의 인재상은 AI을 통한 창조, 생산, 거래 능력을 보유한 사람이 인재로 여겨질 것이다.  각 시대별로 기능적인 측면에 대해서만 인재상을 설명하였는데, 인재상이라고 하면 가장 많이 사용하는 단어가 창의적인, 독창적인 뭐 이런 것을 떠올린다. 굳이 붙이자면 ""AI 기술을 보유한 창의적인 사람"" 이렇게 되는 것입니다. 하지만 정보시대 및 만능 지능의 시대에 가장 중요한 인재상(기능적인 것을 제외한)으로 공감력, 인문학적 사고력, 미래 예측력, 통찰력 등이 보다 중요해집니다.    미래에 대한 준비는? 역량은 어떻게 준비 해야할까?4차 산업혁명의 혁신적인 기술인 AI, 로봇공학, 생명공학, 나노기술, 바이오는 앞으로 계속 각광받는 직종이 될 것이며, 이러한 기술 중심으로 부가 이동될 것입니다. 이러한 시대의 우리는 어떤 미래역량을 보유해야 할까요?1. 4차 산업혁명의 기술 이해는 필수, 스마트한 기술을 잘 사용하는 것은 반드시 필요함2. 인문학적 통찰력, 산업은 결국 사람을 위해 존재, 사람의 문제임으로 인문학적 소양은 반드시 필요함3. 2번과 동일한 맥락으로 인간에 대한 공감능력과 도덕성은 더욱 중요시될 것입니다. 4. 커뮤니케이션 능력, 4차 산업혁명의 키는 초연결로 다른 사업과의 협업은 필수적입니다.    4차 산업혁명 직업_미래 어떤 직업이 유망한가? 4차 산업혁명 시대 유망 직종으로 아래와 같은 미래 직업이 있습니다.  아바타 개발자인공장기 개발자탈부착 골격 증강기 연구자 오감 인식 기술자사물 데이터 기술자데이터 삭제 전문가문화갈등 해결사뽑았는데요 현재는 모두 존재하지 않은 직업들입니다.   마무리하면서...미래를 정확하게 예측할 수는 없지만, 현재의 낡은 방식의 기술과 사고방식은 버릴 수 있어야 합니다. 새로운 미래에 유연하기 대처하기 위해서는 새로운 지식에 항상 적극적인 자세로 맞이하는 사람이 되어야겠습니다.  10일 정도 공부하고 정리해서 작성했는데, 정리하기 쉽지 않네요. 궁금하신 점이나 더 문의사항이 있으시면 댓글 남겨주세요 더 공부해서 추가하도록 하겠습니다.  # 4차 산업혁명 이야기 (tistory.com) # 4차 산업혁명 이야기우리 집 XX염색체가 막연하게 질문을 던졌다. ""4차 산업혁명이 뭐야?"" 음.. ""3차 산업혁명 다음?"" 나의 티스토리 주제(미래사회에 대한 고민)에 가장 먼저 나와야 할 이야기였으나, 이제야 한번 정pt1000.tistory.com이상입니다.감사합니다. 좋은 밤되십시오. window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//pt1000.tistory.com/reaction';window.ReactionReqBody = {    entryId: 45}공유하기게시글 관리부자는 매일아침 뭘 할까? '4차산업혁명' 카테고리의 다른 글인공지능(AI) 2편_인공지능의 시대  (12)2021.04.19인공지능(AI) 1편_인공지능의 역사  (6)2021.04.16로봇(Robot)산업_총정리  (10)2021.04.074차 산업혁명이란? 4차 산업혁명 기술 6가지 총 정리  (18)2021.04.05증강현실(AR)_총정리  (8)2021.04.03태그4차 산업혁명, 4차 산업혁명 유망직업, 4차 산업혁명 인재상, 4차 산업혁명 직업, 미래 유망 직업, 미래 유망직업, 미래 인재상, 미래 직업, 미래학관련글인공지능(AI) 2편_인공지능의 시대인공지능(AI) 1편_인공지능의 역사로봇(Robot)산업_총정리4차 산업혁명이란? 4차 산업혁명 기술 6가지 총 정리loadedComments[45]=true;findFragmentAndHighlight(45);"
94,https://codu.tistory.com/46,1. 아나콘다 설치,"개발 일기라기 보단 메모장/Python파이썬 머신러닝을 위한 환경세팅  막걸리에감자전2022. 7. 11. 22:23     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});1. 아나콘다 설치- 접속 및 다운로드 : https://www.anaconda.com/products/distribution-  아나콘다 설치시 필요한 패키지들이 같이 설치된다.(numpy, pandas , scikit learn, jupyter 등등..) Anaconda | Anaconda DistributionAnaconda's open-source Distribution is the easiest way to perform Python/R data science and machine learning on a single machine.www.anaconda.com - scikit-learn의 버전에 따라서 결과값이 달라지게 되는데, 우선은 학습과 동일한 결과를 위해 1.0.2 버전으로 맞춰준다.$ (base) pip install scikit-learn==1.0.2 2. Xgboost 설치- 접속 및 설치 : https://anaconda.org/conda-forge/xgboost- 아래와 같이 conda로 설치도 가능하고, 설치시 권한오류가 발생하면 앞에 sudo를 붙여서 재실행.$ (base) conda install -c anaconda py-xgboost Xgboost :: Anaconda.orgScalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink and DataFlowanaconda.org 3. lightgbm 설치- 강의에서는 visual studio code 빌드 도구를 다운 받아 설치하여 진행하였으나, 나는 맥을 사용하기에 설치가 되지 않아 다른 블로그를 보고 설치하였다.- 맥 사용자 lightgbm 설치하고 참고 : https://randomwalk.tistory.com/56 맥북 M1에서 LightGBM, XGBoost 설치하는 방법Step 1: Xcode Command Line Tools를 설치한다. xcode-select --install Step 2: Brew를 설치한다. /bin/bash -c ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"" Step 3: m..randomwalk.tistory.com# 1. Xcode Command Line Tools 설치$ xcode-select --install# 2. brew 설치$ /bin/bash -c ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)""# 3. brew로 miniforge 설치$ brew install miniforge# 4. brew로 cmake libomp 설치$ brew install cmake libomp 이후에는 가상환경으로 접속하여 lightgbm과 xgboost를 설치해준다.# lightgbm 설치$ (base) conda install lightgbm# xgboost 설치$ (base) pip install xgboost반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//codu.tistory.com/reaction';window.ReactionReqBody = {    entryId: 46}공유하기게시글 관리막걸리에감자전저작자표시 '개발 일기라기 보단 메모장 > Python' 카테고리의 다른 글머신러닝 공부를 위한 numpy 기본기 1 (ndarray)  (0)2022.07.21머신러닝공부 R vs Python 비교하기  (0)2022.07.11머신러닝이란 무엇일까?  (0)2022.07.11Mac Anaconda 설치 이후 터미널 실행시 가상환경 자동 시작 설정 해제하기  (0)2022.06.28'개발 일기라기 보단 메모장/Python' Related Articles머신러닝 공부를 위한 numpy 기본기 1 (ndarray)머신러닝공부 R vs Python 비교하기머신러닝이란 무엇일까?Mac Anaconda 설치 이후 터미널 실행시 가상환경 자동 시작 설정 해제하기Secret댓글달기loadedComments[46]=true;findFragmentAndHighlight(46);"
95,https://igwest.tistory.com/2043,태그,"IT과학/코딩및컴퓨터머신러닝, 딥러닝 간단히 알아보기 아이지웨스트2023. 9. 30. 04:00300x250반응형(adsbygoogle = window.adsbygoogle || []).push({});ai, 인공지능, 딥러닝, 머신러닝 등 다양한 용어들이 여기저기서 들려옵니다. ai는 챗봇, 빙봇등 다양한 인공지능을 갖춘 인간의 사고방식을 흉내내는 컴퓨터 프로그램입니다. 인공지능이 인류를 능가하는 순간의 날이 다가오고 있는듯합니다. 인공지능의 실체인 소프트웨어는 인간이 만들어낸 것인데, 기술적 특이점은 인공지능이 사람의 힘을 빌리지 않고 자신의 능력을 갱신해 나가는 순간을 뜻하기도 합니다. 오늘은 이러한 인공지능 관련 딥러닝과 머신러닝에 대하여 간단히 알아보겠습니다. ◆ 인공지능(ai)란? 인간의 사고방식을 흉내 내는 컴퓨터 인간이 지닌 스스로 생각하는 능력을 컴퓨터로 실현하는 기술로서, 인공지능(ai)의 실체는 컴퓨터 프로그램이다. 보통의 프로그램은 주어진 지시와 정보만 처리하지만, ai프로그램은 사람이 일일이 지시할 필요가 없는 자율성과 조건이 변화하더라도 처리할 수 있는 적응력을 갖추고 있다. 이런 특성 덕분에 사진에 찍힌 사람의 얼굴을 식별하는 등의 처리가 가능하다. ◆ 머신 러닝(기계학습) 컴퓨터가 공부하는 것 컴퓨터에 데이터를 줘서 학습시키며 인공지능을 실현하는 기술중 하나이다. 답을 표시한 테이터를 인공지능에 줘서 학습시키는 방법은 지도학습. 인공지능이 답이 없는 데이터에서 답을 찾아내도록 학습시키는 방법은 비지도 학습이다. 손 글씨를 자동 인식하는 기능이나 인터넷 쇼핑몰에서 구매 이력을 바탕으로 상품을 추천하는 기능 등에 머신 러닝이 사용되고 있다. 반응형(adsbygoogle = window.adsbygoogle || []).push({});◆ 딥 러닝(심층 학습) 무엇을 학습할지 컴퓨터가 스스로 생각한다. 머신 러닝의 수법 중 하나로, 특히 비지도 학습에 적합하다. 뇌를 모델로 삼은 인공 신경망(뉴럴 네트워크)를 응요한 것으로 인공 신경망의 층이 깊기(많기) 때문에 딥(Deep)이라고 부른다. 학습해야 할 특징은 영상 인식을 예로 들면 색.형태.모양 등을 가리킨다. 빨간 사과와 빨간 토마토처럼 분명히 다르지만 단순히 색(빨간색)이나 형태(구형) 만으로는 구별이 불가능한 차이를 인식할 수 있다. ★인공 신경망 (뉴럴 네트워크) 사람의 뇌 속에는 대량의 신경세포(뉴런)가 있으며, 뉴런과 뉴런 사이에서 펄스 형태의 전기신호를 통해 정보가 전달된다. 사람의 뇌를 컴퓨터로 구현하기 위해 이 정보 전달 방식을 수리 모델로 만든 것이 인공신경망이다. 1950년대에 처음 만들어졌다. https://igwest.tistory.com/1794 모니터 패널(VA,TV,IPS)의 종류와 모니터해상도 알아보기컴퓨터를 사용하다 보면 고사양 컴퓨터를 사고 싶은 욕망이 생깁니다. 컴퓨터의 사양을 체크하다보면 모니터도 중요하다는 걸 새삼 느끼게 되지요. 오늘은 모니터의 종류,패널 장단점에 대하여igwest.tistory.com 300x250반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//igwest.tistory.com/reaction';window.ReactionReqBody = {    entryId: 2043}공유하기게시글 관리아이지웨스트저작자표시 비영리 변경금지 'IT과학 > 코딩및컴퓨터' 카테고리의 다른 글무료암호화프로그램 (이지크립트) 설치과 사용방법  (1)2024.01.08PC 작업표시줄에 아이콘 사라짐 현상.. 간단히 해결하기  (1)2023.10.03PC 시작메뉴 에러시 초기화 하는 간단한 방법  (0)2023.09.05램(메모리) 셀프 업그레이드시 주의사항 알아보기  (0)2023.08.13원드라이브 파일삭제 오류 현상 해결방법  (0)2023.05.31태그기계학습, 뉴럴네트워크, 딥러닝이란, 머신러닝이란, 인공신경망'IT과학/코딩및컴퓨터' Related Articles무료암호화프로그램 (이지크립트) 설치과 사용방법PC 작업표시줄에 아이콘 사라짐 현상.. 간단히 해결하기PC 시작메뉴 에러시 초기화 하는 간단한 방법램(메모리) 셀프 업그레이드시 주의사항 알아보기Secret댓글달기loadedComments[2043]=true;findFragmentAndHighlight(2043);"
96,https://jpub.tistory.com/617,태그,"도서 소개딥 러닝 제대로 시작하기 제이펍2016. 10. 11. 18:02그동안 읽어주신 분들께 감사드립니다. 이 책은 현재 절판되었습니다.데이터 과학과 머신 러닝 전문가를 위한 콤팩트한 입문서!기초부터 고급 이론까지 체계적으로 정리하여 알기 쉬운 딥 러닝 교과서! 출판사 제이펍원출판사 고단샤(講談社)원서명 深層学習(ISBN: 9784061529021)지은이 오카타니 타카유키옮긴이 심효섭출판일 2016년 10월 10일페이지 220쪽시리즈 I♥A.I. 01판  형 크라운판 변형(170*225*13)제  본 무선(soft cover)정  가 20,000원ISBN 979-11-85890-59-3 (93000)키워드 deep learning / 인공지능 / 머신 러닝 / machine learning / 데이터 과학 / 데이터 분석분  야 컴퓨터 공학 > 인공지능 관련 사이트■ 아마존 재팬 도서소개 페이지■ 원출판사 도서소개 페이지 관련 포스트■ 2016/09/29 - [출간전 책소식] - 딥 러닝의 원리를 제대로 배운다 관련 시리즈■ I♥A.I.(아이러브인공지능) 관련 도서■ 인공지능 1: 현대적 접근방식(제3판)■ 인공지능 2: 현대적 접근방식(제3판)■ 머신러닝 인 액션: 기계 학습 알고리즘으로 데이터 마이닝하기 관련 파일 다운로드■ 본문의 그림 과 표 PDF 파일딥러닝제대로시작하기_내지(그림표A4)_160929.pdf다운로드   강의보조 자료교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표 샘플 PDF(차례, 옮긴이 머리말, 머리말, 베타리더 후기, 1장 시작하며)딥러닝제대로시작하기_sample.pdf다운로드  정오표 페이지■ http://jpub.tistory.com/656 도서구매 사이트(가나다순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크] 도서 소개데이터 과학과 머신 러닝 전문가를 위한 콤팩트한 입문서!기초부터 고급 이론까지 체계적으로 정리하여 알기 쉬운 딥 러닝 교과서!딥 러닝의 동작 원리를 이해시키는 핵심 수식과 그림, 간결한 해설이 돋보이는 책! 이 책은 최근 많은 관심을 받고 있는, 머신 러닝의 접근 방법론 중 하나인 딥 러닝을 권위 있는 저자가 알기 쉽게 해설한 책이다. 딥 러닝의 기초부터 확률적 경사 하강법(SGD), 자기부호화기(autoencoder), 합성곱 신경망(CNN), 재귀 신경망(RNN), 제약 볼츠만 머신(RBM)에 이르는 다양한 기법을 명쾌하게 설명하고 있으며, 일본 고단샤 출판사에서 기획한 기계학습 프로페셔널 시리즈(총 29종) 중 가장 인기가 많은 책이기도 하다. 대상 독자■ 데이터 과학을 배우려는 대학생/대학원생■ 머신 러닝 기법을 응용하려는 연구자나 엔지니어 주요 내용1장: 신경망 연구의 간략한 역사와 이 책의 구성을 다룬다.2장: 앞먹임 신경망을 다룬다. 이는 입력에서 출력까지 정해진 한 방향으로만 정보가 전달되는 신경망으로, 가장 기본적이자 널리 응용되는 신경망이다. 3장: 앞먹임 신경망의 학습 방법을 설명한다. 특히, 딥 뉴럴넷에서 기본적인 학습 방법으로 활용되는 확률적 경사 하강법에 초점을 맞추고 기초 이론과 방법을 설명한다. 4장: 오차 기울기를 구하기 위한 방법으로 역전파법을 설명한다. 5장: 자기부호화기(autoencoder)를 다룬다. 이는 비지도 학습을 하는 신경망으로, 주로 데이터를 잘 나타내는 자질을 학습하고 데이터에 대한 좋은 표현을 얻는 것을 목적으로 한다. 열쇠가 되는 희소 규제화나 데이터 백색화에 대해서도 설명한다. 또, 자기부호화기를 이용한 딥 뉴럴넷의 사전훈련 방법도 다룰 것이다.6장: 이미지에 대한 응용에서 빼놓을 수 없는 합성곱 신경망을 다룬다. 합성곱층과 풀링층 등 특수한 구조를 갖는 층에 대해서 자세히 설명하고 구체적인 응용 예를 소개한다. 7장: 재귀 신경망을 다룬다. 재귀 신경망을 위한 기본적인 구성과 학습 방법을 설명하고, 음성 인식, 필기 인식 등의 성공적으로 응용되고 있는 장·단기 기억과 입력 연속열과 길이가 다른 연속열을 추정할 수 있는 커넥셔니스트 시계열 분석법 등을 설명한다.8장: 볼츠만 머신을 다룬다. 다른 장에서 다룬 신경망과 달리, 유닛 간에 양방향성 결합을 가지며 그 거동이 확률적으로 기술되는 것이 특징이다.  저자 소개오카타니 타카유키(岡谷 貴之)1999년에 도쿄대학 대학원 공학계연구과 계수공학 전공으로 박사과정을 수료하였다. 현재는 도호쿠대학 대학원 정보과학연구과 교수로 재직 중이다. 역자 소개심효섭연세대학교 문헌정보학과를 졸업했고, 모교 중앙도서관과의 인연으로 도서관 솔루션 업체에서 일하게 되면서 개발을 시작하였다. 네이버에서는 웹 서비스 개발 업무를 맡았으며, 웹 서비스 외에도 머신 러닝에 대한 학습도 꾸준히 하고 있다. 한편, 최근에는 회사에 속하지 않고 지속 가능한 삶에 골똘하고 있다. 차례1장 시작하며 _ 11.1 신경망 연구의 역사 3    1.1.1 다층 신경망에 대한 기대와 실망 3    1.1.2 다층 신경망의 사전훈련 4    1.1.3 자질에 대한 학습 6    1.1.4 딥 러닝의 융성 71.2 이 책의 구성 9더보기2장 앞먹임 신경망 _ 112.1 유닛의 출력 132.2 활성화 함수 152.3 다층 신경망 182.4 출력층의 설계와 오차함수 21    2.4.1 학습의 얼개 21    2.4.2 회귀 22    2.4.3 이진 분류 23    2.4.4 다클래스 분류 25 3장 확률적 경사 하강법 _ 293.1 경사 하강법 313.2 확률적 경사 하강법 333.3 ‘미니배치’의 이용 353.4 일반화 성능과 과적합 363.5 과적합을 완화시키는 방법 38    3.5.1 규제화 38    3.5.2 가중치 감쇠 39    3.5.3 드롭아웃 403.6 학습을 위한 트릭 43    3.6.1 데이터 정규화 43    3.6.2 데이터 확장 45    3.6.3 여러 신경망의 평균 45    3.6.4 학습률의 결정 방법 46    3.6.5 모멘텀 48    3.6.6 가중치의 초기화 49    3.6.7 샘플의 순서 50 4장 역전파법 _ 534.1 기울기 계산의 어려움 554.2 2층으로 구성된 신경망의 계산 574.3 다층 신경망으로 일반화 604.4 경사 하강법의 전체 알고리즘 63    4.4.1 출력층의 델타 63    4.4.2 순전파와 역전파의 행렬 계산 65    4.4.3 기울기의 차분근사 계산 674.5 기울기 소실 문제 68 5장 자기부호하기 _ 715.1 개요 735.2 자기부호화기의 설계 74    5.2.1 출력층의 활성화 함수와 오차함수 74    5.2.2 가중치 공유 755.3 자기부호화기의 동작 76    5.3.1 데이터를 나타내는 특징을 학습 76    5.3.2 주성분 분석과의 관계 785.4 희소 규제화 80    5.4.1 데이터의 과완비한 표현 80    5.4.2 최적화 83    5.4.3 희소 규제화의 효과 855.5 데이터의 백색화 875.6 딥 뉴럴넷의 사전훈련 925.7 그 외의 자기부호화기 94    5.7.1 심층 자기부호화기 94    5.7.2 디노이징 자기부호화기 95 6장 합성곱 신경망 _ 996.1 단순 세포와 복잡 세포 1016.2 전체적인 구조 1046.3 합성곱 105    6.3.1 정의 105    6.3.2 합성곱의 작용 106    6.3.3 패딩 107    6.3.4 스트라이드 1086.4 합성곱층 1096.5 풀링층 1126.6 정규화층 115    6.6.1 국소 콘트라스트 정규화 115    6.6.2 단일 채널 이미지의 정규화 116    6.6.3 다채널 이미지의 정규화 1186.7 기울기의 계산 1196.8 실제 예: 물체 유형 인식 121 7장 재귀 신경망 _ 1357.1 연속열 데이터의 분류 1377.2 RNN의 구조 1397.3 순전파 계산 1427.4 역전파 계산 1447.5 장·단기기억 147    7.5.1 RNN의 기울기 소실 문제 147    7.5.2 LSTM의 개요 148    7.5.3 순전파 계산 149    7.5.4 역전파 계산 1517.6 입력과 출력의 연속열 길이가 다른 경우 153    7.6.1 은닉 마르코프 모델 153    7.6.2 커넥셔니스트 시계열 분류 154 8장 볼츠만 머신 _ 1618.1 데이터의 생성 모델 1638.2 볼츠만 머신 164    8.2.1 확률적 구조 164    8.2.2 학습 1668.3 깁스 샘플링 1688.4 은닉 변수를 갖는 볼츠만 머신 170    8.4.1 확률적 구조 170    8.4.2 학습 1718.5 제약 볼츠만 머신 173    8.5.1 확률적 구조 173    8.5.2 조건부 분포 174    8.5.3 RBM과 자기부호화기 1758.6 RBM의 학습 176    8.6.1 깁스 샘플링을 사용한 기울기 계산 176    8.6.2 대조적 발산(CD) 178    8.6.3 CD의 실제 적용 180    8.6.4 지속적 CD 1828.7 그 외의 유닛 183    8.7.1 가우시안 유닛 183    8.7.2 ReLU 1848.8 딥 빌리프 네트워크 1868.9 딥 볼츠만 머신 1888.10 성능 비교 191 참고문헌 194찾아보기 199   window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 617}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글ATmega128로 배우는 마이크로컨트롤러 프로그래밍  (7)2016.12.06아이폰 이후의 UX  (0)2016.11.18오픈스택 기반의 프라이빗 클라우드 서비스: 기획에서 구축과 운영까지  (2)2016.10.07TCP/IP 쉽게, 더 쉽게:  명쾌한 설명과 풍부한 그림으로 배우는  (0)2016.09.23리눅스 바이블(제9판)  (4)2016.09.13태그deep learning, Machine Learning, 데이터과학, 데이터분석, 딥러닝, 머신러닝, 심효섭, 아이러브AI, 인공지능, 제이펍'도서 소개' Related ArticlesATmega128로 배우는 마이크로컨트롤러 프로그래밍아이폰 이후의 UX오픈스택 기반의 프라이빗 클라우드 서비스: 기획에서 구축과 운영까지TCP/IP 쉽게, 더 쉽게:  명쾌한 설명과 풍부한 그림으로 배우는    setInitialEntryComments(617, 1723627692)Secret댓글달기loadedComments[617]=true;findFragmentAndHighlight(617);"
97,https://james.tistory.com/163,티스토리툴바,"JAMES BLOGN o t i c el i s tt a gg u e s ta d m i n rssflashWrite(""https://tistory1.daumcdn.net/tistory/537/skin/images/title.swf"",""850"",""50"",""title_flash"",""#ffffff"",""isContent=Y&titleText=@ Tistory.com 이용후기&titleLink=/163&detailText=카테고리 없음 | 2011. 6. 28. 17:57 | "");다음에서 티스토리 도메인으로 메일계정을 서비스했다 티스토리를 사용하는 블로거 로서는 얼마나 고마운 서비스인가?이제는 티스토리만의 이메일로 수신및 발신을 자유롭게 할수있어서 정말좋다..p.s 이용후기쓰면 정말로 용량을 추가해주나요?window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//james.tistory.com/reaction';window.ReactionReqBody = {    entryId: 163}공유하기게시글 관리JAMES BLOG저작자표시 비영리 변경금지 ─ tag  @tistory.com @ Tistory.com 이용후기   :: 2011. 6. 28. 17:57 카테고리 없음 댓글쓰기 1    setInitialEntryComments(163, 1723627692)Your Name (required)Password (required)Your Website AddressSecretloadedComments[163]=true;findFragmentAndHighlight(163);opencloseWAU_colored('5vp12j4oeigx', '28903afff200')"
98,https://mokeya.tistory.com/76,SQL을 이용한 데이터 추출,"Programming/Knowledge[데이터 사이언티스트 독학 01] Data Science의 정의, 데이터 처리(Data Processing)를 배우는 방법by 지표덕후2021. 8. 18..adsbygoogle.post-top-first {display:block;}.adsbygoogle.post-top-second {display:none}@media (min-width: 680px) {.adsbygoogle.post-top-first {display:inline-block;min-width:300px;max-width:300px;width:100%;height:250px;}.adsbygoogle.post-top-second {display:inline-block;margin-left:20px;min-width:300px;max-width:300px;width:100%;height:250px;}}@media (min-width: 768px) {.adsbygoogle.post-top-first {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}.adsbygoogle.post-top-second {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}}(adsbygoogle = window.adsbygoogle || []).push({});(adsbygoogle = window.adsbygoogle || []).push({});반응형(adsbygoogle = window.adsbygoogle || []).push({});싱가폴 출신의 데이터 사이언티스트, Travis Tang님의 아티클을 번역한 글입니다.데이터 사이언티스트 wannabe라면, 일독할 가치가 충분한 글입니다.Travis Tang님은 화학공학을 전공했지만 테크기업에서 데이터 분석가로 사회생활을 시작했습니다.몇 차례에 걸쳐 포스팅 될 그의 이 아티클은 화학공학도가데이터 사이언티스트로 일하기까지의 여정과 필요한 스킬셋(skill set)을 구체적으로 담고 있습니다.Tang은, 데이터 사이언티스트로 나아가는 데 필요한 정보는 홍수처럼 넘치는데오히려 그 때문에 최고의 자원을 선별해내는 것이 어렵다고 토로합니다.그렇기 때문에 먼저 아래의 질문에 답을 할 수 있어야 한다고 강변합니다.정보의 홍수데이터 과학이란 무엇입니까?아, 이것은 인사 담당자와 기업의 면접관 모두를 당황하게 만드는 대답하기 어려운 질문입니다. 사실, 회사마다 데이터 과학을 다르게 정의하여 용어가 모호하고 다소 이해하기 어렵습니다. 프로그래밍이라고 하는 사람도 있고 수학이라고 말하는 사람도 있고 데이터를 이해하는 일이라고 말하는 사람도 있습니다. 모두 어느 정도 맞는 말입니다. 나(Travis Tang)에게 가장 동의하는 정의는 다음과 같습니다.데이터 사이언스data science는 수학, 컴퓨터 과학, 도메인 지식 분야에서 도출된 기술과 이론을 사용하는, 학제를 넘나드는(inter-disciplinary) 분야이다.아래 그림은 위의 정의를 잘 보여주는 이미지입니다.데이터 사이언스는 다양한 학문들의 교차로이 이미지에서 각 분야의 지식이 뭉쳐 데이터 과학을 형성한다는 것을 보여주기 위하여 분야 사이의 경계를 흐릿하게 묘사했습니다.자, 그럼 데이터 사이언스, 데이터 과학을 배우기 위해선 뭘 해야 할까요?일련의 게시물을 통해 저는 데이터 사이언티스트로 나아가는 과정에서 제가 배운 것들을 알려드리려 합니다. 이를 통해 저와 같은 입장에 있는 분들이 데이터 사이언스를 배워나가는 데에 도움이 되었으면 합니다. 이 아티클은 아래와 같은 내용으로 구성될 예정입니다.1부 — SQL, Python 및 R을 사용한 데이터 처리(본 게시물의 내용)2부 — 수학, 확률 및 통계3부 — 컴퓨터 과학 기초4부 — 기계학습(머신러닝)5부 — 첫 번째 기계 학습 프로젝트 구축     (adsbygoogle = window.adsbygoogle || []).push({}); 첫 번째 게시물인 이 글에서는 데이터 사이언티스트에게 필요한 데이터 처리(data processing) 지식에 대해 주로 다루게 될 것입니다. 제가 생각할 때 데이터를 처리와 관련해서는 일반적으로 아래의 것들을 배워야 합니다.SQL(Standard Query Language)을 사용하여 데이터베이스에서 데이터를 추출하고데이터 정리/ 조작/ 분석(일반적으로 Python 및/또는 R 사용)하여,데이터를 효과적으로 시각화합니다.SQL을 이용한 데이터 추출SQL은 데이터가 있는 데이터베이스와 통신하는 언어입니다. 데이터가 지하에 묻혀 있는 보물이라면 SQL은 보물의 원시 형태를 파헤치는 삽입니다. 보다 구체적으로 말하면, SQL을 사용해 데이터베이스에 있는 하나 또는 여러 테이블의 조합에서 정보를 추출할 수 있습니다.SQL 마스터는 그렇게 어렵지 않습니다SQL Server, PostgreSQL, Oracle, MySQL 및 SQLite와 같이 SQL에는 다양한 선택지가 있습니다. 이들 각각은 조금씩 다르지만 구문(문법)은 대체로 유사하므로 굳이 이들 중 하나를 선택하는 데에 긴 시간을 보낼 필욘 없습니다.언어를 배우려면 먼저 단어를 학습한 다음 문장으로 결합하고 단락을 구성해야 합니다. SQL 역시 마찬가지입니다.아주 기본적인 개념(SQL의 단어나 문장)을 배우기 위해 Datacamp(Introduction to SQL)와 Dataquest(SQL Fundamentals)라는 플랫폼을 활용했습니다. (나중에 Datacamp와 Dataquest의 장단점에 대해 설명하겠습니다.) 일반적으로 이러한 사이트는 연습과 예제를 통해 필수 SQL 기술을 경험할 수 있습니다. 이 단계에서 기억해야 할 몇 가지 개념은 다음과 같습니다.     (adsbygoogle = window.adsbygoogle || []).push({});필터링 및 선택을 위한 SELECT 및 WHERE데이터 집계를 위한 COUNT, SUM, MAX, GROUP BY, HAVING유용한 고유 목록 및 고유 집계를 생성하기 위한 DISTINCT, COUNT DISTINCTOUTER JOIN(예: LEFT) 및 INNER JOIN을 언제/어디서 사용할지문자열 및 시간 변환UNION 및 UNION ALL.(잘 알지 못 해도 상관 없습니다! 배우면 되니까요.)사실 이것들을 숙지한다고 해서 분석가로서 충분히 준비된 상태라 볼 수는 없습니다. 단어와 문장을 이해할 수는 있지만 전체 문단을 쓰기에는 추가적인 스킬이 필요할 겁니다. 특히, 하위 쿼리(sub-query) 및 창(window) 기능과 같은 일부 중/고급 개념은 구직면접에서 테스트 항목으로도 출제되는 편이며, 분석가로서 역할을 수행하기 위해서도 반드시 필요합니다. 이러한 기술에는 다음이 포함됩니다.COALESCE로 NULL 처리하위 쿼리와 쿼리 효율성에 미치는 영향임시 테이블자체 조인PARTITION, LEAD, LAG와 같은 창 기능사용자 정의(UDF) 기능작업을 더 빠르게 하기 위해 쿼리에 인덱스를 사용이러한 기술을 배우기 위해 저는 주로 무료이며 각 개념에 대해 매우 어려운 예제를 제공하는 SQLZoo.net을 주로 사용하였습니다. SQLZoo에서 가장 좋아하는 기능은 하나의 통합 문제에서 다양한 개념을 테스트하는 연습문제가 있다는 것입니다. 예를 들어 다음과 같은 엔터티-관계 다이어그램이 제공되고 이를 기반으로 복잡한 쿼리를 생성하도록 요구합니다.엔터티-관계 다이어그램 예시이 과업들은 전문 분석가(analyst)가 하는 일에 가깝습니다. 분석가는 동일한 데이터베이스로부터 정보를 추출하기 위해 다양한 기술들을 배워 사용합니다. 여기 SQLZoo의 예제 링크를 걸어두었습니다. 'Help Desk'의 엔터티-관계 다이어그램입니다. 주어진 상황에서 당신은 2017년 08월 12일 하루 중 각 시간에 수신된 전화 수와 관리자를 표시해야 합니다. (여기서 직접 해보세요!)제가 활용한 다른 리소스로는 Zachary Thomas의 SQL 예제 및 Leetcode가 있습니다.R과 Python을 사용해 데이터 다루기(manipulation)데이터 과학에 필요한 프로그래밍과 도구에 대해 배우려면 R이나 Python에서 벗어날 수 없습니다. 이 둘은 데이터 조작, 시각화를 비롯, 데이터를 지지고 볶는 데에 사용되는 매우 인기 있는 프로그래밍 언어입니다. R이 우월한가 Python이 우월한가는 그 자체로 별도의 포스팅을 할 가치가 있는 질문입니다. 제 의견은요,R을 선택하든 파이썬을 선택하든 상관없습니다. 하나를 마스터하면 다른 하나는 쉽게 익힐 수 있습니다.Python 및 R로 코딩하는 여정은 CodeAcademy, Datacamp, Dataquest, SoloLearn 및 Udemy와 같은 코드 사이트에서 시작되었습니다. 이 사이트는 언어 또는 패키지별로 구성된 자습형 수업을 제공합니다. 이들 플랫폼은 먼저 개념을 설명해주고, 사용자에게 공백을 제시하며 코드로 채울 것을 요구합니다. 이러한 사이트는 일반적으로 간단한 데모를 통해 방금 배운 개념을 즉시 연습할 수 있습니다. 일부는 나중에 프로젝트 기반 예제를 제공합니다.오늘은 저는 제가 가장 좋아하는 두 가지인 Datacamp와 Dataquest를 집중적으로 다루겠습니다.Datacamp데이터캠프DataCamp는 현장 전문가의 비디오 강의와 빈칸 채우기 연습을 제공합니다. 비디오 강의는 대부분 간결하고 효율적입니다.DataCamp에서 내가 좋아하는 부분 중 하나는 SQL, R 및 python 관련 커리어 패쓰별로 구성된 과정입니다. 이를 통해 커리큘럼 을 직접 고민해야 하는 수고를 덜 수 있습니다. 이제 관심 있는 경로를 따라가면 됩니다. 다음과 같은 경로가 제공됩니다.Python/R의 데이터 사이언티스트Python/R/SQL의 데이터 분석가Python/R의 기계학습(머신러닝) 전문가파이썬/R 프로그래머     (adsbygoogle = window.adsbygoogle || []).push({});개인적으로 저는 ""R의 데이터 사이언티스트로 R 교육을 시작했습니다. 이 교육에서는 데이터를 구성, 조작 및 시각화하는 데 매우 유용한 데이터 패키지의 모음인 R의 Tidyverse에 대해 상세하게 소개합니다. ggplot2(데이터 시각화용), dplyr(데이터 조작용) 및 stringr(텍스트 분석용)이 포함되어 있습니다.그러나 DataCamp에 대한 불만도 있습니다. DataCamp를 완료한 후에는 머릿 속에 지식이 제대로 남지 않는다는 점입니다. 빈칸 채우기 형식을 사용하는지라, 개념을 제대로 이해하지 않고도 빈칸에 무엇이 필요한지 쉽게 추측할 수 있기 때문입니다. 제가 이 플랫폼을 통해 배우던 때에 가능한 한 짧은 시간에 최대한 많은 과정을 완료하려는 욕심이 있었습니다. 그러다보니 코드를 훑어보고 더 큰 그림을 이해하지 못한 채 빈칸 채우기에만 급급했습니다. DataCamp에 대한 학습을 다시 시작할 수 있다면, 코드 전체를 더 잘 소화하고 이해하기 위하여 시간을 더 할애할 것입니다.Dataquest데이터퀘스트Dataquest는 DataCamp와 매우 유사합니다. 프로그래밍 개념을 설명하기 위해 코드에 따른 연습을 사용하는 데 중점을 둡니다. Datacamp와 마찬가지로 R, Python 및 SQL로 다양한 과정을 제공하지만 DataCamp보다는 확장성이 떨어집니다. 예를 들어 Datacamp와 달리 Dataquest는 비디오 강의를 제공하지 않습니다.Dataquest에서 제공하는 일부 트랙은 다음과 같습니다.R/Python의 데이터 분석가파이썬의 데이터 과학데이터 엔지니어링DataQuest의 콘텐츠는 일반적으로 DataCamp의 콘텐츠보다 어렵습니다. 빈칸 채우기 형식에 따른 지식 보존 문제도 적습니다. 시간이 더 걸리긴 했지만 DataQuest를 통해 익힌 지식은 머릿속에 더 오래 남았습니다.DataQuest의 또 다른 훌륭한 기능은 이력서를 검토하고 기술 지침을 제공할 멘토와 월마다 통화할 수 있다는 점입니다. 멘토와 개인적으로 연락하지는 않았지만 훨씬 더 빨리 발전하는 데에는 확실히 도움이 되었을 것이라 생각합니다.데이터 시각화데이터 시각화는 데이터에서 도출한 통찰력을 제시(present)하는 핵심입니다. Python과 R을 사용하여 차트를 만드는 기술을 배운 후 Cole Knaflic의 <Storytelling with Data>(역자주: 국내에서는 '데이터 스토리텔링'이라는 제목으로 번역본이 판매되고 있는데 그야말로 끔찍한 번역)라는 책에서 데이터 시각화의 원리를 배웠습니다.이 책은 툴에 의존하지 않습니다. 즉, 특정 소프트웨어에 초점을 맞추지 않고 통찰력 있는 예시를 통해 데이터 시각화의 일반적인 원리를 가르칩니다. 이 책에서 기대할 수 있는 몇 가지 핵심 사항은 다음과 같습니다.컨텍스트 이해효과적인 시각 자료 선택어수선함 제거원하는 곳에 주목디자이너처럼 생각하라이야기를하다나는 이 책을 읽기 전까지 데이터 시각화를 안다고 생각했습니다.Travis Tang 님이 작성한 차트     (adsbygoogle = window.adsbygoogle || []).push({});책을 소화한 후, 나는 흑인에 대한 경찰의 만행을 설명하는 (다소) 시각적으로 즐거운 차트를 만들 수 있었습니다. 여기에 적용된 책의 주요 학습 포인트 중 하나는 원하는 곳에 주의를 집중시키는 것이었습니다. 이것은 BLM 색상을 연상시키는 밝은 노란색으로 아프리카 계 미국인 라인을 강조 표시함으로써 달성되었으며, 나머지 차트는 흰색 및 회색과 같은 더 흐릿한 음영으로 배경에 머물도록 조치했습니다.그 외 읽을거리이 블로그 게시물에 마음에 들었다면 기계학습에 대한 다른 아티클도 읽어보세요.How to be a Data Analyst — Data Viz with Google Data StudioWhat makes great wine… great? (Using Machine Learning and Partial Dependence Plot in the quest for a good wine)Interpreting Black-Box ML Models using LIME (Understand LIME Visually by Modelling Breast Cancer Data)참고문헌[1] Dhar, V. (2013). “Data science and prediction”. Communications of the ACM. 56 (12): 64–73. doi:10.1145/2500499. S2CID 6107147. Archived from the original on 9 November 2014. Retrieved 2 September 2015.다음 포스팅에서는이 게시물에서는 제가 프로그래밍을 배우면서 출발점으로 삼은 스킬셋에 대해 다루었습니다. 이 과정을 통해 이제 데이터를 조작하는 데 필요한 기술을 갖추게 되었습니다! 하지만 아직 갈 길이 꽤 멉니다. 남은 스킬들에 대해서는 다음 포스팅에서 다루겠습니다2부 — 수학, 확률 및 통계3부 — 컴퓨터 과학 기초4부 — 기계학습(머신러닝)5부 — 첫 번째 기계학습(머신러닝) 프로젝트 구축 반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//mokeya.tistory.com/reaction';window.ReactionReqBody = {    entryId: 76}공유하기게시글 관리지표덕후,  지덕智德저작자표시 비영리 변경금지 'Programming > Knowledge' 카테고리의 다른 글[웹개발] 파이썬 웹 프레임워크(Web Frameworks)에 대한 간단 지식과 추천 프레임워크  (0)2022.01.15[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계  (0)2021.09.10[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라  (0)2021.08.26[데이터 사이언티스트 독학 03] 기계학습(머신러닝)은 무엇인가, 어디서 배울 수 있나  (0)2021.08.21[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기  (0)2021.08.19     (adsbygoogle = window.adsbygoogle || []).push({});태그Python, r, SQL, 데이터과학, 데이터사이언티스트, 데이터시각화, 도서추천, 독학, 학습법, 학습사이트관련글[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라[데이터 사이언티스트 독학 03] 기계학습(머신러닝)은 무엇인가, 어디서 배울 수 있나[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기댓글0비밀글댓글등록loadedComments[76]=true;findFragmentAndHighlight(76);"
99,https://thumbnails.tistory.com/3,[후기]햇살론 유스 무직자로 530받은 후기~2편~,"본문 바로가기다시 한번,카테고리검색하기검색하기블로그 내 검색다시 한번,썸넬 분류 전체보기 (4)  정보 (4) GuestbookNoticeRecent Posts[후기] 카카오뱅크 청년전세자금대출 무직자(대학생⋯[후기] 카카오뱅크 청년전세자금대출 무직자(대학생⋯[후기]햇살론 유스 무직자로 530받은 후기~2편⋯[후기]햇살론 유스 무직자로 530받은 후기/상세⋯Recent CommentsLink«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags청년전세자금대출전세대출햇살론 유스 과정햇살론 유스 후기카카오뱅크청년전세대출햇살론 유스 무직자 후기햇살론 방법카카오뱅크청년전세자금대출대학생카뱅청년전세자금대출햇살론 유스 무직자청년전세자금대출무직자카뱅청년전세대출청년전세카카오뱅크전월세보증금대출햇살론 유스 부결햇살론 유스카카오뱅크청년대출햇살론 유스 부결 후기집대출햇살론햇살론 부결햇살론 유스 무직자 대출moreArchives2023/05                                  (2)2021/12                                  (2)Today7Total7,433닫기관리 메뉴글쓰기방명록RSS관리다시 한번,[후기]햇살론 유스 무직자로 530받은 후기~2편~ 본문정보[후기]햇살론 유스 무직자로 530받은 후기~2편~썸넬        2021. 12. 4. 03:03                  ※햇살론 유스 무직자 필요 서류목록 후기는 1편을 참조해주세요※↓​[후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~ (tistory.com) [후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~햇살론 유스 ​ ​ 내가 그랬던 것 처럼 햇살론 유스 내용이 너무 어려워서, 준비할 서류가 복잡해서, 어떻게 해야 부결이 안날 수 있을지 고민하는 분들을 위해 조금이나마 도움이 됬으면 해서thumbnails.tistory.com​​​​1편에서도 말했듯 부결이 싫은 나는 햇살론 유스 폭풍검색으로 몇가지 사실을 알게된다.​​​​1. 기대출의 유무와 금액은 부결에 크게 영향을 미치지 않는다.나는 학자금대출, 삼성카드 대출 합쳐서 기대출이 1000만원 가량있었다. 그 중 삼성카드 대출이 430?정도였을 거고 현금서비스도 받았던 내역도 있었다. 그것도 신청일 기준 한달이내에 카드대출이 있었고 신용등급도 7등급에서 6등급이었음. 하지만 연체는 한번도 없었다!후기 보면 연체있는 분들은 부결 많이 납니다.​​2. 서류가 부족하면 무조건 부결이다.실제로 상담사분이 내게 서류를 너무 잘 준비해왔다며, 원래 처음오면 먼저 서류부족으로 부결나는 사람이 많단다.부결나면 한달 후에 신청가능하다.​​​3. 최종결정은 상담사가 한다.많은 후기들을 본 결과 비슷한 조건인데도 누구는 승인이나고 누구는 부결로 난다. 심지어 더 승인난 사람보다 더 좋은 조건에서 부결이 나기도 한다. 그 이유는 승인의 최종결정권은 나를 상담해주는 상담사분에게 있기 때문이다. 햇살론 유스는 어떤 기준을 충족하면 그 이후에 승인을 결정하는 것은 상담사의 권한인 것 같다. 그러니 상담사에게 잘보이진 못하더라도 밉보이지 말자.​​​​만반의 준비를하고 센터를 찾아갔다. 그리고 상담사분을 만났는데, 나를 보고 하는 첫 마디가""서류 준비를 너무 잘해오셨네요. 이런 경우는 처음이에요"" 이라고 하셨다. 이후에 말씀하시길 처음에 오면 서류 부족으로 부결난다. 이렇게 알아서 다 준비해올 수 있는 건지 몰랐다. 어떻게 준비해온거냐... 굉장히 놀라하셨다. 이 말은 즉 서류부족으로 부결나는 경우가 꽤 많다는 말이다. 그러니 서류준비만 완벽히 해가도 일단 점수를 잘 받을 수 있다.​​그 이후는 굉장히 순조로웠다. 생활자금 대출 300만원 가능하다고 하셨고 내가 주거비 용도로 제출한 300만원의 경우, 한달 월세X6개월으로 계산해서 그 금액만큼 대출 가능하다고 하셨다. 나의 경우 한달월세가 23만원이므로 23만원X6개월 = 138만원 이므로 130으로 계산해서 해주셨다. 그리고 내가 보증금 대출은 안되냐고 물었더니 보증금은 원래 대출이 잘 안된다고 하셨다.(월세 처럼 앞으로 낼 돈이 아니라 이미 낸 돈이라서 그런듯). 하지만 나는 보증금도 받았다...! 다시 한번 상담사분의 의사가 승인을 좌지우지 한다는 걸 느꼈다... 신청일 기준 한달이내에 낸 보증금만 신청 가능하다고 한다. 그리고 이 기준을 충족해도 잘 안해준다고 하니 참고하자.(나는 한달이내 였음)​내가 가져간 통장 거래 내역서에는 보증금 100만원과 월세 2달치를 낸 내역이 있었고, 그래서 주거비 용도 대출은 보증금 100만원 + 월세6개월 약130만원 = 총 230만원 이렇게 받을 수 있었다.​​그리하여 나의 총 대출은  생활자금 300만원+ 주거비 230만원 = 530만원 되시겠다.보증료는 172,350원 나왔따.​​그리고 거치기간과 상환기간을 설정하게 되는데, 거치와 상환기간이 길수록 보증료가 올라간다. 상담사분이 거치, 상환 바꿔가면서 금액 이 각각 얼마나오는지 친절히 알려주신다. 나는 거치 4년+상환4년 이렇게 완료했다. 햇살론 유스는 이자율이 낮은 대출상품이기 때문에 일부러 길게 잡았다. 앞으로 살면서 집도 사고 하다보면 분명 대출을 받을 날이 또 있을텐데 햇살론 유스보다 저렴할리는 없고, 그러면 돈이 생기면 이자율 높은거 부터 갚고 낮은거 늦게 갚는게 합리적으로 좋을테니. 그래서 한국장학재단 학자금대출도 최후로 남겨놓고 갚는다............상담사 분과 뭐 이런얘기들을 나눴다.​​전산처리를 하시면서 나에게 물어본 내용들을 적어보겠다.나한테 대출 얼마있는지 물으셨고 (그냥 참고하는 거니 대충 얼마인지만 말하면된다고 하심) 나는 솔직하게 있는 대출 다 말했다. 그리고 햇살론유스 대출 받으면 바로 삼성카드에 있는 대출을 갚을 예정이라고도 말했다. 현재 삼성카드 연이자가 15%정도인데 이자가 너무 비싸서 햇살론유스로 바꾸는 거라고... (저는 솔직하게 말씀드렸지만 상담사에 따라 이게 득이될지 실이될지는 장담할 수 없습니다)나이가 어린데 카드대출은 왜 많냐고 물어보셨다.(이건 530만원 승인 결정난 후에 물어봄) 그래서 사실대로 내가 쓰려고 빌린게 아니라 부모님이 사업하시는데 급하게 필요해서 빌려드린 거라고 했다. 그랬더니 빚을 내서 그러면 안된다고 하셨고 여러 좋은 얘기들 해주셨는데 깊이 새겨듣고 나왔다. 그리고 가기전에 옆에 창구에서 취업상담도 한번 받고 가라고 하셔서 받으러 갔는데 정말 유용하고 좋은 내용들이 많더라. 청년들을 위한 지원금도 다양하고 정보 사이트들도 많으니 센터에 방문하게 된다면 꼭 취업상담도 같이 받고 오길바란다. 당근 무료다.​그리하여 햇살론유스 530만원 대출승인을 받고 유용한 취업상담도 받고 기분좋게 룰루랄라 나왔는데 문자가 와있었다. 보증승인 안내 문자  다음단계가 존재한다..후..​​대출을 승인 받았다면 1주이내에 약정체결을 해야한다. 1주일이 지나면 자격조회부터 다시시작해야한다.약정체결은 어렵지 않다. 문자로 친절하게 설명이 오니 하란대로 하면 된다.(어플접속-마이페이지-햇살론youth보증신청내역-약정서작성)​그렇게 약정을 체결하면 문자가 띠롱 날아온다.보증약정체결 확인문자 위 사진에서 보듯 보증약정이 체결되면 2주이내에 보증료를 내고 대출을 실행해야한다.2주가 지나면 자격조회부터 다시시작해야한다 ^^ (생각만해도 행.복.)자 그러면 이제 은행을 선택해야한다.신한은행, 전북은행, 기업은행 중 택1하면된다. 세개 밖에 없다.세 은행의 우대 서비스가 다르므로 비교해보고 자신에게 맞는걸 선택하면된다.대출액을 빠르게 받고 싶다면 센터 방문 전에 계좌를 개설하는 것도 나쁘지 않다고 본다. 물론 승인난다는 전제하에.나는 이미 신한은행에 계좌가 있고 또 만들기 귀찮아서 (이미 진이 다 빠졌음) 신한은행으로 선택했다.대출실행 전에 보증료를 미리 선택한 은행계좌에 넣어놔야한다. 신청시 자동으로 빠져나가면서 대출금액이 바로 들어오기때문.​신한은행 어플 (쏠) 접속- 공인인증서 등록 (이미 되어있으면 패쓰) -메뉴-상품-대출-햇살론 Youth​아마 다른 은행도 동일 할 것이다.들어가면 보증번호 입력하라고 하는데 문자로 날아온 시리얼번호 입력하면 된다. 공인인증서로 인증하고 보증료가 빠져나감과 동시에 대출금액이 해당 계좌로 입금된다!매달 입금받은 계좌로 이자가 나가므로 잊지말고 계좌에 돈을 넣어두길 바란다. 연체되면 신용도 떨어진다ㅠ​​참고로 나는 햇살론유스 신청 전에 신용등급 7등급에서 아슬아슬한 6등급이었다(카드대출많음). 근데 글을 작성하는 현재 신용등급 5등급이 되어있다. 딱히 뭘 한건 아니고, 햇살론 유스로 바꿔치기 해서 오른거다. 제2금융권인 삼*카드 대출을 제1금융권(신한은행) 햇살론대출받은 금액으로 싹 값으니 등급이 올랐다. 심지어 햇살론 유스로 대출한 금액이 이전 삼*카드 대출보다 훨씬 많은데도 말이다. 바꾸길 천만번 잘한 것 같다.​​ ​이렇게 하여 나의 기나긴(?) 햇살론 유스 무직자 대출 여정기가 끝이 났다.서류준비와 대출실행하는 과정에서 진이 다 빠져부렀따....힝(신한은행의 경우 오랬동안 거래를 안해서 중지된 계좌를 풀러 은행에 방문해야 했음. 그리고 또 많지만 줄이겠다.)그리고 참고로 요즘 은행에서 계좌 새로 개설하면 한도계좌로 생성돼서 현금인출에 하루 제한금액이 정해져있으니대출받은 돈은 자주쓰는 계좌로 인터넷뱅킹해서 현금으로 인출하면 된다.​​ ​내가 준비하면서 너무 힘들었고 어려웠기 때문에 햇살론 알아보고 이 글을 읽을 분들한테도움이 되었으면 하는 마음에 최대한 열심히 작성해 보았다(나한텐 이게 최선임). 도움이 됐을지 모르겠다. 조만간 센터에서 취업상담 받은것도 정보정리해서 포스팅하겠다힘든 이 시국 모두 잘 이겨냈으면ㅜㅜ 뽜이띵​​​​​+저는 댓글에 답글을 달지 않습니다.이유는,1. 본문에 다 나와있는 내용을 질문하시는 분들이 많습니다.(꼼꼼히 읽어보면 다 나와있는 내용을 질문하십니다)​2. 제가 알지 못하는 부분에 대한 질문들이 있습니다.(저는 제가 아는 것을 모두 1,2편에 나누어 작성하였습니다. 이게 제가 아는 전부입니다)​3. 저도 처음엔 모르는 부분은 제가 직접 찾아보고 장문으로 답변을 드렸고,이미 나와있는 내용에 대해서도 다시 답변을 드렸습니다만,시간을 투자해 열심히 단 답변에 감사하다는 인사 한마디 없이 사라지시는 분들이 계십니다.​제 정보가 많은 분들께 도움이 되었으면 하는 마음에서 게시글을 올렸습니다.제가 아는 정보는 1, 2편에 전부 작성하였으니 꼼꼼히게 읽어보시면 좋을 것 같습니다.긴 글 읽어주셔서 감사합니다.    무단 복사 및 공유를 금지합니다.   썸넬's 네이버 블로그에서 보기 ↓[후기]햇살론 유스 무직자로 530받은 후기~.. : 네이버블로그 (naver.com) [후기]햇살론 유스 무직자로 530받은 후기~2편~썸넬's 티스토리에서 보기 ↓ [후기]햇살론 유스 무직자로 530받은 후기~2편~ (tistory.com) ※햇살론...blog.naver.com  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//thumbnails.tistory.com/reaction';window.ReactionReqBody = {    entryId: 3}공유하기게시글 관리다시 한번, '정보' 카테고리의 다른 글[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~2편~  (0)2023.05.04[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~1편~  (0)2023.05.04[후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~  (0)2021.12.04Tag햇살론, 햇살론 방법, 햇살론 부결, 햇살론 유스, 햇살론 유스 무직자, 햇살론 유스 무직자 대출, 햇살론 유스 무직자 후기, 햇살론 유스 부결, 햇살론 유스 후기'정보' Related Articles[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~2편~2023.05.04[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~1편~2023.05.04[후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~2021.12.04moreloadedComments[3]=true;findFragmentAndHighlight(3);          Blog is powered by          kakao / Designed by          Tistory티스토리툴바다시 한번,구독하기                    (function () {                         var blogTitle = '다시 한번,';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""5074581-3"",""customProps"":{""userId"":""0"",""blogId"":""5074581"",""entryId"":""3"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""3"",""entryTitle"":""[후기]햇살론 유스 무직자로 530받은 후기~2편~"",""entryType"":""POST"",""categoryName"":""정보"",""categoryId"":""1063181"",""serviceCategoryName"":""생활정보"",""serviceCategoryId"":105,""author"":""5163727"",""authorNickname"":""썸넬"",""blogNmae"":""다시 한번,"",""image"":""kage@dRxD0p/btrm0qhXuYm/YKMuVKpokPposmAQVqPny1"",""plink"":""/3"",""tags"":[""햇살론"",""햇살론 방법"",""햇살론 부결"",""햇살론 유스"",""햇살론 유스 무직자"",""햇살론 유스 무직자 대출"",""햇살론 유스 무직자 후기"",""햇살론 유스 부결"",""햇살론 유스 후기""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
100,https://wooono.tistory.com/123,[Docker] Dockerfile 개념 및 작성법,"본문 바로가기우노카테고리검색하기검색하기Search우노글목록방명록About 분류 전체보기 (763)  AI (99)  Machine Learning (48)  Deep Learning (49)  Data (68)  Spark (43)  Graph & Matrix (7)  Hadoop (2)  MapReduce (1)  Recommender System (6)  Natural Language Processing (1)  Data Mining (1)  Airflow (7)  DevOps (91)  Concept (1)  Terraform (20)  Istio (2)  Helm (3)  Kubernetes (23)  Docker (21)  Prometheus (2)  Datadog (1)  GitHub (18)  GCP (14)  CLI (1)  Cloud Run (1)  Cloud Build (1)  Authentication (3)  PubSub (2)  Composer (3)  Bigquery (3)  AWS (37)  CLI (7)  EC2 (8)  EMR (8)  Route 53 (2)  S3 (1)  API Gateway (2)  Lambda (6)  ECS (1)  DocumentDB (2)  Network & Security (16)  Concept (14)  Develop (1)  Keycloak (1)  Web_App (14)  Concept (2)  Develop (2)  API (1)  Nginx (6)  NodeJS (3)  Kotlin (0)  Operating System (61)  Concept (3)  Linux & Ubuntu (39)  MacOS (6)  Shell Script (13)  Language (123)  Python (77)  R (9)  C++ (19)  Scala (12)  Java (6)  Database (18)  Concept (4)  MySQL (2)  MongoDB (12)  Hardware (9)  Concept (5)  NVIDIA (3)  Coral (1)  Etc (24)  Colab (4)  Data Structure (2)  CS Tech Interview (1)  CS Term (10)  Paper (2)  Graphic (2)  Excel (2)  Etc (1)  Algorithm (178)  Concept (19)  Greedy (26)  Implementation (20)  Sliding Window (4)  Two Pointers (4)  Hash (3)  Sort (8)  Stack, Queue (8)  Heap (2)  Dynamic Programming (32)  Binary Search (8)  DFS (10)  BFS (9)  Shortest Path (7)  Graph (8)  String (1)  Backtracking (1)  Flood-Fill (2)  Maximum Flow (1)  Divide and Conquer (1)  Prime Number (1)  Prefix Sum (1)  Kakao (2)  SQL (7)  Basic (2)  JOIN \ GROUP BY (1)  Window Function (4)  일상 (1)  음악 (1) Guestbook오늘의 인기 글[Docker] Dockerfile 개념 및 작성⋯[Linux] 하드디스크 파티션 생성, 포맷, 마⋯[Docker] Docker run 옵션 종류최근 글[BigQuery] streaming buffer⋯Polling과 Pulling의 차이[Network] HTTP, HTTPS 및 SSL⋯최근 댓글도움이 되었습니다 ^^공감-댓글 작성 했습니다. 좋은 일이 있으시기를 기원합⋯Cool ~매우 공감되는 포스팅 입니다. 앞으로 자주 인사 드릴께⋯여기저기 찾아보고 있는데 제가 아는 linear reg⋯안녕하세요 해당 커멘드는 아래와 같이 실행하면 가능합니⋯업무하면서 cidr 개념이 뭔지 궁금했었는데, 잘 배웠⋯토큰생성 설명 감사 합니다. 새해 복 많이 받으십시오.응원드리고 갑니다~행복한 일요일 되셔요!정리 잘 되어있어서 이해하기 좋았습니다. 감사합니다글 잘 보았습니다. 도움이 많이 되었어요!!현재는 변경된 부분이 많습니다! (https://doc⋯감기 조심하시고, 항상 행복하세요!어떤 오류가 발생하셨는지는 모르겠지만, print(⋯earlystopping = EarlyStopping(⋯모델 성능평가 시 코드에 오류가 발생하는 부분이 있는데⋯잘 보고 갑니다. ^^helm helm chart 잘 보고 갑니다. 넵, 가능합니다~!안녕하세요, 포스팅에 사용하신 짱구 이미지를 개인 공부⋯최고의 설명입니다. 감사합니다좋은 글 잘보고 갑니다~~깔끔한 정리 잘보고 갑니다감사합니다~!#include <algorithm>  해야함.안녕하세요~!포트가 다르면 웹 애플리케이션 서버와 ⋯좋은 포스팅 잘 봤습니다!  Protocol, Host⋯jetson Nano의경우 Recovery모드로 들어가⋯유투브 플레이리스트로 짜서 올려주3잘보고 갑니다 :) 행복한 하루되세요!❤️ 누르고 갈⋯Today495Total2,208,192 #chart-time {font-size:11px; text-align:right; color:#999; padding-right: 15px;}08-13 15:14        am4core.ready(function() {            am4core.addLicense(""CH90809262"");            var chart = am4core.create(""chartdiv"", am4charts.XYChart);            chart.data = [{""timestamp"":""2024-08-07T00:00:00+09:00"",""count"":754},{""timestamp"":""2024-08-08T00:00:00+09:00"",""count"":887},{""timestamp"":""2024-08-09T00:00:00+09:00"",""count"":751},{""timestamp"":""2024-08-10T00:00:00+09:00"",""count"":287},{""timestamp"":""2024-08-11T00:00:00+09:00"",""count"":291},{""timestamp"":""2024-08-12T00:00:00+09:00"",""count"":798},{""timestamp"":""2024-08-13T00:00:00+09:00"",""count"":495}];            var values = chart.data.map(function(value){                return value.count            });            var minValue = values.reduce(function(acc, current) {                return Math.min(acc, current);            });            var maxValue = values.reduce(function(acc, current) {                return Math.max(acc, current);            });            chart.dateFormatter.inputDateFormat = ""yyyyMMdd"";            var dateAxis = chart.xAxes.push(new am4charts.DateAxis());            var valueAxis = chart.yAxes.push(new am4charts.ValueAxis());            dateAxis.renderer.grid.template.disabled = true;            dateAxis.dateFormats.setKey(""day"", ""dd"");            dateAxis.periodChangeDateFormats.setKey(""day"", ""dd"");            dateAxis.renderer.minGridDistance = 1;            dateAxis.fontSize = ""10.5px"";            dateAxis.color = ""#ff0000"";            dateAxis.opacity = 0.5;            valueAxis.opacity = 0.5;            valueAxis.fontSize = ""10.5px"";            valueAxis.paddingBottom = 5;            valueAxis.marginLeft = -20;            valueAxis.min = minValue < 0 ? 0 : minValue;            valueAxis.max = maxValue + 10;            var series = chart.series.push(new am4charts.LineSeries());            series.dataFields.valueY = ""count"";            series.dataFields.dateX = ""timestamp"";            series.tooltipText = ""{count}""            series.strokeWidth = 1;            series.minBulletDistance = 15;            series.tooltip.background.cornerRadius = 20;            series.tooltip.background.strokeOpacity = 0;            series.tooltip.pointerOrientation = ""vertical"";            series.tooltip.label.minWidth = 40;            series.tooltip.label.minHeight = 40;            series.tooltip.label.textAlign = ""middle"";            series.tooltip.label.textValign = ""middle"";            var bullet = series.bullets.push(new am4charts.CircleBullet());            bullet.circle.strokeWidth = 2;            bullet.circle.radius = 3;            bullet.circle.fill = am4core.color(""#fff"");        });닫기관리 메뉴글쓰기방명록RSS관리우노[Docker] Dockerfile 개념 및 작성법 본문DevOps/Docker[Docker] Dockerfile 개념 및 작성법운호(Noah)                           2020. 10. 6. 15:49DockerfileDockerfile은 DockerImage를 생성하기 위한 스크립트(설정파일)이다.여러가지 명령어를 토대로 Dockerfile을 작성한 후 빌드하면Docker는 Dockerfile에 나열된 명령문을 차례대로 수행하며 DockerImage를 생성해준다.Dockerfile을 읽을 줄 안다는 것은 해당 이미지가 어떻게 구성되어 있는지 알 수 있다는 의미이다.Dockerfile의 장점(1) 이미지가 어떻게 만들어졌는지를 기록한다.보통 사람들은 완성된 이미지를 가져다 쓰기 때문에 이미지가 어떻게 만들어졌는지에 대해서는 알 필요가 없다.그러나 개발자의 경우라면 조금 다르다. 어떠한 애플리케이션을 담고 있는 이미지가 설치 되기 위한 과정은 어떠한지, 중간에 어떠한 과정을 수정해야 하는지 등을 알아야 하는 경우가 있다.예를 들어 raw한 상태의 우분투 이미지에서 자신이 원하는 애플리케이션을 담은 이미지를 만들어내기까지, 그 과정들을 기록하고 수정하며 바꿔나갈 수 있다는 것이다.이는 Dockerfile이 자동화된 스크립트 형태이기 때문이다.(2) 배포에 용이하다.어떠한 이미지를 배포할 때, 몇 기가씩이나 되는 이미지 파일 자체를 배포하기보다는 그 이미지를 만들 수 있는 스크립트인 Dockerfile만을 배포한다면 매우 편리할 것이다.사용자는 그 스크립트를 실행시키기만 하면 스스로가 그 Dockerfile에 해당하는 이미지를 얻을 수 있기 때문이다.실제로 Docker Hub에 가면, Dockerfile로 이미지를 배포하고 있는 사람들을 심심찮게 볼 수 있다. 물론 이미지로 배포하는 사람도 있지만.(3) 컨테이너(이미지)가 특정 행동을 수행하도록 한다.컨테이너 환경에서 애플리케이션을 개발하다 보면, 특정 행동을 취하도록 하는 컨테이너를(이미지를) 만들어야 할 때가 있다.이는 사실 말로서 설명하기는 좀 어렵고, 실제 개발을 하다보면 '아, 이거 Dockerfile 쓰면 좀 간단해 지겠구나...' 라는 생각이 머릿속에서 불현듯 번개처럼 스칠때가 있다.Dockerfile 작성 및 명령어Dockerfile을 작성 할 땐 실제 파일의 이름을 'Dockerfile'로 해야합니다.ubuntu에 아파치 서버를 설치하는 Dockerfile을 작성해보도록 하겠습니다.Dockerfile을 담을 디렉토리를 생성 한 후 Dockerfile을 생성합니다.  mkdir apache-dockerfile && cd apache-dockerfile  vi DockerfileDockerfile의 내용은 아래와 같습니다.  # server image는 ubunutu 18.04를 사용  FROM ubuntu:18.04   # Dockerfile 작성자  MAINTAINER Wimes <yms04089@kookmin.ac.kr>   # image가 올라갔을 때 수행되는 명령어들  # -y 옵션을 넣어서 무조건 설치가 가능하도록 한다.  RUN \      apt-get update && \      apt-get install -y apache2  # apache가 기본적으로 80포트를 사용하기 때문에 expose를 이용해 apache server로 접근이 가능하도록 한다.  EXPOSE 80   # 컨테이너가 생성 된 이후에 내부의 아파치 서버는 항상 실행중인 상태로 만들어준다.  # apachectl을 foreground(즉, deamon)상태로 돌아가도록 한다.  CMD [""apachectl"", ""-D"", ""FOREGROUND""]FROM : 베이스 이미지어느 이미지에서 시작할건지를 의미한다.MAINTAINER : 이미지를 생성한 개발자의 정보 (1.13.0 이후 사용 X)LABEL : 이미지에 메타데이터를 추가 (key-value 형태)RUN : 새로운 레이어에서 명령어를 실행하고, 새로운 이미지를 생성한다.RUN 명령을 실행할 때 마다 레이어가 생성되고 캐시된다.따라서 RUN 명령을 따로 실행하면 apt-get update는 다시 실행되지 않아서 최신 패키지를 설치할 수 없다.위 처럼 RUN 명령 하나에 apt-get update와 install을 함께 실행 해주자.WORKDIR : 작업 디렉토리를 지정한다. 해당 디렉토리가 없으면 새로 생성한다.작업 디렉토리를 지정하면 그 이후 명령어는 해당 디렉토리를 기준으로 동작한다.cd 명령어와 동일하다.EXPOSE : Dockerfile의 빌드로 생성된 이미지에서 열어줄 포트를 의미한다.호스트 머신과 컨테이너의 포트 매핑시에 사용된다.컨테이너 생성 시 -p 옵션의 컨테이너 포트 값으로 EXPOSE 값을 적어야한다.USER : 이미지를 어떤 계정에서 실행 하는지 지정기본적으로 root에서 해준다.COPY / ADD : build 명령 중간에 호스트의 파일 또는 폴더를 이미지에 가져오는 것ADD 명령문은 좀 더 파워풀한 COPY 명령문이라고 생각할 수 있다.ADD 명령문은 일반 파일 뿐만 아니라 압축 파일이나 네트워크 상의 파일도 사용할 수 있다.이렇게 특수한 파일을 다루는 게 아니라면 COPY 명령문을 사용하는 것이 권장된다.ENV : 이미지에서 사용할 환경 변수 값을 지정한다.path 등CMD / ENTRYPOINT : 컨테이너를 생성 및 실행 할 때 실행할 명령어보통 컨테이너 내부에서 항상 돌아가야하는 서버를 띄울 때 사용한다.CMD컨테이너를 생성할 때만 실행됩니다. (docker run)컨테이너 생성 시, 추가적인 명령어에 따라 설정한 명령어를 수정할 수 있습니다.ENTRYPOINT컨테이너를 시작할 때마다 실행됩니다. (docker start)컨테이너 시작 시, 추가적인 명령어 존재 여부와 상관 없이 무조건 실행됩니다.명령어 형식CMD [""<커맨드>"", ""<파라미터1>"", ""<파라미터2>""]CMD <커맨드> <파라미터1> <파라미터2>ENTRYPOINT [""<커맨드>"", ""<파라미터1>"", ""<파라미터2>""]ENTRYPOINT <커맨드> <파라미터1> <파라미터2>참고https://wooono.tistory.com/679생성한 Dockerfile을 Image로 빌드이미지 빌드 명령어  docker build -t [이미지 이름:이미지 버전] [Dockerfile의 경로]  docker build -t apache-image .생성된 이미지 확인  docker images웹에 띄울 html 파일 생성보통 웹으로 띄울 html 파일을 아파치 서버에 추가하고 싶을 땐Dockerfile의 ADD / COPY를 통해 호스트의 파일을 아파치 서버 옮기는 명령어를 작성 후 빌드합니다.하지만 이렇게 하면 호스트의 html 파일과 아파치 서버의 html 파일이 동기화 되어 있지 않기 때문에 매번 build를 해줘야합니다.우리는 그럴 시간이 없습니다.따라서 도커 볼륨을 사용해 호스트의 html 파일을 만들어놓고, 도커 컨테이너에서 그 파일에 접근해서 사용하는 방법으로 동기화 할 것입니다.우선 호스트에 index.html 파일을 생성 및 수정합니다.  cd ~  mkdir html && cd html  vi index.html  Hello worldImage로 Container를 생성이제 컨테이너 생성 시 도커 볼륨을 통해 host와 도커 컨테이너의 html 폴더를 동기화 하겠습니다.  docker run --name apache-container -d -p 80:80 -v ~/html/:/var/www/html apache-image--name : 컨테이너 이름-d : 백그라운드모드로 실행-p : [호스트포트][컨테이너포트] 포트 연결-v : 로컬과 컨테이너 파일 연동접속 확인Public DNS를 80번 포트로 접속해 접속을 확인합니다.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//wooono.tistory.com/reaction';window.ReactionReqBody = {    entryId: 123}공유하기게시글 관리우노저작자표시 'DevOps > Docker' 카테고리의 다른 글[Docker] MySQL Container 실행 시 host db 볼륨 마운팅하기  (0)2020.11.18[Docker] Docker를 이용한 MySQL 설치 및 접속  (0)2020.11.08[Docker] AWS EC2에서 Docker를 이용한 Nodejs 웹서버 구축  (0)2020.10.04[Docker] AWS EC2에서 Docker를 이용한 Apache 웹서버 구축  (2)2020.10.03[Docker] Image 생성 및 삭제  (0)2020.07.16'DevOps/Docker' Related Articles[Docker] MySQL Container 실행 시 host db 볼륨 마운팅하기2020.11.18[Docker] Docker를 이용한 MySQL 설치 및 접속2020.11.08[Docker] AWS EC2에서 Docker를 이용한 Nodejs 웹서버 구축2020.10.04[Docker] AWS EC2에서 Docker를 이용한 Apache 웹서버 구축2020.10.03more0  Comments댓글쓰기 폼이름비밀번호                                              Secret                                          내용SendloadedComments[123]=true;findFragmentAndHighlight(123);Blog is powered bykakao / Designed byTistory//<![CDATA[// Lazy Load AdSensevar lazyadsense=!1;window.addEventListener(""scroll"",function(){(0!=document.documentElement.scrollTop&&!1===lazyadsense||0!=document.body.scrollTop&&!1===lazyadsense)&&(!function(){var e=document.createElement(""script"");e.type=""text/javascript"",e.async=!0,e.src=""https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"";var a=document.getElementsByTagName(""script"")[0];a.parentNode.insertBefore(e,a)}(),lazyadsense=!0)},!0);//]]>티스토리툴바우노구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4029591-123"",""customProps"":{""userId"":""0"",""blogId"":""4029591"",""entryId"":""123"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""123"",""entryTitle"":""[Docker] Dockerfile 개념 및 작성법"",""entryType"":""POST"",""categoryName"":""DevOps/Docker"",""categoryId"":""914837"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4447808"",""authorNickname"":""운호(Noah)"",""blogNmae"":""우노"",""image"":"""",""plink"":""/123"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
101,https://manchann.tistory.com/16,[DL] 딥러닝 추론이란?,"본문 바로가기강카테고리검색하기검색하기Search강최재강글목록방명록About 분류 전체보기 (41)  AWS (13)  CLI (2)  S3 (3)  EC2 (2)  Lambda (6)  Inferentia (0)  GCP (9)  MS Azure (1)  AI (3)  Deep Learning (3)  Linux Command (3)  Github (4)  Python (5)  Algorithm (1)  Docker (2) Guestbook인기글[DL] 딥러닝 추론이란?[Github] 특정 폴더만 clone 받기Slack ChatGPT 연동하기[GCP] Cloud Storage Bucket ⋯최근에 올라온 글Tensorflow MLFlow 사용해보기Slack ChatGPT 연동하기[AWS Lambda] 서버리스 환경에서 ML 추⋯[AWS CLI] version 1에서 2로 up⋯최근에 달린 댓글안녕하세요 chatgpt api 연동 해보려고 하니 아⋯저는 오늘 실행해보고자 하는데 동일한 메세지가 나오네요⋯많은 도움 됐습니다 :)main.py 에서 아래처럼 변경하면 1:1 대화처럼 ⋯링크AboutGitHubLinkedIn«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Archives2023/06 (1)2023/01 (1)2022/08 (1)2022/05 (2)2021/12 (1)Today94Total65,296닫기관리 메뉴글쓰기방명록RSS관리강[DL] 딥러닝 추론이란? 본문AI/Deep Learning[DL] 딥러닝 추론이란?최재강                           2021. 9. 20. 02:49딥러닝은 크게 두가지 단계로 나눌 수 있다. 한가지는 대다수의 사람들이 알고 있는 학습(Training) 이다.학습과정의 특징은 축적된 많은 데이터를 바탕으로 각 신경망들의 Weight를 업데이트 해가며 딥러닝 모델을 만들어 가는 과정이다. 반면 추론(Inference)은 학습을 통해 만들어진 모델을 실제로 새로운 입력 데이터에 적용하여 결과를 내놓는 단계이다.학습과 추론 비교학습과 추론의 차이점을 조금 더 살펴보겠다.Training vs Inference그림에서 보면 알 수 있듯, 학습을 위해서는 많은 데이터가 필요하다. 그리고 그 데이터 들은 우선 순방향 전파를 통해 각 신경망을 거쳐가고 Loss function을 통해 에러율이 얼마나 되는지 판단하고, 그 에러율을 줄이기 위해 역방향 전파로 다시 신경망을 반대로 지나가면서 각 신경망의 Weight들을 바꾸는 것이다.하지만 모델을 만들어 가기 위한 학습과는 달리 추론의 목적은 현재 데이터에 대해서 해당 모델이 원하는 작업을 수행해 주는 것이다. 이미지 분류 모델의 예를 들면, 사람과 고양이를 분류하는 학습된 모델이 있다고 했을 때 단순히 내가 고양이 사진을 인풋 데이터로 넣으면 고양이라고 분류 해주면 되는 것이다. 따라서 추론 과정에서는 순방향 전파만이 일어난다. 또한 학습 과정에서는 모델이 데이터를 넣을 때 마다 Weight가 업데이트 되며 조금 씩 바뀌어 간다면 추론 과정에서는 인풋 데이터를 어느 정도 넣는 지 상관 없이 모델의 Weight는 고정적이다. 한마디로 해당 모델이 고양이 분류를 5%의 오차율로 수행했다면 같은 데이터에 대해서 다음번에도 5%의 오차율로 수행할 것이라는 것이다.그렇다면 실제 학습과 추론 작업을 수행할 때 어떤 차이점이 있을까?학습은 추론에 비해 많은 데이터를 바탕으로 훨씬 긴 시간에 걸쳐 진행되며 여유로운 데드라인을 가지고 진행될 것이다. 반면 추론작업은 실제로 사용자가 해당 모델에 원하는 사항을 요구하고 그것을 실시간으로 수행하는 서비스에 활용된다. 따라서 사용자에 훨씬 직면에 있는 작업이며 작업이 실시간으로 대응 되어야 하고 사용자가 원하는 시간과 요청 개수에 맞추어 대응해야 한다. 실시간으로 대응해야 한다는 것은 요청이 어떤 경우에는 적게 들어오고 어떤 경우에는 폭발적으로 늘어날 수 있다는 것을 의미한다.내가 좋아하는 NBA 농구 선수인 스테판 커리를 예로 들며 학습과 추론 비교를 마무리 하겠다.스테판 커리 3점슛을 성공하다스테판 커리는 3점슛을 잘쏘는 선수로 유명하다. 그는 농구 시합이 없을 때에도 수만번의 3점슛을 다양한 각도, 위치(많은 데이터셋)에서 던질 것이다(순방향 전파). 그리고 던질 때마다 들어가는 슛과 들어가지 않는 슛이 있을 것이고 들어가지 않는 슛을 보완하기 위해 슛 쏘는 자세를 교정하며(역방향 전파) 열심히 슛을 더 쏠 것이다.그렇게 연습을 한 스테판 커리는 팀의 승리를 책임지기 위해 다소 위험한 상황에 놓였다. 팀이 101: 103 2점차로 지고 있는 상황에 경기 시간은 4초 밖에 남지 않은 것이다. 그 상황에서 타임 아웃을 부른 감독은 스테판 커리에게 이렇게 얘기한다 ""4초 안에 3점슛을 넣어줘"". 감독의 주문(사용자의 요구 사항)을 들은 스테판 커리는 어느 위치, 각도에서건 감독의 요구에 맞추기 위해 그동안 연습해온 슛을 바탕으로 3점슛을 시도하고 성공하거나 실패할 것이다(추론 결과). 이것이 딥러닝의 추론 과정이라고 볼 수 있다. 사용자의 요구에 맞추어 원하는 작업을 수행하는 것, 그것이 딥러닝의 추론 작업의 특징이다.사용자의 요구사항 : SLO앞선 내용에서 언급했듯 추론에서는 사용자의 요구 사항을 충족하는 것이 중요하다. 딥러닝 추론에 관련된 여러 논문들을 읽어보면 SLO 혹은 SLA라는 단어를 많이 사용하는 것을 볼 수 있다. SLO란 Service Level Objectives를 줄인말이며 말 그대로 서비스 단에서 충족해야할 목적이라고 해석하면 된다. 참고로 SLA는 Servcie Level Agreement로 비슷한 뜻을 가진다. 보통 SLO를 주로 쓰는 듯 하다.SLO에 대한 예시를 하나 들어보겠다.다양한 Varient와 사용자의 요구사항위 그림에서 Table2는 3종류의 추론 작업을 돌릴 수 있는 Varient 즉, 선택할 수 있는 가짓수를 나타낸다. Variant A, B, C는 각각 서로 다른 하드웨어,프레임워크로 구성되어 있으며 각 Variant별로 처리하는 대에 걸리는 Latency와 Request수, 드는 비용인 Cost가 명시되어 있다. 예를 들어 Variant A는 5개의 요청을 200ms에 1달러를 소모하며 수행하는 것이다.Table3은 서로 다른 사용자의 요구사항에 맞는 적절한 추론 옵션을 선택하는 시나리오를 보인다. QPS는 처리해야할 쿼리의 수를 의미하고 SLO는 제한 시간을 의미한다. 이 논문에서는 SLO를 처리 시간으로 설정해두었지만 정확도 또한 SLO에 속할 수 있다는 것을 기억해두자. 따라서 첫번 째 경우인 QPS 10, SLO 300ms의 경우 Variant A를 2개 사용하여 처리하는 것이 가장 효율적임을 알 수 있다. 왜냐하면 Variant B나 C를 사용하면 더 빨리 처리할 수 있었겠지만, 그에 따라서 Cost가 증가했을 것이고 SLO가 300ms로 다소 넉넉했기 때문이다.그러면 같은 QPS양에서 SLO가 50ms로 제한된 경우를 살펴 보자. 이 경우 Variant A를 사용할 수는 없을 것이다. 왜냐하면 SLO 요구 조건을 충족할 수 없기 때문이다. 따라서 Variant B 1개로 해당 요구를 수행하는 것이 가장 효율적이다. Variant C를 사용했다면 Cost가 16으로 훨씬 비싸게 수행하는 것이기 때문이다. 이번엔 마지막으로 QPS가 1000으로 많아진 상황을 살펴보자. 이 경우에는 Variant B 2개, Variant C 1개를 사용하여 수행하는 것이 가장 효율적이라고 명시되어 있다. 이 경우 QPS가 높기 때문에 Variant A를 선택하는 것은 비효율적일 것이고 Cost가 비싸지만 처리 가능한 Request수가 많은 Variant C를 1개, 남은 QPS를 Variant B로 처리하는 경우가 가장 효율적이다.이처럼 사용자의 요구사항에 따라서 가지고 있는 하드웨어, 프레임워크, 딥러닝 모델 등의 옵션이 달라짐을 알 수 있고 요구사항에 맞게 효율적인 옵션을 선택하는 것이 중요하다. 위의 경우에서 정확도 등의 요구 사항이 더 추가된다면 조금 더 선택하기에 복잡해질 것이다. 따라서 현재 딥러닝 추론 분야는 미리 선택될 수 있는 Varient들을 정리해두고 이를 시스템적으로 최적화하여 SLO에 알맞은 Variant를 자동적으로 선택할 수 있도록 시도하는 연구가 활발히 진행되고 있다.하드웨어 가속기앞서 추론을 수행하는 데에 다양한 Varient 중 하드웨어가 관여하는 것을 보았다. 실제로 딥러닝 추론 분야에서는 프레임워크, 데이터의 사이즈, 모델의 종류 등 다양한 요소가 성능에 관여하지만 대표적으로 하드웨어를 선택하는 것이 가장 우선으로 꼽힌다.CPU와 GPU 그리고 TPUCPU, GPU, TPUCPU와 GPU는 대표적인 추론 하드웨어로 사용된다. 추론에서의 CPU는 상대적으로 값싼 비용에 범용적으로 모델들을 문제 없이 처리할 수 있다는 장점이 있다. 밑에서 다룰 다른 하드웨어 가속기의 경우 지원하지 않는 모델들이 있는 경우도 있기 때문에 범용성 또한 장점으로 잡을 수 있다. 하지만 값이 싼 만큼 처리량이 다소 떨어지며 이는 인풋 데이터의 배치 사이즈가 커질 수록 단점이 두드러진다. GPU의 경우 CPU보다 비싸지만 높은 처리량을 가지고 이는 특히 인풋 데이터의 배치 사이즈가 커질 수록 장점으로 작용한다. 따라서 SLO 중 처리 시간이 엄격한 경우 CPU보다 사용하기에 적합하다.아래 그림은 딥러닝 추론에서 유명한 MArK 논문(https://www.usenix.org/conference/atc19/presentation/zhang-chengliang)에서 가져왔다. 딥러닝 추론 실시간 서비스를 시스템적으로 구축해놓은 논문이니 참고해보아도 좋을 듯 하다.CPU, GPU, TPU batchsize별 추론 성능 비교MArK에서는 CPU, GPU, TPU에서 배치 사이즈를 증가해보며 추론 작업을 해본 결과를 그래프로 나타낸 것이다. TPU는 Google에서 지원하는 하드웨어 가속기이다.실험 결과를 살펴보면 배치 사이즈가 낮을 때에는 비슷한 처리 시간을 가지는 반면 비용은 CPU가 가장 저렴하여 효율적임을 보인다. 하지만 배치 사이즈가 증가 할수록 GPU가 처리시간이 앞서고 처리 시간이 빠른 만큼 하드웨어가 쓰이는 시간이 적기 때문에 비용면에서도 효율적임이 두드러 진다. TPU의 경우 GPU보다 처리 시간이 비슷하거나 더 느린 반면 비싼 비용이 드는 것으로 보아 가장 비효율적인 하드웨어 가속기로 논문에서는 보였다. 논문에서는 아직까지 Google TPU는 추론보다는 학습에 적합한 하드웨어라고 설명을 하고 있으나 추후 발전될 여지가 보인다.AWS EIA, AWS Inferentia클라우드 서비스로 유명한 AWS에서도 딥러닝 추론을 위한 하드웨어 가속기 서비스를 제공한다.EIA는 Elastic Inference Accelerator의 줄임말로 평소 CPU기반으로 컴퓨팅 작업이 이루어 지다가 추론 작업을 대상으로만 네트워크 통신을 통해 GPU기반의 EIA가 추론 작업을 하고 결과 데이터를 CPU에 전달한다. EIA별로 medium, large, xlarge로 type이 정해져 있고 다수의 EIA 하드웨어를 한번의 추론 작업 시나리오에 사용할 수 있어 다양하게 추론 작업에 사용할 수 있다. 추론 작업에 EIA를 이용하도록 하기 위해 EIA 전용 SDK를 AWS에서 제공하고 있으며 EIA를 호출하는 SDK의 함수를 통해 쉽게 추론 작업을 수행할 수 있다.CPU와 EIA의 네트워크 통신AWS Inferentia는 Neuron Chip이라고 하는 GPU기반 하드웨어를 AWS 전용 인스턴스에서 제공한다. Neuron Chip으로 추론 작업을 수행하기 위해서는 EIA와 마찬가지로 AWS에서 제공하는 SDK를 활용해야 한다. EIA와 다른 점은 EIA는 단순히 기존 CPU에서 수행하던 모델로 함수한 호출하면 되지만, Inferentia의 경우 Neuron Chip으로 추론할 수 있도록 모델을 컴파일 해야한다. 따라서 CPU에서 수행하던 모델을 컴파일 하는 과정에서 Neuron Chip이 지원하지 않는 Layer가 포함되어 있을 경우 사용에 제약을 받을 수 있다. 이러한 제약에도 Inferentia가 가치 있는 이유는 CPU보다는 처리량이 빠르고 GPU보다는 가격적으로 저렴한 중간 위치에 있기 때문이다.AWS EIA, AWS Inferentia 모두 비교적 최근에 발표된 하드웨어로 연구를 해볼 가치가 있는 하드웨어이고 연구 결과에 따라서 추론 시스템에 도입해볼 여지가 있다. 앞으로가 기대되는 하드웨어들이다.이외에도 Nvidia에서 다양한 하드웨어를 제공해 주고 있으며 하드웨어 말고도 프레임워크(Tensorflow, Pytorch, TensorRT, MxNet 등)와 딥러닝 모델 종류 등 고려해볼 다양한 선택 요소들이 존재한다.마무리딥러닝 추론 분야는 학습 분야에 비해 비교적 적은 연구가 이루어 졌고 최근 딥러닝을 실시간으로 서비스화 하면서 필요성이 많아진 분야이다.딥러닝 학습과 추론에서 드는 비용 AWS에서는 딥러닝 학습단계에 비해 추론단계에서 전체 비용의 90%가 든다고 하고 다른 회사에서도 점점 딥러닝 추론 분야에 대한 중요성을 인식하는 중이다. 딥러닝 추론의 실시간 서비스에서 가변적인 요청량들을 어떻게 효율적으로 처리할 것인지에 대해 지금도 여러 연구가 진행되고 있다. 사용자와 밀접한 위치에서 만족도 높은 서비스를 제공하기 위해 발전시키는 것이 정말 매력적인 분야이다. 참조https://lifeisenjoyable.tistory.com/7https://arxiv.org/abs/1905.13348?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+arxiv%2FQSXk+%28ExcitingAds%21+cs+updates+on+arXiv.org%29https://overface.tistory.com/542#https://www.usenix.org/conference/atc19/presentation/zhang-chenglianghttps://towardsdatascience.com/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1chttps://www.intel.co.kr/content/www/kr/ko/artificial-intelligence/posts/deep-learning-training-and-inference.htmlhttps://developer.nvidia.com/blog/inference-next-step-gpu-accelerated-deep-learning/https://www.hellot.net/news/article.html?no=52620window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//manchann.tistory.com/reaction';window.ReactionReqBody = {    entryId: 16}공유하기게시글 관리강저작자표시 'AI > Deep Learning' 카테고리의 다른 글Tensorflow MLFlow 사용해보기  (0)2023.06.26[DL] Keras로 imagenet 모델 save(저장), load(불러오기)  (0)2021.10.01TagAWS EIA, AWS Inferentia, CPU, GPU, Inference, Slo, 딥러닝, 딥러닝 추론, 딥러닝 학습, 하드웨어'AI/Deep Learning' Related ArticlesTensorflow MLFlow 사용해보기2023.06.26[DL] Keras로 imagenet 모델 save(저장), load(불러오기)2021.10.01more4  Comments    setInitialEntryComments(16, 1723623958)댓글쓰기 폼이름비밀번호                                              Secret                                          내용SendloadedComments[16]=true;findFragmentAndHighlight(16);Blog is powered bykakao / Designed byTistory티스토리툴바강구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4336022-16"",""customProps"":{""userId"":""0"",""blogId"":""4336022"",""entryId"":""16"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""16"",""entryTitle"":""[DL] 딥러닝 추론이란?"",""entryType"":""POST"",""categoryName"":""AI/Deep Learning"",""categoryId"":""1229749"",""serviceCategoryName"":""과학"",""serviceCategoryId"":404,""author"":""4651878"",""authorNickname"":""최재강"",""blogNmae"":""강"",""image"":""kage@dspFH4/btrfpsIYHs2/ekOoKY0DhGloYhriaGrkfK"",""plink"":""/16"",""tags"":[""AWS EIA"",""AWS Inferentia"",""CPU"",""GPU"",""Inference"",""Slo"",""딥러닝"",""딥러닝 추론"",""딥러닝 학습"",""하드웨어""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
102,https://lee-soohyun.tistory.com/10,머신러닝 잡다 정보,"본문 바로가기Soohyun’s Machine-learning카테고리검색하기검색하기SearchSoohyun’s Machine-learningAlex_Rose 분류 전체보기 (86)  Machine Learning (43)  Math & Stats (12)  ML_Math (1)  misc (15)  PRML (7)  Natural Language Processing (2)  Lectures (18)  Algorithms (1)  Data structure and Analysis (1)  Machine Learning Basic (3)  CS224N (NLP) (1)  CS231N (ML basic) (6)  CS50 (CS base) (3)  Fundamentals_of_Computer_Scien.. (1)  Review of Papers (6)  Daily routine (6)  Study English (11)  Ringle (6)  Mom-Eng (0)  Articles (1)  Lingua Latina (라틴어) (0)  Motivation for me (0)  Kaggle (1) GuestbookNoticeRecent Posts[C++코테] 시간복잡도(Time Complexi⋯링글에서 글로벌 커리어 컨퍼런스를 개최합니다.링글, 개인적인 활용법들 (+5만 포인트)[Ringle/링글] 영어를 당당하게 대하기 (f⋯Recent Comments댓글 감사합니다 ^_^댓글 감사합니다 :)안녕하세요. 혹시 해당 이슈에 도움이 될지는 모르겠지만⋯안녕하세요. model.eval() 단계에서 input⋯Link«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags해외취업컨퍼런스#체험수업링글경험담#링글화상영어#영어공부강동구장어맛집#영어발음교정링글리뷰성내동장어링글커리어뉴노멀챌린지스몰토크영어로전세계와소통하기링글Ringle영어회화#직장인영어#링글후기총각네장어소통챌린지장어랑고기같이둔촌역장어영어공부영어시험#nlpCommunicateWiththeWorld오피스밋업영어공부법#RinglemoreArchives2024/07 (1)2024/03 (1)2024/02 (1)2023/08 (1)Today6Total69,302닫기관리 메뉴글쓰기방명록RSS관리Soohyun’s Machine-learning머신러닝 잡다 정보 본문Machine Learning/misc머신러닝 잡다 정보Alex_Rose                           2017. 10. 9. 11:30- 머신러닝 학습 모델의 특성상, 모델을 그래프로 정의하고, 세션을 만들어서 그래프로 실행하고, 세션이 실행될 때 그래프에 동적으로 값을 넣어가면서(피딩, feeding) 실행한다는 기본 개념을 잘 이해해야 텐서플로 프로그래밍을 제대로 잘 할 수 있다.- 사이즈가 window size인 이유 : 주변 단어를 몇 개를 ""본다""는 뜻이기 때문에. window 크기로 슬라이딩하면서 스크린하며 중심 단어들로 주변 단어들을 보고 각 단어에 해당하는 벡터들의 요소값들을 조금씩 업데이트하면서 단어를 벡터로 임베딩- 아타리 퐁 게임을 어떻게 학습시키는지를 알려주는 카파시(Karpathy - yup! cs231n의 그 사람!) http://karpathy.github.io/2016/05/31/rl/http://karpathy.github.io/- nadam의 뜻Gradient를 수정한 Momentum, NagLearning Rate를 수정한 Adagrad, RMSProp, AdaDelta이 두 종류의 장점을 합한, Adam, Nadam이 있다.  y-intercept : y절편convention : 일종의 약속, 관습w.r.t : with repect toresidual : 잔차 흔히 eval이라고 되어 있는데, evaluation의 약자임 stddev  - standard deviation, 표준 편차Collections 모듈의 deque 클래스 : double-ended queue. 큐의 처음과 끝에서 아이템을 삽입하거나 삭제할 때 항상 일정한 시간이 걸리는 연산 제공 텐서플로의 flags가 뭐하는 애냐 : http://daeson.tistory.com/256  - weight initialization에서 활성화 함수로 ReLU를 사용할 때는 He initialization, Sigmoid나 tanh 등의 S자 모양 곡선일때는 Xavier initialization 사용... 이라고 하는데, 또 찾아본 결과에서는 Xavier Glorot (+he) = Glorot Gaussian을 쓴다고 함. 이걸 Xavier initialization이라고도 하고, Glorot initialization이라고도 함. Glorot initialization (사진 출처 : http://www.khshim.com/archives/641)2015년 he가 제안한 다른 weight initialization 이걸 넣고 PReLU를 넣으면 좋다-라고 함.. Backpropagation : output에서부터 순차적으로 partial derivative (편미분)을 수행하면서 weight과 bias 갱신regularization을 왜 하나? local noise나 outlier가 학습에 큰 영향을 끼치지 않게 하려고 L1과 L2의 차이는? L1은 통상적으로 상수값을 빼주도록 되어 있어서 작은 가중치들은 거의 0으로 수렴하고, 몇 개의 중요한 가중치들만 남음. 몇 개의 의미있는 값을 꺼내고 싶으면 L2 reg를 쓰는게 좋다. sparse model 에 적합함.  cross-entropy (negative log likelihood 라고도 함)는 2개의 확률 분포의 차이를 나타내는 용도. 두 개의 확률 분포가 얼마나 가깝냐 머냐를 나타낸다. 차이가 클수록 큰 값, 같아질수록 작은 값이 나오는데, 이게 cost function처럼 사용할 수 있는 이유이다. 항상 양의 값이 나온다.  텐서플로우의 variable scope : 변수명끼리의 이름 충돌을 방지함 ReLU : ramp function이라고도 함. fully connected layer = dense layer decision boundaries : 결정 경계 piecewise linear : 부분적으로 선형 squash : 제한시키다, 짓누르다 Leaky ReLU는 dying ReLU 현상을 해결하기 위해 제시된 함수이다. ReLU는 x < 0 일 경우 항상 함수값이 0이라서 뉴런이 으앙 쥬금 ㅠ  Mean Subtraction : 데이터의 모든 feature 마다 평균으로 나누며, 기하학적으로 zero-centered 데이터로 만드는 과정 (preprocessing) 이미지 처리 분야에서는 평균 이미지를 빼거나, 3개 채널 각각 평균을 구해서 각 채널별로 평균을 빼서 전처리를 한다.  principal component analysis, PCA : 주성분 분석(여기 글에 있는 PCA, whitening은 무슨 뜻이지?)중간의 decorrelated data가 PCA를 적용한 것이라고 함. 데이터들이 모두 zero-centered 되어 있고 데이터의 covariance Matrix (공분산 행렬)의 eigenbasis로 회전된 것을 볼 수 있다. (covariance 행렬이 diagonal - 사선의, 대각선의 - 된 상태). 오른쪽은 eigenvalue (고유값) 에 의해 추가적으로 scale 되었으며, 데이터의 covariance matrix 가 indentity matrix (단위행렬) 로 변환된다.correlation coefficient : 상관계수  Bagging (Boostrap aggregating) : 여러개의 모델을 혼합하여 일반화 에러 (generalization error) 를 줄일 수 있는 방법. 서로 다른 모델들을 각자 트레이닝 시키고, 이 모델들로부터 생성되는 결과값을 투표를 통해 최종 결과값으로 선출하는 방법 linear classifier 의 문제점은 각종 카테고리별로 1개의 필터 밖에는 사용할 수 없다는 점이다.VISION- open CV는 BGR로 color 체크. 알파값이 들어가는 건 영상물일 때  sendex의 openCV 강의 영상https://www.youtube.com/watch?v=Z78zbnLlPUA&list=PLQVvvaa0QuDdttJXlLtAJxJetJcqmqlQqNLP  - Natural language processingNLP : Zipf's lawlemmatization : 단어의 어근에 기반하여 단어의 기본형(lemma)을 찾아준다. ex) play, playing, played -> play언어마다 중요한 부분이 다르다. 한국어 : 동사   // 영어 : 명사, 형용사collocation (연어) : 문장내에서 유의미하게 사용되는 조합. ex) 양말을 입다 (x) -> 양말을 신다 (o)  command 용어 중에서 cd = current directory디렉토리 이동시에 쓰는 cd = change directorycmd에서 del 파일명  <- 이렇게 하면 파일이 삭제됨window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//lee-soohyun.tistory.com/reaction';window.ReactionReqBody = {    entryId: 10}공유하기게시글 관리Soohyun’s Machine-learning 저작자표시 비영리 동일조건 'Machine Learning > misc' 카테고리의 다른 글용어 이해  (0)2017.10.13신경망 뼈대 구축하기  (0)2017.10.13머신러닝 자료 링크들  (0)2017.10.09신경망에 대해 이해한 것  (0)2017.09.20텐서플로 GPU / 윈 10 설치  (0)2017.09.17공유하기 링크페이스북카카오스토리트위터'Machine Learning/misc' Related Articles용어 이해2017.10.13신경망 뼈대 구축하기2017.10.13머신러닝 자료 링크들2017.10.09신경망에 대해 이해한 것2017.09.20more0  Comments댓글쓰기 폼이름비밀번호                                              Secret                                          내용SendloadedComments[10]=true;findFragmentAndHighlight(10);Blog is powered bykakao / Designed byTistory티스토리툴바window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2810738-10"",""customProps"":{""userId"":""0"",""blogId"":""2810738"",""entryId"":""10"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""10"",""entryTitle"":""머신러닝 잡다 정보"",""entryType"":""POST"",""categoryName"":""Machine Learning/misc"",""categoryId"":""710435"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""33408"",""authorNickname"":""Alex_Rose"",""blogNmae"":""Soohyun’s Machine-learning"",""image"":""cfile3.uf@9969A23359DB0443038181.png"",""plink"":""/10"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
103,https://james.tistory.com/163,티스토리툴바,"JAMES BLOGN o t i c el i s tt a gg u e s ta d m i n rssflashWrite(""https://tistory1.daumcdn.net/tistory/537/skin/images/title.swf"",""850"",""50"",""title_flash"",""#ffffff"",""isContent=Y&titleText=@ Tistory.com 이용후기&titleLink=/163&detailText=카테고리 없음 | 2011. 6. 28. 17:57 | "");다음에서 티스토리 도메인으로 메일계정을 서비스했다 티스토리를 사용하는 블로거 로서는 얼마나 고마운 서비스인가?이제는 티스토리만의 이메일로 수신및 발신을 자유롭게 할수있어서 정말좋다..p.s 이용후기쓰면 정말로 용량을 추가해주나요?window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//james.tistory.com/reaction';window.ReactionReqBody = {    entryId: 163}공유하기게시글 관리JAMES BLOG저작자표시 비영리 변경금지 ─ tag  @tistory.com @ Tistory.com 이용후기   :: 2011. 6. 28. 17:57 카테고리 없음 댓글쓰기 1    setInitialEntryComments(163, 1723627692)Your Name (required)Password (required)Your Website AddressSecretloadedComments[163]=true;findFragmentAndHighlight(163);opencloseWAU_colored('5vp12j4oeigx', '28903afff200')"
104,https://mokeya.tistory.com/76,SQL을 이용한 데이터 추출,"Programming/Knowledge[데이터 사이언티스트 독학 01] Data Science의 정의, 데이터 처리(Data Processing)를 배우는 방법by 지표덕후2021. 8. 18..adsbygoogle.post-top-first {display:block;}.adsbygoogle.post-top-second {display:none}@media (min-width: 680px) {.adsbygoogle.post-top-first {display:inline-block;min-width:300px;max-width:300px;width:100%;height:250px;}.adsbygoogle.post-top-second {display:inline-block;margin-left:20px;min-width:300px;max-width:300px;width:100%;height:250px;}}@media (min-width: 768px) {.adsbygoogle.post-top-first {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}.adsbygoogle.post-top-second {display:inline-block;min-width:336px;max-width:336px;width:100%;height:280px;}}(adsbygoogle = window.adsbygoogle || []).push({});(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});싱가폴 출신의 데이터 사이언티스트, Travis Tang님의 아티클을 번역한 글입니다.데이터 사이언티스트 wannabe라면, 일독할 가치가 충분한 글입니다.Travis Tang님은 화학공학을 전공했지만 테크기업에서 데이터 분석가로 사회생활을 시작했습니다.몇 차례에 걸쳐 포스팅 될 그의 이 아티클은 화학공학도가데이터 사이언티스트로 일하기까지의 여정과 필요한 스킬셋(skill set)을 구체적으로 담고 있습니다.Tang은, 데이터 사이언티스트로 나아가는 데 필요한 정보는 홍수처럼 넘치는데오히려 그 때문에 최고의 자원을 선별해내는 것이 어렵다고 토로합니다.그렇기 때문에 먼저 아래의 질문에 답을 할 수 있어야 한다고 강변합니다.정보의 홍수데이터 과학이란 무엇입니까?아, 이것은 인사 담당자와 기업의 면접관 모두를 당황하게 만드는 대답하기 어려운 질문입니다. 사실, 회사마다 데이터 과학을 다르게 정의하여 용어가 모호하고 다소 이해하기 어렵습니다. 프로그래밍이라고 하는 사람도 있고 수학이라고 말하는 사람도 있고 데이터를 이해하는 일이라고 말하는 사람도 있습니다. 모두 어느 정도 맞는 말입니다. 나(Travis Tang)에게 가장 동의하는 정의는 다음과 같습니다.데이터 사이언스data science는 수학, 컴퓨터 과학, 도메인 지식 분야에서 도출된 기술과 이론을 사용하는, 학제를 넘나드는(inter-disciplinary) 분야이다.아래 그림은 위의 정의를 잘 보여주는 이미지입니다.데이터 사이언스는 다양한 학문들의 교차로이 이미지에서 각 분야의 지식이 뭉쳐 데이터 과학을 형성한다는 것을 보여주기 위하여 분야 사이의 경계를 흐릿하게 묘사했습니다.자, 그럼 데이터 사이언스, 데이터 과학을 배우기 위해선 뭘 해야 할까요?일련의 게시물을 통해 저는 데이터 사이언티스트로 나아가는 과정에서 제가 배운 것들을 알려드리려 합니다. 이를 통해 저와 같은 입장에 있는 분들이 데이터 사이언스를 배워나가는 데에 도움이 되었으면 합니다. 이 아티클은 아래와 같은 내용으로 구성될 예정입니다.1부 — SQL, Python 및 R을 사용한 데이터 처리(본 게시물의 내용)2부 — 수학, 확률 및 통계3부 — 컴퓨터 과학 기초4부 — 기계학습(머신러닝)5부 — 첫 번째 기계 학습 프로젝트 구축     (adsbygoogle = window.adsbygoogle || []).push({}); 첫 번째 게시물인 이 글에서는 데이터 사이언티스트에게 필요한 데이터 처리(data processing) 지식에 대해 주로 다루게 될 것입니다. 제가 생각할 때 데이터를 처리와 관련해서는 일반적으로 아래의 것들을 배워야 합니다.SQL(Standard Query Language)을 사용하여 데이터베이스에서 데이터를 추출하고데이터 정리/ 조작/ 분석(일반적으로 Python 및/또는 R 사용)하여,데이터를 효과적으로 시각화합니다.SQL을 이용한 데이터 추출SQL은 데이터가 있는 데이터베이스와 통신하는 언어입니다. 데이터가 지하에 묻혀 있는 보물이라면 SQL은 보물의 원시 형태를 파헤치는 삽입니다. 보다 구체적으로 말하면, SQL을 사용해 데이터베이스에 있는 하나 또는 여러 테이블의 조합에서 정보를 추출할 수 있습니다.SQL 마스터는 그렇게 어렵지 않습니다SQL Server, PostgreSQL, Oracle, MySQL 및 SQLite와 같이 SQL에는 다양한 선택지가 있습니다. 이들 각각은 조금씩 다르지만 구문(문법)은 대체로 유사하므로 굳이 이들 중 하나를 선택하는 데에 긴 시간을 보낼 필욘 없습니다.언어를 배우려면 먼저 단어를 학습한 다음 문장으로 결합하고 단락을 구성해야 합니다. SQL 역시 마찬가지입니다.아주 기본적인 개념(SQL의 단어나 문장)을 배우기 위해 Datacamp(Introduction to SQL)와 Dataquest(SQL Fundamentals)라는 플랫폼을 활용했습니다. (나중에 Datacamp와 Dataquest의 장단점에 대해 설명하겠습니다.) 일반적으로 이러한 사이트는 연습과 예제를 통해 필수 SQL 기술을 경험할 수 있습니다. 이 단계에서 기억해야 할 몇 가지 개념은 다음과 같습니다.     (adsbygoogle = window.adsbygoogle || []).push({});필터링 및 선택을 위한 SELECT 및 WHERE데이터 집계를 위한 COUNT, SUM, MAX, GROUP BY, HAVING유용한 고유 목록 및 고유 집계를 생성하기 위한 DISTINCT, COUNT DISTINCTOUTER JOIN(예: LEFT) 및 INNER JOIN을 언제/어디서 사용할지문자열 및 시간 변환UNION 및 UNION ALL.(잘 알지 못 해도 상관 없습니다! 배우면 되니까요.)사실 이것들을 숙지한다고 해서 분석가로서 충분히 준비된 상태라 볼 수는 없습니다. 단어와 문장을 이해할 수는 있지만 전체 문단을 쓰기에는 추가적인 스킬이 필요할 겁니다. 특히, 하위 쿼리(sub-query) 및 창(window) 기능과 같은 일부 중/고급 개념은 구직면접에서 테스트 항목으로도 출제되는 편이며, 분석가로서 역할을 수행하기 위해서도 반드시 필요합니다. 이러한 기술에는 다음이 포함됩니다.COALESCE로 NULL 처리하위 쿼리와 쿼리 효율성에 미치는 영향임시 테이블자체 조인PARTITION, LEAD, LAG와 같은 창 기능사용자 정의(UDF) 기능작업을 더 빠르게 하기 위해 쿼리에 인덱스를 사용이러한 기술을 배우기 위해 저는 주로 무료이며 각 개념에 대해 매우 어려운 예제를 제공하는 SQLZoo.net을 주로 사용하였습니다. SQLZoo에서 가장 좋아하는 기능은 하나의 통합 문제에서 다양한 개념을 테스트하는 연습문제가 있다는 것입니다. 예를 들어 다음과 같은 엔터티-관계 다이어그램이 제공되고 이를 기반으로 복잡한 쿼리를 생성하도록 요구합니다.엔터티-관계 다이어그램 예시이 과업들은 전문 분석가(analyst)가 하는 일에 가깝습니다. 분석가는 동일한 데이터베이스로부터 정보를 추출하기 위해 다양한 기술들을 배워 사용합니다. 여기 SQLZoo의 예제 링크를 걸어두었습니다. 'Help Desk'의 엔터티-관계 다이어그램입니다. 주어진 상황에서 당신은 2017년 08월 12일 하루 중 각 시간에 수신된 전화 수와 관리자를 표시해야 합니다. (여기서 직접 해보세요!)제가 활용한 다른 리소스로는 Zachary Thomas의 SQL 예제 및 Leetcode가 있습니다.R과 Python을 사용해 데이터 다루기(manipulation)데이터 과학에 필요한 프로그래밍과 도구에 대해 배우려면 R이나 Python에서 벗어날 수 없습니다. 이 둘은 데이터 조작, 시각화를 비롯, 데이터를 지지고 볶는 데에 사용되는 매우 인기 있는 프로그래밍 언어입니다. R이 우월한가 Python이 우월한가는 그 자체로 별도의 포스팅을 할 가치가 있는 질문입니다. 제 의견은요,R을 선택하든 파이썬을 선택하든 상관없습니다. 하나를 마스터하면 다른 하나는 쉽게 익힐 수 있습니다.Python 및 R로 코딩하는 여정은 CodeAcademy, Datacamp, Dataquest, SoloLearn 및 Udemy와 같은 코드 사이트에서 시작되었습니다. 이 사이트는 언어 또는 패키지별로 구성된 자습형 수업을 제공합니다. 이들 플랫폼은 먼저 개념을 설명해주고, 사용자에게 공백을 제시하며 코드로 채울 것을 요구합니다. 이러한 사이트는 일반적으로 간단한 데모를 통해 방금 배운 개념을 즉시 연습할 수 있습니다. 일부는 나중에 프로젝트 기반 예제를 제공합니다.오늘은 저는 제가 가장 좋아하는 두 가지인 Datacamp와 Dataquest를 집중적으로 다루겠습니다.Datacamp데이터캠프DataCamp는 현장 전문가의 비디오 강의와 빈칸 채우기 연습을 제공합니다. 비디오 강의는 대부분 간결하고 효율적입니다.DataCamp에서 내가 좋아하는 부분 중 하나는 SQL, R 및 python 관련 커리어 패쓰별로 구성된 과정입니다. 이를 통해 커리큘럼 을 직접 고민해야 하는 수고를 덜 수 있습니다. 이제 관심 있는 경로를 따라가면 됩니다. 다음과 같은 경로가 제공됩니다.Python/R의 데이터 사이언티스트Python/R/SQL의 데이터 분석가Python/R의 기계학습(머신러닝) 전문가파이썬/R 프로그래머     (adsbygoogle = window.adsbygoogle || []).push({});개인적으로 저는 ""R의 데이터 사이언티스트로 R 교육을 시작했습니다. 이 교육에서는 데이터를 구성, 조작 및 시각화하는 데 매우 유용한 데이터 패키지의 모음인 R의 Tidyverse에 대해 상세하게 소개합니다. ggplot2(데이터 시각화용), dplyr(데이터 조작용) 및 stringr(텍스트 분석용)이 포함되어 있습니다.그러나 DataCamp에 대한 불만도 있습니다. DataCamp를 완료한 후에는 머릿 속에 지식이 제대로 남지 않는다는 점입니다. 빈칸 채우기 형식을 사용하는지라, 개념을 제대로 이해하지 않고도 빈칸에 무엇이 필요한지 쉽게 추측할 수 있기 때문입니다. 제가 이 플랫폼을 통해 배우던 때에 가능한 한 짧은 시간에 최대한 많은 과정을 완료하려는 욕심이 있었습니다. 그러다보니 코드를 훑어보고 더 큰 그림을 이해하지 못한 채 빈칸 채우기에만 급급했습니다. DataCamp에 대한 학습을 다시 시작할 수 있다면, 코드 전체를 더 잘 소화하고 이해하기 위하여 시간을 더 할애할 것입니다.Dataquest데이터퀘스트Dataquest는 DataCamp와 매우 유사합니다. 프로그래밍 개념을 설명하기 위해 코드에 따른 연습을 사용하는 데 중점을 둡니다. Datacamp와 마찬가지로 R, Python 및 SQL로 다양한 과정을 제공하지만 DataCamp보다는 확장성이 떨어집니다. 예를 들어 Datacamp와 달리 Dataquest는 비디오 강의를 제공하지 않습니다.Dataquest에서 제공하는 일부 트랙은 다음과 같습니다.R/Python의 데이터 분석가파이썬의 데이터 과학데이터 엔지니어링DataQuest의 콘텐츠는 일반적으로 DataCamp의 콘텐츠보다 어렵습니다. 빈칸 채우기 형식에 따른 지식 보존 문제도 적습니다. 시간이 더 걸리긴 했지만 DataQuest를 통해 익힌 지식은 머릿속에 더 오래 남았습니다.DataQuest의 또 다른 훌륭한 기능은 이력서를 검토하고 기술 지침을 제공할 멘토와 월마다 통화할 수 있다는 점입니다. 멘토와 개인적으로 연락하지는 않았지만 훨씬 더 빨리 발전하는 데에는 확실히 도움이 되었을 것이라 생각합니다.데이터 시각화데이터 시각화는 데이터에서 도출한 통찰력을 제시(present)하는 핵심입니다. Python과 R을 사용하여 차트를 만드는 기술을 배운 후 Cole Knaflic의 <Storytelling with Data>(역자주: 국내에서는 '데이터 스토리텔링'이라는 제목으로 번역본이 판매되고 있는데 그야말로 끔찍한 번역)라는 책에서 데이터 시각화의 원리를 배웠습니다.이 책은 툴에 의존하지 않습니다. 즉, 특정 소프트웨어에 초점을 맞추지 않고 통찰력 있는 예시를 통해 데이터 시각화의 일반적인 원리를 가르칩니다. 이 책에서 기대할 수 있는 몇 가지 핵심 사항은 다음과 같습니다.컨텍스트 이해효과적인 시각 자료 선택어수선함 제거원하는 곳에 주목디자이너처럼 생각하라이야기를하다나는 이 책을 읽기 전까지 데이터 시각화를 안다고 생각했습니다.Travis Tang 님이 작성한 차트     (adsbygoogle = window.adsbygoogle || []).push({});책을 소화한 후, 나는 흑인에 대한 경찰의 만행을 설명하는 (다소) 시각적으로 즐거운 차트를 만들 수 있었습니다. 여기에 적용된 책의 주요 학습 포인트 중 하나는 원하는 곳에 주의를 집중시키는 것이었습니다. 이것은 BLM 색상을 연상시키는 밝은 노란색으로 아프리카 계 미국인 라인을 강조 표시함으로써 달성되었으며, 나머지 차트는 흰색 및 회색과 같은 더 흐릿한 음영으로 배경에 머물도록 조치했습니다.그 외 읽을거리이 블로그 게시물에 마음에 들었다면 기계학습에 대한 다른 아티클도 읽어보세요.How to be a Data Analyst — Data Viz with Google Data StudioWhat makes great wine… great? (Using Machine Learning and Partial Dependence Plot in the quest for a good wine)Interpreting Black-Box ML Models using LIME (Understand LIME Visually by Modelling Breast Cancer Data)참고문헌[1] Dhar, V. (2013). “Data science and prediction”. Communications of the ACM. 56 (12): 64–73. doi:10.1145/2500499. S2CID 6107147. Archived from the original on 9 November 2014. Retrieved 2 September 2015.다음 포스팅에서는이 게시물에서는 제가 프로그래밍을 배우면서 출발점으로 삼은 스킬셋에 대해 다루었습니다. 이 과정을 통해 이제 데이터를 조작하는 데 필요한 기술을 갖추게 되었습니다! 하지만 아직 갈 길이 꽤 멉니다. 남은 스킬들에 대해서는 다음 포스팅에서 다루겠습니다2부 — 수학, 확률 및 통계3부 — 컴퓨터 과학 기초4부 — 기계학습(머신러닝)5부 — 첫 번째 기계학습(머신러닝) 프로젝트 구축 반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//mokeya.tistory.com/reaction';window.ReactionReqBody = {    entryId: 76}공유하기게시글 관리지표덕후,  지덕智德저작자표시 비영리 변경금지 'Programming > Knowledge' 카테고리의 다른 글[웹개발] 파이썬 웹 프레임워크(Web Frameworks)에 대한 간단 지식과 추천 프레임워크  (0)2022.01.15[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계  (0)2021.09.10[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라  (0)2021.08.26[데이터 사이언티스트 독학 03] 기계학습(머신러닝)은 무엇인가, 어디서 배울 수 있나  (0)2021.08.21[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기  (0)2021.08.19     (adsbygoogle = window.adsbygoogle || []).push({});태그Python, r, SQL, 데이터과학, 데이터사이언티스트, 데이터시각화, 도서추천, 독학, 학습법, 학습사이트관련글[머신러닝 for 비즈니스] 비즈니스에 가치를 더하는 기계학습 인프라 구축 6단계[데이터사이언티스트 독학 04] 취업하고자 한다면 데이터 사이언스 프로젝트를 수행하라[데이터 사이언티스트 독학 03] 기계학습(머신러닝)은 무엇인가, 어디서 배울 수 있나[데이터 사이언티스트 독학 02] 데이터 과학에 필요한 수학, 확률과 통계 배우기댓글0비밀글댓글등록loadedComments[76]=true;findFragmentAndHighlight(76);"
105,https://thumbnails.tistory.com/3,[후기]햇살론 유스 무직자로 530받은 후기~2편~,"본문 바로가기다시 한번,카테고리검색하기검색하기블로그 내 검색다시 한번,썸넬 분류 전체보기 (4)  정보 (4) GuestbookNoticeRecent Posts[후기] 카카오뱅크 청년전세자금대출 무직자(대학생⋯[후기] 카카오뱅크 청년전세자금대출 무직자(대학생⋯[후기]햇살론 유스 무직자로 530받은 후기~2편⋯[후기]햇살론 유스 무직자로 530받은 후기/상세⋯Recent CommentsLink«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags청년전세자금대출전세대출햇살론 유스 과정햇살론 유스 후기카카오뱅크청년전세대출햇살론 유스 무직자 후기햇살론 방법카카오뱅크청년전세자금대출대학생카뱅청년전세자금대출햇살론 유스 무직자청년전세자금대출무직자카뱅청년전세대출청년전세카카오뱅크전월세보증금대출햇살론 유스 부결햇살론 유스카카오뱅크청년대출햇살론 유스 부결 후기집대출햇살론햇살론 부결햇살론 유스 무직자 대출moreArchives2023/05                                  (2)2021/12                                  (2)Today7Total7,433닫기관리 메뉴글쓰기방명록RSS관리다시 한번,[후기]햇살론 유스 무직자로 530받은 후기~2편~ 본문정보[후기]햇살론 유스 무직자로 530받은 후기~2편~썸넬        2021. 12. 4. 03:03                  ※햇살론 유스 무직자 필요 서류목록 후기는 1편을 참조해주세요※↓​[후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~ (tistory.com) [후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~햇살론 유스 ​ ​ 내가 그랬던 것 처럼 햇살론 유스 내용이 너무 어려워서, 준비할 서류가 복잡해서, 어떻게 해야 부결이 안날 수 있을지 고민하는 분들을 위해 조금이나마 도움이 됬으면 해서thumbnails.tistory.com​​​​1편에서도 말했듯 부결이 싫은 나는 햇살론 유스 폭풍검색으로 몇가지 사실을 알게된다.​​​​1. 기대출의 유무와 금액은 부결에 크게 영향을 미치지 않는다.나는 학자금대출, 삼성카드 대출 합쳐서 기대출이 1000만원 가량있었다. 그 중 삼성카드 대출이 430?정도였을 거고 현금서비스도 받았던 내역도 있었다. 그것도 신청일 기준 한달이내에 카드대출이 있었고 신용등급도 7등급에서 6등급이었음. 하지만 연체는 한번도 없었다!후기 보면 연체있는 분들은 부결 많이 납니다.​​2. 서류가 부족하면 무조건 부결이다.실제로 상담사분이 내게 서류를 너무 잘 준비해왔다며, 원래 처음오면 먼저 서류부족으로 부결나는 사람이 많단다.부결나면 한달 후에 신청가능하다.​​​3. 최종결정은 상담사가 한다.많은 후기들을 본 결과 비슷한 조건인데도 누구는 승인이나고 누구는 부결로 난다. 심지어 더 승인난 사람보다 더 좋은 조건에서 부결이 나기도 한다. 그 이유는 승인의 최종결정권은 나를 상담해주는 상담사분에게 있기 때문이다. 햇살론 유스는 어떤 기준을 충족하면 그 이후에 승인을 결정하는 것은 상담사의 권한인 것 같다. 그러니 상담사에게 잘보이진 못하더라도 밉보이지 말자.​​​​만반의 준비를하고 센터를 찾아갔다. 그리고 상담사분을 만났는데, 나를 보고 하는 첫 마디가""서류 준비를 너무 잘해오셨네요. 이런 경우는 처음이에요"" 이라고 하셨다. 이후에 말씀하시길 처음에 오면 서류 부족으로 부결난다. 이렇게 알아서 다 준비해올 수 있는 건지 몰랐다. 어떻게 준비해온거냐... 굉장히 놀라하셨다. 이 말은 즉 서류부족으로 부결나는 경우가 꽤 많다는 말이다. 그러니 서류준비만 완벽히 해가도 일단 점수를 잘 받을 수 있다.​​그 이후는 굉장히 순조로웠다. 생활자금 대출 300만원 가능하다고 하셨고 내가 주거비 용도로 제출한 300만원의 경우, 한달 월세X6개월으로 계산해서 그 금액만큼 대출 가능하다고 하셨다. 나의 경우 한달월세가 23만원이므로 23만원X6개월 = 138만원 이므로 130으로 계산해서 해주셨다. 그리고 내가 보증금 대출은 안되냐고 물었더니 보증금은 원래 대출이 잘 안된다고 하셨다.(월세 처럼 앞으로 낼 돈이 아니라 이미 낸 돈이라서 그런듯). 하지만 나는 보증금도 받았다...! 다시 한번 상담사분의 의사가 승인을 좌지우지 한다는 걸 느꼈다... 신청일 기준 한달이내에 낸 보증금만 신청 가능하다고 한다. 그리고 이 기준을 충족해도 잘 안해준다고 하니 참고하자.(나는 한달이내 였음)​내가 가져간 통장 거래 내역서에는 보증금 100만원과 월세 2달치를 낸 내역이 있었고, 그래서 주거비 용도 대출은 보증금 100만원 + 월세6개월 약130만원 = 총 230만원 이렇게 받을 수 있었다.​​그리하여 나의 총 대출은  생활자금 300만원+ 주거비 230만원 = 530만원 되시겠다.보증료는 172,350원 나왔따.​​그리고 거치기간과 상환기간을 설정하게 되는데, 거치와 상환기간이 길수록 보증료가 올라간다. 상담사분이 거치, 상환 바꿔가면서 금액 이 각각 얼마나오는지 친절히 알려주신다. 나는 거치 4년+상환4년 이렇게 완료했다. 햇살론 유스는 이자율이 낮은 대출상품이기 때문에 일부러 길게 잡았다. 앞으로 살면서 집도 사고 하다보면 분명 대출을 받을 날이 또 있을텐데 햇살론 유스보다 저렴할리는 없고, 그러면 돈이 생기면 이자율 높은거 부터 갚고 낮은거 늦게 갚는게 합리적으로 좋을테니. 그래서 한국장학재단 학자금대출도 최후로 남겨놓고 갚는다............상담사 분과 뭐 이런얘기들을 나눴다.​​전산처리를 하시면서 나에게 물어본 내용들을 적어보겠다.나한테 대출 얼마있는지 물으셨고 (그냥 참고하는 거니 대충 얼마인지만 말하면된다고 하심) 나는 솔직하게 있는 대출 다 말했다. 그리고 햇살론유스 대출 받으면 바로 삼성카드에 있는 대출을 갚을 예정이라고도 말했다. 현재 삼성카드 연이자가 15%정도인데 이자가 너무 비싸서 햇살론유스로 바꾸는 거라고... (저는 솔직하게 말씀드렸지만 상담사에 따라 이게 득이될지 실이될지는 장담할 수 없습니다)나이가 어린데 카드대출은 왜 많냐고 물어보셨다.(이건 530만원 승인 결정난 후에 물어봄) 그래서 사실대로 내가 쓰려고 빌린게 아니라 부모님이 사업하시는데 급하게 필요해서 빌려드린 거라고 했다. 그랬더니 빚을 내서 그러면 안된다고 하셨고 여러 좋은 얘기들 해주셨는데 깊이 새겨듣고 나왔다. 그리고 가기전에 옆에 창구에서 취업상담도 한번 받고 가라고 하셔서 받으러 갔는데 정말 유용하고 좋은 내용들이 많더라. 청년들을 위한 지원금도 다양하고 정보 사이트들도 많으니 센터에 방문하게 된다면 꼭 취업상담도 같이 받고 오길바란다. 당근 무료다.​그리하여 햇살론유스 530만원 대출승인을 받고 유용한 취업상담도 받고 기분좋게 룰루랄라 나왔는데 문자가 와있었다. 보증승인 안내 문자  다음단계가 존재한다..후..​​대출을 승인 받았다면 1주이내에 약정체결을 해야한다. 1주일이 지나면 자격조회부터 다시시작해야한다.약정체결은 어렵지 않다. 문자로 친절하게 설명이 오니 하란대로 하면 된다.(어플접속-마이페이지-햇살론youth보증신청내역-약정서작성)​그렇게 약정을 체결하면 문자가 띠롱 날아온다.보증약정체결 확인문자 위 사진에서 보듯 보증약정이 체결되면 2주이내에 보증료를 내고 대출을 실행해야한다.2주가 지나면 자격조회부터 다시시작해야한다 ^^ (생각만해도 행.복.)자 그러면 이제 은행을 선택해야한다.신한은행, 전북은행, 기업은행 중 택1하면된다. 세개 밖에 없다.세 은행의 우대 서비스가 다르므로 비교해보고 자신에게 맞는걸 선택하면된다.대출액을 빠르게 받고 싶다면 센터 방문 전에 계좌를 개설하는 것도 나쁘지 않다고 본다. 물론 승인난다는 전제하에.나는 이미 신한은행에 계좌가 있고 또 만들기 귀찮아서 (이미 진이 다 빠졌음) 신한은행으로 선택했다.대출실행 전에 보증료를 미리 선택한 은행계좌에 넣어놔야한다. 신청시 자동으로 빠져나가면서 대출금액이 바로 들어오기때문.​신한은행 어플 (쏠) 접속- 공인인증서 등록 (이미 되어있으면 패쓰) -메뉴-상품-대출-햇살론 Youth​아마 다른 은행도 동일 할 것이다.들어가면 보증번호 입력하라고 하는데 문자로 날아온 시리얼번호 입력하면 된다. 공인인증서로 인증하고 보증료가 빠져나감과 동시에 대출금액이 해당 계좌로 입금된다!매달 입금받은 계좌로 이자가 나가므로 잊지말고 계좌에 돈을 넣어두길 바란다. 연체되면 신용도 떨어진다ㅠ​​참고로 나는 햇살론유스 신청 전에 신용등급 7등급에서 아슬아슬한 6등급이었다(카드대출많음). 근데 글을 작성하는 현재 신용등급 5등급이 되어있다. 딱히 뭘 한건 아니고, 햇살론 유스로 바꿔치기 해서 오른거다. 제2금융권인 삼*카드 대출을 제1금융권(신한은행) 햇살론대출받은 금액으로 싹 값으니 등급이 올랐다. 심지어 햇살론 유스로 대출한 금액이 이전 삼*카드 대출보다 훨씬 많은데도 말이다. 바꾸길 천만번 잘한 것 같다.​​ ​이렇게 하여 나의 기나긴(?) 햇살론 유스 무직자 대출 여정기가 끝이 났다.서류준비와 대출실행하는 과정에서 진이 다 빠져부렀따....힝(신한은행의 경우 오랬동안 거래를 안해서 중지된 계좌를 풀러 은행에 방문해야 했음. 그리고 또 많지만 줄이겠다.)그리고 참고로 요즘 은행에서 계좌 새로 개설하면 한도계좌로 생성돼서 현금인출에 하루 제한금액이 정해져있으니대출받은 돈은 자주쓰는 계좌로 인터넷뱅킹해서 현금으로 인출하면 된다.​​ ​내가 준비하면서 너무 힘들었고 어려웠기 때문에 햇살론 알아보고 이 글을 읽을 분들한테도움이 되었으면 하는 마음에 최대한 열심히 작성해 보았다(나한텐 이게 최선임). 도움이 됐을지 모르겠다. 조만간 센터에서 취업상담 받은것도 정보정리해서 포스팅하겠다힘든 이 시국 모두 잘 이겨냈으면ㅜㅜ 뽜이띵​​​​​+저는 댓글에 답글을 달지 않습니다.이유는,1. 본문에 다 나와있는 내용을 질문하시는 분들이 많습니다.(꼼꼼히 읽어보면 다 나와있는 내용을 질문하십니다)​2. 제가 알지 못하는 부분에 대한 질문들이 있습니다.(저는 제가 아는 것을 모두 1,2편에 나누어 작성하였습니다. 이게 제가 아는 전부입니다)​3. 저도 처음엔 모르는 부분은 제가 직접 찾아보고 장문으로 답변을 드렸고,이미 나와있는 내용에 대해서도 다시 답변을 드렸습니다만,시간을 투자해 열심히 단 답변에 감사하다는 인사 한마디 없이 사라지시는 분들이 계십니다.​제 정보가 많은 분들께 도움이 되었으면 하는 마음에서 게시글을 올렸습니다.제가 아는 정보는 1, 2편에 전부 작성하였으니 꼼꼼히게 읽어보시면 좋을 것 같습니다.긴 글 읽어주셔서 감사합니다.    무단 복사 및 공유를 금지합니다.   썸넬's 네이버 블로그에서 보기 ↓[후기]햇살론 유스 무직자로 530받은 후기~.. : 네이버블로그 (naver.com) [후기]햇살론 유스 무직자로 530받은 후기~2편~썸넬's 티스토리에서 보기 ↓ [후기]햇살론 유스 무직자로 530받은 후기~2편~ (tistory.com) ※햇살론...blog.naver.com  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//thumbnails.tistory.com/reaction';window.ReactionReqBody = {    entryId: 3}공유하기게시글 관리다시 한번, '정보' 카테고리의 다른 글[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~2편~  (0)2023.05.04[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~1편~  (0)2023.05.04[후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~  (0)2021.12.04Tag햇살론, 햇살론 방법, 햇살론 부결, 햇살론 유스, 햇살론 유스 무직자, 햇살론 유스 무직자 대출, 햇살론 유스 무직자 후기, 햇살론 유스 부결, 햇살론 유스 후기'정보' Related Articles[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~2편~2023.05.04[후기] 카카오뱅크 청년전세자금대출 무직자(대학생) ~1편~2023.05.04[후기]햇살론 유스 무직자로 530받은 후기/상세설명有~1편~2021.12.04moreloadedComments[3]=true;findFragmentAndHighlight(3);          Blog is powered by          kakao / Designed by          Tistory티스토리툴바다시 한번,구독하기                    (function () {                         var blogTitle = '다시 한번,';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""5074581-3"",""customProps"":{""userId"":""0"",""blogId"":""5074581"",""entryId"":""3"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""3"",""entryTitle"":""[후기]햇살론 유스 무직자로 530받은 후기~2편~"",""entryType"":""POST"",""categoryName"":""정보"",""categoryId"":""1063181"",""serviceCategoryName"":""생활정보"",""serviceCategoryId"":105,""author"":""5163727"",""authorNickname"":""썸넬"",""blogNmae"":""다시 한번,"",""image"":""kage@dRxD0p/btrm0qhXuYm/YKMuVKpokPposmAQVqPny1"",""plink"":""/3"",""tags"":[""햇살론"",""햇살론 방법"",""햇살론 부결"",""햇살론 유스"",""햇살론 유스 무직자"",""햇살론 유스 무직자 대출"",""햇살론 유스 무직자 후기"",""햇살론 유스 부결"",""햇살론 유스 후기""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
106,https://wooono.tistory.com/123,[Docker] Dockerfile 개념 및 작성법,"본문 바로가기우노카테고리검색하기검색하기Search우노글목록방명록About 분류 전체보기 (763)  AI (99)  Machine Learning (48)  Deep Learning (49)  Data (68)  Spark (43)  Graph & Matrix (7)  Hadoop (2)  MapReduce (1)  Recommender System (6)  Natural Language Processing (1)  Data Mining (1)  Airflow (7)  DevOps (91)  Concept (1)  Terraform (20)  Istio (2)  Helm (3)  Kubernetes (23)  Docker (21)  Prometheus (2)  Datadog (1)  GitHub (18)  GCP (14)  CLI (1)  Cloud Run (1)  Cloud Build (1)  Authentication (3)  PubSub (2)  Composer (3)  Bigquery (3)  AWS (37)  CLI (7)  EC2 (8)  EMR (8)  Route 53 (2)  S3 (1)  API Gateway (2)  Lambda (6)  ECS (1)  DocumentDB (2)  Network & Security (16)  Concept (14)  Develop (1)  Keycloak (1)  Web_App (14)  Concept (2)  Develop (2)  API (1)  Nginx (6)  NodeJS (3)  Kotlin (0)  Operating System (61)  Concept (3)  Linux & Ubuntu (39)  MacOS (6)  Shell Script (13)  Language (123)  Python (77)  R (9)  C++ (19)  Scala (12)  Java (6)  Database (18)  Concept (4)  MySQL (2)  MongoDB (12)  Hardware (9)  Concept (5)  NVIDIA (3)  Coral (1)  Etc (24)  Colab (4)  Data Structure (2)  CS Tech Interview (1)  CS Term (10)  Paper (2)  Graphic (2)  Excel (2)  Etc (1)  Algorithm (178)  Concept (19)  Greedy (26)  Implementation (20)  Sliding Window (4)  Two Pointers (4)  Hash (3)  Sort (8)  Stack, Queue (8)  Heap (2)  Dynamic Programming (32)  Binary Search (8)  DFS (10)  BFS (9)  Shortest Path (7)  Graph (8)  String (1)  Backtracking (1)  Flood-Fill (2)  Maximum Flow (1)  Divide and Conquer (1)  Prime Number (1)  Prefix Sum (1)  Kakao (2)  SQL (7)  Basic (2)  JOIN \ GROUP BY (1)  Window Function (4)  일상 (1)  음악 (1) Guestbook오늘의 인기 글[Docker] Dockerfile 개념 및 작성⋯[Linux] 하드디스크 파티션 생성, 포맷, 마⋯[Docker] Docker run 옵션 종류최근 글[BigQuery] streaming buffer⋯Polling과 Pulling의 차이[Network] HTTP, HTTPS 및 SSL⋯최근 댓글도움이 되었습니다 ^^공감-댓글 작성 했습니다. 좋은 일이 있으시기를 기원합⋯Cool ~매우 공감되는 포스팅 입니다. 앞으로 자주 인사 드릴께⋯여기저기 찾아보고 있는데 제가 아는 linear reg⋯안녕하세요 해당 커멘드는 아래와 같이 실행하면 가능합니⋯업무하면서 cidr 개념이 뭔지 궁금했었는데, 잘 배웠⋯토큰생성 설명 감사 합니다. 새해 복 많이 받으십시오.응원드리고 갑니다~행복한 일요일 되셔요!정리 잘 되어있어서 이해하기 좋았습니다. 감사합니다글 잘 보았습니다. 도움이 많이 되었어요!!현재는 변경된 부분이 많습니다! (https://doc⋯감기 조심하시고, 항상 행복하세요!어떤 오류가 발생하셨는지는 모르겠지만, print(⋯earlystopping = EarlyStopping(⋯모델 성능평가 시 코드에 오류가 발생하는 부분이 있는데⋯잘 보고 갑니다. ^^helm helm chart 잘 보고 갑니다. 넵, 가능합니다~!안녕하세요, 포스팅에 사용하신 짱구 이미지를 개인 공부⋯최고의 설명입니다. 감사합니다좋은 글 잘보고 갑니다~~깔끔한 정리 잘보고 갑니다감사합니다~!#include <algorithm>  해야함.안녕하세요~!포트가 다르면 웹 애플리케이션 서버와 ⋯좋은 포스팅 잘 봤습니다!  Protocol, Host⋯jetson Nano의경우 Recovery모드로 들어가⋯유투브 플레이리스트로 짜서 올려주3잘보고 갑니다 :) 행복한 하루되세요!❤️ 누르고 갈⋯Today495Total2,208,192 #chart-time {font-size:11px; text-align:right; color:#999; padding-right: 15px;}08-13 15:14        am4core.ready(function() {            am4core.addLicense(""CH90809262"");            var chart = am4core.create(""chartdiv"", am4charts.XYChart);            chart.data = [{""timestamp"":""2024-08-07T00:00:00+09:00"",""count"":754},{""timestamp"":""2024-08-08T00:00:00+09:00"",""count"":887},{""timestamp"":""2024-08-09T00:00:00+09:00"",""count"":751},{""timestamp"":""2024-08-10T00:00:00+09:00"",""count"":287},{""timestamp"":""2024-08-11T00:00:00+09:00"",""count"":291},{""timestamp"":""2024-08-12T00:00:00+09:00"",""count"":798},{""timestamp"":""2024-08-13T00:00:00+09:00"",""count"":495}];            var values = chart.data.map(function(value){                return value.count            });            var minValue = values.reduce(function(acc, current) {                return Math.min(acc, current);            });            var maxValue = values.reduce(function(acc, current) {                return Math.max(acc, current);            });            chart.dateFormatter.inputDateFormat = ""yyyyMMdd"";            var dateAxis = chart.xAxes.push(new am4charts.DateAxis());            var valueAxis = chart.yAxes.push(new am4charts.ValueAxis());            dateAxis.renderer.grid.template.disabled = true;            dateAxis.dateFormats.setKey(""day"", ""dd"");            dateAxis.periodChangeDateFormats.setKey(""day"", ""dd"");            dateAxis.renderer.minGridDistance = 1;            dateAxis.fontSize = ""10.5px"";            dateAxis.color = ""#ff0000"";            dateAxis.opacity = 0.5;            valueAxis.opacity = 0.5;            valueAxis.fontSize = ""10.5px"";            valueAxis.paddingBottom = 5;            valueAxis.marginLeft = -20;            valueAxis.min = minValue < 0 ? 0 : minValue;            valueAxis.max = maxValue + 10;            var series = chart.series.push(new am4charts.LineSeries());            series.dataFields.valueY = ""count"";            series.dataFields.dateX = ""timestamp"";            series.tooltipText = ""{count}""            series.strokeWidth = 1;            series.minBulletDistance = 15;            series.tooltip.background.cornerRadius = 20;            series.tooltip.background.strokeOpacity = 0;            series.tooltip.pointerOrientation = ""vertical"";            series.tooltip.label.minWidth = 40;            series.tooltip.label.minHeight = 40;            series.tooltip.label.textAlign = ""middle"";            series.tooltip.label.textValign = ""middle"";            var bullet = series.bullets.push(new am4charts.CircleBullet());            bullet.circle.strokeWidth = 2;            bullet.circle.radius = 3;            bullet.circle.fill = am4core.color(""#fff"");        });닫기관리 메뉴글쓰기방명록RSS관리우노[Docker] Dockerfile 개념 및 작성법 본문DevOps/Docker[Docker] Dockerfile 개념 및 작성법운호(Noah)                           2020. 10. 6. 15:49     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }DockerfileDockerfile은 DockerImage를 생성하기 위한 스크립트(설정파일)이다.여러가지 명령어를 토대로 Dockerfile을 작성한 후 빌드하면Docker는 Dockerfile에 나열된 명령문을 차례대로 수행하며 DockerImage를 생성해준다.Dockerfile을 읽을 줄 안다는 것은 해당 이미지가 어떻게 구성되어 있는지 알 수 있다는 의미이다.Dockerfile의 장점(1) 이미지가 어떻게 만들어졌는지를 기록한다.보통 사람들은 완성된 이미지를 가져다 쓰기 때문에 이미지가 어떻게 만들어졌는지에 대해서는 알 필요가 없다.그러나 개발자의 경우라면 조금 다르다. 어떠한 애플리케이션을 담고 있는 이미지가 설치 되기 위한 과정은 어떠한지, 중간에 어떠한 과정을 수정해야 하는지 등을 알아야 하는 경우가 있다.예를 들어 raw한 상태의 우분투 이미지에서 자신이 원하는 애플리케이션을 담은 이미지를 만들어내기까지, 그 과정들을 기록하고 수정하며 바꿔나갈 수 있다는 것이다.이는 Dockerfile이 자동화된 스크립트 형태이기 때문이다.(2) 배포에 용이하다.어떠한 이미지를 배포할 때, 몇 기가씩이나 되는 이미지 파일 자체를 배포하기보다는 그 이미지를 만들 수 있는 스크립트인 Dockerfile만을 배포한다면 매우 편리할 것이다.사용자는 그 스크립트를 실행시키기만 하면 스스로가 그 Dockerfile에 해당하는 이미지를 얻을 수 있기 때문이다.실제로 Docker Hub에 가면, Dockerfile로 이미지를 배포하고 있는 사람들을 심심찮게 볼 수 있다. 물론 이미지로 배포하는 사람도 있지만.(3) 컨테이너(이미지)가 특정 행동을 수행하도록 한다.컨테이너 환경에서 애플리케이션을 개발하다 보면, 특정 행동을 취하도록 하는 컨테이너를(이미지를) 만들어야 할 때가 있다.이는 사실 말로서 설명하기는 좀 어렵고, 실제 개발을 하다보면 '아, 이거 Dockerfile 쓰면 좀 간단해 지겠구나...' 라는 생각이 머릿속에서 불현듯 번개처럼 스칠때가 있다.Dockerfile 작성 및 명령어Dockerfile을 작성 할 땐 실제 파일의 이름을 'Dockerfile'로 해야합니다.ubuntu에 아파치 서버를 설치하는 Dockerfile을 작성해보도록 하겠습니다.Dockerfile을 담을 디렉토리를 생성 한 후 Dockerfile을 생성합니다.  mkdir apache-dockerfile && cd apache-dockerfile  vi DockerfileDockerfile의 내용은 아래와 같습니다.  # server image는 ubunutu 18.04를 사용  FROM ubuntu:18.04   # Dockerfile 작성자  MAINTAINER Wimes <yms04089@kookmin.ac.kr>   # image가 올라갔을 때 수행되는 명령어들  # -y 옵션을 넣어서 무조건 설치가 가능하도록 한다.  RUN \      apt-get update && \      apt-get install -y apache2  # apache가 기본적으로 80포트를 사용하기 때문에 expose를 이용해 apache server로 접근이 가능하도록 한다.  EXPOSE 80   # 컨테이너가 생성 된 이후에 내부의 아파치 서버는 항상 실행중인 상태로 만들어준다.  # apachectl을 foreground(즉, deamon)상태로 돌아가도록 한다.  CMD [""apachectl"", ""-D"", ""FOREGROUND""]FROM : 베이스 이미지어느 이미지에서 시작할건지를 의미한다.MAINTAINER : 이미지를 생성한 개발자의 정보 (1.13.0 이후 사용 X)LABEL : 이미지에 메타데이터를 추가 (key-value 형태)RUN : 새로운 레이어에서 명령어를 실행하고, 새로운 이미지를 생성한다.RUN 명령을 실행할 때 마다 레이어가 생성되고 캐시된다.따라서 RUN 명령을 따로 실행하면 apt-get update는 다시 실행되지 않아서 최신 패키지를 설치할 수 없다.위 처럼 RUN 명령 하나에 apt-get update와 install을 함께 실행 해주자.WORKDIR : 작업 디렉토리를 지정한다. 해당 디렉토리가 없으면 새로 생성한다.작업 디렉토리를 지정하면 그 이후 명령어는 해당 디렉토리를 기준으로 동작한다.cd 명령어와 동일하다.EXPOSE : Dockerfile의 빌드로 생성된 이미지에서 열어줄 포트를 의미한다.호스트 머신과 컨테이너의 포트 매핑시에 사용된다.컨테이너 생성 시 -p 옵션의 컨테이너 포트 값으로 EXPOSE 값을 적어야한다.USER : 이미지를 어떤 계정에서 실행 하는지 지정기본적으로 root에서 해준다.COPY / ADD : build 명령 중간에 호스트의 파일 또는 폴더를 이미지에 가져오는 것ADD 명령문은 좀 더 파워풀한 COPY 명령문이라고 생각할 수 있다.ADD 명령문은 일반 파일 뿐만 아니라 압축 파일이나 네트워크 상의 파일도 사용할 수 있다.이렇게 특수한 파일을 다루는 게 아니라면 COPY 명령문을 사용하는 것이 권장된다.ENV : 이미지에서 사용할 환경 변수 값을 지정한다.path 등CMD / ENTRYPOINT : 컨테이너를 생성 및 실행 할 때 실행할 명령어보통 컨테이너 내부에서 항상 돌아가야하는 서버를 띄울 때 사용한다.CMD컨테이너를 생성할 때만 실행됩니다. (docker run)컨테이너 생성 시, 추가적인 명령어에 따라 설정한 명령어를 수정할 수 있습니다.ENTRYPOINT컨테이너를 시작할 때마다 실행됩니다. (docker start)컨테이너 시작 시, 추가적인 명령어 존재 여부와 상관 없이 무조건 실행됩니다.명령어 형식CMD [""<커맨드>"", ""<파라미터1>"", ""<파라미터2>""]CMD <커맨드> <파라미터1> <파라미터2>ENTRYPOINT [""<커맨드>"", ""<파라미터1>"", ""<파라미터2>""]ENTRYPOINT <커맨드> <파라미터1> <파라미터2>참고https://wooono.tistory.com/679생성한 Dockerfile을 Image로 빌드이미지 빌드 명령어  docker build -t [이미지 이름:이미지 버전] [Dockerfile의 경로]  docker build -t apache-image .생성된 이미지 확인  docker images웹에 띄울 html 파일 생성보통 웹으로 띄울 html 파일을 아파치 서버에 추가하고 싶을 땐Dockerfile의 ADD / COPY를 통해 호스트의 파일을 아파치 서버 옮기는 명령어를 작성 후 빌드합니다.하지만 이렇게 하면 호스트의 html 파일과 아파치 서버의 html 파일이 동기화 되어 있지 않기 때문에 매번 build를 해줘야합니다.우리는 그럴 시간이 없습니다.따라서 도커 볼륨을 사용해 호스트의 html 파일을 만들어놓고, 도커 컨테이너에서 그 파일에 접근해서 사용하는 방법으로 동기화 할 것입니다.우선 호스트에 index.html 파일을 생성 및 수정합니다.  cd ~  mkdir html && cd html  vi index.html  Hello worldImage로 Container를 생성이제 컨테이너 생성 시 도커 볼륨을 통해 host와 도커 컨테이너의 html 폴더를 동기화 하겠습니다.  docker run --name apache-container -d -p 80:80 -v ~/html/:/var/www/html apache-image--name : 컨테이너 이름-d : 백그라운드모드로 실행-p : [호스트포트][컨테이너포트] 포트 연결-v : 로컬과 컨테이너 파일 연동접속 확인Public DNS를 80번 포트로 접속해 접속을 확인합니다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//wooono.tistory.com/reaction';window.ReactionReqBody = {    entryId: 123}공유하기게시글 관리우노저작자표시 'DevOps > Docker' 카테고리의 다른 글[Docker] MySQL Container 실행 시 host db 볼륨 마운팅하기  (0)2020.11.18[Docker] Docker를 이용한 MySQL 설치 및 접속  (0)2020.11.08[Docker] AWS EC2에서 Docker를 이용한 Nodejs 웹서버 구축  (0)2020.10.04[Docker] AWS EC2에서 Docker를 이용한 Apache 웹서버 구축  (2)2020.10.03[Docker] Image 생성 및 삭제  (0)2020.07.16'DevOps/Docker' Related Articles[Docker] MySQL Container 실행 시 host db 볼륨 마운팅하기2020.11.18[Docker] Docker를 이용한 MySQL 설치 및 접속2020.11.08[Docker] AWS EC2에서 Docker를 이용한 Nodejs 웹서버 구축2020.10.04[Docker] AWS EC2에서 Docker를 이용한 Apache 웹서버 구축2020.10.03more0  Comments댓글쓰기 폼이름비밀번호                                              Secret                                          내용SendloadedComments[123]=true;findFragmentAndHighlight(123);Blog is powered bykakao / Designed byTistory//<![CDATA[// Lazy Load AdSensevar lazyadsense=!1;window.addEventListener(""scroll"",function(){(0!=document.documentElement.scrollTop&&!1===lazyadsense||0!=document.body.scrollTop&&!1===lazyadsense)&&(!function(){var e=document.createElement(""script"");e.type=""text/javascript"",e.async=!0,e.src=""https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"";var a=document.getElementsByTagName(""script"")[0];a.parentNode.insertBefore(e,a)}(),lazyadsense=!0)},!0);//]]>티스토리툴바우노구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4029591-123"",""customProps"":{""userId"":""0"",""blogId"":""4029591"",""entryId"":""123"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""123"",""entryTitle"":""[Docker] Dockerfile 개념 및 작성법"",""entryType"":""POST"",""categoryName"":""DevOps/Docker"",""categoryId"":""914837"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""4447808"",""authorNickname"":""운호(Noah)"",""blogNmae"":""우노"",""image"":"""",""plink"":""/123"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
107,https://manchann.tistory.com/16,[DL] 딥러닝 추론이란?,"본문 바로가기강카테고리검색하기검색하기Search강최재강글목록방명록About 분류 전체보기 (41)  AWS (13)  CLI (2)  S3 (3)  EC2 (2)  Lambda (6)  Inferentia (0)  GCP (9)  MS Azure (1)  AI (3)  Deep Learning (3)  Linux Command (3)  Github (4)  Python (5)  Algorithm (1)  Docker (2) Guestbook인기글[DL] 딥러닝 추론이란?[Github] 특정 폴더만 clone 받기Slack ChatGPT 연동하기[GCP] Cloud Storage Bucket ⋯최근에 올라온 글Tensorflow MLFlow 사용해보기Slack ChatGPT 연동하기[AWS Lambda] 서버리스 환경에서 ML 추⋯[AWS CLI] version 1에서 2로 up⋯최근에 달린 댓글안녕하세요 chatgpt api 연동 해보려고 하니 아⋯저는 오늘 실행해보고자 하는데 동일한 메세지가 나오네요⋯많은 도움 됐습니다 :)main.py 에서 아래처럼 변경하면 1:1 대화처럼 ⋯링크AboutGitHubLinkedIn«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Archives2023/06 (1)2023/01 (1)2022/08 (1)2022/05 (2)2021/12 (1)Today94Total65,296닫기관리 메뉴글쓰기방명록RSS관리강[DL] 딥러닝 추론이란? 본문AI/Deep Learning[DL] 딥러닝 추론이란?최재강                           2021. 9. 20. 02:49딥러닝은 크게 두가지 단계로 나눌 수 있다. 한가지는 대다수의 사람들이 알고 있는 학습(Training) 이다.학습과정의 특징은 축적된 많은 데이터를 바탕으로 각 신경망들의 Weight를 업데이트 해가며 딥러닝 모델을 만들어 가는 과정이다. 반면 추론(Inference)은 학습을 통해 만들어진 모델을 실제로 새로운 입력 데이터에 적용하여 결과를 내놓는 단계이다.학습과 추론 비교학습과 추론의 차이점을 조금 더 살펴보겠다.Training vs Inference그림에서 보면 알 수 있듯, 학습을 위해서는 많은 데이터가 필요하다. 그리고 그 데이터 들은 우선 순방향 전파를 통해 각 신경망을 거쳐가고 Loss function을 통해 에러율이 얼마나 되는지 판단하고, 그 에러율을 줄이기 위해 역방향 전파로 다시 신경망을 반대로 지나가면서 각 신경망의 Weight들을 바꾸는 것이다.하지만 모델을 만들어 가기 위한 학습과는 달리 추론의 목적은 현재 데이터에 대해서 해당 모델이 원하는 작업을 수행해 주는 것이다. 이미지 분류 모델의 예를 들면, 사람과 고양이를 분류하는 학습된 모델이 있다고 했을 때 단순히 내가 고양이 사진을 인풋 데이터로 넣으면 고양이라고 분류 해주면 되는 것이다. 따라서 추론 과정에서는 순방향 전파만이 일어난다. 또한 학습 과정에서는 모델이 데이터를 넣을 때 마다 Weight가 업데이트 되며 조금 씩 바뀌어 간다면 추론 과정에서는 인풋 데이터를 어느 정도 넣는 지 상관 없이 모델의 Weight는 고정적이다. 한마디로 해당 모델이 고양이 분류를 5%의 오차율로 수행했다면 같은 데이터에 대해서 다음번에도 5%의 오차율로 수행할 것이라는 것이다.그렇다면 실제 학습과 추론 작업을 수행할 때 어떤 차이점이 있을까?학습은 추론에 비해 많은 데이터를 바탕으로 훨씬 긴 시간에 걸쳐 진행되며 여유로운 데드라인을 가지고 진행될 것이다. 반면 추론작업은 실제로 사용자가 해당 모델에 원하는 사항을 요구하고 그것을 실시간으로 수행하는 서비스에 활용된다. 따라서 사용자에 훨씬 직면에 있는 작업이며 작업이 실시간으로 대응 되어야 하고 사용자가 원하는 시간과 요청 개수에 맞추어 대응해야 한다. 실시간으로 대응해야 한다는 것은 요청이 어떤 경우에는 적게 들어오고 어떤 경우에는 폭발적으로 늘어날 수 있다는 것을 의미한다.내가 좋아하는 NBA 농구 선수인 스테판 커리를 예로 들며 학습과 추론 비교를 마무리 하겠다.스테판 커리 3점슛을 성공하다스테판 커리는 3점슛을 잘쏘는 선수로 유명하다. 그는 농구 시합이 없을 때에도 수만번의 3점슛을 다양한 각도, 위치(많은 데이터셋)에서 던질 것이다(순방향 전파). 그리고 던질 때마다 들어가는 슛과 들어가지 않는 슛이 있을 것이고 들어가지 않는 슛을 보완하기 위해 슛 쏘는 자세를 교정하며(역방향 전파) 열심히 슛을 더 쏠 것이다.그렇게 연습을 한 스테판 커리는 팀의 승리를 책임지기 위해 다소 위험한 상황에 놓였다. 팀이 101: 103 2점차로 지고 있는 상황에 경기 시간은 4초 밖에 남지 않은 것이다. 그 상황에서 타임 아웃을 부른 감독은 스테판 커리에게 이렇게 얘기한다 ""4초 안에 3점슛을 넣어줘"". 감독의 주문(사용자의 요구 사항)을 들은 스테판 커리는 어느 위치, 각도에서건 감독의 요구에 맞추기 위해 그동안 연습해온 슛을 바탕으로 3점슛을 시도하고 성공하거나 실패할 것이다(추론 결과). 이것이 딥러닝의 추론 과정이라고 볼 수 있다. 사용자의 요구에 맞추어 원하는 작업을 수행하는 것, 그것이 딥러닝의 추론 작업의 특징이다.사용자의 요구사항 : SLO앞선 내용에서 언급했듯 추론에서는 사용자의 요구 사항을 충족하는 것이 중요하다. 딥러닝 추론에 관련된 여러 논문들을 읽어보면 SLO 혹은 SLA라는 단어를 많이 사용하는 것을 볼 수 있다. SLO란 Service Level Objectives를 줄인말이며 말 그대로 서비스 단에서 충족해야할 목적이라고 해석하면 된다. 참고로 SLA는 Servcie Level Agreement로 비슷한 뜻을 가진다. 보통 SLO를 주로 쓰는 듯 하다.SLO에 대한 예시를 하나 들어보겠다.다양한 Varient와 사용자의 요구사항위 그림에서 Table2는 3종류의 추론 작업을 돌릴 수 있는 Varient 즉, 선택할 수 있는 가짓수를 나타낸다. Variant A, B, C는 각각 서로 다른 하드웨어,프레임워크로 구성되어 있으며 각 Variant별로 처리하는 대에 걸리는 Latency와 Request수, 드는 비용인 Cost가 명시되어 있다. 예를 들어 Variant A는 5개의 요청을 200ms에 1달러를 소모하며 수행하는 것이다.Table3은 서로 다른 사용자의 요구사항에 맞는 적절한 추론 옵션을 선택하는 시나리오를 보인다. QPS는 처리해야할 쿼리의 수를 의미하고 SLO는 제한 시간을 의미한다. 이 논문에서는 SLO를 처리 시간으로 설정해두었지만 정확도 또한 SLO에 속할 수 있다는 것을 기억해두자. 따라서 첫번 째 경우인 QPS 10, SLO 300ms의 경우 Variant A를 2개 사용하여 처리하는 것이 가장 효율적임을 알 수 있다. 왜냐하면 Variant B나 C를 사용하면 더 빨리 처리할 수 있었겠지만, 그에 따라서 Cost가 증가했을 것이고 SLO가 300ms로 다소 넉넉했기 때문이다.그러면 같은 QPS양에서 SLO가 50ms로 제한된 경우를 살펴 보자. 이 경우 Variant A를 사용할 수는 없을 것이다. 왜냐하면 SLO 요구 조건을 충족할 수 없기 때문이다. 따라서 Variant B 1개로 해당 요구를 수행하는 것이 가장 효율적이다. Variant C를 사용했다면 Cost가 16으로 훨씬 비싸게 수행하는 것이기 때문이다. 이번엔 마지막으로 QPS가 1000으로 많아진 상황을 살펴보자. 이 경우에는 Variant B 2개, Variant C 1개를 사용하여 수행하는 것이 가장 효율적이라고 명시되어 있다. 이 경우 QPS가 높기 때문에 Variant A를 선택하는 것은 비효율적일 것이고 Cost가 비싸지만 처리 가능한 Request수가 많은 Variant C를 1개, 남은 QPS를 Variant B로 처리하는 경우가 가장 효율적이다.이처럼 사용자의 요구사항에 따라서 가지고 있는 하드웨어, 프레임워크, 딥러닝 모델 등의 옵션이 달라짐을 알 수 있고 요구사항에 맞게 효율적인 옵션을 선택하는 것이 중요하다. 위의 경우에서 정확도 등의 요구 사항이 더 추가된다면 조금 더 선택하기에 복잡해질 것이다. 따라서 현재 딥러닝 추론 분야는 미리 선택될 수 있는 Varient들을 정리해두고 이를 시스템적으로 최적화하여 SLO에 알맞은 Variant를 자동적으로 선택할 수 있도록 시도하는 연구가 활발히 진행되고 있다.하드웨어 가속기앞서 추론을 수행하는 데에 다양한 Varient 중 하드웨어가 관여하는 것을 보았다. 실제로 딥러닝 추론 분야에서는 프레임워크, 데이터의 사이즈, 모델의 종류 등 다양한 요소가 성능에 관여하지만 대표적으로 하드웨어를 선택하는 것이 가장 우선으로 꼽힌다.CPU와 GPU 그리고 TPUCPU, GPU, TPUCPU와 GPU는 대표적인 추론 하드웨어로 사용된다. 추론에서의 CPU는 상대적으로 값싼 비용에 범용적으로 모델들을 문제 없이 처리할 수 있다는 장점이 있다. 밑에서 다룰 다른 하드웨어 가속기의 경우 지원하지 않는 모델들이 있는 경우도 있기 때문에 범용성 또한 장점으로 잡을 수 있다. 하지만 값이 싼 만큼 처리량이 다소 떨어지며 이는 인풋 데이터의 배치 사이즈가 커질 수록 단점이 두드러진다. GPU의 경우 CPU보다 비싸지만 높은 처리량을 가지고 이는 특히 인풋 데이터의 배치 사이즈가 커질 수록 장점으로 작용한다. 따라서 SLO 중 처리 시간이 엄격한 경우 CPU보다 사용하기에 적합하다.아래 그림은 딥러닝 추론에서 유명한 MArK 논문(https://www.usenix.org/conference/atc19/presentation/zhang-chengliang)에서 가져왔다. 딥러닝 추론 실시간 서비스를 시스템적으로 구축해놓은 논문이니 참고해보아도 좋을 듯 하다.CPU, GPU, TPU batchsize별 추론 성능 비교MArK에서는 CPU, GPU, TPU에서 배치 사이즈를 증가해보며 추론 작업을 해본 결과를 그래프로 나타낸 것이다. TPU는 Google에서 지원하는 하드웨어 가속기이다.실험 결과를 살펴보면 배치 사이즈가 낮을 때에는 비슷한 처리 시간을 가지는 반면 비용은 CPU가 가장 저렴하여 효율적임을 보인다. 하지만 배치 사이즈가 증가 할수록 GPU가 처리시간이 앞서고 처리 시간이 빠른 만큼 하드웨어가 쓰이는 시간이 적기 때문에 비용면에서도 효율적임이 두드러 진다. TPU의 경우 GPU보다 처리 시간이 비슷하거나 더 느린 반면 비싼 비용이 드는 것으로 보아 가장 비효율적인 하드웨어 가속기로 논문에서는 보였다. 논문에서는 아직까지 Google TPU는 추론보다는 학습에 적합한 하드웨어라고 설명을 하고 있으나 추후 발전될 여지가 보인다.AWS EIA, AWS Inferentia클라우드 서비스로 유명한 AWS에서도 딥러닝 추론을 위한 하드웨어 가속기 서비스를 제공한다.EIA는 Elastic Inference Accelerator의 줄임말로 평소 CPU기반으로 컴퓨팅 작업이 이루어 지다가 추론 작업을 대상으로만 네트워크 통신을 통해 GPU기반의 EIA가 추론 작업을 하고 결과 데이터를 CPU에 전달한다. EIA별로 medium, large, xlarge로 type이 정해져 있고 다수의 EIA 하드웨어를 한번의 추론 작업 시나리오에 사용할 수 있어 다양하게 추론 작업에 사용할 수 있다. 추론 작업에 EIA를 이용하도록 하기 위해 EIA 전용 SDK를 AWS에서 제공하고 있으며 EIA를 호출하는 SDK의 함수를 통해 쉽게 추론 작업을 수행할 수 있다.CPU와 EIA의 네트워크 통신AWS Inferentia는 Neuron Chip이라고 하는 GPU기반 하드웨어를 AWS 전용 인스턴스에서 제공한다. Neuron Chip으로 추론 작업을 수행하기 위해서는 EIA와 마찬가지로 AWS에서 제공하는 SDK를 활용해야 한다. EIA와 다른 점은 EIA는 단순히 기존 CPU에서 수행하던 모델로 함수한 호출하면 되지만, Inferentia의 경우 Neuron Chip으로 추론할 수 있도록 모델을 컴파일 해야한다. 따라서 CPU에서 수행하던 모델을 컴파일 하는 과정에서 Neuron Chip이 지원하지 않는 Layer가 포함되어 있을 경우 사용에 제약을 받을 수 있다. 이러한 제약에도 Inferentia가 가치 있는 이유는 CPU보다는 처리량이 빠르고 GPU보다는 가격적으로 저렴한 중간 위치에 있기 때문이다.AWS EIA, AWS Inferentia 모두 비교적 최근에 발표된 하드웨어로 연구를 해볼 가치가 있는 하드웨어이고 연구 결과에 따라서 추론 시스템에 도입해볼 여지가 있다. 앞으로가 기대되는 하드웨어들이다.이외에도 Nvidia에서 다양한 하드웨어를 제공해 주고 있으며 하드웨어 말고도 프레임워크(Tensorflow, Pytorch, TensorRT, MxNet 등)와 딥러닝 모델 종류 등 고려해볼 다양한 선택 요소들이 존재한다.마무리딥러닝 추론 분야는 학습 분야에 비해 비교적 적은 연구가 이루어 졌고 최근 딥러닝을 실시간으로 서비스화 하면서 필요성이 많아진 분야이다.딥러닝 학습과 추론에서 드는 비용 AWS에서는 딥러닝 학습단계에 비해 추론단계에서 전체 비용의 90%가 든다고 하고 다른 회사에서도 점점 딥러닝 추론 분야에 대한 중요성을 인식하는 중이다. 딥러닝 추론의 실시간 서비스에서 가변적인 요청량들을 어떻게 효율적으로 처리할 것인지에 대해 지금도 여러 연구가 진행되고 있다. 사용자와 밀접한 위치에서 만족도 높은 서비스를 제공하기 위해 발전시키는 것이 정말 매력적인 분야이다. 참조https://lifeisenjoyable.tistory.com/7https://arxiv.org/abs/1905.13348?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+arxiv%2FQSXk+%28ExcitingAds%21+cs+updates+on+arXiv.org%29https://overface.tistory.com/542#https://www.usenix.org/conference/atc19/presentation/zhang-chenglianghttps://towardsdatascience.com/a-complete-guide-to-ai-accelerators-for-deep-learning-inference-gpus-aws-inferentia-and-amazon-7a5d6804ef1chttps://www.intel.co.kr/content/www/kr/ko/artificial-intelligence/posts/deep-learning-training-and-inference.htmlhttps://developer.nvidia.com/blog/inference-next-step-gpu-accelerated-deep-learning/https://www.hellot.net/news/article.html?no=52620window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//manchann.tistory.com/reaction';window.ReactionReqBody = {    entryId: 16}공유하기게시글 관리강저작자표시 'AI > Deep Learning' 카테고리의 다른 글Tensorflow MLFlow 사용해보기  (0)2023.06.26[DL] Keras로 imagenet 모델 save(저장), load(불러오기)  (0)2021.10.01TagAWS EIA, AWS Inferentia, CPU, GPU, Inference, Slo, 딥러닝, 딥러닝 추론, 딥러닝 학습, 하드웨어'AI/Deep Learning' Related ArticlesTensorflow MLFlow 사용해보기2023.06.26[DL] Keras로 imagenet 모델 save(저장), load(불러오기)2021.10.01more4  Comments    setInitialEntryComments(16, 1723623958)댓글쓰기 폼이름비밀번호                                              Secret                                          내용SendloadedComments[16]=true;findFragmentAndHighlight(16);Blog is powered bykakao / Designed byTistory티스토리툴바강구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4336022-16"",""customProps"":{""userId"":""0"",""blogId"":""4336022"",""entryId"":""16"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""16"",""entryTitle"":""[DL] 딥러닝 추론이란?"",""entryType"":""POST"",""categoryName"":""AI/Deep Learning"",""categoryId"":""1229749"",""serviceCategoryName"":""과학"",""serviceCategoryId"":404,""author"":""4651878"",""authorNickname"":""최재강"",""blogNmae"":""강"",""image"":""kage@dspFH4/btrfpsIYHs2/ekOoKY0DhGloYhriaGrkfK"",""plink"":""/16"",""tags"":[""AWS EIA"",""AWS Inferentia"",""CPU"",""GPU"",""Inference"",""Slo"",""딥러닝"",""딥러닝 추론"",""딥러닝 학습"",""하드웨어""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
108,https://lee-soohyun.tistory.com/10,머신러닝 잡다 정보,"본문 바로가기Soohyun’s Machine-learning카테고리검색하기검색하기SearchSoohyun’s Machine-learningAlex_Rose 분류 전체보기 (86)  Machine Learning (43)  Math & Stats (12)  ML_Math (1)  misc (15)  PRML (7)  Natural Language Processing (2)  Lectures (18)  Algorithms (1)  Data structure and Analysis (1)  Machine Learning Basic (3)  CS224N (NLP) (1)  CS231N (ML basic) (6)  CS50 (CS base) (3)  Fundamentals_of_Computer_Scien.. (1)  Review of Papers (6)  Daily routine (6)  Study English (11)  Ringle (6)  Mom-Eng (0)  Articles (1)  Lingua Latina (라틴어) (0)  Motivation for me (0)  Kaggle (1) GuestbookNoticeRecent Posts[C++코테] 시간복잡도(Time Complexi⋯링글에서 글로벌 커리어 컨퍼런스를 개최합니다.링글, 개인적인 활용법들 (+5만 포인트)[Ringle/링글] 영어를 당당하게 대하기 (f⋯Recent Comments댓글 감사합니다 ^_^댓글 감사합니다 :)안녕하세요. 혹시 해당 이슈에 도움이 될지는 모르겠지만⋯안녕하세요. model.eval() 단계에서 input⋯Link«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags해외취업컨퍼런스#체험수업링글경험담#링글화상영어#영어공부강동구장어맛집#영어발음교정링글리뷰성내동장어링글커리어뉴노멀챌린지스몰토크영어로전세계와소통하기링글Ringle영어회화#직장인영어#링글후기총각네장어소통챌린지장어랑고기같이둔촌역장어영어공부영어시험#nlpCommunicateWiththeWorld오피스밋업영어공부법#RinglemoreArchives2024/07 (1)2024/03 (1)2024/02 (1)2023/08 (1)Today6Total69,302닫기관리 메뉴글쓰기방명록RSS관리Soohyun’s Machine-learning머신러닝 잡다 정보 본문Machine Learning/misc머신러닝 잡다 정보Alex_Rose                           2017. 10. 9. 11:30- 머신러닝 학습 모델의 특성상, 모델을 그래프로 정의하고, 세션을 만들어서 그래프로 실행하고, 세션이 실행될 때 그래프에 동적으로 값을 넣어가면서(피딩, feeding) 실행한다는 기본 개념을 잘 이해해야 텐서플로 프로그래밍을 제대로 잘 할 수 있다.- 사이즈가 window size인 이유 : 주변 단어를 몇 개를 ""본다""는 뜻이기 때문에. window 크기로 슬라이딩하면서 스크린하며 중심 단어들로 주변 단어들을 보고 각 단어에 해당하는 벡터들의 요소값들을 조금씩 업데이트하면서 단어를 벡터로 임베딩- 아타리 퐁 게임을 어떻게 학습시키는지를 알려주는 카파시(Karpathy - yup! cs231n의 그 사람!) http://karpathy.github.io/2016/05/31/rl/http://karpathy.github.io/- nadam의 뜻Gradient를 수정한 Momentum, NagLearning Rate를 수정한 Adagrad, RMSProp, AdaDelta이 두 종류의 장점을 합한, Adam, Nadam이 있다.  y-intercept : y절편convention : 일종의 약속, 관습w.r.t : with repect toresidual : 잔차 흔히 eval이라고 되어 있는데, evaluation의 약자임 stddev  - standard deviation, 표준 편차Collections 모듈의 deque 클래스 : double-ended queue. 큐의 처음과 끝에서 아이템을 삽입하거나 삭제할 때 항상 일정한 시간이 걸리는 연산 제공 텐서플로의 flags가 뭐하는 애냐 : http://daeson.tistory.com/256  - weight initialization에서 활성화 함수로 ReLU를 사용할 때는 He initialization, Sigmoid나 tanh 등의 S자 모양 곡선일때는 Xavier initialization 사용... 이라고 하는데, 또 찾아본 결과에서는 Xavier Glorot (+he) = Glorot Gaussian을 쓴다고 함. 이걸 Xavier initialization이라고도 하고, Glorot initialization이라고도 함. Glorot initialization (사진 출처 : http://www.khshim.com/archives/641)2015년 he가 제안한 다른 weight initialization 이걸 넣고 PReLU를 넣으면 좋다-라고 함.. Backpropagation : output에서부터 순차적으로 partial derivative (편미분)을 수행하면서 weight과 bias 갱신regularization을 왜 하나? local noise나 outlier가 학습에 큰 영향을 끼치지 않게 하려고 L1과 L2의 차이는? L1은 통상적으로 상수값을 빼주도록 되어 있어서 작은 가중치들은 거의 0으로 수렴하고, 몇 개의 중요한 가중치들만 남음. 몇 개의 의미있는 값을 꺼내고 싶으면 L2 reg를 쓰는게 좋다. sparse model 에 적합함.  cross-entropy (negative log likelihood 라고도 함)는 2개의 확률 분포의 차이를 나타내는 용도. 두 개의 확률 분포가 얼마나 가깝냐 머냐를 나타낸다. 차이가 클수록 큰 값, 같아질수록 작은 값이 나오는데, 이게 cost function처럼 사용할 수 있는 이유이다. 항상 양의 값이 나온다.  텐서플로우의 variable scope : 변수명끼리의 이름 충돌을 방지함 ReLU : ramp function이라고도 함. fully connected layer = dense layer decision boundaries : 결정 경계 piecewise linear : 부분적으로 선형 squash : 제한시키다, 짓누르다 Leaky ReLU는 dying ReLU 현상을 해결하기 위해 제시된 함수이다. ReLU는 x < 0 일 경우 항상 함수값이 0이라서 뉴런이 으앙 쥬금 ㅠ  Mean Subtraction : 데이터의 모든 feature 마다 평균으로 나누며, 기하학적으로 zero-centered 데이터로 만드는 과정 (preprocessing) 이미지 처리 분야에서는 평균 이미지를 빼거나, 3개 채널 각각 평균을 구해서 각 채널별로 평균을 빼서 전처리를 한다.  principal component analysis, PCA : 주성분 분석(여기 글에 있는 PCA, whitening은 무슨 뜻이지?)중간의 decorrelated data가 PCA를 적용한 것이라고 함. 데이터들이 모두 zero-centered 되어 있고 데이터의 covariance Matrix (공분산 행렬)의 eigenbasis로 회전된 것을 볼 수 있다. (covariance 행렬이 diagonal - 사선의, 대각선의 - 된 상태). 오른쪽은 eigenvalue (고유값) 에 의해 추가적으로 scale 되었으며, 데이터의 covariance matrix 가 indentity matrix (단위행렬) 로 변환된다.correlation coefficient : 상관계수  Bagging (Boostrap aggregating) : 여러개의 모델을 혼합하여 일반화 에러 (generalization error) 를 줄일 수 있는 방법. 서로 다른 모델들을 각자 트레이닝 시키고, 이 모델들로부터 생성되는 결과값을 투표를 통해 최종 결과값으로 선출하는 방법 linear classifier 의 문제점은 각종 카테고리별로 1개의 필터 밖에는 사용할 수 없다는 점이다.VISION- open CV는 BGR로 color 체크. 알파값이 들어가는 건 영상물일 때  sendex의 openCV 강의 영상https://www.youtube.com/watch?v=Z78zbnLlPUA&list=PLQVvvaa0QuDdttJXlLtAJxJetJcqmqlQqNLP  - Natural language processingNLP : Zipf's lawlemmatization : 단어의 어근에 기반하여 단어의 기본형(lemma)을 찾아준다. ex) play, playing, played -> play언어마다 중요한 부분이 다르다. 한국어 : 동사   // 영어 : 명사, 형용사collocation (연어) : 문장내에서 유의미하게 사용되는 조합. ex) 양말을 입다 (x) -> 양말을 신다 (o)  command 용어 중에서 cd = current directory디렉토리 이동시에 쓰는 cd = change directorycmd에서 del 파일명  <- 이렇게 하면 파일이 삭제됨window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//lee-soohyun.tistory.com/reaction';window.ReactionReqBody = {    entryId: 10}공유하기게시글 관리Soohyun’s Machine-learning 저작자표시 비영리 동일조건 'Machine Learning > misc' 카테고리의 다른 글용어 이해  (0)2017.10.13신경망 뼈대 구축하기  (0)2017.10.13머신러닝 자료 링크들  (0)2017.10.09신경망에 대해 이해한 것  (0)2017.09.20텐서플로 GPU / 윈 10 설치  (0)2017.09.17공유하기 링크페이스북카카오스토리트위터'Machine Learning/misc' Related Articles용어 이해2017.10.13신경망 뼈대 구축하기2017.10.13머신러닝 자료 링크들2017.10.09신경망에 대해 이해한 것2017.09.20more0  Comments댓글쓰기 폼이름비밀번호                                              Secret                                          내용SendloadedComments[10]=true;findFragmentAndHighlight(10);Blog is powered bykakao / Designed byTistory티스토리툴바window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2810738-10"",""customProps"":{""userId"":""0"",""blogId"":""2810738"",""entryId"":""10"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""10"",""entryTitle"":""머신러닝 잡다 정보"",""entryType"":""POST"",""categoryName"":""Machine Learning/misc"",""categoryId"":""710435"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""33408"",""authorNickname"":""Alex_Rose"",""blogNmae"":""Soohyun’s Machine-learning"",""image"":""cfile3.uf@9969A23359DB0443038181.png"",""plink"":""/10"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
109,https://11111economy.tistory.com/entry/%ED%97%AC%EC%8A%A4%EC%9E%A5-%EC%9D%B8%ED%8F%AC-%EC%95%8C%EB%B0%94-%ED%9B%84%EA%B8%B0-%EC%97%AC%EC%9C%A0-%EC%8B%9C%EA%B0%84-%EB%A7%8E%EC%9D%80-%EC%95%8C%EB%B0%94-%EC%B6%94%EC%B2%9C,1) 청소,"                                                  만두국 블로그                              홈부수입으로 1년에 천만원 모으기경제 용어 사전 A to Z💰만잡러/👷알바 경험담헬스장 인포 알바 후기, 여유 시간 많은 알바 추천만두국2022. 3. 12. 23:53     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }728x90반응형(adsbygoogle = window.adsbygoogle || []).push({}); 헬스장 인포 알바를 꽤 길게 했다. 세 군데에서 일했고, 모두 주말 알바로 총 2년 정도 일했다. 헬스장 알바는 본인의 시간이 많이 필요한 분들, 단순 노동 알바가 잘 맞는 분들께 추천한다. 그 자세한 이유를 아래에 설명드리고자 한다. 하는 일 우선 헬스장 인포 알바는 어떤 일을 하는지 알아보자. 1) 청소 이름은 헬스장 인포 알바지만, 실제로는 청소 일이 대부분이다. 런닝머신 등 기구 닦기, 바닥 청소, 창틀 닦기 등등...  골프장, 샤워실이 함께 있는 헬스장도 있는데, 그러면 청소할 공간이 더 늘어난다고 보면 된다. 실내골프장바닥, 거울 등 청소해야 하고, 샤워실은 물청소도 하고 머리카락도 버려야 한다.  2) 세탁 헬스장 중에 운동복을 대여해주는 헬스장이 있다. 이런 경우 세탁기에 운동복을 넣어 세탁하고, 빨래 건조대에 널어야 한다. 그 다음 건조된 옷을 잘 개어서 넣어야 한다.  3) 고객 응대 및 회원 등록 고객 응대는 회원님들이 문의하는 사항에 답하면 된다. '인바디 기계 작동하는 건가요?', '언제 오픈해요?/언제 마감해요?', '러닝머신 tv 안 나오는데 어떻게 해야 하나요?' 등등... 간단한 질문들이다. 기계는 껐다 켜보고 정 안 되면 사장님께 말씀드려서 해결책을 찾으면 된다.   그리고 회원등록도 해야 한다. 내가 일한 곳들은 생각보다 회원 등록을 할 일은 거의 없었다. 회원 등록을 한다면 개인정보를 헬스장 전산 시스템에 등록하면 된다.(adsbygoogle = window.adsbygoogle || []).push({});  시급과 근무시간 지금까지 3군데에서 일했는데, 모두 최저시급을 받았다. 근무시간은 모두 달랐다. 나는 주말에만 근무했는데 오전 6시부터 오후 6시까지 일하는 곳도 있었고, 오전 10시부터 1시까지만 일하는 곳도 있었다.  장점 & 단점 장점 일이 단순하고 어렵지 않다. 위에서 알 수 있듯이 일은 정말 간단하다. 대부분이 청소라 매일 반복하는 일이고, 고객 응대도 많이 하지 않아서 내성적인 성격이라도 충분히 일할 수 있다.  또한 본인의 할 일을 다 하고 나면, 인포에 앉아서 자기 공부/할 일을 해도 된다. 대부분 청소, 세탁 일이라 일이 익숙해지면 속도가 빨라진다. 청소, 세탁을 마치면 그러면 인포에 그냥 앉아서 자기 할일을 해도 된다. 인포에 앉아 있다가 고객님들이 문의하는 사항에 답하면 된다. 나는 4시간 근무였는데 1시간 반 일하고 나머지 시간은 전자책 읽은 적도 많다. 그래서 수험 공부(공무원 시험 등), 대학생들에게 정말 추천한다. 또는 여유 시간이 필요한 분들께 적극 추천한다.   진상이 거의 없다는 것도 장점이다. 대부분 그냥 운동만 하고 가기 때문에 진상 부릴 일이 거의 없다. 게다가 귤이나 과자 챙겨주시는 분들도 계셨다. 너무 감사했다. ㅎㅎ(adsbygoogle = window.adsbygoogle || []).push({});단점 돌발 상황이 가끔 있는데, 이 때 차분하게 대처해야 한다. 밖에서 헬스장 유리창을 깬 사람을 본 적 있다. 어떤 아기가 아파트 커뮤니티 센터에서 아빠를 잃어버려서 헬스장에 도와달라고 온 적도 있다. 가장 심한 건 누가 샤워실 바닥에 똥 싸고 간 것이다. ㅡㅡ 내가 그 똥 치움... 이런 갑작스러운 일이 생기면 그냥 침착하게 대처하면 된다. 참고로 저런 일은 정말 흔치 않은 일이고 앞서 말했듯이 헬스장은 진상이 거의 없다! 다른 알바와 비교해봤을 때 진상이 극히 적다.   그리고 코로나 시국, 그중에서도 여름이면 더 힘들 수 있다. 운동을 하다보면 더워서 마스크를 벗은 상태로 운동하는 사람이 꽤 있기 때문이다.  나는 코로나19가 막 시작되었을 때에도 헬스장에서 알바를 하고 있었다. 일단 열 체크 안 하는 사람도 많고다. 이건 그래도 그럴 수 있는데, 더 힘든 건 마스크를 계속 벗고 있는 사람이다. 운동을 하다보면 몸에 땀이 많아지고, 마스크를 벗고 있는 사람이 있다. 잠깐 벗는게 아니라 계속 벗고 있는 것이다..^^  이런 경우 다른 회원들에게 컴플레인이 계속 들어온다. 그래서 제재를 하는데, 좋게 말씀을 드려도 되려 나에게 신경질을 부리거나 화를 내는 사람이 몇몇 있었다. ^^; 이 글을 읽고 있는 시점에 아직 코로나가 안 끝난 시점에서 헬스장 알바를 한다면... 이 부분을 어느 정도 감수해야 한다.   끝![함께 읽으면 좋은 글] 음성 녹음 알바, 초간단 꿀알바 후기여태까지 여러 가지 부업, 아르바이트를 해왔다. 부업이나 단기 알바로 돈을 벌고 싶은 분들이 계실 것 같아서 내 경험담이 조금이나마 도움되길 바라며 글을 쓰게 되었다. 오늘은 그 중에서 음11111economy.tistory.com 셀렉트스타 알바, 1시간 일하고 29,000원 버는 이색 알바약 1시간 정도 일하고 29000원을 버는 알바가 있다면?  이건 나의 실제 경험담이다. 정확히는 한 회사에서 2개의 단기 알바를 한 것이다. 하나는 약 40분에 2만원, 나머지 하나는 20분에 9000원 벌었11111economy.tistory.com 유동인구 조사 알바, 카페에 앉아서 숫자 세고 돈 벌기?글을 읽기 전, 아래 4가지를 체크해보자. 시급이 높은 알바를 해서 목돈을 벌고 싶은 분 단순 반복 일이 잘 맞는 분 앉아서 일하고 싶은 분 투잡으로 단기 아르바이트를 해서 용돈 벌고 싶은 분들11111economy.tistory.com[부수입 정보 모아보기] '💰부수입' 카테고리의 글 목록만두국의 돈 복사기 만들기 프로젝트 저축 / 투자 / 절약11111economy.tistory.com 728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//11111economy.tistory.com/reaction';window.ReactionReqBody = {    entryId: 37}공유하기게시글 관리만두국 블로그저작자표시 비영리 변경금지 '💰만잡러 > 👷알바 경험담' 카테고리의 다른 글휴먼미디어테크 알바, 1시간 반 정도 단어 말하고 35,000원 벌기?  (0)2022.10.22시험 진행요원 알바 후기, 강력추천 꿀알바  (0)2022.10.18유동인구 조사 알바, 카페에 앉아서 숫자 세고 돈 벌기?  (1)2022.03.09셀렉트스타 알바, 1시간 일하고 29,000원 버는 이색 알바  (0)2022.03.08음성 녹음 알바, 초간단 꿀알바 후기  (0)2021.12.10'💰만잡러/👷알바 경험담'의 다른글이전글유동인구 조사 알바, 카페에 앉아서 숫자 세고 돈 벌기?현재글헬스장 인포 알바 후기, 여유 시간 많은 알바 추천다음글시험 진행요원 알바 후기, 강력추천 꿀알바관련글휴먼미디어테크 알바, 1시간 반 정도 단어 말하고 35,000원 벌기?2022.10.22시험 진행요원 알바 후기, 강력추천 꿀알바2022.10.18유동인구 조사 알바, 카페에 앉아서 숫자 세고 돈 벌기?2022.03.09셀렉트스타 알바, 1시간 일하고 29,000원 버는 이색 알바2022.03.08loadedComments[37]=true;findFragmentAndHighlight(37);반응형(adsbygoogle = window.adsbygoogle || []).push({});만두국 블로그평범한 20대 1억 모으기, 내 집 마련하기* 문의 : 11111.economy.11111@gmail.com만두국 블로그구독하기글쓰기블로그 관리공지사항티스토리 외 다른 SNS에서도 콘텐츠 보기 분류 전체보기 (323)  💡생각 (34)  🎁목표 → 실천 (23)  💰경제 (19)  🏡부동산 투자 (32)  📈주식 투자 (30)  🆙 예금, 적금 (15)  🚩연금, 보험, 대출 (7)  🧂절약 (36)  🍚식비 절약 (25)  절약 정보 (13)  💸세테크 (0)  💰만잡러 (42)  👷알바 경험담 (13)  📱앱테크 (17)  ⭐중고 거래 (4)  ✍블로그 (2)  📚독서 (21)  📗부동산 투자 책 (2)  🚮 비우기 (23)  🔠 토익 스피킹 바짝 공부 (6)  🧧가계부 (2)  👟운동 (13)  🍵카페 공부 (4)  📄 서류 발급 (1)       (adsbygoogle = window.adsbygoogle || []).push({});      (adsbygoogle = window.adsbygoogle || []).push({});250x250Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tag미니멀리즘,공부,챌린지,절약,부수입,부동산공부,앱테크,짠테크,학습,부동산투자,부동산,생활비절약,앱테크추천,빡공단,식비절약,스터디,재테크,베어유,부업,자기계발,페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk'));       (adsbygoogle = window.adsbygoogle || []).push({});블로그 내 검색Copyright © Kakao Corp. All rights reserved.관련사이트트위터티스토리툴바만두국 블로그구독하기                    (function () {                         var blogTitle = '만두국 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""4356995-37"",""customProps"":{""userId"":""0"",""blogId"":""4356995"",""entryId"":""37"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""37"",""entryTitle"":""헬스장 인포 알바 후기, 여유 시간 많은 알바 추천"",""entryType"":""POST"",""categoryName"":""💰만잡러/👷알바 경험담"",""categoryId"":""979709"",""serviceCategoryName"":""경제"",""serviceCategoryId"":605,""author"":""4347275"",""authorNickname"":""만두국"",""blogNmae"":""만두국 블로그"",""image"":""kage@cLm21K/btrvF9MsxBQ/Gdrgt5pGWpbgLdC1wJkp60"",""plink"":""/entry/%ED%97%AC%EC%8A%A4%EC%9E%A5-%EC%9D%B8%ED%8F%AC-%EC%95%8C%EB%B0%94-%ED%9B%84%EA%B8%B0-%EC%97%AC%EC%9C%A0-%EC%8B%9C%EA%B0%84-%EB%A7%8E%EC%9D%80-%EC%95%8C%EB%B0%94-%EC%B6%94%EC%B2%9C"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
110,https://clemmyy.tistory.com/57,"



","Experience abroad/Working생로랑, 아식스, 코치 지원 및 면접 후기by clemmy2022. 2. 17.반응형(adsbygoogle = window.adsbygoogle || []).push({});생로랑(Saint Laurent), 아식스(Asics), 코치(Coach) 짧은 면접 후기, 짧은 면접이라 면접 내용이 별로 없으므로 다루지 않을 예정이었으나 혹시 모를 누군가에게 조금이라도 도움이 되길 바라며 작성해보기로 했다. 생로랑 지원, 면접 후기지원하기 - 생로랑은 폴 스미스에서 일하던 중 바로 옆에 있었기 때문에 오다가다 많이 보게 되어. 한번 지원하게 된 회사이다. 지원은 공식 홈페이지에서 하였고 2주 정도 후에 전화를 받았다. 간략한 자기소개와 어디서 일하고 있는지 물어보았고 특이하게도 이전에 경험이 없던 스카이프 면접을 보게 되었다. 가능한 날짜를 서로 조율하고 스카이프로 컨택을 한다고 했다. 생로랑 지원 링크 - https://kering.wd3.myworkdayjobs.com/uk-EN/SaintLaurent면접 당일 - 면접 당일 세수를 하고 머리를 한 다음 하의 실종이지만 상의는 풀착으로 갖춰 입고 준하고 있었다. 정해진 시간에 딱 맞춰 스카이프가 왔지만, 당시 살았던 집 와이파이가 매우 저렴한(내가 알기로) Sky 사였기에 Whatsapp 영상통화로 면접이 진행되었다.면접 질문 - 'Thanks for your time blabla', 'Thanks for giving me an opportunity blabla' 스몰톡으로 시작되었고 본격적인 면접 질문은 생로랑에 대해서 아는 것, 지금 하는 일하고 생로랑에서 어떻게 연관 지을 수 있고 역량을 어떻게 발휘할 건지, 잠재고객 발굴과 관계 형성에 네가 가진 노하우가 있는지, 고객 관리에 대해서 네가 잘하는 방법이 있다면 등 나의 역량 평가가 주된 질문이었다. 너무 비슷한 질문을 많이 했고 나중에는 횡설수설하기도 했다. 무엇보다 화상 면접이라 긴장이 더 되었던 것 같다. 면접 결과 - 결과는 다음 기회에. 한 단계 더 올라가고 싶은 마음이 컸기에 아쉬웠지만 좋은 면접 경험이 되었다.아식스, Asics지원 및 면접 장소 - 나의 전공이 체육학어있기 때문에 기능성으로 세계 최고의 제품을 만들고 있는 브랜드였기 때문에 시스템이 궁금했다. 지원은 직접 방문하여 이력서를 제출하였고 다음 날 바로 연락받았다. 면접 당일 Regent st Flagship에서 진행되었고, 매니저와 1대1 면접이었다. 면접 질문 - 면접 질문은 평범했고(이전 다른 회사 질문들과 같아 생략) 나의 경우 체육학을 전공했는데 어떻게 고객들이 구매를 결정하는 데 도움을 줄 수 있냐,경험을 바탕으로 운동에 대한 공감대를 찾아내고 내가 가진 지식을 바탕으로 고객과 관계를 형성할 것이라는 식으로 답변했다. 아식스 같은 경우는 가까운 Argyll st에 러닝 머신을 두고 직접 신고 뛰어볼 수 있는 장소를 제공하는데 그곳에서 나의 고객 serve를 하는 모습을 보여줄 수 있냐고 물었다. 면접 결과 - 기꺼이 할 용의가 있었지만, 급여, 근무 조건이 맞지 않아 거절했다.코치, Coach지원 및 면접장소 - 영국 초창기에 보았던 면접인데 코치라는 브랜드를 잘 몰랐다. 아는 것이라곤 어머니가 전에 선물 받은, 선물 받았지만 옷걸이에 몇 년 동안 그대로 걸려있는 작은 크로스 백이 전부였다. 지원은 직접 방문으로 했고, 다음날 바로 전화 연락을 받았다. Regent st Flagship이었고 Store manager와 1대1 면접이었다.면접 질문 - 매장 소파에서 마주 보고 앉아 편안하게 진행되었다. 질문은 평이했고 코치에 대한 지식을 많이 물어봤다. 코치에 대해서 아는 것, 코치 구매 경험이 있는지, 코치의 주요 아이템은 무엇인지 등면접 결과 - 탈락. 이 부분은 나의 준비 미흡이니 할 말이 없다. 하지만 브랜드 지식을 충분히 숙지하고 경험을 바탕으로 면접을 한다면 수월할 것 같다.휴고보스 인터뷰 보러가기 - https://clemmyy.tistory.com/58 휴고 보스 지원 및 면접 후기휴고 보스(Hugo Boss) 지원, 면접 후기, 2017년 자라를 그만두고 보았던 휴고 보스(Hugo Boss) 1차 그리고 최종 면접 후기이다. 정장 입는 걸 좋아하기로 하고 이 때 내가 응원하는 ..clemmyy.tistory.com 반응형(adsbygoogle = window.adsbygoogle || []).push({});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//clemmyy.tistory.com/reaction';window.ReactionReqBody = {    entryId: 57}공유하기게시글 관리끊임없이 경험하기저작자표시 'Experience abroad > Working' 카테고리의 다른 글자라 지원 및 면접 그리고 근무 후기  (0)2022.02.17휴고 보스 지원 및 면접 후기  (0)2022.02.17영국워홀 런던에서 마이클 코어스(Michael kors) 그룹 면접 후기  (0)2022.02.10영국워홀 런던에서 폴로 랄프로렌(Polo Ralph Lauren) 그룹 면접, 최종 면접 후기  (2)2022.02.08영국워홀 런던에서 캘빈 클라인(Calvin Klein) 면접부터 근무경험의 후기 (feat. 타미 힐피거 면접)  (1)2022.01.21태그런던워홀, 런던취업, 생로랑, 생로랑면접, 아식스면접, 영국워킹홀리데이, 영국워홀, 영국취업, 코치면접관련글자라 지원 및 면접 그리고 근무 후기휴고 보스 지원 및 면접 후기영국워홀 런던에서 마이클 코어스(Michael kors) 그룹 면접 후기영국워홀 런던에서 폴로 랄프로렌(Polo Ralph Lauren) 그룹 면접, 최종 면접 후기댓글0비밀글등록loadedComments[57]=true;findFragmentAndHighlight(57);"
111,https://davinci-ai.tistory.com/18,메뉴 리스트,"                                                                                                    DAVINCI - AI                                                            검색메뉴고정 헤더 영역글 제목메뉴좋아요-댓글달기-공유하기 메뉴 레이어                                                                                                    DAVINCI - AI                                                             메뉴 리스트홈방명록 분류 전체보기  IT  Machine Learning  Deep Learning  SW Architecture  Coding-Interview  Simple-Task  Toy-Project  SSAFY  Django  Certificate  Portfolio  Profile  Book-Review  검색 레이어                                                                                                    DAVINCI - AI                                                             검색 영역컨텐츠 검색 상세 컨텐츠본문 제목머신러닝 (5) -  Cross Validation(교차검증) IT/Machine Learningby HarimKang2020. 1. 28. 15:12본문좋아요-댓글달기9     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }Writer: Harim Kang머신러닝 - 5. End-to-End Machine Learning Project (4)해당 포스팅은 머신러닝의 교과서라고 불리는 Hands-On Machine Learning with Scikit-Learn & Tensor flow 책을 학습하며 정리하고, 제 생각 또한 함께 포스팅한 내용입니다. 아래의 포스팅에 이어진 내용입니다. 2020/01/28 - [IT/Machine Learning] - 머신러닝 (4) - ML 모델 생성과 훈련, 예측, 평가 머신러닝 (4) - ML 모델 생성과 훈련, 예측, 평가Writer: Harim Kang 머신러닝 - 4. End-to-End Machine Learning Project (3) 해당 포스팅은 머신러닝의 교과서라고 불리는 Hands-On Machine Learning with Scikit-Learn & Tensor flow 책을 학습하며 정리하고,..davinci-ai.tistory.com오늘의 포스팅은 위의 포스팅에 이어지는 내용으로, 교차 검증 Cross-Validation에 대한 내용입니다. 해당 포스팅은 Cross-Validation, KFold, StratifiedKFold, cross_val_score(), cross_validate() 에 대한 내용을 포함하고 있으며, Scikit-learn 라이브러리 메서드를 사용하여 코드를 작성하였습니다.Cross-Validation (k-Fold Cross Validation)모델을 생성하고 예측했다고 해서 모델이 좋은 예측을 하는 것은 아닙니다. 훈련 시에는 좋은 점수를 얻었지만, 훈련에서 너무 안 좋은 점수를 얻는 경우가 생깁니다. 이를 과적합(Overfitting)이라고 합니다. 이것을 피하기 위해서 훈련 데이터 세트 전체를 한 번에 훈련시키지 않고, 일부를 남겨두고 테스트하는 것에 사용합니다. 이러한 방법을 Cross-Validation, 교차 검증이라고 합니다.데이터를 분할하고 모델을 학습시킬 때, 다양한 매개변수를 필요로 합니다. 하지만 각각의 최적의 매개변수를 찾는 일은 아주 힘듭니다. 최고의 매개변수를 찾기 위한 여러 방법 중 하나가 바로 교차 검증입니다.정의이것은 먼저, 훈련 데이터세트를 Fold라고 하는 단위로 k개를 무작위로 나눕니다. 이것은 데이터 양이 충분치 않을 때, 성능 측정의 신뢰도를 높이기 위해 사용됩니다. Evaluating estimator performance. 이는 Grid Search와 함께 최적의 모델 parameter를 찾는 방법입니다.순서데이터를 k개의 Group으로 나눕니다. (Ramdomly)한 그룹을 학습에 사용합니다.다른 그룹을 사용하여 Test 및 성능을 평가합니다.2,3번 과정을 k번 반복합니다.모든 결과의 평균을 측정합니다.교차 검증 반복자(Cross Validation iterators)반복자의 선정은 데이터 세트의 모양과 구조에 따라 신중하게 선택이 되어야 합니다. 일반적으로 독립적인지, 동일한 분포인지를 보게 됩니다.데이터가 독립적이고 동일한 분포를 가진 경우KFold, RepeatedKFold, LeaveOneOut(LOO), LeavePOutLeaveOneOut(LPO)동일한 분포가 아닌 경우StratifiedKFold, RepeatedStratifiedKFold, StratifiedShuffleSplit그룹화된 데이터의 경우GroupKFold, LeaveOneGroupOut, LeavePGroupsOut, GroupShuffleSplit시계열 데이터의 경우TimeSeriesSplit데이터가 독립적이고 동일한 분포를 가진 경우KFold모든 데이터를 Fold라고 불리는 그룹으로 나누고 이를 split 하여 데이터 자체에서 훈련 데이터, 테스트 데이터를 반복적으로 선정합니다.  import numpy as np  from sklearn.model_selection import KFold  X = [""a"", ""b"", ""c"", ""d""]  kf = KFold(n_splits=2)  for train, test in kf.split(X):      print(""%s %s"" % (train, test))  [2 3] [0 1]  [0 1] [2 3]위의 코드에서는 인덱스 0, 1, 2, 3을 두 개씩 fold로 나누게 됩니다. [0 1]을 하나의 fold, [2 3]을 하나의 fold로 나누고 각각을 훈련과 테스트 세트로 반복합니다.RepeatedKFoldKFold를 n번 반복하는 반복자입니다. 각 반복마다 다른 분할을 생성하여 진행합니다.  import numpy as np  from sklearn.model_selection import RepeatedKFold  X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])  random_state = 12883823  rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)  for train, test in rkf.split(X):      print(""%s %s"" % (train, test))  [2 3] [0 1]  [0 1] [2 3]  [0 2] [1 3]  [1 3] [0 2]LeaveOneOut(LOO)간단한 교차 유효성 검사를 위한 반복자입니다. 하나의 데이터만을 테스트 데이터로 사용합니다. 데이터가 적을 때 데이터 낭비를 막는 방법입니다.  from sklearn.model_selection import LeaveOneOut  X = [1, 2, 3, 4]  loo = LeaveOneOut()  for train, test in loo.split(X):      print(""%s %s"" % (train, test))  [1 2 3] [0]  [0 2 3] [1]  [0 1 3] [2]  [0 1 2] [3]해당 방법은 샘플 기준 k가 n에 비해 너무 작을 때 오히려 더 비싼 계산 방식입니다. 또한, 가끔씩 높은 분산 결과를 나타납니다.LeavePOutLeaveOneOut(LPO)LOO 반복자와 KFold를 섞은 방식의 반복자로서, KFold와 아주 유사한 방식입니다.  from sklearn.model_selection import LeavePOut  X = np.ones(4)  lpo = LeavePOut(p=2)  for train, test in lpo.split(X):      print(""%s %s"" % (train, test))  [2 3] [0 1]  [1 3] [0 2]  [1 2] [0 3]  [0 3] [1 2]  [0 2] [1 3]  [0 1] [2 3]ShuffleSplit데이터를 먼저 섞은 후에 Fold를 분할하는 방식입니다. random_state를 통하여 난수를 제어할 수 있습니다. KFold의 대안으로 좀 더 세밀한 반복자를 형성하는 방식입니다.  from sklearn.model_selection import ShuffleSplit  X = np.arange(10)  ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)  for train_index, test_index in ss.split(X):      print(""%s %s"" % (train_index, test_index))  [9 1 6 7 3 0 5] [2 8 4]  [2 9 8 0 6 7 4] [3 5 1]  [4 5 1 0 6 9 7] [2 3 8]  [2 7 5 8 0 3 4] [6 1 9]  [4 1 0 6 8 9 3] [5 2 7]동일한 분포가 아닌 경우StratifiedKFold계층을 가진 Fold를 리턴하는 KFold의 변형된 반복자입니다. 각각 비율이 다른 클래스의 비율을 유지하면서 훈련과 테스트 세트를 분류합니다.  from sklearn.model_selection import StratifiedKFold, KFold  import numpy as np  X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))  skf = StratifiedKFold(n_splits=3)  for train, test in skf.split(X, y):      print('train -  {}   |   test -  {}'.format(          np.bincount(y[train]), np.bincount(y[test])))  train -  [30  3]   |   test -  [15  2]  train -  [30  3]   |   test -  [15  2]  train -  [30  4]   |   test -  [15  1]  kf = KFold(n_splits=3)  for train, test in kf.split(X, y):      print('train -  {}   |   test -  {}'.format(          np.bincount(y[train]), np.bincount(y[test])))  train -  [28  5]   |   test -  [17]  train -  [28  5]   |   test -  [17]  train -  [34]   |   test -  [11  5]위의 코드는 0 클래스 45개, 1 클래스 5개로 이루어진 데이터를 생성하여 Fold로 훈련, 테스트 세트를 나누는 코드입니다. 훈련 및 테스트 데이터 세트를 기존 데이터 비율 9:1과 비슷하게 유지하는 것을 확인할 수 있습니다.RepeatedStratifiedKFold위의 StratifiedKFold 방식을 n번 반복하는 방식입니다.StratifiedShuffleSplitShuffleSplit의 변형으로 계층화된 클래스의 비율을 유지하면서 Shuffle 하는 방식입니다.그룹화된 데이터의 경우GroupKFoldKFold의 변형된 방식으로, 동일한 한 클래스가 테스트 또는 훈련 데이터 세트에 한 번에 들어가지 않도록 합니다. 각각 클래스들의 특징을 살리기 위한 방식입니다.LeaveOneGroupOut하나의 클래스를 제외시키고 GroupKFold 하는 방식입니다. 이 방식은 시간과 관련된 데이터에서 많이 사용됩니다.  from sklearn.model_selection import LeaveOneGroupOut  X = [1, 5, 10, 50, 60, 70, 80]  y = [0, 1, 1, 2, 2, 2, 2]  groups = [1, 1, 2, 2, 3, 3, 3]  logo = LeaveOneGroupOut()  for train, test in logo.split(X, y, groups=groups):      print(""%s %s"" % (train, test))  [2 3 4 5 6] [0 1]  [0 1 4 5 6] [2 3]  [0 1 2 3] [4 5 6]LeavePGroupsOut하나가 아닌 P개의 클래스를 제외하는 방식으로, LeaveOneGroupOut과 유사합니다.GroupShuffleSplitShuffleSplit과 GroupKFold를 합친 방식입니다. 클래스의 치우침을 방지하고, 랜덤 분할하는 방식입니다.  from sklearn.model_selection import GroupShuffleSplit  X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]  y = [""a"", ""b"", ""b"", ""b"", ""c"", ""c"", ""c"", ""a""]  groups = [1, 1, 2, 2, 3, 3, 4, 4]  gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)  for train, test in gss.split(X, y, groups=groups):      print(""%s %s"" % (train, test))  [0 1 2 3] [4 5 6 7]  [2 3 6 7] [0 1 4 5]  [2 3 4 5] [0 1 6 7]  [4 5 6 7] [0 1 2 3]시계열 데이터의 경우TimeSeriesSplit그룹을 나누는 것까진 다른 것들과 동일합니다. 대신, 시계열 데이터는 연속적인 데이터를 유지해야 하므로, 앞에서 훈련시킨 것들을 다음에도 연속적으로 사용합니다. 훈련 데이터 세트를 키워나가는 식으로 진행합니다.  from sklearn.model_selection import TimeSeriesSplit  X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])  y = np.array([1, 2, 3, 4, 5, 6])  tscv = TimeSeriesSplit(n_splits=3)  print(tscv)  TimeSeriesSplit(max_train_size=None, n_splits=3)  for train, test in tscv.split(X):      print(""%s %s"" % (train, test))  [0 1 2] [3]  [0 1 2 3] [4]  [0 1 2 3 4] [5]사용법cross_val_score()estimator: estimator학습을 할 모델을 의미합니다.x: array학습시킬 훈련 데이터 세트입니다.y: array학습시킬 훈련 데이터 세트의 Label입니다.scoring: string or None각 모델에서 사용할 평가 방법입니다.교차 검증은 utility function을 사용합니다. 그래서 더 큰 값이 좋은 결과라는 의미입니다.위와 같은 이유로 Regression 모델에서는 MSE를 얻기 위해 주로 'neg_mean_squred_error'값을 사용합니다. (0으로 갈수록 좋은 점수)cv: int or kfoldCross-Validation generatorFold의 수를 의미합니다.앞서 정리한 교차 검증 반복자를 사용합니다. 또는, custom 한 fold를 생성하는 iterator를 만들어서 주어도 됩니다.cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)cross_val_score(clf, X_train, Y_train, cv=cv)scores: returns, arrayscoring을 사용하여 평가한 점수를 각각 교차 검증을 반복 시마다 기록하여 돌려줍니다.cross_score = cross_val_score(lin_reg, X_train, Y_train, scoring='neg_mean_squared_error', cv=10)rmse_score = nq.sqrt(-cross_score)rmse_mean = rmse_score.mean()rmse_std = rmse_score.std()평가 결과는 neg_mean_squared_error값으로 리턴되도록 선언한 코드이며, 이를 양수 값으로 바꾸고 rmse를 계산한 코드입니다.mean()과 std()를 사용하여 평균값과 표준편차를 확인할 수 있습니다.cross_validate()다중 평가 지표는 모델을 평가할 때 여러 개의 지표를 사용하여 모델을 평가한다는 의미입니다. Scikit-learn은 0.19 버전부터 cross_validate() 함수를 통해 다중 평가 지표 기능을 제공합니다. 다중 평가 지표는 GridSearch에서도 사용 가능합니다.cross_val_score와 파라미터는 유사합니다.cross_val_score()와 마찬가지로 scoring 매개변수를 통하여 평가 지표를 지정합니다. 다중 평가 지표를 사용하고자 한다면 리스트로 작성하여 전달하면 됩니다.return_train_score: cross_val_score와 다르게 테스트 폴드 점수뿐 아니라 훈련 폴드에 대한 점수를 리턴 받을 수 있습니다. 해당 매개변수는 훈련 폴드의 점수를 받을지 여부를 설정하는 변수입니다.from sklearn.model_selection import cross_validatecross_validate(SVC(gamma='auto'), X_train, y_train, scoring=['accuracy', 'roc_auc'], return_train_score=True)SVC를 모델로 사용하였고, scoring 매개변수에서 리스트로 여러 평가 지표를 전달합니다. 리스트의 지표가 하나이면, cross_val_score()와 같은 기능을 합니다. return_train_score에서는 훈련 Fold에 대한 점수를 받는지 여부입니다. 결과는 아래와 같은 예제 형식으로 나타납니다.{'fit_time': array([0.07761502, 0.07732582, 0.07719207]),  'score_time': array([0.06746364, 0.06803942, 0.06800795]),  'test_accuracy': array([0.90200445, 0.90200445, 0.90200445]),  'test_roc_auc': array([0.99657688, 0.99814815, 0.99943883]),  'train_accuracy': array([1., 1., 1.]),  'train_roc_auc': array([1., 1., 1.])}훈련 및 테스트에 걸린 시간과 각각 지표마다의 점수를 딕셔너리 형태로 반환합니다.또한 아래의 코드와 같이 딕셔너리 형태로 scoring을 전달 가능합니다. 결과는 딕셔너리의 키 값에 맞게 바뀌어서 전달됩니다.cross_validate(SVC(gamma='auto'), X_train, y_train, scoring={'acc':'accuracy', 'ra':'roc_auc'},             return_train_score=False, cv=3)다음 포스팅에는 이어서 Grid Search에 대한 내용을 이어서 포스팅하겠습니다!ReferenceCross-Validation Scikit-Learn Document(Code & Figure):https://scikit-learn.org/stable/modules/cross_validation.htmlcross_val_score():https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_scorecross_validate():https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate텐서 플로우 블로그:https://tensorflow.blog/tag/cross_val_score/window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//davinci-ai.tistory.com/reaction';window.ReactionReqBody = {    entryId: 18}공유하기게시글 관리DAVINCI - AI저작자표시 변경금지 'IT > Machine Learning' 카테고리의 다른 글머신러닝 (7) - Regression(회귀)  (4)2020.02.12머신러닝 (6) - Fine Tuning Model  (2)2020.02.12머신러닝 (4) - ML 모델 생성과 훈련, 예측, 평가  (2)2020.01.28머신러닝 (3) - 데이터 전처리  (0)2020.01.22머신러닝 (2) - ML프로젝트를 위한 데이터 선택 및 준비  (0)2020.01.21태그cross-validation, cross_validate, cross_val_score, KFold, RepeatedKFold, Scikit Learn, sklearn, StratifiedKFold, TimeSeriesSplit, 교차검증관련글 더보기머신러닝 (7) - Regression(회귀)2020.02.12머신러닝 (6) - Fine Tuning Model2020.02.12머신러닝 (4) - ML 모델 생성과 훈련, 예측, 평가2020.01.28머신러닝 (3) - 데이터 전처리2020.01.22댓글 영역댓글 9개댓글 쓰기이전                                    댓글 더보기    setInitialEntryComments(18, 1723627698) 비밀글                                                댓글                                        남기기loadedComments[18]=true;findFragmentAndHighlight(18);추가 정보인기글--딥러닝 (8) - [RL1] 강화학습(Reinforcement Learning)이란?2020.03.22 01:36--머신러닝 (3) - 데이터 전처리2020.01.22 01:58--파이썬으로 구현하는 자료구조 요약 정리 - 배열(Array), 큐(Queue), Stack, Linked List2020.01.22 22:09--딥러닝 (6) - CNN (Convolutional Neural Network)2020.02.24 22:12 최신글--[도서리뷰] 소프트웨어 스펙의 모든것Portfolio/Book-Review--[Tensorflow Certificate] 준비 및 후기IT/Certificate--[간단 리뷰] Practices of the Python ProPortfolio/Book-Review--빅데이터 분석기사 필기 - 빅데이터 분석 기획 #3IT/Certificate DAVINCI - AIHarimKang패밀리사이트Harim's Git-HubLinked-inGit-hub[HITS]  Total : 550,260     Today : 88     Yesterday : 158DAVINCI - AI© Harim Kang   "
112,https://jpub.tistory.com/1374,태그,"도서 소개리얼월드 암호학 제이펍2023. 1. 20. 16:50 2023 대한민국학술원 우수학술도서 선정세상에서 가장 실용적인 암호학 가이드북  도서구매 사이트(가나다순)[교보문고] [도서11번가] [알라딘] [예스이십사] [인터파크] [쿠팡] 전자책 구매 사이트(가나다순)교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 출판사 제이펍저작권사 Manning원서명 Real-World Cryptography (9781617296710)도서명 리얼월드 암호학부제 블록체인과 양자 컴퓨팅까지 그림과 사례로 실용적으로 익히는 현대 암호학 지은이 데이비드 웡옮긴이 임지순감수자 (없음)시리즈 (없음)출판일 2023. 01. 20페이지 424쪽판 형 46배판변형(188*245*20.4)제 본 무선(soft cover)정 가 34,000원ISBN 979-11-92469-53-9 (93000)키워드 암호, 해시, 서명, HTTPS, 보안, 양자, TLS, 시그널, HSM, ZKP분 야 네트워크 / 보안 관련 사이트■ 아마존 도서 페이지■ 저작권사 도서 페이지 관련 포스트■ 2023.01.09 - [출간 전 책 소식] - 양자 컴퓨터는 암호 보안의 종말을 의미하는가? 관련 시리즈■ (없음) 관련 도서■ (없음) 관련 파일 다운로드■ (없음) 강의 보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음 자료를 보내드립니다.)■ 본문의 그림과 표 미리보기(차례, 옮긴이 머리말, 추천의 글, 베타리더 후기, 시작하며, 감사의 글, 이 책에 대하여, 표지에 대하여, 1장 일부) 정오표 페이지■ (등록되는 대로 링크를 걸겠습니다.) 도서구매 사이트(가나다순)[교보문고] [도서11번가] [알라딘] [예스이십사] [인터파크] [쿠팡] 전자책 구매 사이트(가나다순) 교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 도서 소개수식 대신 그림, 역사 대신 사례, 이론 대신 응용으로 배우는 암호학의 현재와 미래 암호학은 웹 API, 유저 서비스, 블록체인 등 IT 보안의 근간이지만, 유달리 읽을 만한 책이 없다. 카이사르 암호나 비즈네르 암호 같은 역사로 시작하는 책은 지겹다. 현대 암호학이 어떤 요소로 구성되었는지, 어떤 프로토콜이 자주 쓰이며, 어떤 공격 사례가 있었는지, 양자 컴퓨터가 나온 마당에 암호학의 미래는 어떻게 될 것인지. 실무자가 궁금한 건 이런 내용이다. 이 책의 저자는 암호학의 역사나 레거시 알고리즘 대신 TLS, 노이즈 프로토콜 프레임워크, 시그널 프로토콜, 암호화폐(저자는 이 책이 암호화폐를 한 챕터로 다루는 최초의 암호학 책이라고 주장한다!), HSM, 임곗값 암호학 등 오늘날 실제로 대규모로 사용되는 사례로 이 책을 채웠다. 수식이 없을 수는 없지만, 우리에게 친숙한 앨리스와 밥을 포함해 수많은 그림을 삽입해 알기 쉽게 설명하려 노력했다. 저자 본인 역시 대학에서 배운 타원 곡선 수학이 현실 세계 알고리즘에서 어떻게 사용되는지 알 수 없었고, 많은 개발자가 ‘구현’을 잘못해 보안 실패를 초래하고 있기에, 장마다 ‘좋은’ 라이브러리를 골라 자바, 자바스크립트, 고랭, 러스트 등 다양한 언어로 작성한 예제 스니펫을 담았다. 풍부한 도표와 사례 덕분에 개발자, 시스템 관리자, 보안 실무자는 인증, 암호화, 비밀 유지 등 암호학 개념을 익히고 공격자보다 앞서기 위한 도구, 프레임워크, 프로토콜을 배울 수 있다. 해시 함수와 서명 등 기초부터 HTTPS와 보안 메시징 등 암호학 프로토콜, 그리고 양자 후 암호학(양자 내성 암호학)과 암호화폐 등 첨단 기술까지 살펴보는, 가장 실용적이며 가장 현대적인 암호학 책이다. 주요 내용■ 암호학 활용 시의 베스트 프랙티스■ 암호학 알고리즘에 대한 그림과 해설■ 디지털 서명 및 영지식 증명 구현■ 공격 등에 대비하기 위한 하드웨어 솔루션■ 나쁜 프랙티스를 식별하고 고치는 법■ 문제별로 적합한 암호학 도구 선택하기 지은이 소개데이비드 웡(David Wong)O(1) Labs의 수석 암호학 엔지니어로서 미나(Mina) 암호화폐를 연구하고 있다. 그 전에는 메타의 자회사 노비에서 디엠(전 리브라) 암호화폐의 보안 리더였고, 그 전에는 NCC 그룹의 암호학 서비스의 보안 컨설턴트였다. OpenSSL과 Let’s Encrypt 등 여러 공적 자금 지원 오픈소스 감사에 참여했다. 블랙햇과 DEFCON 등 다양한 콘퍼런스에서 강연했으며, 블랙햇에서 암호학 과정을 정기적으로 맡았다. TLS 1.3과 노이즈 프로토콜 프레임워크 등의 표준에 기여했다. 고 언어 표준 라이브러리(CVE-2016-3959)라든가 여러 TLS 라이브러리(CVS-2018-12404 등)에서 보안 취약점을 찾아내기도 했다. 디스코 프로토콜(www.discocrypto.com), 스마트 계약용 댑 보안 프로젝트(www.dasp.co) 등의 창시자이며, RSA 캐시 공격, QUIC 기반 프로토콜, ECDSA 타이밍 공격, 디피-헬먼 백도어 등의 연구를 발표했다. 블로그(www.cryptologie.net)에 암호학 관련 글을 꾸준히 올리고 있다. 옮긴이 소개임지순낮에는 계약서와 코드를 두드리고 밤에는 신시사이저와 기타를 난도질하는 공학과 미디어의 주변인. 임베디드 프로그래머, 미들웨어 개발자, 프로젝트 매니저, 사업 개발 등 다양한 직군에 종사해왔으며 최근에는 엔터테인먼트 산업에서 다양한 웹 프로젝트를 진행 중이다. 사회적인 덕후로 생존하기 위해 오늘도 코드, 그리고 글과 씨름하고 있다. 참여 도서로는 《쉽게 배우는 AWS AI 서비스》(한빛미디어, 2022), 《모던 자바스크립트 핵심 가이드》(한빛미디어, 2021), 《초소형 머신러닝 TinyML》(한빛미디어, 2020), 《라즈베리 파이로 배우는 컴퓨터 아키텍처》(위키북스, 2017) 등이 있다. 차례옮긴이 머리말 xii추천의 글 xiii베타리더 후기 xv시작하며 xvii감사의 글 xxii이 책에 대하여 xxiii표지에 대하여 xxvii PART I 프리미티브: 암호학의 재료 CHAPTER 1 시작하며 31.1 암호학은 프로토콜을 보호한다 41.2 대칭 암호학: 대칭 암호화란? 51.3 케르크호프스의 원칙: 키만은 비밀로 지키자 71.4 비대칭 암호학: 키 두 개가 하나보단 낫지 10__1.4.1 비밀을 공유하는 방법, 키 교환 10__1.4.2 비대칭 암호화, 대칭 암호화와는 다르다! 13__1.4.3 디지털 서명: 펜과 종이의 서명과 그리 다르지 않다 151.5 암호학의 분류 17더보기1.6 이론 암호학 vs 실세계 암호학 191.7 이론에서 현실로: 암호학의 현실화를 위한 시뮬레이션 201.8 경고장 25요약 26 CHAPTER 2 해시 함수 272.1 해시 함수란? 272.2 해시 함수의 보안 속성 302.3 해시 함수의 보안 제약 322.4 해시 함수의 실사용 34__2.4.1 커밋 34__2.4.2 서브리소스 무결성 35__2.4.3 비트토렌트 35__2.4.4 토르 352.5 표준화된 해시 함수 36__2.5.1 SHA-2 해시 함수 37__2.5.2 SHA-3 해시 함수 41__2.5.3 두 가지 XOF, SHAKE와 cSHAKE 44__2.5.4 튜플해시, 모호성을 해결하다 462.6 비밀번호 해시 48요약 50 CHAPTER 3 메시지 인증 코드 513.1 MAC의 대표적 예, 무상태성 쿠키 513.2 코드 예제 543.3 MAC의 보안 속성 56__3.3.1 인증 태그의 위조 56__3.3.2 인증 태그의 길이 57__3.3.3 리플레이 공격 58__3.3.4 주기적 인증 태그 검증 593.4 실세계의 MAC 61__3.4.1 메시지 인증 61__3.4.2 키 파생 61__3.4.3 쿠키의 정합성 61__3.4.4 해시 테이블 623.5 실무에서의 MAC 62__3.5.1 해시 기반 MAC, HMAC 62__3.5.2 cSHAKE 기반 MAC, KMAC 633.6 SHA-2와 가변 길이 공격 64요약 67 CHAPTER 4 인증 암호화 694.1 암호문이란? 704.2 AES 블록 암호화 71__4.2.1 AES가 제공하는 보안의 수준 72__4.2.2 AES의 인터페이스 73__4.2.3 AES의 내부 744.3 암호화된 펭귄, 그리고 CBC 모드 754.4 인증이 필요하면? AES-CBC-HMAC 784.5 올인원 구조: 인증 암호화 80__4.5.1 AEAD 80__4.5.2 AES-GCM AEAD 82__4.5.3 ChaCha20-Poly1305 864.6 그 밖의 대칭 암호화 90__4.6.1 키 래핑 91__4.6.2 논스 오용 방지 인증 암호화 91__4.6.3 디스크 암호화 91__4.6.4 데이터베이스 암호화 92요약 92 CHAPTER 5 키 교환 955.1 키 교환이란? 965.2 DH 키 교환 99__5.2.1 군론 99__5.2.2 디피-헬먼의 기반, 이산 로그 문제 103__5.2.3 디피-헬먼 표준 1055.3 ECDH 키 교환 106__5.3.1 타원 곡선이란? 107__5.3.2 ECDH 키 교환의 작동 원리 110__5.3.3 타원 곡선 디피-헬먼의 표준 1125.4 작은 부분군 공격과 그 밖의 보안 고려 사항 114요약 117 CHAPTER 6 비대칭 암호화와 하이브리드 암호화 1196.1 비대칭 암호화란? 1206.2 실전 비대칭 암호화와 하이브리드 암호화 122__6.2.1 키 교환 및 키 캡슐화 122__6.2.2 하이브리드 암호화 1236.3 RSA 비대칭 암호화: 최악과 차악 127__6.3.1 교과서 RSA 127__6.3.2 RSA PKCS#1 v1.5를 쓰지 않는 이유 131__6.3.3 RSA-OAEP 비대칭 암호화 1336.4 ECIES 하이브리드 암호화 136요약 138 CHAPTER 7 서명과 영지식 증명 1397.1 서명이란? 140__7.1.1 실전에서 서명하고 서명을 검증하는 방법 141__7.1.2 서명의 주된 사용: 인증된 키 교환 142__7.1.3 실세계의 사용 사례: 공개 키 인프라 1437.2 ZKP: 서명의 근원 144__7.2.1 슈노어 식별 프로토콜: 대화형 ZKP 145__7.2.2 비대화형 ZKP로서의 서명 1487.3 권장하는 서명 알고리즘 149__7.3.1 불안한 표준, RSA PKCS#1 v1.5 150__7.3.2 개선된 표준, RSA-PSS 153__7.3.3 ECDSA 154__7.3.4 EdDSA 1577.4 서명 체계의 미묘한 속성 160__7.4.1 대체 공격 160__7.4.2 서명의 가단성 162요약 162 CHAPTER 8 무작위성과 비밀 1658.1 무작위성이란? 1668.2 느린 무작위성? PRNG를 쓰세요 1678.3 실전에서 무작위성 확보하기 1718.4 난수 생성과 보안 고려 사항 1738.5 공개적 무작위성 1758.6 키 파생과 HKDF 1778.7 키 관리와 비밀 관리 1818.8 임곗값 암호학을 통한 신뢰의 탈중앙화 183요약 186 PART II 프로토콜: 암호학의 레시피 CHAPTER 9 보안 전송 1899.1 보안 전송 프로토콜, SSL과 TLS 190__9.1.1 SSL에서 TLS로 190__9.1.2 실전에서 TLS 활용하기 1919.2 TLS 프로토콜의 작동 원리 193__9.2.1 TLS 핸드셰이크 194__9.2.2 TLS 1.3이 애플리케이션 데이터를 암호화하는 방법 2079.3 암호화된 웹의 현재 2089.4 기타 전송 프로토콜 2119.5 TLS에 대한 현대적인 대안, 노이즈 프로토콜 프레임워크 211__9.5.1 노이즈의 다양한 핸드셰이크 212__9.5.2 노이즈의 핸드셰이크 213요약 214 CHAPTER 10 종단 간 암호화 21510.1 종단 간 암호화가 왜 필요한가? 21610.2 어디에서도 찾을 수 없는 신뢰의 근원 21710.3 이메일 암호화의 실패 219__10.3.1. PGP? GPG? 어떻게 작동할까? 219__10.3.2 사용자 간의 신뢰를 확장시키는 신뢰의 웹 222__10.3.3 진짜 이슈는 키 발견 223__10.3.4 PGP가 아니라면, 대안은? 22410.4 보안 메시징: 시그널을 활용한 현대적 종단 간 암호화 226__10.4.1 신뢰하되, 검증하라. WOT보다 사용자 친화적으로 227__10.4.2 시그널 프로토콜의 핸드셰이크, X3DH 230__10.4.3 시그널의 핸드셰이크 후 프로토콜, 더블 래칫 23310.5 종단 간 암호화의 현재 238요약 240 CHAPTER 11 사용자 인증 24311.1 인증 복습하기 24311.2 사용자 인증, 비밀번호를 없애기 위한 여정 245__11.2.1 비밀번호의 지배자, SSO와 비밀번호 관리자 248__11.2.2 비밀번호 노출을 막고 싶다고요? 비대칭 비밀번호 인증 키 교환을 쓰세요 249__11.2.3 O TP는 실제 비밀번호가 아니다. 대칭 키를 사용하여 비밀번호 없이 전환하기 253__11.2.4 비대칭 키로 비밀번호 대체하기 25711.3 사용자 지원 인증: 사람의 도움으로 장치 페어링하기 260__11.3.1 미리 공유된 키 261__11.3.2 CPace를 사용한 대칭 비밀번호 인증 키 교환 263__11.3.3 내 키 교환이 MITM 공격을 당했나? SAS를 확인하자 264요약 267 CHAPTER 12 ‘암호화폐’의 ‘암호’? 26912.1 BFT 합의 알고리즘에 대한 간단한 소개 270__12.1.1 회복력의 문제: 구조를 위한 분산 프로토콜 270__12.1.2 신뢰의 문제를 해결하는 탈중앙화 272__12.1.3 규모의 문제: 무허가 및 검열 방지 네트워크 27312.2 비트코인의 작동 방식 275__12.2.1 비트코인이 사용자 잔고와 트랜잭션을 관리하는 방법 276__12.2.2 디지털 금광 시대, BTC를 채굴한다는 것 278__12.2.3 포크 지옥! 채굴 분쟁 해결 281__12.2.4 머클 트리를 사용하여 블록 크기 줄이기 28412.3 암호화폐 둘러보기 286__12.3.1 변동성 286__12.3.2 지연 시간 286__12.3.3 블록체인의 크기 287__12.3.4 기밀성 287__12.3.5 에너지 효율 28812.4 디엠BFT: BFT 합의 프로토콜 288__12.4.1 BFT 합의 프로토콜의 두 속성, 안전성과 활성 288__12.4.2 디엠BFT 프로토콜의 라운드 289__12.4.3 프로토콜은 부정직함을 어느 정도까지 허용할 수 있는가? 290__12.4.4 디엠BFT 투표 규칙 291__12.4.5 트랜잭션은 언제 확정되는가? 292__12.4.6 디엠BFM의 안전성에 숨은 직관 293요약 295 CHAPTER 13 하드웨어 암호학 29713.1 현대 암호학의 공격자 모델 29713.2 비신뢰 환경의 구원자, 하드웨어 299__13.2.1 화이트박스 암호학 300__13.2.2 스마트 카드와 보안 요소 300__13.2.3 은행이 사랑한 HSM 303__13.2.4. 보안 요소의 훌륭한 표준화, TPM 305__13.2.5 TEE를 이용한 보안 컴퓨팅 30813.3 어떤 솔루션을 고를까? 30913.4 누출 저항 암호학, 그리고 사이드채널 공격 방어법 311__13.4.1 상수 시간 프로그래밍 313__13.4.2 마스킹과 블라인드 315__13.4.3 결함 공격 대처법 316요약 316 CHAPTER 14 양자 컴퓨터 시대의 암호학 31914.1 양자 컴퓨터가 뭐길래? 320__14.1.1 작은 것에 대한 탐구, 양자역학 320__14.1.2 양자 컴퓨터의 탄생으로부터 양자 우위까지 323__14.1.3 그로버와 쇼어의 알고리즘 324__14.1.4 양자 컴퓨터에 맞서는 양자 후 암호학 32614.2 해시 함수만 있으면 된다! 해시 기반 서명 326__14.2.1 램포트 서명을 통한 OTS 327__14.2.2 WOTS와 작은 키 329__14.2.3 XMSS와 SPHINCS+를 통한 다회 서명 33014.3 격자 기반 암호학을 사용한 더 짧은 키 및 서명 333__14.3.1 격자란? 333__14.3.2 오류를 통한 학습 335__14.3.3 격자 기반 키 교환, 카이버 337__14.3.4 격자 기반 서명 체계, 다이리튬 33914.4 양자 컴퓨터는 공포인가? 340요약 342 CHAPTER 15 차세대 암호학 34515.1 함께할수록 좋은 MPC 346__15.1.1 PSI 347__15.1.2 범용 MPC 348__15.1.3 MPC의 현재 35015.2 FHE, 그리고 암호화 클라우드의 미래 350__15.2.1 RSA 암호화와 동형 암호화의 예 351__15.2.2 다양한 동형 암호화 351__15.2.3 FHE의 열쇠, 부트스트래핑 352__15.2.4 오류를 통한 학습 기반 FHE 체계 354__15.2.5 어디에 사용할까? 35615.3 범용 ZKP 357__15.3.1 zk-SNARK의 작동 원리 359__15.3.2 증거의 일부를 숨기는 동형 커밋 360__15.3.3 동형 커밋을 개선하는 쌍선형 페어링 361__15.3.4 간결성은 어디에? 361__15.3.5 프로그램을 다항식으로 362__15.3.6 프로그램은 컴퓨터를 위한 것. 우리에게 필요한 것은 산술 회로 363__15.3.7 R1CS 산술 회로 364__15.3.8 R1CS에서 다항식까지 364__15.3.9 지수에 숨은 다항식을 계산하기 365요약 367 CHAPTER 16 암호학의 끝 36916.1 알맞은 암호학 프리미티브 또는 프로토콜을 찾는 지루한 작업 37016.2 암호학 프리미티브 및 프로토콜을 사용하는 법? 표준과 형식 검증 37116.3 좋은 라이브러리는 어디에? 37416.4 개발자가 적? 암호학의 오용 37616.5 사용이 편한 보안 37716.6 암호학은 섬이 아니다 37816.7 암호학 실무자의 책임: 자신의 암호학을 시험하지 말자 379 요약 381연습 문제 정답 383찾아보기 388  제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)네이버 책 포스트 유튜브 인스타그램 트위터 페이스북window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1374}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글그림으로 배우는 StatQuest 머신러닝 강의  (6)2023.02.13진짜 쓰는 일러스트레이터  (0)2023.02.03프로그래밍 러스트(개정판)  (2)2023.01.19진짜 쓰는 윈도우 11  (0)2023.01.12메이크잇의 폭신폭신 말랑말랑 종이 스퀴시 만들기  (0)2023.01.12태그HSM, https, tls, ZKP, 보안, 서명, 시그널, 암호, 양자, 해시'도서 소개' Related Articles그림으로 배우는 StatQuest 머신러닝 강의진짜 쓰는 일러스트레이터프로그래밍 러스트(개정판)진짜 쓰는 윈도우 11    setInitialEntryComments(1374, 1723627698)Secret댓글달기loadedComments[1374]=true;findFragmentAndHighlight(1374);"
113,https://lsjsj92.tistory.com/555,머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization),"본문 바로가기꿈 많은 사람의 이야기카테고리검색하기검색하기Search꿈 많은 사람의 이야기이수진의 블로그 분류 전체보기 (571)  python (85)  Data Engineering  및 Infra (33)  machine learning(머신러닝) (19)  deep learning(딥러닝) (39)  추천시스템 (26)  LLM&RAG (2)  컨퍼런스(IT, AI) (4)  python-django (15)  빅데이터 (20)  kaggle(캐글) (13)  알고리즘&자료구조 (12)  IT 및 개발 TIP (21)  생활팁 (20)  R (23)  javascript (16)  암호화폐 (0)  perl (22)  java (47)  일상 (53)  맛집 (50)  전시회(일상) (7)  spring(스프링) 프레임워크 (3)  jsp (5)  리눅스(linux) (2)  국내여행 (17)  해외여행 (2)  책 (4)  초대장 (2)  티스토리 (2)  축제 (3)  mysql (3) Guestbook세로형(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_goB19ZXe', {ignore_items: true});Notice[contact] 컨택 정보 공지Recent Posts인공지능 윤리(AI Ethics)란 무엇일까? AI개발자가 바라⋯LLM과 추천 시스템을 결합해 설명가능성(Explainabili⋯개인화를 고려한 LLM 모델 기반 추천 시스템 - PALR 추천⋯vLLM 사용법 - LLM을 쉽고 빠르게 추론(inference⋯LLM 기반 추천 시스템 논문 리뷰 - LlamaRec: Two⋯Recent Comments안녕하세요. 맥에서 Modelfile을 만들어 모델 배포하려고 ⋯안녕하세요 음 beeline으로는 제가 경험이 없어서 모르겠습니⋯혹시 여기서 beeline 으로 접속하는 방법 은 없을까요? n⋯안녕하세요. 네~ 질문 남겨주시면 답변 드리겠습니다네네~ 해결 되셨다니 다행이네요 ㅎㅎ Link #chart-time {font-size:11px; text-align:right; color:#999; padding-right: 15px;}08-14 02:04        am4core.ready(function() {            am4core.addLicense(""CH90809262"");            var chart = am4core.create(""chartdiv"", am4charts.XYChart);            chart.data = [{""timestamp"":""2024-08-08T00:00:00+09:00"",""count"":899},{""timestamp"":""2024-08-09T00:00:00+09:00"",""count"":783},{""timestamp"":""2024-08-10T00:00:00+09:00"",""count"":342},{""timestamp"":""2024-08-11T00:00:00+09:00"",""count"":334},{""timestamp"":""2024-08-12T00:00:00+09:00"",""count"":1022},{""timestamp"":""2024-08-13T00:00:00+09:00"",""count"":899},{""timestamp"":""2024-08-14T00:00:00+09:00"",""count"":45}];            var values = chart.data.map(function(value){                return value.count            });            var minValue = values.reduce(function(acc, current) {                return Math.min(acc, current);            });            var maxValue = values.reduce(function(acc, current) {                return Math.max(acc, current);            });            chart.dateFormatter.inputDateFormat = ""yyyyMMdd"";            var dateAxis = chart.xAxes.push(new am4charts.DateAxis());            var valueAxis = chart.yAxes.push(new am4charts.ValueAxis());            dateAxis.renderer.grid.template.disabled = true;            dateAxis.dateFormats.setKey(""day"", ""dd"");            dateAxis.periodChangeDateFormats.setKey(""day"", ""dd"");            dateAxis.renderer.minGridDistance = 1;            dateAxis.fontSize = ""10.5px"";            dateAxis.color = ""#ff0000"";            dateAxis.opacity = 0.5;            valueAxis.opacity = 0.5;            valueAxis.fontSize = ""10.5px"";            valueAxis.paddingBottom = 5;            valueAxis.marginLeft = -20;            valueAxis.min = minValue < 0 ? 0 : minValue;            valueAxis.max = maxValue + 10;            var series = chart.series.push(new am4charts.LineSeries());            series.dataFields.valueY = ""count"";            series.dataFields.dateX = ""timestamp"";            series.tooltipText = ""{count}""            series.strokeWidth = 1;            series.minBulletDistance = 15;            series.tooltip.background.cornerRadius = 20;            series.tooltip.background.strokeOpacity = 0;            series.tooltip.pointerOrientation = ""vertical"";            series.tooltip.label.minWidth = 40;            series.tooltip.label.minHeight = 40;            series.tooltip.label.textAlign = ""middle"";            series.tooltip.label.textValign = ""middle"";            var bullet = series.bullets.push(new am4charts.CircleBullet());            bullet.circle.strokeWidth = 2;            bullet.circle.radius = 3;            bullet.circle.fill = am4core.color(""#fff"");        });«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031TagsPython일상취미프로그래밍머신러닝자바딥러닝프로그래밍언어추천시스템Java컴퓨터deep learning맛집맛있다취업하고싶다공부개발파이썬ITmachine learningmoreArchives2024/07 (1)2024/06 (1)2024/05 (2)2024/04 (4)2024/02 (1)Today45Total3,264,595닫기관리 메뉴글쓰기방명록RSS관리꿈 많은 사람의 이야기머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization) 본문machine learning(머신러닝)머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization)이수진의 블로그                            2019. 12. 12. 09:18     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({});728x170(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_x7yWv3X6', {ignore_items: true});포스팅 주제더보기이번 포스팅은 지난 포스팅에 이어서 캐글의 신용카드 사기 탐지(kaggle credit card fraud detection) 데이터를 활용합니다.또한, kaggle credit card fraud detection의 커널 중 https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets커널을 참조하여 공부하고 정리하였습니다.이번 글은 지난 글에서 진행한 신용카드 사기 탐지 데이터의 데이터 스케일(data scale)을 변경시켜보려고 합니다.그리고 이렇게 데이터 스케일이 변경되었을 때 머신러닝 모델 성능이 어떻게 변화되는지 살펴보겠습니다. 지난 포스팅에서는 데이터 원본을 그대로 사용하여 단순히 신용카드 사기를 탐지했습니다.궁금하신 분들은 지난 포스팅을 보시면 되겠습니다.(https://lsjsj92.tistory.com/553) 머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud이번 포스팅은 머신러닝으로 신용카드 사기를 탐지하는 모델을 만들어보려고 합니다. 해당 포스팅의 데이터는 kaggle에서 제공해준 kaggle credit card fraud를 사용했습니다. 또한, 한 커널을 필사하면서 진행하..lsjsj92.tistory.com 코드는 아래 github에 존재합니다.https://github.com/lsjsj92/machine_learning_basic lsjsj92/machine_learning_basicRepo for everyone who wants a machine learning basic - lsjsj92/machine_learning_basicgithub.com11번에 코드가 존재합니다. 데이터 분포 변경 - 데이터 정규화(data normalization)캐글의 신용카드 사기 탐지 데이터를 살펴보면 Amount라는 column과 Time이라는 column이 존재합니다.그리고 V1에서 V28까지의 컬럼도 존재하지만 이게 정확히 어떤 것을 뜻하는 것인지 알 수가 없죠.그러니 이번에는 Amount와 Time 컬럼에 focus를 두고 데이터를 살펴봅니다.먼저 Amount와 Time의 데이터 분포를 살펴봅니다. python seaborn을 사용하여서 distplot을 이용해 데이터 분포를 살펴보겠습니다.seaborn의 distplot을 이용해서 amount와 time을 보았는데 데이터가 특이한 점이 있습니다.Amount는 대부분 0 부분쪽에 쏠려있는 경향이 있습니다. 하지만 아~주 미세하게 25000까지 쭉 이어져있죠.또한, Time 컬럼은 데이터 분포가 Amount보다는 고르지만 최소 0부터 16만이 넘는 값이 존재하고 있습니다. 이 두 개의 문제는 지금 데이터 분포가 너무 크다는 것입니다.이렇게 데이터 분포가 커지게 되면 머신러닝 모델이 제대로 동작되지 않을 수 있습니다. 큰 값에 쏠려버리는 경우가 있을 수 있기 때문입니다.따라서 이렇게 데이터 분포가 고르지 않을 경우에는 데이터 분포를 data normalization 과정을 거쳐주어야 합니다.data normalization 과정에서는 표준화(Standardization)으로 바꿔주는 방법, 0 ~ 1 범위로 축소하는 방법 등 다양한 방법이 있습니다.여기서는 Standardization과 log scale 등을 적용해보겠습니다. Amount 컬럼 data normalization먼저 Amount 컬럼에 데이터 정규화를 적용하고 다시 seaborn으로 살펴보겠습니다. Amount에서는 StandardScaler를 사용해서 Standardization 분포와 log scale을 살펴봅니다.왼쪽이 log scale로 데이터 정규화를 진행한 그래프고 오른쪽이 standard scale로 변경한 그래프입니다.둘 다 데이터 분포가 0 ~ 25000이 되었던 것에 비해서 상당히 많이 줄었습니다.이 중 standard scale은 기존에 Amount와 데이터 분포가 상당히 유사합니다.그래서 여기서는 standard scale을 채택하려고 합니다! Time 컬럼 data normalization다음으로 Time 컬럼을 보겠습니다.Time에서는 Robust scale과 log scale, standard scale 3개의 scaler로 데이터 normalization을 진행하겠습니다.3개의 그림은 왼쪽부터 robust scale, log scale, standard scale입니다.기존 데이터 분포와 비슷한 것은 robust scale과 standard scale입니다. 그 중 robust scale이 데이터 분포가 좀 더 적게 나왔고 (결과론 적이지만) overfitting이 걸리지 않기 때문에 이것으로 채택하겠습니다. 정규화(data normalization)된 데이터 추가자! 여기까지 TIme과 Amount에 대해서 데이터 정규화를 진행했습니다.그리고 Amount에서는 standard(표준화)를, Time에서는 Robust를 채택하기로 했죠이제 Amount와 TIme 데이터를 이 정규화된 데이터로 바꿔주고 기존에 불필요한 데이터는 drop하겠습니다. dataframe에 있었던 불필요한 컬럼을 drop해줍니다.근데 문제가 이렇게 하면 맨 마지막에 scaled_amount와 scaled_time이 들어가있습니다.이를 맨 앞으로 빼내야지 나중에 class(target)을 뽑을 떄 불편하지도 않고 보기도 좋습니다. 그래서 맨 앞으로 빼냅니다 머신러닝 모델 평가자! 이제 이 상태에서 머신러닝 모델을 평가해보겠습니다.지난 포스팅에서 로지스틱 회귀(logistic regression)과 lightgbm 2개의 머신러닝 모델을 적용해서신용카드 사기를 탐지할 수 있는 모델을 만들었는데요 이제 데이터 정규화(data normalization)을 진행한 현재 상태에서 머신러닝 모델들이 어떻게 성능이 변화되는지 살펴봅니다. 짠! 이렇게 나오는군요지난 포스팅에서 logistic regression 모델의 평가는 아래와 같았습니다.정밀도 : 0.77재현율 : 0.53f1-score : 0.62하지만 지금 로지스틱 회귀 성능을 보시면 정밀도 : 0.87재현율 : 0.66f1-score : 0.75이렇게 변경이 되었습니다. lightgbm의 모델 성능은 변화가 없구요.즉, 여기서 알 수 있는 것은! 로지스틱 회귀(logistic regression)의 성능은 데이터 분포가 중요하다!이것을 알 수 있습니다. 이제 다음 포스팅에서 더 이어서 신용카드 사기 탐지를 진행해보겠습니다.https://lsjsj92.tistory.com/556 머신러닝, 딥러닝 이상치(outlier) 데이터 탐지 및 제거 하기 - outlier data detection and remove포스팅 개요 이번 포스팅은 머신러닝과 딥러닝에서 많이 사용하는 데이터 이상치 탐지(outlier detection)에 대해서 작성합니다. 또한, 지난 포스팅인 캐글의 신용카드 사기 탐지 대회 데이터셋(kaggle credit car..lsjsj92.tistory.com 반응형(adsbygoogle = window.adsbygoogle || []).push({});그리드형(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_GlGkg5lx', {ignore_items: true});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//lsjsj92.tistory.com/reaction';window.ReactionReqBody = {    entryId: 555}공유하기게시글 관리꿈 많은 사람의 이야기저작자표시 'machine learning(머신러닝)' 카테고리의 다른 글머신러닝 스태킹 앙상블(stacking ensemble) 이란? - 스태킹 앙상블 기본편(stacking ensemble basic)  (3)2019.12.19머신러닝, 딥러닝 이상치(outlier) 데이터 탐지 및 제거 하기 - outlier data detection and remove  (10)2019.12.15머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud  (0)2019.12.02머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자  (2)2019.11.22머신러닝 앙상블(ensemble) xgboost란? - Python 예제와 함께 살펴보기  (15)2019.11.21TagData Science, Kaggle, lightgbm, machine learning, machine-learning, Normalization, Standard, 머신러닝, 정규화, 캐글공유하기 링크페이스북카카오스토리트위터'machine learning(머신러닝)' Related Articles머신러닝 스태킹 앙상블(stacking ensemble) 이란? - 스태킹 앙상블 기본편(stacking ensemble basic)2019.12.19머신러닝, 딥러닝 이상치(outlier) 데이터 탐지 및 제거 하기 - outlier data detection and remove2019.12.15머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud2019.12.02머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자2019.11.22more0  Comments댓글쓰기 폼이름비밀번호                                        Secret                                    내용SendloadedComments[555]=true;findFragmentAndHighlight(555);            Blog is powered by            kakao / Designed by            Tistoryif(!wcs_add) var wcs_add = {};wcs_add[""wa""] = ""1498aaff6eff2c0"";if(window.wcs) {wcs_do();}티스토리툴바꿈 많은 사람의 이야기구독하기                    (function () {                         var blogTitle = '꿈 많은 사람의 이야기';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()if(!wcs_add) var wcs_add = {};   wcs_add[""wa""] = encodeURI(""1498aaff6eff2c0"");   wcs_do();document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2798029-555"",""customProps"":{""userId"":""0"",""blogId"":""2798029"",""entryId"":""555"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""555"",""entryTitle"":""머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization)"",""entryType"":""POST"",""categoryName"":""machine learning(머신러닝)"",""categoryId"":""853217"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""3704517"",""authorNickname"":""이수진의 블로그"",""blogNmae"":""꿈 많은 사람의 이야기"",""image"":""kage@btJar1/btqAnn12FzJ/dzwssK2lLVzltZikiNJHBk"",""plink"":""/555"",""tags"":[""Data Science"",""Kaggle"",""lightgbm"",""machine learning"",""machine-learning"",""Normalization"",""Standard"",""머신러닝"",""정규화"",""캐글""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
114,https://jpub.tistory.com/918,태그,"도서 소개파이토치 첫걸음 제이펍2019. 5. 9. 15:28정말정말 쉽게 시작하는 파이토치&딥러닝 입문!실무에도 바로 활용할 수 있는 파이토치 입문서!종이책 구매 사이트(가나다 순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]출판사 제이펍원출판사 쇼에이샤(翔泳社)원서명 現場で使える！PyTorch開発入門(원서 ISBN: 9784798157184)저자명 두세교역자명 김완섭출판일 2019년 5월 9일페이지 232쪽시리즈 I♥A.I. 16 (아이러브A.I. 16)판  형 크라운판 변형(170*225*14)제  본 무선(soft cover)정  가 24,000원ISBN 979-11-88621-59-0 (93000)키워드 파이토치 / 인공지능 / 딥러닝 / 머신러닝 / 프레임워크 / 신경망 / 오픈 소스 프로젝트 / 구글 컬래버레터리 / 주피터 노트북분야 인공지능 / 딥러닝관련 사이트■ 저작권사 도서소개 페이지■ 아마존 도서소개 페이지■ 파이토치 공식 사이트관련 포스트■ 2019/04/18 - [출간전 책소식] - 딥러닝 때문에 얼굴 찌푸리지 말아요~♪ 파이토치와 이 책이 있잖아요! 관련 시리즈■ I♥A.I. 시리즈관련 도서(* 관련 시리즈 참고)관련 파일 다운로드■ 예제 코드 다운로드(깃헙)  강의보조자료 다운로드교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표샘플 PDF(차례, 옮긴이 머리말, 시작하며, 이 책의 대상 독자와 필요한 사전 지식, 이 책의 구성, About the SAMPLE: 이 책의 개발 환경과 예제 프로그램, 베타리더 후기, 프롤로그 '개발 환경 준비', 1장 '파이토치의 기본' 일부, 2장 '최대 우도 추정과 선형 모델' 일부, 3장 '다층 퍼셉트론' 일부, 4장 '이미지 처리와 합성곱 신경망' 일부, 5장 '자연어 처리와 순환 신경망' 일부) sample_파이토치첫걸음.pdf정오표 페이지■ (등록되는 대로 링크를 걸어 드리겠습니다)종이책 구매 사이트(가나다 순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]도서 소개실무에도 바로 활용할 수 있는 파이토치 입문서!딥러닝의 파이썬 라이브러리로는 구글이 개발한 텐서플로(TensorFlow) 프레임워크가 가장 유명하지만, 심벌을 사용하는 프로그래밍 스타일 때문에 초보자가 접근하기 어렵다는 의견도 존재한다. 반면 이 책에서 다루는 파이토치는 페이스북을 중심으로 개발된 오픈 소스 프로젝트로 동적 네트워크라는 구조를 도입했으며, 일반적인 파이썬 프로그램과 같은 환경에서 간단하게 신경망을 구축할 수 있다는 점에서 많은 관심을 받고 있다. 특히, 해외 연구자들로부터 많은 지지를 받고 있어서 최신 연구들이 파이토치를 사용해 구현되는 중이다. 연구 결과들도 깃허브를 통해 빠르게 공개되는 것이 당연시되고 있다. 아직 한글 자료는 부족하지만, 사용하기 쉽고 최신 연구 결과를 바로 적용할 수 있어서 서비스에 딥러닝을 곧바로 적용하고 싶은 사람에게는 최적의 프레임워크가 될 것이다. 이 책을 통해서 독자 여러분이 신경망이나 딥러닝, 그리고 머신러닝 등에 흥미를 가지고 실제로 자신의 업무에 적용할 수 있게 되기를 바란다.- ‘시작하며’ 중에서이 책의 대상 독자인공지능을 배우고자 하는 프로그래머머신러닝 및 딥러닝 엔지니어저자 소개두세교(杜世橋)도쿄공업대학에서 계산 기기를 활용한 분자생물학을 연구했으며, 졸업 후에는 IT 기업에서 소프트웨어 개발 및 데이터 분석을 담당하고 있다. 대학원 시절에 아직 유명해지기 전이었던 파이썬과 NumPy를 접했고, 스터디 모임이나 집필 등을 통해 파이썬을 전파했다. 요근래 몇 년 동안은 스타트업을 중심으로 데이터 분석이나 머신러닝 개발 지원 등을 해왔으며, 2018년 4월부터 물류 IT 관련 스타트업에서 근무하고 있다. 머신러닝, 빅데이터 분석, 서버 개발 등에 관심이 많으나, 지금은 자녀 교육을 위해 육아 휴직 중인 아빠 엔지니어다.역자 소개김완섭네덜란드 ITC에서 Geoinformation for Disaster Risk Management 석사 학위를 취득했다. 약 9년간 일본과 한국의 기업에서 IT 및 GIS/LBS 분야 업무를 담당했으며, 일본에서는 세콤(SECOM) 계열사인 파스코(PASCO)에서 일본 외무부, 국토지리정보원 같은 정부기관을 대상으로 한 시스템 통합(SI) 업무를 담당했다. 이후 야후 재팬으로 직장을 옮겨 야후맵 개발 담당 시니어 엔지니어로 근무했으며, 한국으로 돌아와 SK에서 내비게이션 지도 데이터 담당 매니저로 근무했다. 현재는 싱가포르에 있는 일본계 회사에서 은행 관련 IT 프로젝트를 담당하고 있다. 저서로는 《나는 도쿄 롯폰기로 출근한다》가 있으며, 역서로는 《알고리즘 도감》, 《처음 만나는 HTML5 & CSS3》, 《인공지능 70》, 《처음 만나는 자바스크립트》, 《다양한 언어로 배우는 정규표현식》, 《그림으로 공부하는 IT 인프라 구조》, 《그림으로 공부하는 시스템 성능 구조》 등 20여 종이 있다. 블로그를 통해 IT 번역 관련 이야기와 싱가포르 직장 생활을 소개하고 있다.차례PROLOGUE 개발 환경 준비 10.1 이 책의 검증 환경 20.1.1 OS 환경: 우분투 16.04 20.1.2 엔비디아의 GPU 20.1.3 클라우드에서 GPU를 탑재한 인스턴스 실행하기 30.2 개발 환경 구축 50.2.1 미니콘다 설치 50.2.2 가상 환경 구축 7   더보기접기CHAPTER 1 파이토치의 기본 111.1 파이토치의 구성 121.1.1 파이토치의 전반적인 구성 121.2 텐서 131.2.1 텐서 생성과 변환 131.2.2 텐서의 인덱스 조작 151.2.3 텐서 연산 161.3 텐서와 자동 미분 201.4 정리 22CHAPTER 2 최대 우도 추정과 선형 모델 232.1 확률 모델과 최대 우도 추정 242.2 확률적 경사 하강법 262.3 선형 회귀 모델 282.3.1 선형 회귀 모델의 최대 우도 추정 282.3.2 파이토치로 선형 회귀 모델 만들기(직접 만들기) 302.3.3 파이토치로 선형 회귀 모델 만들기(nn, optim 모듈 사용) 322.4 로지스틱 회귀 352.4.1 로지스틱 회귀의 최대 우도 추정 352.4.2 파이토치를 사용한 로지스틱 회귀 분석 362.4.3 다중 분류를 위한 로지스틱 회귀 분석 402.5 정리 42CHAPTER 3 다층 퍼셉트론 433.1 MLP 구축과 학습 443.2 Dataset과 DataLoader 483.2.1 Dataset과 DataLoader 483.3 학습 효율화 팁 503.3.1 Dropout을 사용한 정규화 503.3.2 Batch Normalization를 사용한 학습 가속 533.4 신경망의 모듈화 553.4.1 자체 신경망 계층(커스텀 계층) 만들기 553.5 정리 57CHAPTER 4 이미지 처리와 합성곱 신경망 594.1 이미지와 합성곱 계산 604.2 CNN을 사용한 이미지 분류 624.2.1 Fashion-MNIST 624.2.2 CNN 구축과 학습 654.3 전이 학습 694.3.1 데이터 준비 724.3.2 파이토치를 사용한 전이 학습 754.4 CNN 회귀 모델을 사용한 이미지 해상도 향상 804.4.1 데이터 준비 804.4.2 모델 작성 834.5 DCGAN을 사용한 이미지 생성 894.5.1 GAN이란 894.5.2 데이터 준비 904.5.3 파이토치를 사용한 DCGAN 914.6 정리 101CHAPTER 5 자연어 처리와 순환 신경망 1035.1 RNN이란? 1045.2 텍스트 데이터의 수치화 1065.3 RNN과 문장 분류 1095.3.1 IMDb 리뷰 데이터 1095.3.2 신경망 정의와 훈련 1135.3.3 가변 길이 계열 처리 1185.4 RNN을 사용한 문장 생성 1215.4.1 데이터 준비 1225.4.2 모델 정의 및 학습 1245.5 인코더-디코더 모델을 사용한 기계 번역 1295.5.1 인코더-디코더 모델이란 1305.5.2 데이터 준비 1315.5.3 파이토치를 사용한 인코더-디코더 모델 1355.6 정리 142CHAPTER 6 추천 시스템과 행렬 분해 1436.1 행렬 인수분해 1446.1.1 이론적 배경 1446.1.2 MovieLens 데이터 1456.1.3 파이토치에서 행렬 인수분해하기 1476.2 신경망 행렬 인수분해 1516.2.1 행렬 인수분해를 비선형화 1516.2.2 부속 정보 이용 1536.3 정리 160CHAPTER 7 애플리케이션 적용 1617.1 모델 저장과 불러오기 1627.2 플라스크를 사용한 웹 API화 1647.3 도커를 이용한 배포 1737.3.1 nvidia-docker 설치 1747.3.2 파이토치의 도커 이미지 작성 1757.3.3 웹 API 배포 1767.4 ONNX를 사용한 다른 프레임워크와의 연계 1797.4.1 ONNX란 1797.4.2 파이토치 모델 엑스포트 1817.4.3 Cae2에서 ONNX 모델 사용하기 1837.4.4 ONNX 모델을 Cae2 모델로 저장 1847.5 정리 186APPENDIX A 훈련 상태 가시화 187A1.1 텐서보드를 사용한 가시화 188APPENDIX B 컬래버레터리로 파이토치 개발 환경 구축 193B1.1 컬래버레터리를 사용한 파이토치 개발 환경 구축 방법 194B1.1.1 컬래버레터리란 194B1.1.2 장비 사양 194B1.1.3 파이토치 환경 구축 195B1.1.4 데이터 처리 201접기window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 918}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글업무와 일상을 정리하는 새로운 방법 Notion  (0)2019.05.15송쌤의 엔트리 게임 코딩 학교  (1)2019.05.14빅 너드 랜치의 코틀린 프로그래밍  (0)2019.03.29테라폼: 설치에서 운영까지  (0)2019.03.29앤디 필드의 유쾌한 R 통계학  (14)2019.02.28태그pytorch, 구글 컬래버레터리, 딥러닝, 머신러닝, 신경망, 오픈 소스 프로젝트, 인공지능, 주피터 노트북, 파이토치, 프레임워크'도서 소개' Related Articles업무와 일상을 정리하는 새로운 방법 Notion송쌤의 엔트리 게임 코딩 학교빅 너드 랜치의 코틀린 프로그래밍테라폼: 설치에서 운영까지Secret댓글달기loadedComments[918]=true;findFragmentAndHighlight(918);"
115,https://zoa0.tistory.com/4,태그,"마이스터고 취업/삼성전자마이스터고에서 삼성전자를 제일 쉽게 가는법 - 2편 프로에 관하여2021. 1. 17. 02:25 학교선택을 다 했다면 이제 준비를 할 차례이다. 입학전에는 무엇을 해야하는가?  입학전에는 시간이 매우 널널할것이다. 망쳐도 되는 기말고사, 넘쳐나는 자습기간, 누워서 폰 등등  입사 확률을 높이려면 남들과 다른 '차별성'이 필요합니다. 이 기간에는 남들이 쉽게 하지 않는것으로 자기개발을 하면 된다.  삼성전자의 특채 자격 조건은 이렇다.  1. 내신 성적 30% 이내 2. 추천인원 내에 들기 ( 약 정원의 15% ~ 20%) 이 두가지만 만족하면 누구든지 서류에 넣을 수 있다. 1번은 입학전에 직접적으로 할 수 없다. 간접적으로 내가 입학할 학교가 사용하는 출판사 교재를 사용하여 수학 선행학습, 영어, 전공과목 필기 취득 이정도면 내신은  전교권안에 들어갈 것이다. 시험난이도는 중학교때와 99%일치한다. 걱정하지 말자 노력으로 커버 가능하다. 2번. 마이스터고 점수란 것이있는데 이것으로 줄서기를 시킨다. 특채를 받으려면 필수적인 요소이다.대표적으로 토익이 가장높은 점수를 차지하고 그다음 제2외국어 (중국어, 일본어) 삼성전자를 목표로 한다면 중국에 삼성전자 사업장이 많기 때문에 무조건 무조건 중국어를 선택하길 바란다. 그다음 컴퓨터활용능력 1,2급  한국사 검정능력독서기록, 봉사 , 전공자격증 취득, 교내상장 등등 있다. 서류전형을 합격한다면 그다음 필기전형이 있다. 필기전형은 다른기업에 비해 매우 쉬운편이다. 서류전형에 합격한다면 약 3.5명중 한명을 뽑는 어려운 난이도의 면접이 있을 것이다.  이 최종면접만 합격하면 최종합격이다.  그러면 무엇을 해야할까? 잘 선택을 못하겠다면 순서를 정해주겠다. 1. 전기기능사 필기 취득이것만한 자격증이 없다. 삼성전자 서류합격률이 제일 높은 자격증이다. 또한 대형채용하는 한국전력공사 역시 이 자격증을 자격요건으로 필요로 한다. 2.전공자격증 필기 취득내신+마이스터점수를 한번에 챙길 수 있다. 남들과 차별성을 가질 제일 좋은 기회이다. 3.토익 500점 취득토익을 하고가면 대기업갈시에 장점이 매우 많다. 교내 상장, 큰 마이스터점수, 영어 내신 4. hsk3급 취득삼성전자하면 이자격증을 빼놓을 수 없다. 설비엔지니어 직군의 승진자격증에 포함되어있다. 조금 힘들겠지만 미래를 생각하며 따놓자. 이것또한 내신 + 마이스터점수 + 교내상장 을 받을 수 있다.  5. 오픽 im3 취득4번과 마찬가지로 설비엔지니어의 승진자격증에 포함된다. hsk와 면접에서 어필하기 좋은 자격증이다. 이것은 높은 등급일수록 재능이 좀 필요하기때문에 노력으로 im3를 취득하고 나서 좀 재능있다 판단하면 조금 더 연습에서 오픽 ih를 따버리면 된다. 6. 컴퓨터활용능력 1급 필기컴맹이 아니라면 금방 딸 수 있는 자격증이다. 이것만 하면 끝이다. 힘을내자  7. Gsat 풀어보기 5급 전용을 쇼핑몰같은곳에서 사서 더도말고 한권만 이해중심으로 풀어보자. 당장 일이 닥치지 않아서 매우 지루할 것이다. 욕심이 난다면 해보자. 솔직히 1~6만 하고 학교에서 실기만 취득해도 서류전형은 90%이상 합격이다. 학교생활이 엄청 편해진다는 말이다. 안전하게 취직하고 싶으면 흘려보지 말고 꼭 해보자   다음편에는 면접준비에대한 예상질문과 면접하기 쉬운 자소서 작성 요령이 있다. 마이스터고에서 삼성전자를 제일 쉽게 가는법 -3편 면접준비 (tistory.com)  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//zoa0.tistory.com/reaction';window.ReactionReqBody = {    entryId: 4}공유하기게시글 관리IT Archive - 아이티 아카이브 '마이스터고 취업 > 삼성전자' 카테고리의 다른 글마이스터고에서 삼성전자를 제일 쉽게 가는법 -3편 면접준비  (1)2021.01.17마이스터고에서 삼성전자를 제일 쉽게 가는 방법 - 학교선택  (0)2021.01.17태그고졸채용, 마이스터고, 삼성, 삼성전자, 삼성전자 고졸, 삼성전자 설비엔지니어, 설비엔지니어, 연봉, 월급, 특성화고'마이스터고 취업/삼성전자' Related Articles마이스터고에서 삼성전자를 제일 쉽게 가는법 -3편 면접준비마이스터고에서 삼성전자를 제일 쉽게 가는 방법 - 학교선택    setInitialEntryComments(4, 1723627700)Secret댓글달기loadedComments[4]=true;findFragmentAndHighlight(4);"
116,https://jpub.tistory.com/1314,"베테랑에게 배우는 파이써닉한 애플리케이션 구축, 유지보수, 패키징 기법 ","도서 소개전문가를 위한 파이썬 프로그래밍(제4판) 제이펍2022. 9. 5. 11:07베테랑에게 배우는 모던 파이썬 개발의 베스트 프랙티스와 인사이트   도서구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 출판사 제이펍저작권사 Packt Publishing원서명 Expert Python Programming, 4th Edition (9781801071109)도서명 전문가를 위한 파이썬 프로그래밍(제4판)부제 애플리케이션 구축, 유지보수, 패키징, 배포 등 모던 파이썬 개발 마스터하기지은이 미하우 야보르스키, 타레크 지아데옮긴이 김모세감수자 (없음)시리즈 (없음)출판일 2022. 08. 12페이지 592쪽판 형 46배판변형(188*245*29.0)제 본 무선(soft cover)정 가 38,000원ISBN 979-11-92469-20-1 (93000)키워드 파이썬, 유지보수, 패키징, 배포, 패턴매칭, 테스트, 메타프로그래밍, 동시성, 자료구조, 알고리즘분 야 프로그래밍 언어 / 파이썬 관련 사이트 ■ 파이썬 공식 사이트 관련 사이트■ 아마존 도서 페이지■ 저작권사 도서 페이지 관련 포스트■ 2022.07.29 - [출간 전 책 소식] - 가장 깊은 곳까지 놀라운 파이썬 여행 관련 시리즈■ (없음) 관련 도서■ 실무에 바로 적용하는 파이썬 코드 레시피 302■ 알 스웨이가트의 파이썬 프로젝트 관련 파일 다운로드 ■ https://github.com/moseskim/Expert-Python-Programming-Fourth-Edition/   강의 보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음 자료를 보내드립니다.)■ 본문의 그림과 표 ■ 미리보기(지은이·옮긴이 소개, 기술 감수자 소개, 옮긴이 머리말, 베타리더 후기, 감사의 글, 이 책에 대하여, 1장, 2장 일부) 정오표 페이지 ■ https://jpub.tistory.com/1316 도서구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 도서 소개베테랑에게 배우는 파이써닉한 애플리케이션 구축, 유지보수, 패키징 기법 파이썬 코드를 작성하기는 쉽지만, 유지보수하기 좋은 환경을 갖추고 가독성 높은 코드를 만들기는 쉽지 않다. 이 책은 수년간 다양한 파이썬 애플리케이션을 구현한 전문 경험을 담아, 프로덕션 레벨에서 파이썬을 파이썬답게 쓰기 위해 알아야 할 모든 것을 망라한 지침서다. 전문 파이썬 프로그래머라면 꼭 알아야 할 애플리케이션 구축, 유지보수, 패키징, 배포 방법을 자세히 살펴보고, 베스트 프랙티스, 유용한 도구, 표준을 배울 수 있다.  1~4장에서는 파이썬 프로그래머들이 이용하는 도구의 기본적인 요소들에 초점을 맞춘다. 생산성 도구, 현대적인 환경, 최신 파이썬 릴리스에서 도입된 새로운 구문 요소들을 살펴본다. 서로 다른 디펜던시들로 구성된 복잡한 환경을 세팅하는 우아한 방법부터 딕셔너리 병합, zoneinfo, 구조적 패턴 매칭 등 최신 파이썬 피처까지, 특히 다른 언어에서 파이썬으로 전향하는 개발자가 모던 파이썬 개발의 세계에 안착하는 데 도움을 준다.  5~9장에서는 디자인 패턴, 프로그래밍 패러다임, 메타프로그래밍 기법에 관해 살펴본다. 작은 규모의 예제 프로그램을 구현해보고 애플리케이션 아키텍처에 대해서도 깊이 다룬다. 인터페이스, 동시성, 이벤트 주도 프로그래밍/아키텍처 등 현대 애플리케이션 구축에서 반드시 고려해야 하는 요소를 파이써닉하게 구현하는 방법을 배운다. 파이썬의 태생적 성능 한계를 극복하기 위해 C/C++ 코드를 파이썬에 통합하는 방법도 살펴본다.  10~13장에서는 애플리케이션을 구축한 이후 쉽게 유지보수하는 데 도움이 되는 도구와 기법들을 살펴본다. 테스팅, 패키징 및 배포, 로깅 및 모니터링, 코드 최적화 등 개발 수명주기의 마지막 단계에 대해서도 다른 곳에서는 찾아보기 어려운 인사이트를 얻을 수 있다.  베테랑 개발자가 엄선한 베스트 프랙티스, 유용한 도구, 표준을 익힘으로써 파이썬 전문가에 한 걸음 더 가까워질 수 있다. 모던 파이썬 개발의 가장 깊은 곳으로 뛰어들자.  주요 내용■ 반복 가능하고 일관된 파이썬 개발 환경을 세팅하는 최신 방법들 ■ 커뮤니티 및 프로덕션 사용을 위해 파이썬 코드를 효과적으로 패키징하는 법 ■ f-string, enum, lambda 함수 등 모던 파이썬 구문 학습 ■ 메타클래스를 이용해 복잡한 파이썬 메타프로그래밍 쉽게 익히기 ■ 파이썬 동시성 코드 작성 ■ C/C++ 코드와 파이썬 코드의 통합   지은이 소개미하우 야보르스키(Michał Jaworski)10년 이상 다양한 프로그래밍 언어를 이용해 전문적으로 소프트웨어를 작성했다. 주로 웹 애플리케이션을 위한 고성능 분산 백엔드 서비스 코드를 만들었다. 소프트웨어 엔지니어에서 리드 소프트웨어 아키텍트까지 여러 기업에서 다양한 역할을 했다. 과거부터 지금까지 파이썬을 가장 선호한다. 국내에 번역된 책으로는 《파이썬을 이용한 머신러닝, 딥러닝 실전 개발 입문(개정판)》(2019), 《모던 자바스크립트 개발자를 위한 리액트 프로그래밍》(2017), 《러닝스쿨! 파이썬 교과서》(이상 위키북스, 2017), 《자바스크립트와 Node.js를 이용한 웹 크롤링 테크닉》(제이펍, 2016) 등이 있다.타레크 지아데(Tarek Ziadé)프랑스 부르고뉴에 거주하는 소프트웨어 엔지니어. 일래스틱Elastic에서 개발자를 위한 도구를 만들고 있다. 이전에는 모질라에서 10여 년간 일했으며, 프랑스 파이썬 사용자 그룹인 AFPy를 설립했다. 다양한 잡지에 파이썬 관련 글을 기고했으며, 프랑스어와 영어로 여러 책을 집필했다. 국내에는 《파이썬 마이크로서비스》(에이콘출판사, 2019), 《파이썬 핵심 개발자들과의 인터뷰》(터닝포인트, 2019)로 소개된 바 있다.   옮긴이 소개김모세대학 졸업 후 소프트웨어 엔지니어, 소프트웨어 품질 엔지니어, 애자일 코치 등 다양한 부문에서 소프트웨어 개발에 참여했다. 재미있는 일, 나와 조직이 성장하고 성과를 내도록 돕는 일에 보람을 느끼며 나 자신에게 도전하고 더 나은 사람이 되기 위해 항상 노력하고 있다. 저서로 《코드 품질 시각화의 정석》(지앤선, 2015)이 있고, 옮긴 책으로는 《제대로 배우는 수학적 최적화》(한빛미디어, 2021), 《그림으로 배우는 TCP/IP》, 《파이썬 머신러닝 실무 테크닉 100》, 《라라벨 실전 웹 애플리케이션 개발》(이상 제이펍, 2021) 등이 있다.  차례지은이·옮긴이 소개 xi기술 감수자 소개 xii옮긴이 머리말 xiii베타리더 후기 xv감사의 글 xvii이 책에 대하여 xviii CHAPTER 1 파이썬의 현재 11.1 파이썬의 현재와 진행 상황 21.2 파이썬 2의 현재와 미래 31.3 최신 정보의 확인과 습득 5__1.3.1 PEP 문서 6__1.3.2 활성화된 커뮤니티 8__1.3.3 기타 자료들 101.4 요약 12 CHAPTER 2 모던 파이썬 개발 환경 132.1 기술적 요구 사항 142.2 파이썬 패키징 생태계 15__2.2.1 pip를 이용한 파이썬 패키지 설치하기 152.3 런타임 환경 격리 17__2.3.1 애플리케이션 레벨 격리 vs. 시스템 레벨 격리 202.4 애플리케이션 레벨 환경 격리 22__2.4.1 포어트리: 디펜던시 관리 시스템 24더보기2.5 시스템 레벨 환경 격리 29__2.5.1 컨테이너화 vs. 가상화 31__2.5.2 도커를 이용한 가상 환경 33__2.5.3 베이그런트를 이용한 가상 개발 환경 522.6 유명한 생산성 도구들 54__2.6.1 커스텀 파이썬 셸 55__2.6.2 IPython 이용하기 56__2.6.3 커스텀 스크립트 및 프로그램과 셸 연동하기 59__2.6.4 인터랙티브 디버거 60__2.6.5 기타 생산성 향상 도구 622.7 요약 64 CHAPTER 3 파이썬의 새로운 기능 653.1 기술 요구 사항 663.2 최근의 언어 추가 사항 66__3.2.1 딕셔너리 병합 및 업데이트 연산자 67__3.2.2 할당 표현식 72__3.2.3 타입 힌팅 제네릭 76__3.2.4 위치 전달만 가능한 매개변수 78__3.2.5 zoneinfo 모듈 81__3.2.6 graphlib 모듈 823.3 그다지 새롭지는 않지만 여전히 멋진 요소들 86__3.3.1 breakpoint() 함수 86__3.3.2 개발 모드 88__3.3.3 모듈 레벨 __getattr__() 및 __dir__() 함수 90__3.3.4 f-string을 이용한 문자열 서식 지정 91__3.3.5 숫자 리터럴의 언더스코어 93__3.3.6 secrets 모듈 933.4 미래에 관한 예상 95__3.4.1 | 연산자를 이용한 유니언 타입 95__3.4.2 구조적 패턴 매칭 963.5 요약 101 CHAPTER 4 파이썬과 다른 언어와의 비교 1034.1 기술적 요구 사항 1044.2 클래스 모델과 객체 지향 프로그래밍 104__4.2.1 슈퍼클래스로의 접근 105__4.2.2 다중 상속과 메서드 결정 순서 107__4.2.3 클래스 인스턴스 초기화 113__4.2.4 속성 접근 패턴 117__4.2.5 디스크립터 118__4.2.6 프로퍼티 1254.3 동적 다형성 131__4.3.1 연산자 오버로딩 132__4.3.2 함수 및 메서드 오버로딩 1394.4 데이터 클래스 1434.5 함수형 프로그래밍 147__4.5.1 람다 함수 149__4.5.2 map(), filter(), reduce() 함수 151__4.5.3 부분 객체와 부분 함수 154__4.5.4 제너레이터 155__4.5.5 제너레이터 표현식 156__4.5.6 데커레이터 1574.6 열거형 1594.7 요약 162 CHAPTER 5 인터페이스, 패턴, 모듈성 1635.1 기술적 요구 사항 1645.2 인터페이스 165__5.2.1 간단한 역사: zope.interface 167__5.2.2 함수 애너테이션과 추상 베이스 클래스 이용하기 175__5.2.3 타입 애너테이션을 통한 인터페이스 1815.3 제어 반전과 디펜던시 주입 184__5.3.1 애플리케이션의 통제 반전 186__5.3.2 디펜던시 주입 프레임워크 사용하기 1945.4 요약 200 CHAPTER 6 동시성 2016.1 기술적 요구 사항 2026.2 동시성이란 무엇인가? 2026.3 멀티스레딩 204__6.3.1 멀티스레딩이란? 205__6.3.2 파이썬의 스레드 처리 방식 209__6.3.3 언제 멀티스레딩을 사용해야 하는가? 210__6.3.4 멀티스레드 애플리케이션 예시 2136.4 멀티프로세싱 230__6.4.1 내장 multiprocessing 모듈 233__6.4.2 프로세스 풀 이용하기 237__6.4.3 multiprocessing.dummy를 멀티스레딩 인터페이스로 이용하기 2396.5 비동기 프로그래밍 240__6.5.1 협력적 멀티태스킹과 비동기 I/O 241__6.5.2 파이썬의 async/await 키워드 242__6.5.3 비동기 프로그래밍의 실질적 예 247__6.5.4 비동기가 아닌 코드와 async/future 통합하기 2506.6 요약 254 CHAPTER 7 이벤트 주도 프로그래밍 2557.1 기술적 요구 사항 2567.2 이벤트 주도 프로그래밍이란 무엇인가? 256__7.2.1 이벤트 주도 != 비동기 257__7.2.2 GUI에서의 이벤트 주도 프로그래밍 258__7.2.3 이벤트 주도 통신 2617.3 이벤트 주도 프로그래밍의 다양한 스타일 263__7.3.1 콜백 기반 스타일 263__7.3.2 주체 기반 스타일 265__7.3.3 토픽 기반 스타일 2707.4 이벤트 주도 아키텍처 272__7.4.1 이벤트와 메시지 큐 2737.5 요약 276 CHAPTER 8 메타프로그래밍 요소들 2778.1 기술적 요구 사항 2788.2 메타프로그래밍이란 무엇인가? 2788.3 데커레이터를 이용해 함수의 행동을 사용 전 수정하기 279__8.3.1 한 단계 더: 클래스 데커레이터 2818.4 클래스 인스턴스 생성 프로세스 가로채기 2868.5 메타클래스 289__8.5.1 일반적인 구문 290__8.5.2 메타클래스 사용 예시 293__8.5.3 메타클래스의 함정 297__8.5.4 메타클래스의 대안으로 __init_subclass__() 메서드 이용하기 2988.6 코드 생성 300__8.6.1 exec, eval, compile 301__8.6.2 추상 구문 트리 302__8.6.3 임포트 훅 304__8.6.4 파이썬에서의 유명한 코드 생성 사례 3048.7 요약 307 CHAPTER 9 파이썬에 C와 C++ 연결하기 3099.1 기술적 요구 사항 3119.2 파이썬 확장 기능의 핵심인 C/C++ 3119.3 파이썬 C 확장 기능 컴파일 및 로딩 3129.4 확장 기능 이용의 필요성 314__9.4.1 크리티컬 코드 섹션의 성능 개선 315__9.4.2 다른 언어로 작성된 기존 코드 통합 316__9.4.3 서드파티 다이내믹 라이브러리 통합 316__9.4.4 효율적인 커스텀 데이터 타입 생성 3179.5 확장 기능 작성 317__9.5.1 순수한 C 확장 기능 319__9.5.2 Cython을 이용한 확장 기능 작성 3379.6 확장 기능 사용의 단점 343__9.6.1 추가적인 복잡성 344__9.6.2 보다 어려운 디버깅 3459.7 확장 기능 없이 다이내믹 라이브러리와 인터페이싱하기 345__9.7.1 ctypes 모듈 346__9.7.2 CFFI 3539.8 요약 355 CHAPTER 10 테스팅과 품질 자동화 35710.1 기술적 요구 사항 35810.2 테스트 주도 개발 원칙 35910.3 pytest를 이용해 테스트 작성하기 362__10.3.1 테스트 매개변수화 369__10.3.2 pytest의 픽스처 372__10.3.3 페이크 이용하기 381__10.3.4 목과 unittest.mock 모듈 38510.4 품질 자동화 389__10.4.1 테스트 커버리지 390__10.4.2 스타일 픽서와 코드 린터 394__10.4.3 정적 타입 분석 39710.5 돌연변이 테스팅 39910.6 유용한 테스팅 유틸리티 406__10.6.1 실제적인 데이터값 조작하기 406__10.6.2 시간값 조작하기 40710.7 요약 409 CHAPTER 11 파이썬 코드 패키징과 배포 41111.1 기술적 요구 사항 41211.2 라이브러리 패키징 및 배포 412__11.2.1 파이썬 패키지 구조 413__11.2.2 패키지 배포 유형 422__11.2.3 패키지 등록 및 공개 427__11.2.4 패키지 버저닝과 디펜던시 관리 429__11.2.5 커스텀 패키지 설치 433__11.2.6 네임스페이스 패키지 435__11.2.7 패키지 스크립트와 엔트리 포인트 43711.3 웹용 애플리케이션 및 서비스 패키징 441__11.3.1 12요소 앱 방법론 442__11.3.2 도커 활용하기 444__11.3.3 환경 변수 다루기 446__11.3.4 애플리케이션 프레임워크에서 환경 변수의 역할 45011.4 스탠드얼론 실행 파일 생성 454__11.4.1 스탠드얼론 실행 파일이 유용한 경우 455__11.4.2 널리 알려진 도구들 456__11.4.3 실행 파일 패키지에서 파이썬 코드의 보안 46411.5 요약 465 CHAPTER 12 애플리케이션 동작과 성능 관측 46712.1 기술적 요구 사항 46812.2 에러와 로그 캡처 468__12.2.1 파이썬 로깅 기초 469__12.2.2 좋은 로깅 프랙티스 482__12.2.3 분산 로깅 484__12.2.4 사후 리뷰를 위한 에러 캡처 48712.3 코드와 커스텀 지표 조사 490__12.3.1 프로메테우스 이용 49212.4 분산 애플리케이션 트레이싱 502__12.4.1 Jaeger를 이용한 분산 트레이싱 50512.5 요약 511 CHAPTER 13 코드 최적화 51313.1 기술적 요구 사항 51413.2 나쁜 성능을 발생시키는 일반적인 요소들 514__13.2.1 코드 복잡도 515__13.2.2 과도한 리소스 할당과 누수 519__13.2.3 과도한 I/O와 블로킹 52013.3 코드 프로파일링 521__13.3.1 CPU 사용량 프로파일링 522__13.3.2 메모리 사용량 프로파일링 53013.4 적절한 데이터 구조를 선택하여 복잡도 줄이기 541__13.4.1 리스트 검색하기 541__13.4.2 집합 이용하기 542__13.4.3 collections 모듈 이용하기 54313.5 아키텍처 트레이드오프 활용하기 548__13.5.1 휴리스틱과 근사 알고리즘 이용하기 548__13.5.2 태스크 큐와 지연된 처리 이용하기 550__13.5.3 확률적 데이터 구조 이용하기 553__13.5.4 캐싱 55513.6 요약 563 찾아보기 565  제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!) 네이버 책 포스트 유튜브 인스타그램 트위터 페이스북window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1314}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글누구나 할 수 있는 유니티 2D 게임 제작  (0)2022.09.27예제로 배우는 파이썬 머신러닝(제3판)  (0)2022.09.05삐뽀삐뽀 보안 119  (0)2022.09.01모두를 위한 클라우드 컴퓨팅  (6)2022.08.24디자이너의 포토샵 테크닉 141  (0)2022.08.23태그동시성, 메타프로그래밍, 배포, 알고리즘, 유지보수, 자료구조, 테스트, 파이썬, 패키징, 패턴매칭'도서 소개' Related Articles누구나 할 수 있는 유니티 2D 게임 제작예제로 배우는 파이썬 머신러닝(제3판)삐뽀삐뽀 보안 119모두를 위한 클라우드 컴퓨팅    setInitialEntryComments(1314, 1723618299)Secret댓글달기loadedComments[1314]=true;findFragmentAndHighlight(1314);"
117,https://jpub.tistory.com/677,태그,"도서 소개러닝 스칼라 제이펍2017. 4. 19. 16:42객체지향 프로그래머를 위한 최적의 스칼라 입문서!출판사 제이펍원출판사 O’Reilly원서명 Learning Scala(원서 ISBN 9781449367930)저자명 제이슨 스와츠역자명 김정인, 강성용출판일 2017년 04월 17일페이지 292쪽시리즈 (없음)판  형 (188*245*14)제  본 무선(soft cover)정  가 24,000원ISBN 979-11-85890-79-1 (93000)키워드 Scala / 함수형 프로그래밍/ 스칼라 / 컬렉션 / 객체지향 / JVM분야 프로그래밍 언어 / 스칼라관련 사이트■ 아마존 도서 소개 페이지■ 원출판사 도서 소개 페이지관련 포스트■ 2017/04/11 - [출간전 책소식] - 객체지향 프로그래머를 위한 최적의 스칼라 입문서관련 시리즈■ (없음)관련 도서■ 스칼라로 배우는 함수형 프로그래밍■ 하스켈로 배우는 함수형 프로그래밍관련 파일 다운로드■ 예제 코드 강의보조 자료교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표샘플 PDF(차례, 옮긴이 머리말, 이 책에 대하여, 배타리더 후기, 1장 '스칼라 시작하기', 2장 '데이터로 작업하기: 리터럴, 값, 변수, 타입') 러닝스칼라_sample.pdf정오표 페이지■ http://jpub.tistory.com/686 도서구매 사이트(가나다순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]도서 소개객체지향 프로그래머를 위한 최적의 스칼라 입문서!왜 스칼라를 배울까? 이 객체지향 함수형 프로그래밍 언어를 제대로 이해하기 위해 여러분이 데이터 과학자나 분산 컴퓨팅 전문가일 필요는 없다. 이 책은 구문 다이어그램, 그리고 예제와 실습을 적절히 제공하여 스칼라를 포괄적이지만 이해하기 쉽게 소개하고 있다. 여러분은 고차 함수와 불변의 데이터 구조에 뛰어들기 전에 스칼라의 핵심 타입과 구문에 대해 먼저 배우게 될 것이다.저자 스와츠는 자신의 기술이 나아지기를 원하는 루비나 파이썬 개발자에게 스칼라의 간결하고 표현력 있는 구문이 얼마나 이상적인지를 잘 보여준다. 또한, 어떠한 애플리케이션에도 충분히 안정적이고 빠른 실행을 보장하는 타입 안전성과 성능을 지닌 스칼라를 잘 묘사하고 있다.이 책의 주요 내용■ 핵심 데이터 타입, 리터럴, 값, 변수에 대한 학습■ 스칼라 문법의 기초인 표현식을 생각하고 작성하는 방법■ 불변의 데이터 구조를 익히고 이를 타입에 안전하고 선언적인 연산으로 변경하는 방법■ 기존 연산을 단순화시키거나 여러분만의 영역에 특화된 언어를 시작하기 위한 맞춤형 이항연산자 작성법■ 완전한 재사용을 위해 하나 이상의 트레이트로 구성된 클래스를 생성하거나 인스턴스생성 시 클래스들을 혼합한 새로운 기능 제작법누구를 위한 책인가?이 책은 지금까지 자바(Java), 루비(Ruby), 파이썬(Python)과 같은 객체지향 언어로 작업해왔으며, 스칼라를 배워 자신의 기술을 발전시키고자 하는 개발자들을 위한 책이다. 추천사《러닝 스칼라》는 우리에게 친숙한 객체지향 스타일을 스칼라의 자연스러운 특징들과 결합하여 초보자들도 이해하기 쉽게 설명하고 있다. 이 책은 처음 스칼라를 시작할 때 읽고 싶었던 바로 그 책이다!_ 캐서린 펠로우, 컴캐스트(Comcast)의 소프트웨어 엔지니어지은이 소개제이슨 스와츠(Jason Swartz)제이슨 스와츠는 샌프란시스코에서 스칼라 커뮤니티 행사를 기획하고, 넷플릭스의 소비자 디바이스 프로그램을 위한 애플리케이션을 개발하고 있는 소프트웨어 엔지니어이며, 직관적인 사용자 인터페이스, 표현력 높은 프로그래밍 언어와 간결한 사용자 문서화를 좋아한다. 함수형 프로그래밍으로 전향하기 전에는 이베이(eBay)에서 개발자 문서와 지원팀을 관리하였으며, 자바 기반의 홍보 및 머천다이징 플랫폼을 구축했다. 애플(Apple)에서 도구와 UI 프로토타입을 만들기도 했었다.옮긴이 소개김정인평생을 문과 성향이라 생각하며 지내왔지만, 학업을 포함하여 20여 년간 IT 분야에 종사했다. 회사라는 우산에서 벗어나 꿈이었던 번역을 시작하기 전까지는 BI/BA 분야에 몸담았다. 바라는 것은 늘 이 책으로 가장 먼저 배우는 사람의 자세로 이 일에 임하는 것이다. 현재 가장 관심 있는 분야는 재활운동이다.강성용수능 모의고사를 치르다 교실을 뛰쳐나왔던 그날 이후로 지난 16년간 개발자로 일했으며, 지금은 1인 회사를 만들고 혼자서 사장 노릇 중이다. 역자에 대한 소식은 ulzima.com에서 볼 수 있다. 옮긴 책으로는 《리뷰의 기술》, 《윈도우 파워셸 3 시작하기》, 《C 포인터의 이해와 활용》, 《자바 네트워크 프로그래밍(제4판)》이 있다.차례1부 핵심 스칼라1장 스칼라 시작하기 _ 3스칼라 설치하기 _ 3스칼라 REPL 사용하기 _ 5요약 _ 7연습문제 _ 7더보기접기2장 데이터로 작업하기: 리터럴, 값, 변수, 타입 _ 9값 _ 11변수 _ 13명명 _ 14타입 _ 16    숫자형 데이터 타입 _ 16    문자열 _ 19    스칼라 타입의 개요 _ 23    튜플 _ 28요약 _ 29연습문제 _ 303장 표현식과 조건문 _ 31표현식 _ 32    표현식으로 값과 변수 정의하기 _ 32    표현식 블록 _ 33    문장 _ 34If .. Else 표현식 블록 _ 34    If 표현식 _ 35    If-Else 표현식 _ 36매치 표현식 _ 37    와일드카드로 매칭하기 _ 40    패턴 가드를 이용한 매칭 _ 42    패턴 변수를 이용한 타입 매칭 _ 42루프 _ 43    반복자 가드 _ 46    중첩된 반복자 _ 46    값 바인딩 _ 47    While과 Do/While 루프 _ 48요약 _ 49연습문제 _ 494장 함수 _ 52프로시저 _ 55빈 괄호를 가지는 함수 _ 56표현식 블록을 이용한 함수 호출 _ 57재귀 함수 _ 58중첩 함수 _ 60이름으로 매개변수를 지정하여 함수 호출하기 _ 61기본값을 갖는 매개변수 _ 62가변 매개변수 _ 63매개변수 그룹 _ 64타입 매개변수 _ 64메소드와 연산자 _ 67가독성 있는 함수 작성하기 _ 71요약 _ 73연습문제 _ 735장  일급 함수 _ 75함수 타입과 값 _ 76고차 함수 _ 79함수 리터럴 _ 80자리표시자 구문 _ 83부분 적용 함수와 커링 _ 86이름에 의한 호출 매개변수 _ 88부분 함수 _ 89함수 리터럴 블록으로 고차 함수 호출하기 _ 91요약 _ 94연습문제 _ 946장 보편적인 컬렉션 _ 96리스트, 집합, 그리고 맵 _ 97리스트에는 무엇이 있는가? _ 100    생성 연산자 _ 103리스트 산술 연산 _ 105리스트 매핑 _ 108리스트 축소하기 _ 109컬렉션 전환하기 _ 115    자바와 스칼라 컬렉션 호환성 _ 116컬렉션으로 패턴 매칭하기 _ 117요약 _ 118연습문제 _ 1197장 그 외의 컬렉션 _ 122가변적인 컬렉션 _ 122    새로운 가변 컬렉션 생성하기 _ 123    불변의 컬렉션으로부터 가변적인 컬렉션 만들기 _ 125    컬렉션 빌더 사용하기 _ 126배열 _ 127Seq와 시퀀스 _ 129스트림 _ 131모나딕 컬렉션 _ 133    Option 컬렉션 _ 134    Try 컬렉션 _ 139    퓨처 컬렉션 _ 143요약 _ 149연습문제 _ 1502부 객체지향 스칼라8장 클래스 _ 157클래스 정의하기 _ 163그 외의 클래스 유형 _ 168    추상 클래스 _ 168    익명 클래스 _ 170그 외의 필드와 메소드 유형 _ 171    중복 정의된 메소드 _ 172    apply 메소드 _ 172    지연값 _ 173패키징 _ 175    패키징된 클래스에 접근하기 _ 176    패키징 구문 _ 181프라이버시 제어 _ 182프라이버시 접근 변경자 _ 185종단 클래스와 봉인 클래스 _ 187요약 _ 188연습문제 _ 1889장 객체, 케이스 클래스, 트레이트 _ 192객체 _ 192    Apply 메소드와 동반 객체 _ 195    객체를 가지는 명령줄 애플리케이션 _ 197케이스 클래스 _ 199트레이트 _ 202    셀프 타입 _ 207    트레이트를 이용하여 인스턴스화 _ 210인스턴스 구성원 임포트하기 _ 212요약 _ 214쉬어가는 시간 — 첫 번째 스칼라 프로젝트 환경 설정하기 _ 215연습문제 _ 22110장 고급 타입 특징 _ 229튜플과 함숫값 클래스 _ 231묵시적 매개변수 _ 234묵시적 클래스 _ 236타입 _ 238    타입 별칭 _ 239    추상 타입 _ 240    경계가 있는 타입 _ 241    타입 가변성 _ 244    패키지 객체 _ 249요약 _ 250질문 _ 251부록 A 예약어 _ 253찾아보기 _ 257접기window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 677}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글처음 만나는 알고리즘  (6)2017.04.28프로그래머처럼 생각하라: 문제 해결을 위한 모델 기반 사고법  (0)2017.04.27ROS로 배우는 로봇 프로그래밍  (0)2017.04.04처음 만나는 파이썬  (0)2017.04.04서버/인프라 엔지니어를 위한 DevOps  (0)2017.03.23태그JVM, Scala, 강성용, 객체지향, 김정인, 제이슨 스와츠, 제이펍, 컬렉션, 함수형 프로그래밍'도서 소개' Related Articles처음 만나는 알고리즘프로그래머처럼 생각하라: 문제 해결을 위한 모델 기반 사고법ROS로 배우는 로봇 프로그래밍처음 만나는 파이썬    setInitialEntryComments(677, 1723627700)Secret댓글달기loadedComments[677]=true;findFragmentAndHighlight(677);"
118,https://jpub.tistory.com/1374,태그,"도서 소개리얼월드 암호학 제이펍2023. 1. 20. 16:50 2023 대한민국학술원 우수학술도서 선정세상에서 가장 실용적인 암호학 가이드북  도서구매 사이트(가나다순)[교보문고] [도서11번가] [알라딘] [예스이십사] [인터파크] [쿠팡] 전자책 구매 사이트(가나다순)교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 출판사 제이펍저작권사 Manning원서명 Real-World Cryptography (9781617296710)도서명 리얼월드 암호학부제 블록체인과 양자 컴퓨팅까지 그림과 사례로 실용적으로 익히는 현대 암호학 지은이 데이비드 웡옮긴이 임지순감수자 (없음)시리즈 (없음)출판일 2023. 01. 20페이지 424쪽판 형 46배판변형(188*245*20.4)제 본 무선(soft cover)정 가 34,000원ISBN 979-11-92469-53-9 (93000)키워드 암호, 해시, 서명, HTTPS, 보안, 양자, TLS, 시그널, HSM, ZKP분 야 네트워크 / 보안 관련 사이트■ 아마존 도서 페이지■ 저작권사 도서 페이지 관련 포스트■ 2023.01.09 - [출간 전 책 소식] - 양자 컴퓨터는 암호 보안의 종말을 의미하는가? 관련 시리즈■ (없음) 관련 도서■ (없음) 관련 파일 다운로드■ (없음) 강의 보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음 자료를 보내드립니다.)■ 본문의 그림과 표 미리보기(차례, 옮긴이 머리말, 추천의 글, 베타리더 후기, 시작하며, 감사의 글, 이 책에 대하여, 표지에 대하여, 1장 일부) 정오표 페이지■ (등록되는 대로 링크를 걸겠습니다.) 도서구매 사이트(가나다순)[교보문고] [도서11번가] [알라딘] [예스이십사] [인터파크] [쿠팡] 전자책 구매 사이트(가나다순) 교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 도서 소개수식 대신 그림, 역사 대신 사례, 이론 대신 응용으로 배우는 암호학의 현재와 미래 암호학은 웹 API, 유저 서비스, 블록체인 등 IT 보안의 근간이지만, 유달리 읽을 만한 책이 없다. 카이사르 암호나 비즈네르 암호 같은 역사로 시작하는 책은 지겹다. 현대 암호학이 어떤 요소로 구성되었는지, 어떤 프로토콜이 자주 쓰이며, 어떤 공격 사례가 있었는지, 양자 컴퓨터가 나온 마당에 암호학의 미래는 어떻게 될 것인지. 실무자가 궁금한 건 이런 내용이다. 이 책의 저자는 암호학의 역사나 레거시 알고리즘 대신 TLS, 노이즈 프로토콜 프레임워크, 시그널 프로토콜, 암호화폐(저자는 이 책이 암호화폐를 한 챕터로 다루는 최초의 암호학 책이라고 주장한다!), HSM, 임곗값 암호학 등 오늘날 실제로 대규모로 사용되는 사례로 이 책을 채웠다. 수식이 없을 수는 없지만, 우리에게 친숙한 앨리스와 밥을 포함해 수많은 그림을 삽입해 알기 쉽게 설명하려 노력했다. 저자 본인 역시 대학에서 배운 타원 곡선 수학이 현실 세계 알고리즘에서 어떻게 사용되는지 알 수 없었고, 많은 개발자가 ‘구현’을 잘못해 보안 실패를 초래하고 있기에, 장마다 ‘좋은’ 라이브러리를 골라 자바, 자바스크립트, 고랭, 러스트 등 다양한 언어로 작성한 예제 스니펫을 담았다. 풍부한 도표와 사례 덕분에 개발자, 시스템 관리자, 보안 실무자는 인증, 암호화, 비밀 유지 등 암호학 개념을 익히고 공격자보다 앞서기 위한 도구, 프레임워크, 프로토콜을 배울 수 있다. 해시 함수와 서명 등 기초부터 HTTPS와 보안 메시징 등 암호학 프로토콜, 그리고 양자 후 암호학(양자 내성 암호학)과 암호화폐 등 첨단 기술까지 살펴보는, 가장 실용적이며 가장 현대적인 암호학 책이다. 주요 내용■ 암호학 활용 시의 베스트 프랙티스■ 암호학 알고리즘에 대한 그림과 해설■ 디지털 서명 및 영지식 증명 구현■ 공격 등에 대비하기 위한 하드웨어 솔루션■ 나쁜 프랙티스를 식별하고 고치는 법■ 문제별로 적합한 암호학 도구 선택하기 지은이 소개데이비드 웡(David Wong)O(1) Labs의 수석 암호학 엔지니어로서 미나(Mina) 암호화폐를 연구하고 있다. 그 전에는 메타의 자회사 노비에서 디엠(전 리브라) 암호화폐의 보안 리더였고, 그 전에는 NCC 그룹의 암호학 서비스의 보안 컨설턴트였다. OpenSSL과 Let’s Encrypt 등 여러 공적 자금 지원 오픈소스 감사에 참여했다. 블랙햇과 DEFCON 등 다양한 콘퍼런스에서 강연했으며, 블랙햇에서 암호학 과정을 정기적으로 맡았다. TLS 1.3과 노이즈 프로토콜 프레임워크 등의 표준에 기여했다. 고 언어 표준 라이브러리(CVE-2016-3959)라든가 여러 TLS 라이브러리(CVS-2018-12404 등)에서 보안 취약점을 찾아내기도 했다. 디스코 프로토콜(www.discocrypto.com), 스마트 계약용 댑 보안 프로젝트(www.dasp.co) 등의 창시자이며, RSA 캐시 공격, QUIC 기반 프로토콜, ECDSA 타이밍 공격, 디피-헬먼 백도어 등의 연구를 발표했다. 블로그(www.cryptologie.net)에 암호학 관련 글을 꾸준히 올리고 있다. 옮긴이 소개임지순낮에는 계약서와 코드를 두드리고 밤에는 신시사이저와 기타를 난도질하는 공학과 미디어의 주변인. 임베디드 프로그래머, 미들웨어 개발자, 프로젝트 매니저, 사업 개발 등 다양한 직군에 종사해왔으며 최근에는 엔터테인먼트 산업에서 다양한 웹 프로젝트를 진행 중이다. 사회적인 덕후로 생존하기 위해 오늘도 코드, 그리고 글과 씨름하고 있다. 참여 도서로는 《쉽게 배우는 AWS AI 서비스》(한빛미디어, 2022), 《모던 자바스크립트 핵심 가이드》(한빛미디어, 2021), 《초소형 머신러닝 TinyML》(한빛미디어, 2020), 《라즈베리 파이로 배우는 컴퓨터 아키텍처》(위키북스, 2017) 등이 있다. 차례옮긴이 머리말 xii추천의 글 xiii베타리더 후기 xv시작하며 xvii감사의 글 xxii이 책에 대하여 xxiii표지에 대하여 xxvii PART I 프리미티브: 암호학의 재료 CHAPTER 1 시작하며 31.1 암호학은 프로토콜을 보호한다 41.2 대칭 암호학: 대칭 암호화란? 51.3 케르크호프스의 원칙: 키만은 비밀로 지키자 71.4 비대칭 암호학: 키 두 개가 하나보단 낫지 10__1.4.1 비밀을 공유하는 방법, 키 교환 10__1.4.2 비대칭 암호화, 대칭 암호화와는 다르다! 13__1.4.3 디지털 서명: 펜과 종이의 서명과 그리 다르지 않다 151.5 암호학의 분류 17더보기1.6 이론 암호학 vs 실세계 암호학 191.7 이론에서 현실로: 암호학의 현실화를 위한 시뮬레이션 201.8 경고장 25요약 26 CHAPTER 2 해시 함수 272.1 해시 함수란? 272.2 해시 함수의 보안 속성 302.3 해시 함수의 보안 제약 322.4 해시 함수의 실사용 34__2.4.1 커밋 34__2.4.2 서브리소스 무결성 35__2.4.3 비트토렌트 35__2.4.4 토르 352.5 표준화된 해시 함수 36__2.5.1 SHA-2 해시 함수 37__2.5.2 SHA-3 해시 함수 41__2.5.3 두 가지 XOF, SHAKE와 cSHAKE 44__2.5.4 튜플해시, 모호성을 해결하다 462.6 비밀번호 해시 48요약 50 CHAPTER 3 메시지 인증 코드 513.1 MAC의 대표적 예, 무상태성 쿠키 513.2 코드 예제 543.3 MAC의 보안 속성 56__3.3.1 인증 태그의 위조 56__3.3.2 인증 태그의 길이 57__3.3.3 리플레이 공격 58__3.3.4 주기적 인증 태그 검증 593.4 실세계의 MAC 61__3.4.1 메시지 인증 61__3.4.2 키 파생 61__3.4.3 쿠키의 정합성 61__3.4.4 해시 테이블 623.5 실무에서의 MAC 62__3.5.1 해시 기반 MAC, HMAC 62__3.5.2 cSHAKE 기반 MAC, KMAC 633.6 SHA-2와 가변 길이 공격 64요약 67 CHAPTER 4 인증 암호화 694.1 암호문이란? 704.2 AES 블록 암호화 71__4.2.1 AES가 제공하는 보안의 수준 72__4.2.2 AES의 인터페이스 73__4.2.3 AES의 내부 744.3 암호화된 펭귄, 그리고 CBC 모드 754.4 인증이 필요하면? AES-CBC-HMAC 784.5 올인원 구조: 인증 암호화 80__4.5.1 AEAD 80__4.5.2 AES-GCM AEAD 82__4.5.3 ChaCha20-Poly1305 864.6 그 밖의 대칭 암호화 90__4.6.1 키 래핑 91__4.6.2 논스 오용 방지 인증 암호화 91__4.6.3 디스크 암호화 91__4.6.4 데이터베이스 암호화 92요약 92 CHAPTER 5 키 교환 955.1 키 교환이란? 965.2 DH 키 교환 99__5.2.1 군론 99__5.2.2 디피-헬먼의 기반, 이산 로그 문제 103__5.2.3 디피-헬먼 표준 1055.3 ECDH 키 교환 106__5.3.1 타원 곡선이란? 107__5.3.2 ECDH 키 교환의 작동 원리 110__5.3.3 타원 곡선 디피-헬먼의 표준 1125.4 작은 부분군 공격과 그 밖의 보안 고려 사항 114요약 117 CHAPTER 6 비대칭 암호화와 하이브리드 암호화 1196.1 비대칭 암호화란? 1206.2 실전 비대칭 암호화와 하이브리드 암호화 122__6.2.1 키 교환 및 키 캡슐화 122__6.2.2 하이브리드 암호화 1236.3 RSA 비대칭 암호화: 최악과 차악 127__6.3.1 교과서 RSA 127__6.3.2 RSA PKCS#1 v1.5를 쓰지 않는 이유 131__6.3.3 RSA-OAEP 비대칭 암호화 1336.4 ECIES 하이브리드 암호화 136요약 138 CHAPTER 7 서명과 영지식 증명 1397.1 서명이란? 140__7.1.1 실전에서 서명하고 서명을 검증하는 방법 141__7.1.2 서명의 주된 사용: 인증된 키 교환 142__7.1.3 실세계의 사용 사례: 공개 키 인프라 1437.2 ZKP: 서명의 근원 144__7.2.1 슈노어 식별 프로토콜: 대화형 ZKP 145__7.2.2 비대화형 ZKP로서의 서명 1487.3 권장하는 서명 알고리즘 149__7.3.1 불안한 표준, RSA PKCS#1 v1.5 150__7.3.2 개선된 표준, RSA-PSS 153__7.3.3 ECDSA 154__7.3.4 EdDSA 1577.4 서명 체계의 미묘한 속성 160__7.4.1 대체 공격 160__7.4.2 서명의 가단성 162요약 162 CHAPTER 8 무작위성과 비밀 1658.1 무작위성이란? 1668.2 느린 무작위성? PRNG를 쓰세요 1678.3 실전에서 무작위성 확보하기 1718.4 난수 생성과 보안 고려 사항 1738.5 공개적 무작위성 1758.6 키 파생과 HKDF 1778.7 키 관리와 비밀 관리 1818.8 임곗값 암호학을 통한 신뢰의 탈중앙화 183요약 186 PART II 프로토콜: 암호학의 레시피 CHAPTER 9 보안 전송 1899.1 보안 전송 프로토콜, SSL과 TLS 190__9.1.1 SSL에서 TLS로 190__9.1.2 실전에서 TLS 활용하기 1919.2 TLS 프로토콜의 작동 원리 193__9.2.1 TLS 핸드셰이크 194__9.2.2 TLS 1.3이 애플리케이션 데이터를 암호화하는 방법 2079.3 암호화된 웹의 현재 2089.4 기타 전송 프로토콜 2119.5 TLS에 대한 현대적인 대안, 노이즈 프로토콜 프레임워크 211__9.5.1 노이즈의 다양한 핸드셰이크 212__9.5.2 노이즈의 핸드셰이크 213요약 214 CHAPTER 10 종단 간 암호화 21510.1 종단 간 암호화가 왜 필요한가? 21610.2 어디에서도 찾을 수 없는 신뢰의 근원 21710.3 이메일 암호화의 실패 219__10.3.1. PGP? GPG? 어떻게 작동할까? 219__10.3.2 사용자 간의 신뢰를 확장시키는 신뢰의 웹 222__10.3.3 진짜 이슈는 키 발견 223__10.3.4 PGP가 아니라면, 대안은? 22410.4 보안 메시징: 시그널을 활용한 현대적 종단 간 암호화 226__10.4.1 신뢰하되, 검증하라. WOT보다 사용자 친화적으로 227__10.4.2 시그널 프로토콜의 핸드셰이크, X3DH 230__10.4.3 시그널의 핸드셰이크 후 프로토콜, 더블 래칫 23310.5 종단 간 암호화의 현재 238요약 240 CHAPTER 11 사용자 인증 24311.1 인증 복습하기 24311.2 사용자 인증, 비밀번호를 없애기 위한 여정 245__11.2.1 비밀번호의 지배자, SSO와 비밀번호 관리자 248__11.2.2 비밀번호 노출을 막고 싶다고요? 비대칭 비밀번호 인증 키 교환을 쓰세요 249__11.2.3 O TP는 실제 비밀번호가 아니다. 대칭 키를 사용하여 비밀번호 없이 전환하기 253__11.2.4 비대칭 키로 비밀번호 대체하기 25711.3 사용자 지원 인증: 사람의 도움으로 장치 페어링하기 260__11.3.1 미리 공유된 키 261__11.3.2 CPace를 사용한 대칭 비밀번호 인증 키 교환 263__11.3.3 내 키 교환이 MITM 공격을 당했나? SAS를 확인하자 264요약 267 CHAPTER 12 ‘암호화폐’의 ‘암호’? 26912.1 BFT 합의 알고리즘에 대한 간단한 소개 270__12.1.1 회복력의 문제: 구조를 위한 분산 프로토콜 270__12.1.2 신뢰의 문제를 해결하는 탈중앙화 272__12.1.3 규모의 문제: 무허가 및 검열 방지 네트워크 27312.2 비트코인의 작동 방식 275__12.2.1 비트코인이 사용자 잔고와 트랜잭션을 관리하는 방법 276__12.2.2 디지털 금광 시대, BTC를 채굴한다는 것 278__12.2.3 포크 지옥! 채굴 분쟁 해결 281__12.2.4 머클 트리를 사용하여 블록 크기 줄이기 28412.3 암호화폐 둘러보기 286__12.3.1 변동성 286__12.3.2 지연 시간 286__12.3.3 블록체인의 크기 287__12.3.4 기밀성 287__12.3.5 에너지 효율 28812.4 디엠BFT: BFT 합의 프로토콜 288__12.4.1 BFT 합의 프로토콜의 두 속성, 안전성과 활성 288__12.4.2 디엠BFT 프로토콜의 라운드 289__12.4.3 프로토콜은 부정직함을 어느 정도까지 허용할 수 있는가? 290__12.4.4 디엠BFT 투표 규칙 291__12.4.5 트랜잭션은 언제 확정되는가? 292__12.4.6 디엠BFM의 안전성에 숨은 직관 293요약 295 CHAPTER 13 하드웨어 암호학 29713.1 현대 암호학의 공격자 모델 29713.2 비신뢰 환경의 구원자, 하드웨어 299__13.2.1 화이트박스 암호학 300__13.2.2 스마트 카드와 보안 요소 300__13.2.3 은행이 사랑한 HSM 303__13.2.4. 보안 요소의 훌륭한 표준화, TPM 305__13.2.5 TEE를 이용한 보안 컴퓨팅 30813.3 어떤 솔루션을 고를까? 30913.4 누출 저항 암호학, 그리고 사이드채널 공격 방어법 311__13.4.1 상수 시간 프로그래밍 313__13.4.2 마스킹과 블라인드 315__13.4.3 결함 공격 대처법 316요약 316 CHAPTER 14 양자 컴퓨터 시대의 암호학 31914.1 양자 컴퓨터가 뭐길래? 320__14.1.1 작은 것에 대한 탐구, 양자역학 320__14.1.2 양자 컴퓨터의 탄생으로부터 양자 우위까지 323__14.1.3 그로버와 쇼어의 알고리즘 324__14.1.4 양자 컴퓨터에 맞서는 양자 후 암호학 32614.2 해시 함수만 있으면 된다! 해시 기반 서명 326__14.2.1 램포트 서명을 통한 OTS 327__14.2.2 WOTS와 작은 키 329__14.2.3 XMSS와 SPHINCS+를 통한 다회 서명 33014.3 격자 기반 암호학을 사용한 더 짧은 키 및 서명 333__14.3.1 격자란? 333__14.3.2 오류를 통한 학습 335__14.3.3 격자 기반 키 교환, 카이버 337__14.3.4 격자 기반 서명 체계, 다이리튬 33914.4 양자 컴퓨터는 공포인가? 340요약 342 CHAPTER 15 차세대 암호학 34515.1 함께할수록 좋은 MPC 346__15.1.1 PSI 347__15.1.2 범용 MPC 348__15.1.3 MPC의 현재 35015.2 FHE, 그리고 암호화 클라우드의 미래 350__15.2.1 RSA 암호화와 동형 암호화의 예 351__15.2.2 다양한 동형 암호화 351__15.2.3 FHE의 열쇠, 부트스트래핑 352__15.2.4 오류를 통한 학습 기반 FHE 체계 354__15.2.5 어디에 사용할까? 35615.3 범용 ZKP 357__15.3.1 zk-SNARK의 작동 원리 359__15.3.2 증거의 일부를 숨기는 동형 커밋 360__15.3.3 동형 커밋을 개선하는 쌍선형 페어링 361__15.3.4 간결성은 어디에? 361__15.3.5 프로그램을 다항식으로 362__15.3.6 프로그램은 컴퓨터를 위한 것. 우리에게 필요한 것은 산술 회로 363__15.3.7 R1CS 산술 회로 364__15.3.8 R1CS에서 다항식까지 364__15.3.9 지수에 숨은 다항식을 계산하기 365요약 367 CHAPTER 16 암호학의 끝 36916.1 알맞은 암호학 프리미티브 또는 프로토콜을 찾는 지루한 작업 37016.2 암호학 프리미티브 및 프로토콜을 사용하는 법? 표준과 형식 검증 37116.3 좋은 라이브러리는 어디에? 37416.4 개발자가 적? 암호학의 오용 37616.5 사용이 편한 보안 37716.6 암호학은 섬이 아니다 37816.7 암호학 실무자의 책임: 자신의 암호학을 시험하지 말자 379 요약 381연습 문제 정답 383찾아보기 388  제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)네이버 책 포스트 유튜브 인스타그램 트위터 페이스북window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1374}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글그림으로 배우는 StatQuest 머신러닝 강의  (6)2023.02.13진짜 쓰는 일러스트레이터  (0)2023.02.03프로그래밍 러스트(개정판)  (2)2023.01.19진짜 쓰는 윈도우 11  (0)2023.01.12메이크잇의 폭신폭신 말랑말랑 종이 스퀴시 만들기  (0)2023.01.12태그HSM, https, tls, ZKP, 보안, 서명, 시그널, 암호, 양자, 해시'도서 소개' Related Articles그림으로 배우는 StatQuest 머신러닝 강의진짜 쓰는 일러스트레이터프로그래밍 러스트(개정판)진짜 쓰는 윈도우 11    setInitialEntryComments(1374, 1723627698)Secret댓글달기loadedComments[1374]=true;findFragmentAndHighlight(1374);"
119,https://lsjsj92.tistory.com/555,머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization),"본문 바로가기꿈 많은 사람의 이야기카테고리검색하기검색하기Search꿈 많은 사람의 이야기이수진의 블로그 분류 전체보기 (571)  python (85)  Data Engineering  및 Infra (33)  machine learning(머신러닝) (19)  deep learning(딥러닝) (39)  추천시스템 (26)  LLM&RAG (2)  컨퍼런스(IT, AI) (4)  python-django (15)  빅데이터 (20)  kaggle(캐글) (13)  알고리즘&자료구조 (12)  IT 및 개발 TIP (21)  생활팁 (20)  R (23)  javascript (16)  암호화폐 (0)  perl (22)  java (47)  일상 (53)  맛집 (50)  전시회(일상) (7)  spring(스프링) 프레임워크 (3)  jsp (5)  리눅스(linux) (2)  국내여행 (17)  해외여행 (2)  책 (4)  초대장 (2)  티스토리 (2)  축제 (3)  mysql (3) Guestbook세로형(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_goB19ZXe', {ignore_items: true});Notice[contact] 컨택 정보 공지Recent Posts인공지능 윤리(AI Ethics)란 무엇일까? AI개발자가 바라⋯LLM과 추천 시스템을 결합해 설명가능성(Explainabili⋯개인화를 고려한 LLM 모델 기반 추천 시스템 - PALR 추천⋯vLLM 사용법 - LLM을 쉽고 빠르게 추론(inference⋯LLM 기반 추천 시스템 논문 리뷰 - LlamaRec: Two⋯Recent Comments안녕하세요. 맥에서 Modelfile을 만들어 모델 배포하려고 ⋯안녕하세요 음 beeline으로는 제가 경험이 없어서 모르겠습니⋯혹시 여기서 beeline 으로 접속하는 방법 은 없을까요? n⋯안녕하세요. 네~ 질문 남겨주시면 답변 드리겠습니다네네~ 해결 되셨다니 다행이네요 ㅎㅎ Link #chart-time {font-size:11px; text-align:right; color:#999; padding-right: 15px;}08-14 02:04        am4core.ready(function() {            am4core.addLicense(""CH90809262"");            var chart = am4core.create(""chartdiv"", am4charts.XYChart);            chart.data = [{""timestamp"":""2024-08-08T00:00:00+09:00"",""count"":899},{""timestamp"":""2024-08-09T00:00:00+09:00"",""count"":783},{""timestamp"":""2024-08-10T00:00:00+09:00"",""count"":342},{""timestamp"":""2024-08-11T00:00:00+09:00"",""count"":334},{""timestamp"":""2024-08-12T00:00:00+09:00"",""count"":1022},{""timestamp"":""2024-08-13T00:00:00+09:00"",""count"":899},{""timestamp"":""2024-08-14T00:00:00+09:00"",""count"":45}];            var values = chart.data.map(function(value){                return value.count            });            var minValue = values.reduce(function(acc, current) {                return Math.min(acc, current);            });            var maxValue = values.reduce(function(acc, current) {                return Math.max(acc, current);            });            chart.dateFormatter.inputDateFormat = ""yyyyMMdd"";            var dateAxis = chart.xAxes.push(new am4charts.DateAxis());            var valueAxis = chart.yAxes.push(new am4charts.ValueAxis());            dateAxis.renderer.grid.template.disabled = true;            dateAxis.dateFormats.setKey(""day"", ""dd"");            dateAxis.periodChangeDateFormats.setKey(""day"", ""dd"");            dateAxis.renderer.minGridDistance = 1;            dateAxis.fontSize = ""10.5px"";            dateAxis.color = ""#ff0000"";            dateAxis.opacity = 0.5;            valueAxis.opacity = 0.5;            valueAxis.fontSize = ""10.5px"";            valueAxis.paddingBottom = 5;            valueAxis.marginLeft = -20;            valueAxis.min = minValue < 0 ? 0 : minValue;            valueAxis.max = maxValue + 10;            var series = chart.series.push(new am4charts.LineSeries());            series.dataFields.valueY = ""count"";            series.dataFields.dateX = ""timestamp"";            series.tooltipText = ""{count}""            series.strokeWidth = 1;            series.minBulletDistance = 15;            series.tooltip.background.cornerRadius = 20;            series.tooltip.background.strokeOpacity = 0;            series.tooltip.pointerOrientation = ""vertical"";            series.tooltip.label.minWidth = 40;            series.tooltip.label.minHeight = 40;            series.tooltip.label.textAlign = ""middle"";            series.tooltip.label.textValign = ""middle"";            var bullet = series.bullets.push(new am4charts.CircleBullet());            bullet.circle.strokeWidth = 2;            bullet.circle.radius = 3;            bullet.circle.fill = am4core.color(""#fff"");        });«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031TagsPython일상취미프로그래밍머신러닝자바딥러닝프로그래밍언어추천시스템Java컴퓨터deep learning맛집맛있다취업하고싶다공부개발파이썬ITmachine learningmoreArchives2024/07 (1)2024/06 (1)2024/05 (2)2024/04 (4)2024/02 (1)Today45Total3,264,595닫기관리 메뉴글쓰기방명록RSS관리꿈 많은 사람의 이야기머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization) 본문machine learning(머신러닝)머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization)이수진의 블로그                            2019. 12. 12. 09:18반응형(adsbygoogle = window.adsbygoogle || []).push({});728x170(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_x7yWv3X6', {ignore_items: true});포스팅 주제더보기이번 포스팅은 지난 포스팅에 이어서 캐글의 신용카드 사기 탐지(kaggle credit card fraud detection) 데이터를 활용합니다.또한, kaggle credit card fraud detection의 커널 중 https://www.kaggle.com/janiobachmann/credit-fraud-dealing-with-imbalanced-datasets커널을 참조하여 공부하고 정리하였습니다.이번 글은 지난 글에서 진행한 신용카드 사기 탐지 데이터의 데이터 스케일(data scale)을 변경시켜보려고 합니다.그리고 이렇게 데이터 스케일이 변경되었을 때 머신러닝 모델 성능이 어떻게 변화되는지 살펴보겠습니다. 지난 포스팅에서는 데이터 원본을 그대로 사용하여 단순히 신용카드 사기를 탐지했습니다.궁금하신 분들은 지난 포스팅을 보시면 되겠습니다.(https://lsjsj92.tistory.com/553) 머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud이번 포스팅은 머신러닝으로 신용카드 사기를 탐지하는 모델을 만들어보려고 합니다. 해당 포스팅의 데이터는 kaggle에서 제공해준 kaggle credit card fraud를 사용했습니다. 또한, 한 커널을 필사하면서 진행하..lsjsj92.tistory.com 코드는 아래 github에 존재합니다.https://github.com/lsjsj92/machine_learning_basic lsjsj92/machine_learning_basicRepo for everyone who wants a machine learning basic - lsjsj92/machine_learning_basicgithub.com11번에 코드가 존재합니다. 데이터 분포 변경 - 데이터 정규화(data normalization)캐글의 신용카드 사기 탐지 데이터를 살펴보면 Amount라는 column과 Time이라는 column이 존재합니다.그리고 V1에서 V28까지의 컬럼도 존재하지만 이게 정확히 어떤 것을 뜻하는 것인지 알 수가 없죠.그러니 이번에는 Amount와 Time 컬럼에 focus를 두고 데이터를 살펴봅니다.먼저 Amount와 Time의 데이터 분포를 살펴봅니다. python seaborn을 사용하여서 distplot을 이용해 데이터 분포를 살펴보겠습니다.seaborn의 distplot을 이용해서 amount와 time을 보았는데 데이터가 특이한 점이 있습니다.Amount는 대부분 0 부분쪽에 쏠려있는 경향이 있습니다. 하지만 아~주 미세하게 25000까지 쭉 이어져있죠.또한, Time 컬럼은 데이터 분포가 Amount보다는 고르지만 최소 0부터 16만이 넘는 값이 존재하고 있습니다. 이 두 개의 문제는 지금 데이터 분포가 너무 크다는 것입니다.이렇게 데이터 분포가 커지게 되면 머신러닝 모델이 제대로 동작되지 않을 수 있습니다. 큰 값에 쏠려버리는 경우가 있을 수 있기 때문입니다.따라서 이렇게 데이터 분포가 고르지 않을 경우에는 데이터 분포를 data normalization 과정을 거쳐주어야 합니다.data normalization 과정에서는 표준화(Standardization)으로 바꿔주는 방법, 0 ~ 1 범위로 축소하는 방법 등 다양한 방법이 있습니다.여기서는 Standardization과 log scale 등을 적용해보겠습니다. Amount 컬럼 data normalization먼저 Amount 컬럼에 데이터 정규화를 적용하고 다시 seaborn으로 살펴보겠습니다. Amount에서는 StandardScaler를 사용해서 Standardization 분포와 log scale을 살펴봅니다.왼쪽이 log scale로 데이터 정규화를 진행한 그래프고 오른쪽이 standard scale로 변경한 그래프입니다.둘 다 데이터 분포가 0 ~ 25000이 되었던 것에 비해서 상당히 많이 줄었습니다.이 중 standard scale은 기존에 Amount와 데이터 분포가 상당히 유사합니다.그래서 여기서는 standard scale을 채택하려고 합니다! Time 컬럼 data normalization다음으로 Time 컬럼을 보겠습니다.Time에서는 Robust scale과 log scale, standard scale 3개의 scaler로 데이터 normalization을 진행하겠습니다.3개의 그림은 왼쪽부터 robust scale, log scale, standard scale입니다.기존 데이터 분포와 비슷한 것은 robust scale과 standard scale입니다. 그 중 robust scale이 데이터 분포가 좀 더 적게 나왔고 (결과론 적이지만) overfitting이 걸리지 않기 때문에 이것으로 채택하겠습니다. 정규화(data normalization)된 데이터 추가자! 여기까지 TIme과 Amount에 대해서 데이터 정규화를 진행했습니다.그리고 Amount에서는 standard(표준화)를, Time에서는 Robust를 채택하기로 했죠이제 Amount와 TIme 데이터를 이 정규화된 데이터로 바꿔주고 기존에 불필요한 데이터는 drop하겠습니다. dataframe에 있었던 불필요한 컬럼을 drop해줍니다.근데 문제가 이렇게 하면 맨 마지막에 scaled_amount와 scaled_time이 들어가있습니다.이를 맨 앞으로 빼내야지 나중에 class(target)을 뽑을 떄 불편하지도 않고 보기도 좋습니다. 그래서 맨 앞으로 빼냅니다 머신러닝 모델 평가자! 이제 이 상태에서 머신러닝 모델을 평가해보겠습니다.지난 포스팅에서 로지스틱 회귀(logistic regression)과 lightgbm 2개의 머신러닝 모델을 적용해서신용카드 사기를 탐지할 수 있는 모델을 만들었는데요 이제 데이터 정규화(data normalization)을 진행한 현재 상태에서 머신러닝 모델들이 어떻게 성능이 변화되는지 살펴봅니다. 짠! 이렇게 나오는군요지난 포스팅에서 logistic regression 모델의 평가는 아래와 같았습니다.정밀도 : 0.77재현율 : 0.53f1-score : 0.62하지만 지금 로지스틱 회귀 성능을 보시면 정밀도 : 0.87재현율 : 0.66f1-score : 0.75이렇게 변경이 되었습니다. lightgbm의 모델 성능은 변화가 없구요.즉, 여기서 알 수 있는 것은! 로지스틱 회귀(logistic regression)의 성능은 데이터 분포가 중요하다!이것을 알 수 있습니다. 이제 다음 포스팅에서 더 이어서 신용카드 사기 탐지를 진행해보겠습니다.https://lsjsj92.tistory.com/556 머신러닝, 딥러닝 이상치(outlier) 데이터 탐지 및 제거 하기 - outlier data detection and remove포스팅 개요 이번 포스팅은 머신러닝과 딥러닝에서 많이 사용하는 데이터 이상치 탐지(outlier detection)에 대해서 작성합니다. 또한, 지난 포스팅인 캐글의 신용카드 사기 탐지 대회 데이터셋(kaggle credit car..lsjsj92.tistory.com 반응형(adsbygoogle = window.adsbygoogle || []).push({});그리드형(function(d,a,b,l,e,_) {    if(d[b]&&d[b].q)return;d[b]=function(){(d[b].q=d[b].q||[]).push(arguments)};e=a.createElement(l);    e.async=1;e.charset='utf-8';e.src='//static.dable.io/dist/plugin.min.js';    _=a.getElementsByTagName(l)[0];_.parentNode.insertBefore(e,_);    })(window,document,'dable','script');dable('setService', 'lsjsj92.tistory.com');dable('sendLogOnce');dable('renderWidget', 'dablewidget_GlGkg5lx', {ignore_items: true});     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//lsjsj92.tistory.com/reaction';window.ReactionReqBody = {    entryId: 555}공유하기게시글 관리꿈 많은 사람의 이야기저작자표시 'machine learning(머신러닝)' 카테고리의 다른 글머신러닝 스태킹 앙상블(stacking ensemble) 이란? - 스태킹 앙상블 기본편(stacking ensemble basic)  (3)2019.12.19머신러닝, 딥러닝 이상치(outlier) 데이터 탐지 및 제거 하기 - outlier data detection and remove  (10)2019.12.15머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud  (0)2019.12.02머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자  (2)2019.11.22머신러닝 앙상블(ensemble) xgboost란? - Python 예제와 함께 살펴보기  (15)2019.11.21TagData Science, Kaggle, lightgbm, machine learning, machine-learning, Normalization, Standard, 머신러닝, 정규화, 캐글공유하기 링크페이스북카카오스토리트위터'machine learning(머신러닝)' Related Articles머신러닝 스태킹 앙상블(stacking ensemble) 이란? - 스태킹 앙상블 기본편(stacking ensemble basic)2019.12.19머신러닝, 딥러닝 이상치(outlier) 데이터 탐지 및 제거 하기 - outlier data detection and remove2019.12.15머신러닝으로 신용카드 사기 탐지하기 1편- kaggle credit card fraud2019.12.02머신러닝 ensemble lightgbm 알고리즘이란? - python 예제와 함께 살펴보자2019.11.22more0  Comments댓글쓰기 폼이름비밀번호                                        Secret                                    내용SendloadedComments[555]=true;findFragmentAndHighlight(555);            Blog is powered by            kakao / Designed by            Tistoryif(!wcs_add) var wcs_add = {};wcs_add[""wa""] = ""1498aaff6eff2c0"";if(window.wcs) {wcs_do();}티스토리툴바꿈 많은 사람의 이야기구독하기                    (function () {                         var blogTitle = '꿈 많은 사람의 이야기';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()if(!wcs_add) var wcs_add = {};   wcs_add[""wa""] = encodeURI(""1498aaff6eff2c0"");   wcs_do();document.oncontextmenu = new Function ('return false');document.ondragstart = new Function ('return false');document.onselectstart = new Function ('return false');document.body.style.MozUserSelect = 'none';hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""2798029-555"",""customProps"":{""userId"":""0"",""blogId"":""2798029"",""entryId"":""555"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""555"",""entryTitle"":""머신러닝으로 신용카드 사기 탐지하기 2편 - 데이터 정규화(data normalization)"",""entryType"":""POST"",""categoryName"":""machine learning(머신러닝)"",""categoryId"":""853217"",""serviceCategoryName"":""IT 인터넷"",""serviceCategoryId"":401,""author"":""3704517"",""authorNickname"":""이수진의 블로그"",""blogNmae"":""꿈 많은 사람의 이야기"",""image"":""kage@btJar1/btqAnn12FzJ/dzwssK2lLVzltZikiNJHBk"",""plink"":""/555"",""tags"":[""Data Science"",""Kaggle"",""lightgbm"",""machine learning"",""machine-learning"",""Normalization"",""Standard"",""머신러닝"",""정규화"",""캐글""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
120,https://jpub.tistory.com/918,태그,"도서 소개파이토치 첫걸음 제이펍2019. 5. 9. 15:28정말정말 쉽게 시작하는 파이토치&딥러닝 입문!실무에도 바로 활용할 수 있는 파이토치 입문서!종이책 구매 사이트(가나다 순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]출판사 제이펍원출판사 쇼에이샤(翔泳社)원서명 現場で使える！PyTorch開発入門(원서 ISBN: 9784798157184)저자명 두세교역자명 김완섭출판일 2019년 5월 9일페이지 232쪽시리즈 I♥A.I. 16 (아이러브A.I. 16)판  형 크라운판 변형(170*225*14)제  본 무선(soft cover)정  가 24,000원ISBN 979-11-88621-59-0 (93000)키워드 파이토치 / 인공지능 / 딥러닝 / 머신러닝 / 프레임워크 / 신경망 / 오픈 소스 프로젝트 / 구글 컬래버레터리 / 주피터 노트북분야 인공지능 / 딥러닝관련 사이트■ 저작권사 도서소개 페이지■ 아마존 도서소개 페이지■ 파이토치 공식 사이트관련 포스트■ 2019/04/18 - [출간전 책소식] - 딥러닝 때문에 얼굴 찌푸리지 말아요~♪ 파이토치와 이 책이 있잖아요! 관련 시리즈■ I♥A.I. 시리즈관련 도서(* 관련 시리즈 참고)관련 파일 다운로드■ 예제 코드 다운로드(깃헙)  강의보조자료 다운로드교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표샘플 PDF(차례, 옮긴이 머리말, 시작하며, 이 책의 대상 독자와 필요한 사전 지식, 이 책의 구성, About the SAMPLE: 이 책의 개발 환경과 예제 프로그램, 베타리더 후기, 프롤로그 '개발 환경 준비', 1장 '파이토치의 기본' 일부, 2장 '최대 우도 추정과 선형 모델' 일부, 3장 '다층 퍼셉트론' 일부, 4장 '이미지 처리와 합성곱 신경망' 일부, 5장 '자연어 처리와 순환 신경망' 일부) sample_파이토치첫걸음.pdf정오표 페이지■ (등록되는 대로 링크를 걸어 드리겠습니다)종이책 구매 사이트(가나다 순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]전자책 구매 사이트(가나다순)[교보문고]  [구글북스]  [리디북스]  [알라딘]  [예스이십사]  [인터파크]도서 소개실무에도 바로 활용할 수 있는 파이토치 입문서!딥러닝의 파이썬 라이브러리로는 구글이 개발한 텐서플로(TensorFlow) 프레임워크가 가장 유명하지만, 심벌을 사용하는 프로그래밍 스타일 때문에 초보자가 접근하기 어렵다는 의견도 존재한다. 반면 이 책에서 다루는 파이토치는 페이스북을 중심으로 개발된 오픈 소스 프로젝트로 동적 네트워크라는 구조를 도입했으며, 일반적인 파이썬 프로그램과 같은 환경에서 간단하게 신경망을 구축할 수 있다는 점에서 많은 관심을 받고 있다. 특히, 해외 연구자들로부터 많은 지지를 받고 있어서 최신 연구들이 파이토치를 사용해 구현되는 중이다. 연구 결과들도 깃허브를 통해 빠르게 공개되는 것이 당연시되고 있다. 아직 한글 자료는 부족하지만, 사용하기 쉽고 최신 연구 결과를 바로 적용할 수 있어서 서비스에 딥러닝을 곧바로 적용하고 싶은 사람에게는 최적의 프레임워크가 될 것이다. 이 책을 통해서 독자 여러분이 신경망이나 딥러닝, 그리고 머신러닝 등에 흥미를 가지고 실제로 자신의 업무에 적용할 수 있게 되기를 바란다.- ‘시작하며’ 중에서이 책의 대상 독자인공지능을 배우고자 하는 프로그래머머신러닝 및 딥러닝 엔지니어저자 소개두세교(杜世橋)도쿄공업대학에서 계산 기기를 활용한 분자생물학을 연구했으며, 졸업 후에는 IT 기업에서 소프트웨어 개발 및 데이터 분석을 담당하고 있다. 대학원 시절에 아직 유명해지기 전이었던 파이썬과 NumPy를 접했고, 스터디 모임이나 집필 등을 통해 파이썬을 전파했다. 요근래 몇 년 동안은 스타트업을 중심으로 데이터 분석이나 머신러닝 개발 지원 등을 해왔으며, 2018년 4월부터 물류 IT 관련 스타트업에서 근무하고 있다. 머신러닝, 빅데이터 분석, 서버 개발 등에 관심이 많으나, 지금은 자녀 교육을 위해 육아 휴직 중인 아빠 엔지니어다.역자 소개김완섭네덜란드 ITC에서 Geoinformation for Disaster Risk Management 석사 학위를 취득했다. 약 9년간 일본과 한국의 기업에서 IT 및 GIS/LBS 분야 업무를 담당했으며, 일본에서는 세콤(SECOM) 계열사인 파스코(PASCO)에서 일본 외무부, 국토지리정보원 같은 정부기관을 대상으로 한 시스템 통합(SI) 업무를 담당했다. 이후 야후 재팬으로 직장을 옮겨 야후맵 개발 담당 시니어 엔지니어로 근무했으며, 한국으로 돌아와 SK에서 내비게이션 지도 데이터 담당 매니저로 근무했다. 현재는 싱가포르에 있는 일본계 회사에서 은행 관련 IT 프로젝트를 담당하고 있다. 저서로는 《나는 도쿄 롯폰기로 출근한다》가 있으며, 역서로는 《알고리즘 도감》, 《처음 만나는 HTML5 & CSS3》, 《인공지능 70》, 《처음 만나는 자바스크립트》, 《다양한 언어로 배우는 정규표현식》, 《그림으로 공부하는 IT 인프라 구조》, 《그림으로 공부하는 시스템 성능 구조》 등 20여 종이 있다. 블로그를 통해 IT 번역 관련 이야기와 싱가포르 직장 생활을 소개하고 있다.차례PROLOGUE 개발 환경 준비 10.1 이 책의 검증 환경 20.1.1 OS 환경: 우분투 16.04 20.1.2 엔비디아의 GPU 20.1.3 클라우드에서 GPU를 탑재한 인스턴스 실행하기 30.2 개발 환경 구축 50.2.1 미니콘다 설치 50.2.2 가상 환경 구축 7   더보기접기CHAPTER 1 파이토치의 기본 111.1 파이토치의 구성 121.1.1 파이토치의 전반적인 구성 121.2 텐서 131.2.1 텐서 생성과 변환 131.2.2 텐서의 인덱스 조작 151.2.3 텐서 연산 161.3 텐서와 자동 미분 201.4 정리 22CHAPTER 2 최대 우도 추정과 선형 모델 232.1 확률 모델과 최대 우도 추정 242.2 확률적 경사 하강법 262.3 선형 회귀 모델 282.3.1 선형 회귀 모델의 최대 우도 추정 282.3.2 파이토치로 선형 회귀 모델 만들기(직접 만들기) 302.3.3 파이토치로 선형 회귀 모델 만들기(nn, optim 모듈 사용) 322.4 로지스틱 회귀 352.4.1 로지스틱 회귀의 최대 우도 추정 352.4.2 파이토치를 사용한 로지스틱 회귀 분석 362.4.3 다중 분류를 위한 로지스틱 회귀 분석 402.5 정리 42CHAPTER 3 다층 퍼셉트론 433.1 MLP 구축과 학습 443.2 Dataset과 DataLoader 483.2.1 Dataset과 DataLoader 483.3 학습 효율화 팁 503.3.1 Dropout을 사용한 정규화 503.3.2 Batch Normalization를 사용한 학습 가속 533.4 신경망의 모듈화 553.4.1 자체 신경망 계층(커스텀 계층) 만들기 553.5 정리 57CHAPTER 4 이미지 처리와 합성곱 신경망 594.1 이미지와 합성곱 계산 604.2 CNN을 사용한 이미지 분류 624.2.1 Fashion-MNIST 624.2.2 CNN 구축과 학습 654.3 전이 학습 694.3.1 데이터 준비 724.3.2 파이토치를 사용한 전이 학습 754.4 CNN 회귀 모델을 사용한 이미지 해상도 향상 804.4.1 데이터 준비 804.4.2 모델 작성 834.5 DCGAN을 사용한 이미지 생성 894.5.1 GAN이란 894.5.2 데이터 준비 904.5.3 파이토치를 사용한 DCGAN 914.6 정리 101CHAPTER 5 자연어 처리와 순환 신경망 1035.1 RNN이란? 1045.2 텍스트 데이터의 수치화 1065.3 RNN과 문장 분류 1095.3.1 IMDb 리뷰 데이터 1095.3.2 신경망 정의와 훈련 1135.3.3 가변 길이 계열 처리 1185.4 RNN을 사용한 문장 생성 1215.4.1 데이터 준비 1225.4.2 모델 정의 및 학습 1245.5 인코더-디코더 모델을 사용한 기계 번역 1295.5.1 인코더-디코더 모델이란 1305.5.2 데이터 준비 1315.5.3 파이토치를 사용한 인코더-디코더 모델 1355.6 정리 142CHAPTER 6 추천 시스템과 행렬 분해 1436.1 행렬 인수분해 1446.1.1 이론적 배경 1446.1.2 MovieLens 데이터 1456.1.3 파이토치에서 행렬 인수분해하기 1476.2 신경망 행렬 인수분해 1516.2.1 행렬 인수분해를 비선형화 1516.2.2 부속 정보 이용 1536.3 정리 160CHAPTER 7 애플리케이션 적용 1617.1 모델 저장과 불러오기 1627.2 플라스크를 사용한 웹 API화 1647.3 도커를 이용한 배포 1737.3.1 nvidia-docker 설치 1747.3.2 파이토치의 도커 이미지 작성 1757.3.3 웹 API 배포 1767.4 ONNX를 사용한 다른 프레임워크와의 연계 1797.4.1 ONNX란 1797.4.2 파이토치 모델 엑스포트 1817.4.3 Cae2에서 ONNX 모델 사용하기 1837.4.4 ONNX 모델을 Cae2 모델로 저장 1847.5 정리 186APPENDIX A 훈련 상태 가시화 187A1.1 텐서보드를 사용한 가시화 188APPENDIX B 컬래버레터리로 파이토치 개발 환경 구축 193B1.1 컬래버레터리를 사용한 파이토치 개발 환경 구축 방법 194B1.1.1 컬래버레터리란 194B1.1.2 장비 사양 194B1.1.3 파이토치 환경 구축 195B1.1.4 데이터 처리 201접기window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 918}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글업무와 일상을 정리하는 새로운 방법 Notion  (0)2019.05.15송쌤의 엔트리 게임 코딩 학교  (1)2019.05.14빅 너드 랜치의 코틀린 프로그래밍  (0)2019.03.29테라폼: 설치에서 운영까지  (0)2019.03.29앤디 필드의 유쾌한 R 통계학  (14)2019.02.28태그pytorch, 구글 컬래버레터리, 딥러닝, 머신러닝, 신경망, 오픈 소스 프로젝트, 인공지능, 주피터 노트북, 파이토치, 프레임워크'도서 소개' Related Articles업무와 일상을 정리하는 새로운 방법 Notion송쌤의 엔트리 게임 코딩 학교빅 너드 랜치의 코틀린 프로그래밍테라폼: 설치에서 운영까지Secret댓글달기loadedComments[918]=true;findFragmentAndHighlight(918);"
121,https://zoa0.tistory.com/4,태그,"마이스터고 취업/삼성전자마이스터고에서 삼성전자를 제일 쉽게 가는법 - 2편 프로에 관하여2021. 1. 17. 02:25 학교선택을 다 했다면 이제 준비를 할 차례이다. 입학전에는 무엇을 해야하는가?  입학전에는 시간이 매우 널널할것이다. 망쳐도 되는 기말고사, 넘쳐나는 자습기간, 누워서 폰 등등  입사 확률을 높이려면 남들과 다른 '차별성'이 필요합니다. 이 기간에는 남들이 쉽게 하지 않는것으로 자기개발을 하면 된다.  삼성전자의 특채 자격 조건은 이렇다.  1. 내신 성적 30% 이내 2. 추천인원 내에 들기 ( 약 정원의 15% ~ 20%) 이 두가지만 만족하면 누구든지 서류에 넣을 수 있다. 1번은 입학전에 직접적으로 할 수 없다. 간접적으로 내가 입학할 학교가 사용하는 출판사 교재를 사용하여 수학 선행학습, 영어, 전공과목 필기 취득 이정도면 내신은  전교권안에 들어갈 것이다. 시험난이도는 중학교때와 99%일치한다. 걱정하지 말자 노력으로 커버 가능하다. 2번. 마이스터고 점수란 것이있는데 이것으로 줄서기를 시킨다. 특채를 받으려면 필수적인 요소이다.대표적으로 토익이 가장높은 점수를 차지하고 그다음 제2외국어 (중국어, 일본어) 삼성전자를 목표로 한다면 중국에 삼성전자 사업장이 많기 때문에 무조건 무조건 중국어를 선택하길 바란다. 그다음 컴퓨터활용능력 1,2급  한국사 검정능력독서기록, 봉사 , 전공자격증 취득, 교내상장 등등 있다. 서류전형을 합격한다면 그다음 필기전형이 있다. 필기전형은 다른기업에 비해 매우 쉬운편이다. 서류전형에 합격한다면 약 3.5명중 한명을 뽑는 어려운 난이도의 면접이 있을 것이다.  이 최종면접만 합격하면 최종합격이다.  그러면 무엇을 해야할까? 잘 선택을 못하겠다면 순서를 정해주겠다. 1. 전기기능사 필기 취득이것만한 자격증이 없다. 삼성전자 서류합격률이 제일 높은 자격증이다. 또한 대형채용하는 한국전력공사 역시 이 자격증을 자격요건으로 필요로 한다. 2.전공자격증 필기 취득내신+마이스터점수를 한번에 챙길 수 있다. 남들과 차별성을 가질 제일 좋은 기회이다. 3.토익 500점 취득토익을 하고가면 대기업갈시에 장점이 매우 많다. 교내 상장, 큰 마이스터점수, 영어 내신 4. hsk3급 취득삼성전자하면 이자격증을 빼놓을 수 없다. 설비엔지니어 직군의 승진자격증에 포함되어있다. 조금 힘들겠지만 미래를 생각하며 따놓자. 이것또한 내신 + 마이스터점수 + 교내상장 을 받을 수 있다.  5. 오픽 im3 취득4번과 마찬가지로 설비엔지니어의 승진자격증에 포함된다. hsk와 면접에서 어필하기 좋은 자격증이다. 이것은 높은 등급일수록 재능이 좀 필요하기때문에 노력으로 im3를 취득하고 나서 좀 재능있다 판단하면 조금 더 연습에서 오픽 ih를 따버리면 된다. 6. 컴퓨터활용능력 1급 필기컴맹이 아니라면 금방 딸 수 있는 자격증이다. 이것만 하면 끝이다. 힘을내자  7. Gsat 풀어보기 5급 전용을 쇼핑몰같은곳에서 사서 더도말고 한권만 이해중심으로 풀어보자. 당장 일이 닥치지 않아서 매우 지루할 것이다. 욕심이 난다면 해보자. 솔직히 1~6만 하고 학교에서 실기만 취득해도 서류전형은 90%이상 합격이다. 학교생활이 엄청 편해진다는 말이다. 안전하게 취직하고 싶으면 흘려보지 말고 꼭 해보자   다음편에는 면접준비에대한 예상질문과 면접하기 쉬운 자소서 작성 요령이 있다. 마이스터고에서 삼성전자를 제일 쉽게 가는법 -3편 면접준비 (tistory.com)  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//zoa0.tistory.com/reaction';window.ReactionReqBody = {    entryId: 4}공유하기게시글 관리IT Archive - 아이티 아카이브 '마이스터고 취업 > 삼성전자' 카테고리의 다른 글마이스터고에서 삼성전자를 제일 쉽게 가는법 -3편 면접준비  (1)2021.01.17마이스터고에서 삼성전자를 제일 쉽게 가는 방법 - 학교선택  (0)2021.01.17태그고졸채용, 마이스터고, 삼성, 삼성전자, 삼성전자 고졸, 삼성전자 설비엔지니어, 설비엔지니어, 연봉, 월급, 특성화고'마이스터고 취업/삼성전자' Related Articles마이스터고에서 삼성전자를 제일 쉽게 가는법 -3편 면접준비마이스터고에서 삼성전자를 제일 쉽게 가는 방법 - 학교선택    setInitialEntryComments(4, 1723627700)Secret댓글달기loadedComments[4]=true;findFragmentAndHighlight(4);"
122,https://jpub.tistory.com/1314,"베테랑에게 배우는 파이써닉한 애플리케이션 구축, 유지보수, 패키징 기법 ","도서 소개전문가를 위한 파이썬 프로그래밍(제4판) 제이펍2022. 9. 5. 11:07베테랑에게 배우는 모던 파이썬 개발의 베스트 프랙티스와 인사이트   도서구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 출판사 제이펍저작권사 Packt Publishing원서명 Expert Python Programming, 4th Edition (9781801071109)도서명 전문가를 위한 파이썬 프로그래밍(제4판)부제 애플리케이션 구축, 유지보수, 패키징, 배포 등 모던 파이썬 개발 마스터하기지은이 미하우 야보르스키, 타레크 지아데옮긴이 김모세감수자 (없음)시리즈 (없음)출판일 2022. 08. 12페이지 592쪽판 형 46배판변형(188*245*29.0)제 본 무선(soft cover)정 가 38,000원ISBN 979-11-92469-20-1 (93000)키워드 파이썬, 유지보수, 패키징, 배포, 패턴매칭, 테스트, 메타프로그래밍, 동시성, 자료구조, 알고리즘분 야 프로그래밍 언어 / 파이썬 관련 사이트 ■ 파이썬 공식 사이트 관련 사이트■ 아마존 도서 페이지■ 저작권사 도서 페이지 관련 포스트■ 2022.07.29 - [출간 전 책 소식] - 가장 깊은 곳까지 놀라운 파이썬 여행 관련 시리즈■ (없음) 관련 도서■ 실무에 바로 적용하는 파이썬 코드 레시피 302■ 알 스웨이가트의 파이썬 프로젝트 관련 파일 다운로드 ■ https://github.com/moseskim/Expert-Python-Programming-Fourth-Edition/   강의 보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음 자료를 보내드립니다.)■ 본문의 그림과 표 ■ 미리보기(지은이·옮긴이 소개, 기술 감수자 소개, 옮긴이 머리말, 베타리더 후기, 감사의 글, 이 책에 대하여, 1장, 2장 일부) 정오표 페이지 ■ https://jpub.tistory.com/1316 도서구매 사이트(가나다순)  [교보문고]  [도서11번가]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)  교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 도서 소개베테랑에게 배우는 파이써닉한 애플리케이션 구축, 유지보수, 패키징 기법 파이썬 코드를 작성하기는 쉽지만, 유지보수하기 좋은 환경을 갖추고 가독성 높은 코드를 만들기는 쉽지 않다. 이 책은 수년간 다양한 파이썬 애플리케이션을 구현한 전문 경험을 담아, 프로덕션 레벨에서 파이썬을 파이썬답게 쓰기 위해 알아야 할 모든 것을 망라한 지침서다. 전문 파이썬 프로그래머라면 꼭 알아야 할 애플리케이션 구축, 유지보수, 패키징, 배포 방법을 자세히 살펴보고, 베스트 프랙티스, 유용한 도구, 표준을 배울 수 있다.  1~4장에서는 파이썬 프로그래머들이 이용하는 도구의 기본적인 요소들에 초점을 맞춘다. 생산성 도구, 현대적인 환경, 최신 파이썬 릴리스에서 도입된 새로운 구문 요소들을 살펴본다. 서로 다른 디펜던시들로 구성된 복잡한 환경을 세팅하는 우아한 방법부터 딕셔너리 병합, zoneinfo, 구조적 패턴 매칭 등 최신 파이썬 피처까지, 특히 다른 언어에서 파이썬으로 전향하는 개발자가 모던 파이썬 개발의 세계에 안착하는 데 도움을 준다.  5~9장에서는 디자인 패턴, 프로그래밍 패러다임, 메타프로그래밍 기법에 관해 살펴본다. 작은 규모의 예제 프로그램을 구현해보고 애플리케이션 아키텍처에 대해서도 깊이 다룬다. 인터페이스, 동시성, 이벤트 주도 프로그래밍/아키텍처 등 현대 애플리케이션 구축에서 반드시 고려해야 하는 요소를 파이써닉하게 구현하는 방법을 배운다. 파이썬의 태생적 성능 한계를 극복하기 위해 C/C++ 코드를 파이썬에 통합하는 방법도 살펴본다.  10~13장에서는 애플리케이션을 구축한 이후 쉽게 유지보수하는 데 도움이 되는 도구와 기법들을 살펴본다. 테스팅, 패키징 및 배포, 로깅 및 모니터링, 코드 최적화 등 개발 수명주기의 마지막 단계에 대해서도 다른 곳에서는 찾아보기 어려운 인사이트를 얻을 수 있다.  베테랑 개발자가 엄선한 베스트 프랙티스, 유용한 도구, 표준을 익힘으로써 파이썬 전문가에 한 걸음 더 가까워질 수 있다. 모던 파이썬 개발의 가장 깊은 곳으로 뛰어들자.  주요 내용■ 반복 가능하고 일관된 파이썬 개발 환경을 세팅하는 최신 방법들 ■ 커뮤니티 및 프로덕션 사용을 위해 파이썬 코드를 효과적으로 패키징하는 법 ■ f-string, enum, lambda 함수 등 모던 파이썬 구문 학습 ■ 메타클래스를 이용해 복잡한 파이썬 메타프로그래밍 쉽게 익히기 ■ 파이썬 동시성 코드 작성 ■ C/C++ 코드와 파이썬 코드의 통합   지은이 소개미하우 야보르스키(Michał Jaworski)10년 이상 다양한 프로그래밍 언어를 이용해 전문적으로 소프트웨어를 작성했다. 주로 웹 애플리케이션을 위한 고성능 분산 백엔드 서비스 코드를 만들었다. 소프트웨어 엔지니어에서 리드 소프트웨어 아키텍트까지 여러 기업에서 다양한 역할을 했다. 과거부터 지금까지 파이썬을 가장 선호한다. 국내에 번역된 책으로는 《파이썬을 이용한 머신러닝, 딥러닝 실전 개발 입문(개정판)》(2019), 《모던 자바스크립트 개발자를 위한 리액트 프로그래밍》(2017), 《러닝스쿨! 파이썬 교과서》(이상 위키북스, 2017), 《자바스크립트와 Node.js를 이용한 웹 크롤링 테크닉》(제이펍, 2016) 등이 있다.타레크 지아데(Tarek Ziadé)프랑스 부르고뉴에 거주하는 소프트웨어 엔지니어. 일래스틱Elastic에서 개발자를 위한 도구를 만들고 있다. 이전에는 모질라에서 10여 년간 일했으며, 프랑스 파이썬 사용자 그룹인 AFPy를 설립했다. 다양한 잡지에 파이썬 관련 글을 기고했으며, 프랑스어와 영어로 여러 책을 집필했다. 국내에는 《파이썬 마이크로서비스》(에이콘출판사, 2019), 《파이썬 핵심 개발자들과의 인터뷰》(터닝포인트, 2019)로 소개된 바 있다.   옮긴이 소개김모세대학 졸업 후 소프트웨어 엔지니어, 소프트웨어 품질 엔지니어, 애자일 코치 등 다양한 부문에서 소프트웨어 개발에 참여했다. 재미있는 일, 나와 조직이 성장하고 성과를 내도록 돕는 일에 보람을 느끼며 나 자신에게 도전하고 더 나은 사람이 되기 위해 항상 노력하고 있다. 저서로 《코드 품질 시각화의 정석》(지앤선, 2015)이 있고, 옮긴 책으로는 《제대로 배우는 수학적 최적화》(한빛미디어, 2021), 《그림으로 배우는 TCP/IP》, 《파이썬 머신러닝 실무 테크닉 100》, 《라라벨 실전 웹 애플리케이션 개발》(이상 제이펍, 2021) 등이 있다.  차례지은이·옮긴이 소개 xi기술 감수자 소개 xii옮긴이 머리말 xiii베타리더 후기 xv감사의 글 xvii이 책에 대하여 xviii CHAPTER 1 파이썬의 현재 11.1 파이썬의 현재와 진행 상황 21.2 파이썬 2의 현재와 미래 31.3 최신 정보의 확인과 습득 5__1.3.1 PEP 문서 6__1.3.2 활성화된 커뮤니티 8__1.3.3 기타 자료들 101.4 요약 12 CHAPTER 2 모던 파이썬 개발 환경 132.1 기술적 요구 사항 142.2 파이썬 패키징 생태계 15__2.2.1 pip를 이용한 파이썬 패키지 설치하기 152.3 런타임 환경 격리 17__2.3.1 애플리케이션 레벨 격리 vs. 시스템 레벨 격리 202.4 애플리케이션 레벨 환경 격리 22__2.4.1 포어트리: 디펜던시 관리 시스템 24더보기2.5 시스템 레벨 환경 격리 29__2.5.1 컨테이너화 vs. 가상화 31__2.5.2 도커를 이용한 가상 환경 33__2.5.3 베이그런트를 이용한 가상 개발 환경 522.6 유명한 생산성 도구들 54__2.6.1 커스텀 파이썬 셸 55__2.6.2 IPython 이용하기 56__2.6.3 커스텀 스크립트 및 프로그램과 셸 연동하기 59__2.6.4 인터랙티브 디버거 60__2.6.5 기타 생산성 향상 도구 622.7 요약 64 CHAPTER 3 파이썬의 새로운 기능 653.1 기술 요구 사항 663.2 최근의 언어 추가 사항 66__3.2.1 딕셔너리 병합 및 업데이트 연산자 67__3.2.2 할당 표현식 72__3.2.3 타입 힌팅 제네릭 76__3.2.4 위치 전달만 가능한 매개변수 78__3.2.5 zoneinfo 모듈 81__3.2.6 graphlib 모듈 823.3 그다지 새롭지는 않지만 여전히 멋진 요소들 86__3.3.1 breakpoint() 함수 86__3.3.2 개발 모드 88__3.3.3 모듈 레벨 __getattr__() 및 __dir__() 함수 90__3.3.4 f-string을 이용한 문자열 서식 지정 91__3.3.5 숫자 리터럴의 언더스코어 93__3.3.6 secrets 모듈 933.4 미래에 관한 예상 95__3.4.1 | 연산자를 이용한 유니언 타입 95__3.4.2 구조적 패턴 매칭 963.5 요약 101 CHAPTER 4 파이썬과 다른 언어와의 비교 1034.1 기술적 요구 사항 1044.2 클래스 모델과 객체 지향 프로그래밍 104__4.2.1 슈퍼클래스로의 접근 105__4.2.2 다중 상속과 메서드 결정 순서 107__4.2.3 클래스 인스턴스 초기화 113__4.2.4 속성 접근 패턴 117__4.2.5 디스크립터 118__4.2.6 프로퍼티 1254.3 동적 다형성 131__4.3.1 연산자 오버로딩 132__4.3.2 함수 및 메서드 오버로딩 1394.4 데이터 클래스 1434.5 함수형 프로그래밍 147__4.5.1 람다 함수 149__4.5.2 map(), filter(), reduce() 함수 151__4.5.3 부분 객체와 부분 함수 154__4.5.4 제너레이터 155__4.5.5 제너레이터 표현식 156__4.5.6 데커레이터 1574.6 열거형 1594.7 요약 162 CHAPTER 5 인터페이스, 패턴, 모듈성 1635.1 기술적 요구 사항 1645.2 인터페이스 165__5.2.1 간단한 역사: zope.interface 167__5.2.2 함수 애너테이션과 추상 베이스 클래스 이용하기 175__5.2.3 타입 애너테이션을 통한 인터페이스 1815.3 제어 반전과 디펜던시 주입 184__5.3.1 애플리케이션의 통제 반전 186__5.3.2 디펜던시 주입 프레임워크 사용하기 1945.4 요약 200 CHAPTER 6 동시성 2016.1 기술적 요구 사항 2026.2 동시성이란 무엇인가? 2026.3 멀티스레딩 204__6.3.1 멀티스레딩이란? 205__6.3.2 파이썬의 스레드 처리 방식 209__6.3.3 언제 멀티스레딩을 사용해야 하는가? 210__6.3.4 멀티스레드 애플리케이션 예시 2136.4 멀티프로세싱 230__6.4.1 내장 multiprocessing 모듈 233__6.4.2 프로세스 풀 이용하기 237__6.4.3 multiprocessing.dummy를 멀티스레딩 인터페이스로 이용하기 2396.5 비동기 프로그래밍 240__6.5.1 협력적 멀티태스킹과 비동기 I/O 241__6.5.2 파이썬의 async/await 키워드 242__6.5.3 비동기 프로그래밍의 실질적 예 247__6.5.4 비동기가 아닌 코드와 async/future 통합하기 2506.6 요약 254 CHAPTER 7 이벤트 주도 프로그래밍 2557.1 기술적 요구 사항 2567.2 이벤트 주도 프로그래밍이란 무엇인가? 256__7.2.1 이벤트 주도 != 비동기 257__7.2.2 GUI에서의 이벤트 주도 프로그래밍 258__7.2.3 이벤트 주도 통신 2617.3 이벤트 주도 프로그래밍의 다양한 스타일 263__7.3.1 콜백 기반 스타일 263__7.3.2 주체 기반 스타일 265__7.3.3 토픽 기반 스타일 2707.4 이벤트 주도 아키텍처 272__7.4.1 이벤트와 메시지 큐 2737.5 요약 276 CHAPTER 8 메타프로그래밍 요소들 2778.1 기술적 요구 사항 2788.2 메타프로그래밍이란 무엇인가? 2788.3 데커레이터를 이용해 함수의 행동을 사용 전 수정하기 279__8.3.1 한 단계 더: 클래스 데커레이터 2818.4 클래스 인스턴스 생성 프로세스 가로채기 2868.5 메타클래스 289__8.5.1 일반적인 구문 290__8.5.2 메타클래스 사용 예시 293__8.5.3 메타클래스의 함정 297__8.5.4 메타클래스의 대안으로 __init_subclass__() 메서드 이용하기 2988.6 코드 생성 300__8.6.1 exec, eval, compile 301__8.6.2 추상 구문 트리 302__8.6.3 임포트 훅 304__8.6.4 파이썬에서의 유명한 코드 생성 사례 3048.7 요약 307 CHAPTER 9 파이썬에 C와 C++ 연결하기 3099.1 기술적 요구 사항 3119.2 파이썬 확장 기능의 핵심인 C/C++ 3119.3 파이썬 C 확장 기능 컴파일 및 로딩 3129.4 확장 기능 이용의 필요성 314__9.4.1 크리티컬 코드 섹션의 성능 개선 315__9.4.2 다른 언어로 작성된 기존 코드 통합 316__9.4.3 서드파티 다이내믹 라이브러리 통합 316__9.4.4 효율적인 커스텀 데이터 타입 생성 3179.5 확장 기능 작성 317__9.5.1 순수한 C 확장 기능 319__9.5.2 Cython을 이용한 확장 기능 작성 3379.6 확장 기능 사용의 단점 343__9.6.1 추가적인 복잡성 344__9.6.2 보다 어려운 디버깅 3459.7 확장 기능 없이 다이내믹 라이브러리와 인터페이싱하기 345__9.7.1 ctypes 모듈 346__9.7.2 CFFI 3539.8 요약 355 CHAPTER 10 테스팅과 품질 자동화 35710.1 기술적 요구 사항 35810.2 테스트 주도 개발 원칙 35910.3 pytest를 이용해 테스트 작성하기 362__10.3.1 테스트 매개변수화 369__10.3.2 pytest의 픽스처 372__10.3.3 페이크 이용하기 381__10.3.4 목과 unittest.mock 모듈 38510.4 품질 자동화 389__10.4.1 테스트 커버리지 390__10.4.2 스타일 픽서와 코드 린터 394__10.4.3 정적 타입 분석 39710.5 돌연변이 테스팅 39910.6 유용한 테스팅 유틸리티 406__10.6.1 실제적인 데이터값 조작하기 406__10.6.2 시간값 조작하기 40710.7 요약 409 CHAPTER 11 파이썬 코드 패키징과 배포 41111.1 기술적 요구 사항 41211.2 라이브러리 패키징 및 배포 412__11.2.1 파이썬 패키지 구조 413__11.2.2 패키지 배포 유형 422__11.2.3 패키지 등록 및 공개 427__11.2.4 패키지 버저닝과 디펜던시 관리 429__11.2.5 커스텀 패키지 설치 433__11.2.6 네임스페이스 패키지 435__11.2.7 패키지 스크립트와 엔트리 포인트 43711.3 웹용 애플리케이션 및 서비스 패키징 441__11.3.1 12요소 앱 방법론 442__11.3.2 도커 활용하기 444__11.3.3 환경 변수 다루기 446__11.3.4 애플리케이션 프레임워크에서 환경 변수의 역할 45011.4 스탠드얼론 실행 파일 생성 454__11.4.1 스탠드얼론 실행 파일이 유용한 경우 455__11.4.2 널리 알려진 도구들 456__11.4.3 실행 파일 패키지에서 파이썬 코드의 보안 46411.5 요약 465 CHAPTER 12 애플리케이션 동작과 성능 관측 46712.1 기술적 요구 사항 46812.2 에러와 로그 캡처 468__12.2.1 파이썬 로깅 기초 469__12.2.2 좋은 로깅 프랙티스 482__12.2.3 분산 로깅 484__12.2.4 사후 리뷰를 위한 에러 캡처 48712.3 코드와 커스텀 지표 조사 490__12.3.1 프로메테우스 이용 49212.4 분산 애플리케이션 트레이싱 502__12.4.1 Jaeger를 이용한 분산 트레이싱 50512.5 요약 511 CHAPTER 13 코드 최적화 51313.1 기술적 요구 사항 51413.2 나쁜 성능을 발생시키는 일반적인 요소들 514__13.2.1 코드 복잡도 515__13.2.2 과도한 리소스 할당과 누수 519__13.2.3 과도한 I/O와 블로킹 52013.3 코드 프로파일링 521__13.3.1 CPU 사용량 프로파일링 522__13.3.2 메모리 사용량 프로파일링 53013.4 적절한 데이터 구조를 선택하여 복잡도 줄이기 541__13.4.1 리스트 검색하기 541__13.4.2 집합 이용하기 542__13.4.3 collections 모듈 이용하기 54313.5 아키텍처 트레이드오프 활용하기 548__13.5.1 휴리스틱과 근사 알고리즘 이용하기 548__13.5.2 태스크 큐와 지연된 처리 이용하기 550__13.5.3 확률적 데이터 구조 이용하기 553__13.5.4 캐싱 55513.6 요약 563 찾아보기 565  제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!) 네이버 책 포스트 유튜브 인스타그램 트위터 페이스북window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1314}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글누구나 할 수 있는 유니티 2D 게임 제작  (0)2022.09.27예제로 배우는 파이썬 머신러닝(제3판)  (0)2022.09.05삐뽀삐뽀 보안 119  (0)2022.09.01모두를 위한 클라우드 컴퓨팅  (6)2022.08.24디자이너의 포토샵 테크닉 141  (0)2022.08.23태그동시성, 메타프로그래밍, 배포, 알고리즘, 유지보수, 자료구조, 테스트, 파이썬, 패키징, 패턴매칭'도서 소개' Related Articles누구나 할 수 있는 유니티 2D 게임 제작예제로 배우는 파이썬 머신러닝(제3판)삐뽀삐뽀 보안 119모두를 위한 클라우드 컴퓨팅    setInitialEntryComments(1314, 1723618299)Secret댓글달기loadedComments[1314]=true;findFragmentAndHighlight(1314);"
123,https://jpub.tistory.com/677,태그,"도서 소개러닝 스칼라 제이펍2017. 4. 19. 16:42객체지향 프로그래머를 위한 최적의 스칼라 입문서!출판사 제이펍원출판사 O’Reilly원서명 Learning Scala(원서 ISBN 9781449367930)저자명 제이슨 스와츠역자명 김정인, 강성용출판일 2017년 04월 17일페이지 292쪽시리즈 (없음)판  형 (188*245*14)제  본 무선(soft cover)정  가 24,000원ISBN 979-11-85890-79-1 (93000)키워드 Scala / 함수형 프로그래밍/ 스칼라 / 컬렉션 / 객체지향 / JVM분야 프로그래밍 언어 / 스칼라관련 사이트■ 아마존 도서 소개 페이지■ 원출판사 도서 소개 페이지관련 포스트■ 2017/04/11 - [출간전 책소식] - 객체지향 프로그래머를 위한 최적의 스칼라 입문서관련 시리즈■ (없음)관련 도서■ 스칼라로 배우는 함수형 프로그래밍■ 하스켈로 배우는 함수형 프로그래밍관련 파일 다운로드■ 예제 코드 강의보조 자료교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표샘플 PDF(차례, 옮긴이 머리말, 이 책에 대하여, 배타리더 후기, 1장 '스칼라 시작하기', 2장 '데이터로 작업하기: 리터럴, 값, 변수, 타입') 러닝스칼라_sample.pdf정오표 페이지■ http://jpub.tistory.com/686 도서구매 사이트(가나다순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]도서 소개객체지향 프로그래머를 위한 최적의 스칼라 입문서!왜 스칼라를 배울까? 이 객체지향 함수형 프로그래밍 언어를 제대로 이해하기 위해 여러분이 데이터 과학자나 분산 컴퓨팅 전문가일 필요는 없다. 이 책은 구문 다이어그램, 그리고 예제와 실습을 적절히 제공하여 스칼라를 포괄적이지만 이해하기 쉽게 소개하고 있다. 여러분은 고차 함수와 불변의 데이터 구조에 뛰어들기 전에 스칼라의 핵심 타입과 구문에 대해 먼저 배우게 될 것이다.저자 스와츠는 자신의 기술이 나아지기를 원하는 루비나 파이썬 개발자에게 스칼라의 간결하고 표현력 있는 구문이 얼마나 이상적인지를 잘 보여준다. 또한, 어떠한 애플리케이션에도 충분히 안정적이고 빠른 실행을 보장하는 타입 안전성과 성능을 지닌 스칼라를 잘 묘사하고 있다.이 책의 주요 내용■ 핵심 데이터 타입, 리터럴, 값, 변수에 대한 학습■ 스칼라 문법의 기초인 표현식을 생각하고 작성하는 방법■ 불변의 데이터 구조를 익히고 이를 타입에 안전하고 선언적인 연산으로 변경하는 방법■ 기존 연산을 단순화시키거나 여러분만의 영역에 특화된 언어를 시작하기 위한 맞춤형 이항연산자 작성법■ 완전한 재사용을 위해 하나 이상의 트레이트로 구성된 클래스를 생성하거나 인스턴스생성 시 클래스들을 혼합한 새로운 기능 제작법누구를 위한 책인가?이 책은 지금까지 자바(Java), 루비(Ruby), 파이썬(Python)과 같은 객체지향 언어로 작업해왔으며, 스칼라를 배워 자신의 기술을 발전시키고자 하는 개발자들을 위한 책이다. 추천사《러닝 스칼라》는 우리에게 친숙한 객체지향 스타일을 스칼라의 자연스러운 특징들과 결합하여 초보자들도 이해하기 쉽게 설명하고 있다. 이 책은 처음 스칼라를 시작할 때 읽고 싶었던 바로 그 책이다!_ 캐서린 펠로우, 컴캐스트(Comcast)의 소프트웨어 엔지니어지은이 소개제이슨 스와츠(Jason Swartz)제이슨 스와츠는 샌프란시스코에서 스칼라 커뮤니티 행사를 기획하고, 넷플릭스의 소비자 디바이스 프로그램을 위한 애플리케이션을 개발하고 있는 소프트웨어 엔지니어이며, 직관적인 사용자 인터페이스, 표현력 높은 프로그래밍 언어와 간결한 사용자 문서화를 좋아한다. 함수형 프로그래밍으로 전향하기 전에는 이베이(eBay)에서 개발자 문서와 지원팀을 관리하였으며, 자바 기반의 홍보 및 머천다이징 플랫폼을 구축했다. 애플(Apple)에서 도구와 UI 프로토타입을 만들기도 했었다.옮긴이 소개김정인평생을 문과 성향이라 생각하며 지내왔지만, 학업을 포함하여 20여 년간 IT 분야에 종사했다. 회사라는 우산에서 벗어나 꿈이었던 번역을 시작하기 전까지는 BI/BA 분야에 몸담았다. 바라는 것은 늘 이 책으로 가장 먼저 배우는 사람의 자세로 이 일에 임하는 것이다. 현재 가장 관심 있는 분야는 재활운동이다.강성용수능 모의고사를 치르다 교실을 뛰쳐나왔던 그날 이후로 지난 16년간 개발자로 일했으며, 지금은 1인 회사를 만들고 혼자서 사장 노릇 중이다. 역자에 대한 소식은 ulzima.com에서 볼 수 있다. 옮긴 책으로는 《리뷰의 기술》, 《윈도우 파워셸 3 시작하기》, 《C 포인터의 이해와 활용》, 《자바 네트워크 프로그래밍(제4판)》이 있다.차례1부 핵심 스칼라1장 스칼라 시작하기 _ 3스칼라 설치하기 _ 3스칼라 REPL 사용하기 _ 5요약 _ 7연습문제 _ 7더보기접기2장 데이터로 작업하기: 리터럴, 값, 변수, 타입 _ 9값 _ 11변수 _ 13명명 _ 14타입 _ 16    숫자형 데이터 타입 _ 16    문자열 _ 19    스칼라 타입의 개요 _ 23    튜플 _ 28요약 _ 29연습문제 _ 303장 표현식과 조건문 _ 31표현식 _ 32    표현식으로 값과 변수 정의하기 _ 32    표현식 블록 _ 33    문장 _ 34If .. Else 표현식 블록 _ 34    If 표현식 _ 35    If-Else 표현식 _ 36매치 표현식 _ 37    와일드카드로 매칭하기 _ 40    패턴 가드를 이용한 매칭 _ 42    패턴 변수를 이용한 타입 매칭 _ 42루프 _ 43    반복자 가드 _ 46    중첩된 반복자 _ 46    값 바인딩 _ 47    While과 Do/While 루프 _ 48요약 _ 49연습문제 _ 494장 함수 _ 52프로시저 _ 55빈 괄호를 가지는 함수 _ 56표현식 블록을 이용한 함수 호출 _ 57재귀 함수 _ 58중첩 함수 _ 60이름으로 매개변수를 지정하여 함수 호출하기 _ 61기본값을 갖는 매개변수 _ 62가변 매개변수 _ 63매개변수 그룹 _ 64타입 매개변수 _ 64메소드와 연산자 _ 67가독성 있는 함수 작성하기 _ 71요약 _ 73연습문제 _ 735장  일급 함수 _ 75함수 타입과 값 _ 76고차 함수 _ 79함수 리터럴 _ 80자리표시자 구문 _ 83부분 적용 함수와 커링 _ 86이름에 의한 호출 매개변수 _ 88부분 함수 _ 89함수 리터럴 블록으로 고차 함수 호출하기 _ 91요약 _ 94연습문제 _ 946장 보편적인 컬렉션 _ 96리스트, 집합, 그리고 맵 _ 97리스트에는 무엇이 있는가? _ 100    생성 연산자 _ 103리스트 산술 연산 _ 105리스트 매핑 _ 108리스트 축소하기 _ 109컬렉션 전환하기 _ 115    자바와 스칼라 컬렉션 호환성 _ 116컬렉션으로 패턴 매칭하기 _ 117요약 _ 118연습문제 _ 1197장 그 외의 컬렉션 _ 122가변적인 컬렉션 _ 122    새로운 가변 컬렉션 생성하기 _ 123    불변의 컬렉션으로부터 가변적인 컬렉션 만들기 _ 125    컬렉션 빌더 사용하기 _ 126배열 _ 127Seq와 시퀀스 _ 129스트림 _ 131모나딕 컬렉션 _ 133    Option 컬렉션 _ 134    Try 컬렉션 _ 139    퓨처 컬렉션 _ 143요약 _ 149연습문제 _ 1502부 객체지향 스칼라8장 클래스 _ 157클래스 정의하기 _ 163그 외의 클래스 유형 _ 168    추상 클래스 _ 168    익명 클래스 _ 170그 외의 필드와 메소드 유형 _ 171    중복 정의된 메소드 _ 172    apply 메소드 _ 172    지연값 _ 173패키징 _ 175    패키징된 클래스에 접근하기 _ 176    패키징 구문 _ 181프라이버시 제어 _ 182프라이버시 접근 변경자 _ 185종단 클래스와 봉인 클래스 _ 187요약 _ 188연습문제 _ 1889장 객체, 케이스 클래스, 트레이트 _ 192객체 _ 192    Apply 메소드와 동반 객체 _ 195    객체를 가지는 명령줄 애플리케이션 _ 197케이스 클래스 _ 199트레이트 _ 202    셀프 타입 _ 207    트레이트를 이용하여 인스턴스화 _ 210인스턴스 구성원 임포트하기 _ 212요약 _ 214쉬어가는 시간 — 첫 번째 스칼라 프로젝트 환경 설정하기 _ 215연습문제 _ 22110장 고급 타입 특징 _ 229튜플과 함숫값 클래스 _ 231묵시적 매개변수 _ 234묵시적 클래스 _ 236타입 _ 238    타입 별칭 _ 239    추상 타입 _ 240    경계가 있는 타입 _ 241    타입 가변성 _ 244    패키지 객체 _ 249요약 _ 250질문 _ 251부록 A 예약어 _ 253찾아보기 _ 257접기window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 677}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글처음 만나는 알고리즘  (6)2017.04.28프로그래머처럼 생각하라: 문제 해결을 위한 모델 기반 사고법  (0)2017.04.27ROS로 배우는 로봇 프로그래밍  (0)2017.04.04처음 만나는 파이썬  (0)2017.04.04서버/인프라 엔지니어를 위한 DevOps  (0)2017.03.23태그JVM, Scala, 강성용, 객체지향, 김정인, 제이슨 스와츠, 제이펍, 컬렉션, 함수형 프로그래밍'도서 소개' Related Articles처음 만나는 알고리즘프로그래머처럼 생각하라: 문제 해결을 위한 모델 기반 사고법ROS로 배우는 로봇 프로그래밍처음 만나는 파이썬    setInitialEntryComments(677, 1723627700)Secret댓글달기loadedComments[677]=true;findFragmentAndHighlight(677);"
124,https://jpub.tistory.com/779,태그,"도서 소개딥 러닝 제대로 정리하기 제이펍2018. 3. 15. 10:16이 책은 현재 절판입니다. 그간 읽어주신 분들께 감사드립니다.  딥 러닝 전문가를 위한 콤팩트한 기본서!딥 러닝의 원리를 이해시키는 핵심 수식과 그림, 간결한 해설이 돋보이는 책!인공지능과 딥 러닝의 원리를 명료한 수식과 그림으로 설명한 체계적인 딥 러닝 교과서! 출판사 제이펍원출판사 近代科学社원서명 深層学習(원서 ISBN: 9784764904873) 저자명 카미시마 토시히로, 아소 히데키, 야스다 무네키, 마에다 신이치, 오카노하라 다이스케, 오카타니 타카유키, 쿠보 요타로, 다누슈카 볼레갈라역자명 심효섭출판일 2018년 3월 12일페이지 320쪽시리즈 I♥A.I. 09판  형 크라운변형(170*225*16)제  본 무선(soft cover)정  가 23,000원ISBN 979-11-88621-05-7 (93000)키워드 딥러닝 / 심층학습 / 인공지능 / 머신러닝 / 기계학습 /  신경망 / 자연어 처리 / 이미지 인식 / 음성 인식분야 컴퓨터공학 / 인공지능 관련 사이트■ 아마존재팬 도서 소개 페이지■ 원출판사 도서 소개 페이지■ 원서 도서 지원 페이지 관련 포스트■ 2018/02/28 - [출간전 책소식] - 일본 인공지능학회가 감수한 딥 러닝 서적!  관련 시리즈■ I♥A.I 시리즈 관련 도서■ 그림과 수식으로 배우는 통통 인공지능■ 그림과 수식으로 배우는 통통 머신러닝■ 텐서플로로 시작하는 딥러닝■ 그림과 수식으로 배우는 통통 딥러닝■ 엑셀로 배우는 인공지능■ 알고리즘 중심의 머신러닝 가이드(제2판)■ 딥러닝 제대로 시작하기■ 머신러닝 인 액션: 기계 학습 알고리즘으로 데이터 마이닝하기■ 인공지능 1: 현대적 접근 방식(제3판)■ 인공지능 2: 현대적 접근 방식(제3판) 관련 파일 다운로드■ (없음)   강의보조 자료교재로 채택하신 분들은 메일을 보내주시면 아래의 자료를 보내드리겠습니다: jeipubmarketer@gmail.com■ 본문의 그림과 표 샘플 PDF(차례, 옮긴이 머리말, 머리말, 수식 표기법, 딥 러닝의 전체 모습, 베타리더 후기, 1장 '계층형 신경망을 이용한 딥 러닝' 일부, 2장 '딥 볼츠만 머신' 일부, 4장 '대규모 딥 러닝을 실현하기 위한 기술' 일부, 6장 '스음성 인식을 위한 딥 러닝' 일부)딥러닝제대로정리하기_sample.pdf다운로드  정오표 페이지■ http://jpub.tistory.com/791■ 원서 정오표 페이지 도서구매 사이트(가나다순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크] 도서 소개딥 러닝 전문가를 위한 콤팩트한 기본서!딥 러닝의 원리를 이해시키는 핵심 수식과 그림, 간결한 해설이 돋보이는 책!인공지능과 딥 러닝의 원리를 명료한 수식과 그림으로 설명한 체계적인 딥 러닝 교과서! 이 책은 인공지능 분야 최일선에 있는 연구자들이 일본 인공지능학회지에 게재했던 자신들의 연재물에 내용을 대폭 보강하여 만든 책이다. 지금까지의 딥 러닝 연구 성과를 수식과 함께 체계적으로 정리하였을 뿐만 아니라 앞으로 남은 과제를 구체적인 사례와 함께 서술하였다. 기초편에서는 딥 러닝의 전체 그림과 함께 대규모 신경망을 학습하는 데 필요한 노하우를 간략하게 정리하였으며, 응용편에서는 딥 러닝의 주요 응용 분야인 이미지 인식, 음성 인식, 자연어 처리에서 딥 러닝이 어떻게 적용되고 있는지와 함께 각 분야에 특화된 응용 기법을 소개하였다. 대상 독자 및 주요 내용인공지능 학과 대학원생관련 업계 연구자나 엔지니어 기초편1장 딥 러닝 개요 2장 볼츠만 머신 3장 대조적 발산 4장 딥 러닝의 대규모 구현 응용편5장 이미지 인식6장 음성 인식7장 자연어 처리 지은이 소개아소 히데키(麻生 英樹)_1장 집필산업기술종합연구소 인공지능 연구센터 부센터장연구 분야: 기계학습 및 응용 야스다 무네키(安田 宗樹)_2장 집필야마가타 대학교 부교수연구 분야: 기계학습, 정보통계 역학, 이미지 처리 마에다 신이치(前田 新一)_3장 집필교토 대학교 조교연구 분야: 기계학습, 강화학습, 통계적 이미지 처리 오카노하라 다이스케(岡野原 大輔)_4장 집필Preferred Infrastructure와 Preferred Networks의 임원 및 부사장연구 분야: 기계학습, 대규모 데이터 분석, 자연어 처리, 데이터 구조 오카타니 타카유키(岡谷 貴之)_5장 집필도호쿠 대학교 교수연구 분야: 컴퓨터 비전 쿠보 요타로(久保 陽太郎)_6장 집필아마존 음성인식 과학자연구 분야: 음성인식 다누슈카 볼레갈라(Danushka Bollegala)_7장 집필리버풀 대학교 부교수연구 분야: 자연어 처리, 데이터 마이닝, 기계학습 카미시마 토시히로(神嶌 敏弘)_편집 담당산업기술종합연구소 주임연구원연구 분야: 데이터 마이닝, 기계학습, 추천 시스템 옮긴이 소개심효섭연세대학교 문헌정보학과를 졸업했고, 모교 중앙도서관과의 인연으로 도서관 솔루션 업체에서 일하게 되면서 개발을 시작하였다. 네이버에서는 웹 서비스 개발 업무를 맡았으며, 웹 서비스 외에도 머신 러닝에 대한 학습도 꾸준히 하고 있다. 한편, 최근에는 회사에 속하지 않고 지속 가능한 삶에 골똘하고 있다. 차례PART 1 기초편_1CHAPTER 1 계층형 신경망을 이용한 딥 러닝_31.1 시작하며 31.2 데이터로부터 내부 표현 학습하기 5    1.2.1 내부 표현의 중요성과 학습 기법 6    1.2.2 특징 엔지니어링과 표현 학습 71.3 계층형 신경망 10    1.3.1 신경망 연구의 계보 10    1.3.2 계층형 신경망의 수리적 모형 111.4 계층형 신경망의 학습 13    1.4.1 오차수정 학습 14    1.4.2 오차역전파 학습 15    1.4.3 경쟁학습 171.5 딥 뉴럴넷을 이용한 심층 표현학습 18    1.5.1 오차역전파 학습을 통한 내부 표현학습 19    1.5.2 딥 뉴럴넷의 학습 201.6 합성곱 신경망 211.7 자기부호화기 24    1.7.1 자기부호화기와 자기부호화기의 학습 24    1.7.2 적층 자기부호화기 25    1.7.3 희소 자기부호화기 27    1.7.4 잡음제거 자기부호화기 281.8 정리 28참고 문헌 30더보기CHAPTER 2 딥 볼츠만 머신_352.1시작하며 352.2 통계적 머신 러닝의 아이디어 ― 데이터 생성 모형의 재현 372.3 마르코프 확률장과 볼츠만 머신 40    2.3.1 마르코프 확률장 40    2.3.2 볼츠만 머신 42    2.3.3 볼츠만 머신과 홉필드 네트워크의 관계 44    2.3.4 볼츠만 머신의 학습을 위한 준비 452.4 가시변수만 있는 볼츠만 머신의 학습 46    2.4.1 쿨벡 - 라이블러 발산으로부터의 학습방정식 유도방법 49    2.4.2 볼츠만 머신 학습에 대한 구현과 조합의 폭발 문제 512.5 비가시변수가 있는 볼츠만 머신의 학습 53    2.5.1 비가시변수가 있는 경우의 학습에 대해서 56    2.5.2 비가시변수를 도입하는 의미 572.6 볼츠만 머신에서의 근사 기법 59    2.6.1 깁스 샘플링 60    2.6.2 평균장 근사 632.7 제약 볼츠만 머신 66    2.7.1 조건부 독립성에 기초한 제약 볼츠만 머신의 성질 67    2.7.2 제약 볼츠만 머신의 학습 692.8 딥 볼츠만 머신 71    2.8.1 딥 볼츠만 머신의 사전훈련 73    2.8.2 사전훈련 후의 최대우도추정법에 기초한 학습 77    2.8.3 제약 볼츠만 머신을 자기부호화기로 활용하기 79    2.8.4 딥 볼츠만 머신의 이용법 812.9 딥 빌리프넷 83    2.9.1 딥 빌리프넷에 대한 사전훈련 및 추론 84    2.9.2 딥 빌리프넷에 대한 사전훈련의 정당성 862.10 정리 91참고 문헌 92 CHAPTER 3 사전훈련과 그 주변_953.1 시작하며 953.2 자유도가 높은 통계 모형에 대한 학습의 어려움과 해결책 96    3.2.1 학습을 어렵게 하는 요인 96    3.2.2 기존의 해결법 98    3.2.3 새로운 해결법 1013.3 자기부호화기를 이용한 내부 표현학습 104    3.3.1 자기부호화기와 자기부호화기의 손실함수 정의 104    3.3.2 층 단위 탐욕학습을 통한 자기부호화기의 사전훈련 1063.4 확률적 모형을 사용한 사전훈련 107    3.4.1 제약 볼츠만 머신 107    3.4.2 지수형 하모니움족 110    3.4.3 대조적 발산을 이용한 지수형 하모니움족의 학습 114    3.4.4 대조적 발산법이 최적화하는 손실함수 115    3.4.5 대조적 발산법과 비슷한 학습 규칙을 갖는 알고리즘 123    3.4.6 대조적 발산으로부터 파생한 학습 규칙 125    3.4.7 확률적인 모형의 사전훈련과 자기부호화기 학습의 관계 1273.5 결정적 모형을 사용한 사전훈련 128    3.5.1 비지도 학습을 통한 결정적 모형의 학습 130    3.5.2 지도학습 방식을 이용한 결정적 모형의 학습 1333.6 Product of Experts 학습법으로 본 대조적 발산법 1343.7 정리 136참고 문헌 137 CHAPTER 4 대규모 딥 러닝을 실현하기 위한 기술_1414.1 시작하며 1414.2 딥 러닝의 최적화 143    4.2.1 딥 러닝의 기본 연산 143    4.2.2 확률적 경사하강법 1454.3 속도 향상을 위한 기법 146    4.3.1 분산병렬처리: 디스트빌리프 146    4.3.2 GPU를 이용한 대규모 신경망학습 150    4.3.3 인피니밴드의 이용 153    4.3.4 학습수렴 속도를 향상시키는 방법 1544.4 과적합 억제: 드롭아웃 1574.5 활성화함수 161    4.5.1 ReLU 161    4.5.2 MaxOut 1624.6 학습률을 조정하는 기법 163    4.6.1 AdaGrad 164    4.6.2 Adam 164    4.6.3 하이퍼파라미터의 최적화 1654.7 구현을 위한 기법 167    4.7.1 구현이 올바른지 확인하기 1674.8 정리 168참고 문헌 168 PART 2 응용편_171CHAPTER 5 이미지 인식을 위한 딥 러닝_1735.1 시작하며 173    5.1.1 합성곱 신경망의 재발견 174    5.1.2 후속 연구 1755.2 합성곱 신경망 177    5.2.1 기본 구조 177    5.2.2 합성곱층 178    5.2.3 풀링층 181    5.2.4 예제: 숫자 필기 인식을 위한 합성곱 신경망 182    5.2.5 학습 184    5.2.6 콘트라스트 조정과 데이터 정규화 1865.3 합성곱 신경망의 동작 188    5.3.1 일반물체 인식의 어려움 188    5.3.2 일반물체 인식의 기존 방법 189    5.3.3 기존의 방법과 합성곱 신경망의 비교 193    5.3.4 네트워크 구조와 인식 성능 195    5.3.5 합성곱 신경망의 확장을 위한 시도 1975.4 합성곱 신경망의 내부 표현 198    5.4.1 시각화 198    5.4.2 뇌신경계와의 관계 199    5.4.3 전이학습 2005.5 이미지 특징에 대한 비지도학습 201    5.5.1 단층 자기부호화기를 이용한 국소특징 학습 201    5.5.2 다층 신경망을 이용한 특징학습 2045.6 정리 208참고 문헌 209 CHAPTER 6 음성 인식을 위한 딥 러닝_2136.1 시작하며 2136.2 음성 인식 215    6.2.1 음성 인식에 사용되는 모형 215    6.2.2 대규모 어휘 연속 음성 인식 시스템의 구성 2196.3 음성 인식에서 사용되는 신경망 220    6.3.1 시간 지연 신경망 222    6.3.2 은닉 마르코프 모형과 조합한 신경망: 절충적 방식 223    6.3.3 은닉 마르코프와 조합한 신경망: 탠덤 방식 2256.4 음향 모형을 위한 딥 러닝: 사전훈련 227    6.4.1 제약 볼츠만 머신을 이용한 사전훈련을 적용한 딥 뉴럴넷 ― 은닉 마르코프 모형 227    6.4.2 잡음제거 자기부호화기를 이용한 사전훈련 230    6.4.3 식별적 사전훈련 2326.5 음향 모형을 위한 딥 러닝: 학습과 모형의 진전 233    6.5.1 연속열 식별학습 233    6.5.2 순환결합 신경망을 이용한 음향 모형 238    6.5.3 장단기 기억 241    6.5.4 멀티스트림/멀티태스크 학습 2456.6 언어 모형에 대한 딥 러닝 246    6.6.1 회귀 결합 신경망을 이용한 언어 모형 2476.7 정리 249참고 문헌 250 CHAPTER 7 자연어 처리를 위한 딥 러닝_2537.1 시작하며 2537.2 딥 러닝과 언어 모형 256    7.2.1 신경망 언어 모형 257    7.2.2 그 외의 언어 모형 2607.3 단어 의미표현에 대한 학습 262    7.3.1 상향식 의미표현 구축 기법 262    7.3.2 하향식 의미표현 예측 기법 263    7.3.3 계층형 소프트맥스를 이용한 계산 268    7.3.4 의미표현학습 기법과 그 외의 주제 2707.4 딥 러닝과 의미 구축 273    7.4.1 패러프레이즈 표현 인식에 대한 응용 2747.5 정리 279참고 문헌 280 window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 779}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글러닝 파이썬(제5판): 하편  (2)2018.03.30러닝 파이썬(제5판): 상편  (9)2018.03.30핵심만 골라 배우는 코틀린 프로그래밍  (0)2018.03.06봇 설계는 이렇게 한다  (0)2018.03.02전문가를 위한 오라클 아키텍처 입문(제2판)  (0)2018.02.26태그cnn, deep learning, Machine Learning, 기계학습, 딥러닝, 머신러닝, 신경망, 심층학습, 심효섭, 아이러브인공지능, 제이펍'도서 소개' Related Articles러닝 파이썬(제5판): 하편러닝 파이썬(제5판): 상편핵심만 골라 배우는 코틀린 프로그래밍봇 설계는 이렇게 한다    setInitialEntryComments(779, 1723627703)Secret댓글달기loadedComments[779]=true;findFragmentAndHighlight(779);"
125,https://jpub.tistory.com/1160,태그,"도서 소개엑셀과 비교하며 배우는 파이썬 데이터 분석 제이펍2021. 6. 16. 09:12중국에서 각종 우수 도서상을 수상하고 베스트셀러로 판매되고 있는, 데이터 분석을 위한 최고의 한 권! 도서 구매 사이트(가나다순)  [교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 출판사 제이펍저작권사 电子工业出版社원서명 对比Excel，轻松学习Python数据分析 (ISBN 9787121357930)저자명 장쥔홍역자명 이춘혁출판일 2021년 6월 17일페이지 328쪽시리즈 (없음)판  형 크라운판(170*225*18.1)제  본 무선(soft cover)정  가 24,000원ISBN 979-11-91600-11-7 (93000)키워드 엑셀 / 파이썬 / 데이터 / 데이터 분석 / 데이터 전처리 / 데이터 조작 / 데이터 선별 / 데이터 조작 / 데이터 연산 / 시계열 / 데이터 그룹화 / 다중 테이블 결합 / 데이터 시각화 / 배열 / 통계 / 연산 / Jupyter Notebook / 데이터 구조 / 문자열 / 리스트 / 딕셔너리 / 튜플 / 연산자 / 반복문 / 조건문 / 함수분야 엑셀 / 파이썬 / 데이터 분석 관련 사이트■ 현지 인터넷 서점 해당 도서 페이지 관련 포스트■ 2021/6/8 - [출간전 책소식] - 엑셀과 파이썬의 기묘하고 절묘한 조합! 관련 시리즈 ■ (없음)관련 도서 ■ 4차 산업혁명 현장 전문가가 알려주는 빅데이터 분석과 활용 ■ 빅데이터를 지탱하는 기술 관련 파일 다운로드■ (* 각 장별 엑셀 테이블 예제 데이터셋입니다.)[예제데이터셋]엑셀과비교하며배우는파이썬데이터분석.zip1.80MB  강의보조 자료(교재로 채택하신 분들은 메일(textbook@jpub.kr)을 보내주시면 다음의 자료를 보내드리겠습니다.)■ 본문의 그림과 표 샘플 PDF(표지, 차례, 옮긴이 머리말, 추천사, 이 책에 대하여, 베타리더 후기, '쏙쏙 들어오는 인공지능 알고리즘' 지도, 1장 '데이터 분석 기초' 일부, 2장 '냄비 확인하기 ― 파이썬 기초 지식' 일부, 5장 '쌀과 야채 씻기 ― 데이터 전처리' 일부, 13장 '요리 가지런히 놓기 ― 데이터 시각화' 일부, 14장 '대표적인 데이터 분석 사례' 일부, 15장 'NumPy 배열' 일부) sample_엑셀과비교하며배우는파이썬데이터분석.pdf3.26MB 정오표 페이지■ https://jpub.tistory.com/1179 도서 구매 사이트(가나다순)  [교보문고]  [도서11번가]  [반디앤루니스]  [알라딘]  [예스이십사]  [인터파크]  [쿠팡]  전자책 구매 사이트(가나다순)교보문고 / 구글북스 / 리디북스 / 알라딘 / 예스이십사 도서 소개데이터 분석 + 엑셀 데이터 분석 + 파이썬 데이터 분석을 한 권으로 끝낸다!이 책은 데이터 분석의 전체 프로세스를 체계적으로 학습할 수 있는 실습서이자 데이터 분석가에게는 꼭 필요한 실전 도구와 같다. 파이썬 데이터 분석, 엑셀 데이터 분석, 그리고 일반적인 데이터 분석을 서로 비교하며 쉽게 배울 수 있도록 구성하였다. 데이터 분석을 위한 절차인 도구 숙지, 데이터 획득, 데이터 숙지, 데이터 처리, 데이터 분석, 분석 결과를 엑셀과 파이썬으로 비교하며 구현한다. 또한 그 각각의 과정에서 어떤 것들이 사용될 수 있는지, 과정과 과정 사이에 무슨 연관이 있는지를 알려준다. 아울러, 엑셀 기능과의 비교를 통해 파이썬 구현 코드를 학습하고, 직접 따라 하며 배우는 실습 위주의 구성을 통해서 코딩에 대한 독자들의 두려움을 없앴다. 처음부터 하나씩 따라 하다 보면 데이터분석의 전 과정을 체계적으로 학습할 수 있을 것이다. 이 책의 주요 구성 ● 입문편 - 주로 데이터 분석의 기초 지식을 소개. 데이터 분석의 정의와 필요성, 분석 대상, 일반적인 과정을 소개 ● 실전편 - 데이터 분석에 대한 전체적인 과정과 각 단계별 조작 및 엑셀과 파이썬을 통한 분석 방법 ● 심화편 - 실제 사례 소개 및 실제 업무에서 응용 가능한 파이썬의 사용 소개 이 책의 대상 독자 ● 엑셀 또는 파이썬에 익숙하지 않은 데이터 분석가 ● 엑셀을 사용하고 있지만 파이썬을 통해 업무 효율을 높이고 싶은 담당자 지은이 소개장쥔홍(张俊红)인터넷 회사에서 데이터 분석가로 일하고 있으며, 파이썬, SQL, 엑셀을 능숙하게 다룰 수 있어서 데이터 분석뿐만 아니라 머신러닝 분야에서도 두각을 드러내고 있다. 지식 나누기를 좋아하고, 데이터 과학자로서 평생 공부하고, 실천하며, 나누는 삶을 소망하고 있다. 개인 위챗 계정에서 데이터 분석, 머신러닝, 웹 크롤링, 파이썬 프로그래밍에 도움이 되는 정보를 공유하고 있다. 옮긴이 소개이춘혁 고려대학교에서 한문학을 전공하며 자연스레 중국어와 일본어를 익히게 되었다. 중국, 스페인, 일본 등에서 생활하며 다양한 문화와 외국어를 접했고, 공부에 매진해 영어/중국어/일본어/스페인어를 이해하고 구사할 수 있는 수준이 되었다. 일본에서 웹과 ADAS 개발 업무를 담당하였으며, 현재는 한국비건인증원에서 웹 시스템 개발자로 일하고 있다. 신기술과 최적화에 관심이 많으며, ‘젊음을 값진 모험과 바꾸자’는 마음으로 다양한 경험을 하기 위해 노력 중이다. 차례CHAPTER 01 데이터 분석 기초 3 1.1 데이터 분석이란? 3 1.2 데이터 분석의 필요성 3 1.3 데이터 분석의 분석 대상은 무엇인가? 5 1.4 데이터 분석의 일반적인 프로세스 8 1.5 데이터 분석 도구: 엑셀과 파이썬 11 더보기CHAPTER 02 냄비 확인하기 ― 파이썬 기초 지식 15 2.1 파이썬이란? 15 2.2 파이썬 설치 16 2.3 Jupyter Notebook 소개 21 2.4 기본 개념 30 2.5 문자열 34 2.6 데이터 구조-리스트 38 2.7 데이터 구조-딕셔너리(dict) 43 2.8 데이터 구조-튜플 45 2.9 연산자 47 2.10 반복문 48 2.11 조건문 50 2.12 함수 53 2.13 고급 기능 56 2.14 모듈 58 CHAPTER 03 Pandas 데이터 구조 59 3.1 Series 데이터 구조 59 3.2 DataFrame 테이블 형식의 데이터 구조 61 CHAPTER 04 원재료 준비하기 ― 데이터 소스 가져오기 66 4.1 외부 데이터 가져오기 66 4.2 데이터 생성하기 77 4.34.3 데이터 파악하기 77 CHAPTER 05 쌀과 야채 씻기 ― 데이터 전처리 83 5.1 결측값 처리 83 5.2 중복값 처리 89 5.3 이상값 검측과 처리 92 5.4 데이터 유형 변환 94 5.5 인덱스 설정 97 CHAPTER 06 요리와 재료 선택하기 ― 데이터 선별 103 6.1 열 선택하기 103 6.2 행 선택하기 106 6.3 행과 열 동시 선택하기 109 CHAPTER 07 재료 손질하기 ― 데이터 조작 113 7.1 데이터 바꾸기 113 7.2 데이터 정렬하기 118 7.3 데이터 순위 확인하기 122 7.4 데이터 삭제하기 125 7.5 숫자 카운트하기 128 7.6 유일한 데이터 가져오기(중복값을 하나로 표현하기) 130 7.7 데이터 찾기 130 7.8 구간 분할하기 132 7.9 새로운 행 또는 열 삽입하기 135 7.10 행과 열 바꾸기 136 7.11 인덱스 재구성하기 138 7.12 테이블의 길이와 너비 전환하기 139 7.13 apply( )와 applymap( ) 함수 142 CHAPTER 08 요리 시작하기 ― 데이터 연산 144 8.1 산술 연산 144 8.2 비교 연산 146 8.3 일괄 연산 146 8.4 상관성 계산하기 155 CHAPTER 09 요리 타이머 ― 시계열 157 9.1 현재 시간 가져오기 157 9.2 날짜와 시간 형식 지정하기 159 9.3 문자열과 시간 형식 상호 변환하기 161 9.4 시간 인덱스 161 9.5 시간 계산하기 165 CHAPTER 10 요리 분류 ― 데이터 그룹화/피벗 테이블 168 10.1 데이터 그룹화 168 10.2 데이터 피벗 테이블 174 CHAPTER 11 디저트 과일 접시 준비 ― 다중 테이블 결합 179 11.1 테이블의 가로 결합 179 11.2 테이블의 수직 결합 187 CHAPTER 12 상 차리기 ― 결과 도출 191 12.1 .xlsx 파일 내보내기 191 12.2 .csv 파일 내보내기 195 12.3 파일을 여러 시트로 내보내기 198 CHAPTER 13 요리 가지런히 놓기 ― 데이터 시각화 199 13.1 데이터 시각화란? 199 13.2 데이터 시각화의 기본 과정 199 13.3 그래프의 기본 구성 요소 200 13.4 엑셀과 파이썬의 시각화 202 13.5 캔버스와 좌표계 생성하기 203 13.6 좌표축 설정하기 209 13.7 다른 그래프 형식 설정하기 216 13.8 일반적인 그래프 그리기 226 13.9 그래프 조합하기 251 13.10 이중축 그래프 생성 255 13.11 그래프 스타일 설정 257 CHAPTER 14 대표적인 데이터 분석 사례 263 14.1 파이썬을 사용한 보고서 자동화 263 14.2 이메일 자동으로 보내기 268 14.3 슈퍼마켓 체인점 관련 데이터 분석 271 14.4 은행 관련 데이터 분석 275 CHAPTER 15 NumPy 배열 280 15.1 NumPy 소개 280 15.2 NumPy 배열 생성 281 15.3 NumPy 배열의 기본 속성 286 15.4 NumPy 배열의 데이터 선택 288 15.5 NumPy 배열의 데이터 전처리 292 15.6 NumPy 배열 재구성 293 15.7 NumPy 배열 병합 29515.8 자주 사용하는 데이터 분석 함수 297제이펍 소식 더 보기(제이펍의 소통 채널에서 더욱 다양한 소식을 확인하세요!)  네이버 책 포스트 유튜브 인스타그램 트위터 페이스북  window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1160}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글실전에서 바로 쓰는 시계열 데이터 처리와 분석 in R: 교육, 고용, 코로나 데이터를 활용한 시계열 프로젝트  (0)2021.07.15아두이노 바이블: 상상이 현실이 되는 마법 스케치  (0)2021.07.03쏙쏙 들어오는 인공지능 알고리즘  (2)2021.06.09파이썬 챌린지: 150개의 코딩 과제로 배운다  (7)2021.05.10유튜브 채널 운영을 위한 포토샵 디자인  (0)2021.05.10태그Numpy, 데이터, 데이터구조, 데이터분석, 데이터시각화, 데이터전처리, 시계열, 엑셀, 통계, 파이썬'도서 소개' Related Articles실전에서 바로 쓰는 시계열 데이터 처리와 분석 in R: 교육, 고용, 코로나 데이터를 활용한 시계열 프로젝트아두이노 바이블: 상상이 현실이 되는 마법 스케치쏙쏙 들어오는 인공지능 알고리즘파이썬 챌린지: 150개의 코딩 과제로 배운다Secret댓글달기loadedComments[1160]=true;findFragmentAndHighlight(1160);"
126,https://lebi.tistory.com/5,[Machine Learning] 혼동행렬,"본문 바로가기메뉴 바로가기Data Science에일[Eyl]              글쓰기관리태그방명록RSSData Science카테고리 메뉴열기닫기검색하기검색하기 폼블로그 내 검색CATEGORY  Story (25)  Data Science (25)  Project (0)  Machine Learning (6)  Deep Learning (1)  Individual (16)  Team (2) 방명록티스토리 뷰Data Science/Machine Learning[Machine Learning] 혼동행렬에일[Eyl]            2019. 3. 29. 17:09                      혼동행렬(confusion matrix)은 모델의 성능을 평가할 때 사용되는 지표입니다.처음에 이해하기가 좀 헷갈렸는데 굉장히 이해가 잘되는 자료를 보고 정리해봤어요!먼저 모델의 성능을 평가하기 위해 혼동행렬과 함께 필요한 네 가지 개념이 있습니다.TP(True Positive) - 맞는 것을 올바르게 맞다고 예측한 것TN(True Negative) - 아닌 것을 올바르게 틀리다고 예측한 것FP(False Positive) - 아닌 것을 올바르지 않게 맞다고 예측한 것FN(False Negative) - 맞는 것을 올바르지 않게 틀리다고 예측한 것이건 ADSP공부할 때 나왔던 개념인데 솔직히 이해도 제대로 못하고 무작정 외웠었어요!이해를 돕기 위해'질병이 있는 사람(맞는 것)'과 '질병이 없는 사람(아닌 것)'을질병 진단기가 '올바르게(True) 혹은 올바르지 않게(False)' '맞다고(Positive) 혹은 틀리다고(Negative)' 판단하는지 그림과 같이 예를 들어볼게요!1.TP(True Positive) - 맞는 것을 올바르게 맞다고 예측한 것질병이 있는 사람이 진단기에게 검사를 받았는데 Positive라는 예측을 하였습니다.이 진단기는 질병이 있는 사람(맞는 것)을 '올바르게(True) 맞다고(Positive) 예측'하였으니 이 경우는 TP입니다. 2.TN(True Negative) - 아닌 것을 올바르게 틀리다고 예측한 것질병이 없는 사람이 진단기에게 검사를 받았는데 Negative라는 예측을 하였습니다.이 진단기는 질병이 없는 사람(아닌 것)을 '올바르게(True) 틀리다고(Negative) 예측'하였으니 TN입니다.3.FP(False Positive) - 아닌 것을 올바르지 않게 맞다고 예측한 것질병이 없는 사람이 진단기에게 검사를 받았는데 Positive라는 예측을 하였습니다.이 진단기는 질병이 없는 사람(아닌 것)을 '올바르지 않게(False) 맞다고(Positive) 예측'하였으니 FP입니다.4.FN(False Negative) - 맞는 것을 올바르지 않게 틀리다고 예측한 것질병이 있는 사람이 진단기에게 검사를 받았는데 Negative라는 예측을 하였습니다.이 진단기는 질병이 있는 사람(맞는 것)을 '올바르지 않게(False) 틀리다고(Negative) 예측'하였으니 FN입니다.혼동행렬 표 이해하기혼동행렬을 통해 모델이 다소 B를 C로 혼동하는 것과, C를 A로 혼동한다는 등의 정보를 알아낼 수 있고그에 따른 모델 개선을 생각해볼 수 있습니다. 더불어 대략적인 모델의 성능도 눈으로 확인할 수 있어요!위에서 이해가 되셨다면 이제 실제 혼동행렬을 보면서 정리해봅시다!이 모델은 A,B,C,D를 보여주면 A,B,C,D중에 하나를 예측하는 기계라고 생각해볼게요.혼동행렬 예시A : 10번 A를 보여줬을 경우, 9번은 A로 정확하게 맞췄으나, 1번은 B라고 대답함            B : 20번 B를 보여줬을 경우, 15번은 B로 맞췄으나, 1번은 A, 3번은 C, 1번은 D라고 대답함 C : 30번 C를 보여줬을 경우, 24번은 C로 맞췄으나, 5번은 A, 1번은 D라고 대답함 D : 20번 D를 보여줬을 경우, 15번은 D로 맞췄으나, 4번은 B, 1번은 C라고 대답함1. TP혼동행렬에서 TP 찾기TP는 맞는 것을 올바르게(True) 맞다고(Positive)예측 하는 거였죠?각 클래스별로 A는 A, B는 B, C는 C, D는 D라고 올바르게 예측한 부분들이 TP겠네요!  2. TNA클래스의 TN찾기TN은 아닌 것을 올바르게(True) 틀리다고(Negative) 예측하는 개념이였습니다.A클래스에서 봤을 때 A가 아닌 것(B,C,D)을 올바르게 틀리다(B,C,D)고 예측한 부분이 어느부분일까요?B클래스에서는 15 , 3 , 1C에서는 0 , 24 , 1D에서는 4 , 1 , 15이해가 되시나요 ? 그럼 이번엔 B클래스에 대한 TN을 찾아봐요!B클래스의 TN찾기B가 아닌 것(A,C,D)을 올바르게 틀리다(A,C,D)라고 예측한 부분을한줄 한줄 차례 보면,A에서는 9 , 0 , 0C에서는 5 , 24 , 1D에서는 0 , 1 , 15이 부분들이 B가 아니라고 예측한 값이 되겠죠?3.FPA클래스의 FPFP는 아닌 것을 올바르지 않게 맞다고 예측해버린다는 개념이었습니다. A가 아닌 것(B,C,D)을 A라고 올바르지 않게 예측한 값들은 B에서는 1C에서는 5D에서는 0입니다.한번 더 볼게요.B클래스의 FPB가 아닌 것(A,C,D)을 B라고 올바르지 않게 예측해버린 값들은A에서는 1C에서는 0D에서는 4가 되겠죠?4.FNA클래스에 대한 FN은 어느 부분 일까요?A라는 실제값에 대해서 맞는 것을 올바르지 않게 틀리다고 예측해버린 값들은 어디일까요?맞는 것(A)을 올바르지 않게 틀리다고 예측한 값은 A클래스에 대해선 B,C,D가 되겠네요!이상으로 혼동행렬의 기본적인 4가지 개념에 대해 알아봤습니당이해가 되셨다면 좋겠네요! (●'◡'●)<참고 문헌> -https://www.youtube.com/watch?v=VAogHvCqf3E -Minseok-Heo, [나의 첫 머신러닝/딥러닝], Wikibooks, 2019. 이 글은 저자님과 출판사의 참고 허가를 받고 작성되었습니다. window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//lebi.tistory.com/reaction';window.ReactionReqBody = {    entryId: 5}공유하기게시글 관리Data Science 'Data Science > Machine Learning' 카테고리의 다른 글[Machine Learning] 선형 회귀와 경사하강법  (0)2019.04.14[Machine Learning] K-최근접 이웃(KNN) 알고리즘  (0)2019.04.04[Machine Learning] 서포트 벡터 머신 - SVM  (0)2019.04.03[Machine Learning] 과대적합과 과소적합  (0)2019.03.28[Machine Learning] 지도학습과 비지도학습  (0)2019.03.27TAGFN, TP, 혼동행렬loadedComments[5]=true;findFragmentAndHighlight(5);글 보관함2020/06                          (1)2020/05                          (4)2020/01                          (6)2019/09                          (4)        Blog is powered by        Tistory / Designed by        Tistory    (function ($) {      $.Area.init();    })(jQuery);  티스토리툴바window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""3068508-5"",""customProps"":{""userId"":""0"",""blogId"":""3068508"",""entryId"":""5"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""5"",""entryTitle"":""[Machine Learning] 혼동행렬"",""entryType"":""POST"",""categoryName"":""Data Science/Machine Learning"",""categoryId"":""702317"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""3859797"",""authorNickname"":""에일[Eyl]"",""blogNmae"":""Data Science"",""image"":""kage@vnB7g/btqtVfbYiJs/EYLmgzMs92XpDNsp1aWOS0"",""plink"":""/5"",""tags"":[""FN"",""TP"",""혼동행렬""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
127,https://doooob.tistory.com/215,1. TensorFlow 개발자 인증 응시자를 위한 안내서,"AI · 인공지능/AI 칼럼나는 어떻게 TensorFlow 개발자 자격증을 통과했는가by 두우우부2020. 8. 17.     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }반응형(adsbygoogle = window.adsbygoogle || []).push({}); 저자 Daniel Bourke 씨는 호주에 거주하는 기계 학습 엔지니어입니다. 그는 최근 Medium에 투고한 기사 ""나는 어떻게 TensorFlow 개발자 인증을 통과했는가""를 통해서 합격에 이른 전말을 설명하고 있습니다. Daniel BourkeThe official blog of Daniel Bourke. I play at the crossroads of artificial intelligence, health science, life and art.www.mrdbourke.com 뭔가에 도전하는 것을 좋아하는 그는, 도전과 스킬업을 겸해 Google이 운영하는 자격시험 ""TensorFlow 개발자 인증""을 시험 보기로 했습니다. 이 자격은 이름에서 알 수 있듯이 주요 AI 모델 개발 환경의 하나인 TensorFlow를 활용하여 AI모델을 구축하는 능력을 묻는 것입니다. 시험 주최자Google응시 자격개인적으로 응시한다. 법인 단위로 자격취득 불가시험 내용TensorFlow 2.0 이상을 사용하여 신경망 모델을 구축하고 훈련. 이미지 분류, 자연 언어 처리 , 시계열 데이터의 예측.출제 형식PyCharm 환경에서 TensorFlow를 사용한 TensorFlow 모델을 도입, 온라인으로 성능 기반 테스트공식 교재추천 교재를 정리한 웹 페이지가 있다시험 시간5시간시험 장소시험 환경을 사용할 수 있는 곳이라면 어디서나시험일언제든지응시료100US 달러 당신도 합격하는 방법5월 초, 저는 TensorFlow 개발자 자격증을 취득하기로 했습니다. 6월 3일에 인증 시험을 받았고, 결국 합격했습니다. 제가 어떻게 통과했는지...그리고, 당신도 충분히 합격 가능하다는 것을 알려드리겠습니다. 잠깐만... TensorFlow가 뭔가요? TensorFlow는 오픈 소스 수치계산 프레임워크로 데이터를 전 처리하여 데이터를 모델링하고(일반적으로 딥러닝을 통해 패턴을 찾아) 해결 솔루션을 세계에 실증하는 것이 가능한 녀석입니다. 이 프레임워크는 Google이 기계 학습 서비스의 모든 것을 작동시키기 위하여 사용하는 것으로, 당신이 이 기사를 읽는 데 사용하는 디바이스도, 이전에 어떤 TensorFlow가 실행된 적이 있을지 모릅니다. 보통 사용자는, TensorFlow 코드를 이해하기 쉬운(시험에 출제되는) Python 또는 JavaScript(tensorflow.js)로 작성하고 C언어로 작성된 일련의 기초 함수를 트리거로 하여, 실행되도록 지시한 것들을 수행합니다(다량의 수치계산을 수행). 자, 이제 TensorFlow가 무엇인지는 알았습니다만, 그럼 TensorFlow 개발자 인증 자격은 뭐죠? 이 자격은 흥미를 끌만한 것인지에 대해 알아봅시다. TensorFlow 개발자 인증이란?TensorFlow 개발자 인증은 상상하신 대로, TensorFlow의 사용 능력을 어필하기 위한 것입니다. TensorFlow 개발자 인증서를 받으세요 - TensorFlowTensorFlow 인증 프로그램을 통과함으로써 TensorFlow를 활용하여 딥러닝 및 머신러닝(ML) 문제를 해결할 수 있는 능력을 입증하세요.www.tensorflow.org 보다 구체적으로는 TensorFlow(Python 버전)을 사용하여 회귀, 컴퓨터 비전(이미지의 패턴을 찾음), 자연 언어 처리(텍스트 패턴을 찾음), 시계열 예측(주어진 과거 사건의 범위에서 향후 추세를 예측) 등의 작업에 대한 딥러닝 모델을 구축하는 능력을 묻는 자격입니다. TensorFlow 개발자 인증을 취득하고 싶은 이유는?저의 경우, 최초의 이유는 재미였습니다. 저는 저 자신이 조금이라도 무엇인가에 도전하는 것을 바랐고, 구입한 새 책을 읽는 이유가 되기도 했습니다(이에 대해서는 나중에 자세히 설명하겠습니다). 하지만 그 밖에도 2개의 타당한 이유가 있습니다.기계 학습을 베이스로 한 응용 프로그램을 구축하는 데 필요한 기초 기술을 습득합니다.미래의 고용주에게 자신의 기술 역량을 어필합니다.고용주와 관련해서(소프트웨어 개발자 구인 정보를 매월 모은 페이지인) Hacker News의 Who's Hiring 페이지 데이터에 따르면, 다른 딥러닝 프레임워크와 비교하면 TensorFlow가 우위에 있는 것으로 보입니다.  Hacker News의 Who's Hiring 페이지에 게재되어 있는 다양한 채용 정보에서 언급되는 다양한 딥러닝 프레임워크를 비교하여 보았습니다. 주 1 : TensorFlow 2.x 시점에서는 Keras는 기본적으로 TensorFlow의 일부입니다.주 2 : 코로나라는 세계적인 상황 때문에 소프트웨어 개발자의 전반적인 채용은 감소하고 있습니다.  확실히 해두고 싶지만, 유료 자격 인증서가 취업의 보증이 되는 것은 아닙니다. 그러나 기술이 상품화되고 있는 온라인 학습의 세계에서, 유료 자격증의 취득은 자신의 능력을 어필하기 위한 또 하나의 방법인 것입니다. 온라인 강좌에서 기초 지식을 구축하고 사적인 프로젝트에서 특정 지식을 구축, 이러한 두 가지 기술 구축 방법 이외에, 유료 자격증은 당신이 해왔던 개인 프로젝트의 목록에 멋진 가치를 더해준다고 저는 생각합니다. 라고는 해도, 어떻게 유료 자격증을 취득하나요? 시험 준비 방법저는 우선 인증 사이트를 보고, TensorFlow 개발자 인증 핸드북을 읽었습니다. TensorFlow 개발자 인증서를 받으세요 - TensorFlowTensorFlow 인증 프로그램을 통과함으로써 TensorFlow를 활용하여 딥러닝 및 머신러닝(ML) 문제를 해결할 수 있는 능력을 입증하세요.www.tensorflow.orgTF_Certificate_Candidate_Handbook_ko.pdf0.28MB 이 인증 사이트와 핸드북 두 가지 리소스를 받고서, 저는 다음과 같은 커리큘럼을 구축했습니다. 커리큘럼 - 합격에 필요한 스킬을 습득하기 위해 공부한 것제 스킬에 대해 주목할만한 것은 시험공부를 시작하기 전에 TensorFlow를 사용한 여러 프로젝트를 구축한 실무 경험이 있다는 것입니다. 경험이 풍부한 TensorFlow와 딥러닝 실무자는 저와 거의 같은 속도(총 3주) 거나, 더 빠르게 다음 과정을 해내리라는 것을 알 수 있을 것입니다. 초심자는 필요한 만큼 시간을 들이고 싶으시겠지만, 기억해 주셨으면 하는 것은 : 가치 있는 스킬을 습득하는 것은 시간이 걸리는 일이라는 것입니다. 각각의 리소스에 대하여, 타임 라인, 비용(US 달러), 시험에 합격하기 위한 도움의 정도를 나열했습니다. 타임라인은 저의 경험에 근거하고 있습니다. 만약 스스로 커리큘럼을 만든다면, 아래의 것들을 추천합니다. 참고 : 유료 리소스에 관해서는 광고 제휴가 되어 있습니다. 링크가 자원의 가격을 변화시키는 것은 아니지만, 당신이 이들 자원 중 하나를 구입한 경우, 제가 그 지불의 일부를 받게 됩니다. 그것은 제가 이런 글을 작성한 대가이기도 합니다.     (adsbygoogle = window.adsbygoogle || []).push({});1. TensorFlow 개발자 인증 응시자를 위한 안내서TF_Certificate_Candidate_Handbook_ko.pdf0.28MB시간 : 1시간비용 : 무료유용도 : 필수이 자원은 당신의 첫 번째 단계가 될 것입니다. 이것은 시험에서 다루는 주제의 개요를 나타내고 있습니다. 우선 핸드북을 읽고, 또 읽으세요. 만약 당신이 TensorFlow와 기계 학습의 초심자라면 핸드북을 읽고, 너무 다양한 토픽이 있어서 걱정이 앞설 수 있습니다. 하지만 걱정하실 필요 없습니다. 다음 리소스는 그런 주제에 익숙해지는 데 도움이 됩니다.2. Courcera의 ""TensorFlow in Practice 전문 강좌"" TensorFlow in PracticeOffered by deeplearning.ai. Discover the tools software developers use to build scalable AI-powered algorithms in TensorFlow, a popular open-source machine learning framework. In this four-course Specialization, you’ll explore exciting opportunities forwww.coursera.org시간 : 3주(상급자) ~ 3개월(초심자)비용 : 7일 무료체험 후 한 달에 59달러 신청을 통해 경제적 지원을 받을 수 있습니다. Coursera에 액세스 할 수 없는 경우에는 YouTube에서 동등한 무료 버전을 시청합시다.유용성 : 10/10  Coding TensorFlowWelcome to Coding TensorFlow! In this series, we will look at various parts of TensorFlow from a coding perspective. Subscribe to TensorFlow → https://goo.gl...www.youtube.com(※ 역주 1) TensorFlow in Practice 전문 강좌에는 한국어 자막이 지원됩니다.(설정 -> 자동번역 -> 한국어) Coursera의 전문 강좌는 시험(및 일반적으로 TensorFlow를 시작하는 데)에 가장 좋은 자원입니다. 신중한 학생은 TensorFlow 인증 핸드북과 전문 강좌 개요가 거의 동일하다는 것을 눈치챌 것입니다. 이 전문 강좌는 TensorFlow와 기계 학습의 양대 산맥인 로렌스 모로니(Laurence Moroney)와 앤드류 응(Andrew Ng, ※ 역주2)이 가르쳐 줍니다. 시험 준비를 위해 자원을 하나만 선택해야 한다면, 저는 망설임 없이 이것을 선택할 것입니다.(※ 역주 2) 앤드류 응은 영어권에서 가장 유명한 온라인 학습 서비스 Coursera의 창시자이며, 미국의 AI 업계를 견인하는 교육자이기도 합니다. 이 전문 강좌는 짧은 비디오 형식으로 최대한 빠르게 실사례에 초점을 맞추고 있음을 저는 높이 평가합니다. 각 섹션의 마지막에 있는 여러 코드 노트는 모든 학습자에게 필수적인 것입니다. 프로그래밍 연습 팁 : 코드의 빈 답을 채울 뿐만 아니라 전체를 직접 만들어 봅시다. 3. Scikit-Learn, Keras, TensorFlow를 사용한 실용적인 기계 학습 제2판 Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent SystemsHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systemswww.amazon.com 시간 : 3주(처음부터 끝까지 읽고 연습은 없이) ~ 3개월(처음부터 끝까지 읽고 연습을 실시)비용 : Amazon에는 다양한 가격이 있지만, 저는 이 책을 55달러에 입수했습니다. 이 책의 소스 코드는 GitHub에서 모두 무료로 볼 수 있습니다.유용성 : 7/10 (일부 챕터는 시험에 관계없다는 이유로...) ageron/handson-ml2A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2. - ageron/handson-ml2github.com 700 페이지 이상의 책이며, 기본적으로 기계 학습의 모든 것을 다루고 있습니다. 따라서 시험에 관련 없는 몇 가지 주제를 다루고 있습니다. 그러나 기계 학습의 탄탄한 기반 구축에 관심 있는 사람들에겐 필독서이며, 시험 합격만을 위한 책은 아닙니다. 기계 학습의 초심자라면 이 책을 읽는 것은 분명 어려울 것입니다. 하지만 걱정은 필요 없습니다. 초조해하지 않아도, 유용한 기술을 습득하려면 시간이 걸릴 것입니다. 이 책의 질을 알고 싶으시다면, 제가 기계 학습 엔지니어로 출근하던 아침의 통근 시간에 초판을 읽고 있었다는 것을 전하고 싶습니다. 그리고 통근 중에 책에서 읽은 것을 그대로 하루 종일 직장에서 사용한 것이 종종 있었습니다. 제2판에서는 최신 도구와 함께 사용하는 기술, 즉 Tensor Flow 2.x 를 충당하기 위해 업데이트된 것을 제외하고, 제1판과 변함이 없습니다. 또한 시험은 TensorFlow 2.x에 기초하고 있습니다. 시험에 관련된 장만 보시려면 다음을 읽어보시는 것이 좋습니다.제10 장 : Keras를 사용한 인공 신경망 입문제11 장 : 딥 신경망 훈련제12 장 : TensorFlow에 의한 커스텀 모델과 훈련제13 장 : TensorFlow에 의한 데이터 로딩 및 전처리제14 장 : 컨볼루션 신경망을 이용한 딥 컴퓨터 비전제15 장 : RNN과 CNN을 이용한 시퀀싱제16 장 : RNN과 어텐션에 의한 자연언어처리성실한 학생이라면 책 전체를 공부하고 연습해 보는 것을 권장합니다. 4. MIT에 의한 딥러닝 입문 MIT Deep Learning 6.S191MIT's official introductory course on deep learning methods and applications.introtodeeplearning.com시간 : 3시간(저는 강의를 3회까지 밖에 보지 않았습니다) ~ 24시간(한 강의 당 1시간 + 복습을 각 1시간씩).비용 : 무료유용성 : 8/10 세계 수준의 대학이 발신하는 세계 수준의 딥러닝 정보를 얻을 수 있습니다. 그리고 무료입니다. 처음 세 개의 강의, 딥 러닝(개론) 콘볼루션 신경망(컴퓨터 비전에 사용), 리커런트 뉴럴 네트워크(보통 텍스트 처리에 사용)는 가장 시험과 관련 있는 부분입니다. 그러나 열성적인 학습자는 전체 과정을 수강하는 것도 좋을 것입니다. GitHub에서 제공되는 강의, 실험실과 코드, 특히 TensorFlow 입문에 대한 것을 확인합시다. aamini/introtodeeplearningLab Materials for MIT 6.S191: Introduction to Deep Learning - aamini/introtodeeplearninggithub.com 5. PyCharm의 사용을 시작 PyCharm Learning Center | JetBrainsIntelligent Python IDE with refactorings, debugger, code completion, on-the-fly code analysis and coding productivity orientationwww.jetbrains.com 시간 : 3시간(PC의 속도에 따라 다름)비용 : 무료유용성 : 10/10 (PyCharm을 사용하는 것이 조건). 시험은 PyCharm(Python의 개발 도구)으로 치러집니다. 저는 시험 전에 PyCharm을 사용한 적이 없었습니다. 적어도 어느 정도는 다룰 수 있게 되고 나서 시험에 임할 것을 권합니다. 우선 PyCharm에 익숙해지기 위해, ""이 버튼이 하는 일(here’s what this button does.)""이라는 YouTube 입문 시리즈를 보고 있었습니다. 그러나 위의 입문에서 확인하고 싶었던 것은 TensorFlow 2.x가 문제없이 작동하는지, 그리고 내 컴퓨터가 딥 뉴럴 네트워크를 적절한 시간 안에 수행할 수 있는지 였습니다(제 MacBook Pro에는 Nvidia GPU가 탑재되어 있지 않습니다). 이를 테스트하기 위해 다음의 두 가지 TensorFlow 튜토리얼을 제 로컬 컴퓨터에 복제했습니다.TensorFlow에 의한 화상 분류TensorFlow에 의한 텍스트 분류모두 로컬 환경에서 문제없이 움직였지만, 후술 하는 바와 같이 시험을 시작하자마자 문제에 부딪쳤습니다. 기타 리소스Coursera 또는, YouTube의 ""deeplearning.ai""동영상 - 시험은 순수하게 코드 베이스(Python 코드)지만 자신이 쓰고 있는 코드의 뒷면(선형 대수, 미적분)을 알고 싶다면 이곳의 동영상을 적당히 보시면 좋을 것입니다. 예를 들어, 미니 배치 경사 하강이 무엇인지 모르는 경우, ""deeplearning.ai mini-batch gradient descent""로 검색해보세요.TensorFlow 문서 - TensorFlow 실무자가 되려면 문서를 읽을 수 있도록 해 둘 필요가 있습니다. 모르는 것이 있으면, 코드를 작성하고 스스로 주석을 달아봅시다.YouTube(재생 목록) ""Coding TensorFlow"" - YouTube 동영상 시리즈 ""Coding TensorFlow""의 대부분은 Coursera와 같은 강사가 가르치고 있습니다.     (adsbygoogle = window.adsbygoogle || []).push({});어떻게 시험을 준비했나?위의 자원을 활용한 시험 대책에 대해 Notion(※ 역주 3)에서 개요를 정리해 보았습니다. Getting TensorFlow Developer Certified CurriculumAll of Daniel Bourke's (me) notes and curriculum for passing the TensorFlow Developer Certification exam.www.notion.so (※ 역주 3) Notion은 메모 작성, 작업 관리, 프로젝트 관리를 통합한 메모 어플리케이션입니다. Windows / MacOS / iOS / Android / Web에 대응하고 있습니다. Notion – The all-in-one workspace for your notes, tasks, wikis, and databases.A new tool that blends your everyday work apps into one. It's the all-in-one workspace for you and your teamwww.notion.so Notion에서 만든 제 TensorFlow 개발자 자격증의 교육 과정, Kanban의 기술을 사용하여 다양한 자원 및 메모와 함께, 해야 할 일들을 정리했습니다. 링크로 이동하여 우측 상단의 ""복제""버튼을 클릭하여 복사본을 만들 수 있습니다. Getting TensorFlow Developer Certified CurriculumAll of Daniel Bourke's (me) notes and curriculum for passing the TensorFlow Developer Certification exam.www.notion.so 5월 중 매일 아침에 일어나서 산책 후, 실천적인 기계 학습의 책을 1시간 읽고, TensorFlow를 2~3시간 연습하고(첫 강의를 본 후 Google Colab 코딩 연습을 모두 완료) 각 학습 모듈의 마무리에 해당하는 MIT에 의한 딥러닝 입문 강의를 보았습니다. 예를 들어, Coursera의 TensorFlow in Practice 전문 강좌에서 컴퓨터 비전 섹션을 마친 후에는 MIT의(컴퓨터 비전 알고리즘의 일종인) Convolutional Neural Network 강의를 보았습니다. 이 '책을 읽고 코드를 작성하고 동영상 강의로 복습한다'는 삼위일체의 접근 방식은 특히 효과가 있는 것으로 밝혀졌습니다. 책에서 읽은 개념은 Coursera의 전문 강좌의 샘플 코드에서 다져져 결국 MIT의 동영상 지식과 실천을 정리하는 것입니다. 5월 11일부터 수험 공부를 시작하여 6월 3일에 응시했습니다. (Notion을 사용한) 저의 트래킹과 필기 북마크에 따르면, 1시간에 평균 20페이지(집중해서) 2 ~ 3시간의 학습으로 약 1주간의 코스로 진행하고 있었네요. 결국, 시험 며칠 전에 PyCharm를 다운로드하여 제가 이미 경험한 몇 가지 예제 코드를 로컬 컴퓨터에서 작동하는 것을 확인했습니다. 시험의 상세 - 실제 시험은 어떤가?공부는 끝난 것인가? 그럼 그다음은 뭐지? 우선 중요한 두 가지 요소부터 설명하겠습니다. 시험 비용 : 100US 달러(1차 시험에 실패했을 경우는 2주간 대기 후 다시 도전해야 합니다. 그 후, 시험에 실패할 때마다 대기 시간이 길어집니다). TensorFlow 개발자 자격증 수험을 위한 가이드 북에 따르면, 재시험에 관해서는 다음과 같이 규정되어 있습니다.첫 번째 시험에서 불합격한 경우 재시험까지 14일간 기다리실 필요가 있습니다.두 번째 시험에서 불합격한 경우 재시험까지 2개월 동안 기다리셔야 합니다.세 번째 이후의 시험에서 불합격한 경우 재시험까지 1년간 기다리셔야 합니다. 시험 제한 시간 : 5시간. 시험 시작 시 오류가 없으면, 저는 편안하게 3시간 이내에 완료할 수 있었습니다. 그러나 제한 시간이 생각보다 긴 것은, 컴퓨터가 딥러닝 모델을 훈련하는 데 걸리는 시간을 충분히 응시자에게 제공하는 것입니다(따라서 시험 전에 훈련이 잘 되는지 확인해 봅시다). 시험은 어떻게 구성되어 있는지?시험의 구성을 설명하는 것은 부정행위이기 때문에, 이 문서에서는 많은 것을 밝힐 생각은 없습니다. 제가 말하고 싶은 것은 TensorFlow 개발자 인증 핸드북을 읽으면 시험의 주요 부분에 대한 아이디어를 공정하게 얻을 수 있다는 것뿐입니다. (위의 리소스를 사용하여) 핸드북에 소개되는 기술을 하나하나 실행하다 보면, 시험은 괜찮을 것입니다. 시험에 관한 짧은 지식모델 훈련 - 만약 당신의 컴퓨터가 딥러닝 모델을 충분히 빠르게 훈련할 수 없는 경우(합격 기준의 일부는 훈련된 모델을 제출하는 것), 무료 GPU를 사용하여 Google Colab에서 모델 훈련이 가능하며, 훈련 후 그들을 다운로드할 수 있습니다. 그리고 시험 관련 디렉터리에 배치하고 PyCharm을 사용하여 제출할 수 있습니다. 내 망가진 Python 인터프리터 - 시험 대비 문서에 Python3.7가 필수라고 강조되어 있습니다. 제가 시험 준비를 시작했을 때 Python 3.7.3 이었습니다. 그리고 전날까지 제 로컬 컴퓨터에서 PyCharm을 사용하여 TensorFlow가 움직이고 있었다 하더라도, 어떤 이유로 시험 시작 후(응시자를 위해 자동으로 TensorFlow 환경이 만들어지는) 시험 환경이 망가져 버렸습니다. 무슨 일인가 하면, TensorFlow 코드를 한 줄 실행할 때마다 다음과 같은 오류 메시지가 나온 것입니다.RuntimeError : dictionary changed size during iteration 지금에 와서는 오류의 원인이 시험 시에 설치되는 TensorFlow 버전(2.0.0)의 탓인지, 제가 가지고 있던 Python의 특정 버전(3.7.3) 때문인지는 잘 모릅니다. 하지만 욕 나오는 것을 참으며, 당면한 문제에 대한 GitHub의 이전 스레드를 열심히 검색한 결과, 사용했던 Python 소스 코드(구체적으로는 lincache.py의 48번째 줄)를 변경하지 않으면 안 된다는 기묘한 수정 방법을 발견했습니다. RuntimeError: dictionary changed size during iteration · Issue #33183 · tensorflow/tensorflowSystem information OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.15 Beta (virtual environment) TensorFlow installed from (source or binary): source TensorFlow version: 2.0.0 Py...github.com# 수정 이전 lincache.py의 48번째 줄for mod in sys.modules.values() :# 업데이트 후 lincache.py의 48번째 줄for mod in list (sys.modules.values()) : # 추가된 목록() 참고 : 이러한 변경 사항은 시험 중에 수행한 빠른 수정에 지나지 않기 때문에, 장기적인 효과와 영향이 있는지는 잘 모르겠습니다. 필사적으로 찾고 있는 가운데, PyCharm에서 사용하는 TensorFlow 버전을 업데이트 및 재설치하는 방법을 찾고(예 : 2.0.0 -> 2.2.x). 이 방법을 시도해 봤지만 잘 되지 않았습니다. 애당초 PyCharm 초보자인 제가 저질렀을 사용자 오류의 가능성이 가장 큽니다만. 아무튼, 수정을 실시하여 시험을 잘 마칠 수 있었습니다. 시험이 끝난 후에는 어떻게 될까?시험에 합격하면 이메일로 통지됩니다. ""합격 축하합니다""또는 ""불행히도 이번에는 통과할 수 없습니다."" 그 이외의 의견은 없습니다. 의욕을 잃지 않도록, 시험을 치는 동안에도 당신의 합격여부에 대해 매우 명확한 지표를 얻을 수 있습니다(모델을 제출할 때마다 시험 합격 지표가 표시됩니다). 여하튼, 만약 통과되면 TensorFlow 인증 개발자 네트워크에 추가된 것을 확인하기 위해 반드시 메일을 작성합시다. 시험에 합격하고 확인 메일 양식을 작성 후 몇 주 후에는 Google의 Global Certification Network에 나갈 수 있게 됩니다(1 ~ 2주 소요). 여기에 등록하는 것으로, 숙련된 TensorFlow 개발자를 찾고 있는 사람은 누구나 자격의 종류, 경험, 지역에 따라 당신을 검색할 수 있게 됩니다. 마지막으로, (저는 아직 취득하지 않았지만) 몇 주 이내에 공식 TensorFlow 개발자 인증서와 뱃지를 이메일로 보내줍니다. 채용 면접 시 선보일 수 있는 것이 두 가지 추가되는 셈입니다. Q & A강좌를 수강하고, 책을 읽고 스스로 연습하는 것만으로도 좋을 것 같은데, 자격증이 정말 필요한 것인가?물론 자격증이 필수는 아닙니다. 결국, 당신이 요구받는 것은 기술이고, 자격증이 아닙니다. 자격증은 가지고 있으면 좋은 것이지, 꼭 있어야 하는 것은 아닙니다. 자격증이 필요 없다면, 당신은 왜 취득했는지?저는 목표를 향해 도전하는 것을 좋아합니다. '6월 3일에 응시'처럼 기일을 정해두면 공부할 수밖에 없습니다. 무료 리소스만으로 합격할 수 있을까?네, 물론 가능합니다. TensorFlow 문서를 보시면, 필요한 기술을 모두 배울 수 있습니다. 사실 뭔가 연습이 필요한 경우에는 문서의 예제 코드를 일일이 복사하고(즉, 코드의 각 라인) 한 줄씩 이해하는 연습을 해서 스스로 응시 가능 여부를 확인하는 것입니다. 왜 PyTorch는 아닌가?저는 PyTorch가 가장 좋습니다. 그러나 Google은 PyTorch에서 인증을 제공하지 않기 때문에, 만약 제공되면 그 자격증에도 도전할 것입니다(그것도 즐겁게!). 또한, (PyTorch와 TensorFlow의) 두 프레임워크 양쪽에 다 숙련된 사용자라면 최신 업데이트가 매우 닮아있다는 것을 알 것입니다. 어느 쪽인가 하면, TensorFlow는 기업의 세계에서 우위에 있습니다. 기계 학습을 모르는데, 무엇부터 시작해야 할지?제가 쓴 기사 ""기계 학습을 배울 수 있는 5 개의 초심자 친화 단계""에서 읽을 수 있습니다. 시험에 합격하여 Google 개발자 인증 네트워크에 가입했지만, 다음은 무엇을 해야 합니까?만들 때가 왔습니다! 배운 기술을 사용하여 당신이 세상에서 해보고 싶은 것들을 만들어 봅시다. 당신의 작품을 누가 볼지 모르니 꼭 공유하는 것을 잊지 마세요. PS : 더 자세한 내용은 이 기사의 동영상 버전도 만들었기 때문에, 그쪽을 참고하십시오.  원문 : ""How I passed the TensorFlow Developer Certification Exam"" And how you can too How I passed the TensorFlow Developer Certification ExamAnd how you can tootowardsdatascience.com저자 : Daniel Bourke반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//doooob.tistory.com/reaction';window.ReactionReqBody = {    entryId: 215}공유하기게시글 관리두우우부 'AI · 인공지능 > AI 칼럼' 카테고리의 다른 글누가 NeurIPS 2020에서 AI 연구를 선도하는가?(전편)  (0)2021.02.01일본의 머신러닝 엔지니어 연봉은 얼마? 연령별 수입 및 미국과의 차이점  (0)2020.12.15틱톡(TikTok)은 왜 사용자를 사로잡은 것일까? - 사용자를 매혹시키는 AI 알고리즘[후편]  (1)2020.11.20틱톡(TikTok)은 왜 사용자를 사로잡은 것일까? - 사용자를 매혹시키는 AI 알고리즘[전편]  (0)2020.11.18일본에서 60만 건의 구인정보를 분석하여 데이터 과학자의 평균 연봉과 채용 조건을 분석  (0)2020.07.01코드 없는 AI 플랫폼, 사용해야 하나요? 그 한계와 기회  (0)2020.06.28기계 학습 엔지니어는 10년 후에는 존재하지 않을것이다.  (0)2020.06.13GAN의 발전의 역사( 응용 편 )  (0)2020.06.10태그AI 자격증, TensorFlow 개발자 인증 시험, TensorFlow 개발자 자격증, 텐서플로우 개발자 인증 시험관련글틱톡(TikTok)은 왜 사용자를 사로잡은 것일까? - 사용자를 매혹시키는 AI 알고리즘[후편]틱톡(TikTok)은 왜 사용자를 사로잡은 것일까? - 사용자를 매혹시키는 AI 알고리즘[전편]일본에서 60만 건의 구인정보를 분석하여 데이터 과학자의 평균 연봉과 채용 조건을 분석코드 없는 AI 플랫폼, 사용해야 하나요? 그 한계와 기회loadedComments[215]=true;findFragmentAndHighlight(215);"
128,https://bcho.tistory.com/1150,Tag,"                                                  조대협의 블로그                              HOMETAGSMEDIAGUESTBOOKADMINWRITE빅데이타 & 머신러닝/머신러닝텐서플로우-#1 자료형의 이해Terry Cho2016. 12. 9. 22:42텐서플로우-#1 자료형의 이해조대협 (http://bcho.tistory.com)딥러닝에 대한 대략적인 개념을 익히고 실제로 코딩을 해보려고 하니, 모 하나를 할때 마다 탁탁 막힌다. 파이썬이니 괜찮겠지 했는데, (사실 파이썬도 다 까먹어서 헷갈린다.) 이건 라이브러리로 도배가 되어 있다.당연히 텐서플로우 프레임웍은 이해를 해야 하고, 데이타를 정재하고 시각화 하는데, numpy,pandas와 같은 추가적인 프레임웍에 대한 이해가 필요하다.node.js 시작했을때도 자바스크립트 때문에 많이 헤매고 몇달이 지난후에야 어느정도 이해하게 되었는데, 역시나 차근차근 기초 부터 살펴봐야 하지 않나 싶다.텐서 플로우에 대해 공부한 내용들을 하나씩 정리할 예정인데, 이 컨텐츠들은 유투브의 이찬우님의 강의를 기반으로 정리하였다. 무엇보다 한글이고 개념을 쉽게 풀어서 정리해주시기 때문에, 왠만한 교재 보다 났다.https://www.youtube.com/watch?v=a74pFg8paVc텐서플로우 환경 설정텐서 플로우 환경을 설정 하는 방법은 쉽지 않다. 텐서플로우 뿐 아니라, 여러 파이썬 버전과 그에 맞는 라이브러리도 함께 설정해야 하기 때문에 여간 까다로운게 아닌데, 텐서플로우 환경은 크게 대략 두 가지 환경으로 쉽게 설정이 가능하다.구글 데이타랩첫번째 방법은 구글에서 주피터 노트북을 도커로 패키징해놓은 패키지를 이용하는 방법이다. 도커 패키지안에, numpy,pandas,matplotlib,tensorflow,python 등 텐서플로우 개발에 필요한 모든 환경이 패키징 되어 있다. 데이타 랩 설치 방법은 http://bcho.tistory.com/1134 링크를 참고하면 된다.도커 런타임이 설치되어 있다면, 데이타랩 환경 설정은 10분이면 충분하다.아나콘다다음 방법은 일반적으로 가장 많이 사용하는 방법인데, 파이썬 수학관련 라이브러리를 패키징해놓은 아나콘다를 이용하는 방법이 있다. 자세한 환경 설정 방법은 https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#anaconda-installation 를 참고하기 바란다. 아나콘다를 설치해놓고, tensorflow 환경(environment)를 정의한 후에, 주피터 노트북을 설치하면 된다. http://stackoverflow.com/questions/37061089/trouble-with-tensorflow-in-jupyter-notebook 참고Tensorflow 환경을 만든 후에, $ source activate tensorflow 를 실행해서 텐서 플로우 환경으로 전환한후, 아래와 같이 ipython 을 설치한후에, 주피터 (jupyter) 노트북을 설치하면 된다.(tensorflow) username$ conda install ipython (tensorflow) username$ pip install jupyter #(use pip3 for python3)아나콘다 기반의 텐서플로우 환경 설정은 나중에 시간이 될때 다른 글을 통해서 다시 설명하도록 하겠다.텐서플로우의 자료형텐서플로우는 뉴럴네트워크에 최적화되어 있는 개발 프레임웍이기 때문에, 그 자료형과, 실행 방식이 약간 일반적인 프로그래밍 방식과 상의하다. 그래서 삽질을 많이 했다. 상수형 (Constant)상수형은 말 그대로 상수를 저장하는 데이타 형이다. tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)와 같은 형태로 정의 된다. 각 정의되는 내용을 보면value : 상수의 값이다.dtype : 상수의 데이타형이다. tf.float32와 같이 실수,정수등의 데이타 타입을 정의한다.shape : 행렬의 차원을 정의한다. shape=[3,3]으로 정의해주면, 이 상수는 3x3 행렬을 저장하게 된다.name : name은 이 상수의 이름을 정의한다. name에 대해서는 나중에 좀 더 자세하게 설명하도록 하겠다.간단한 예제를 하나 보자. a,b,c 상수에, 각각 5,10,2 의 값을 넣은 후에, d=a*b+c 를 계산해서 계산 결과 d를 출력하려고 한다.import tensorflow as tfa = tf.constant([5],dtype=tf.float32)b = tf.constant([10],dtype=tf.float32)c = tf.constant([2],dtype=tf.float32)d = a*b+cprint d그런데, 막상 실행해보면, a*b+c의 값이 아니라 다음과 같이 Tensor… 라는 문자열이 출력된다.Tensor(""add_8:0"", shape=(1,), dtype=float32)그래프와 세션의 개념먼저 그래프와 세션이라는 개념을 이해해야 텐서플로우의 프로그래밍 모델을 이해할 수 있다.위의 d=a*b+c 에서 d 역시 계산을 수행하는 것이 아니라 다음과 같이 a*b+c 그래프를 정의하는 것이다.실제로 값을 뽑아내려면, 이 정의된 그래프에 a,b,c 값을 넣어서 실행해야 하는데, 세션 (Session)을 생성하여,  그래프를 실행해야 한다. 세션은 그래프를 인자로 받아서 실행을 해주는 일종의 러너(Runner)라고 생각하면 된다.자 그러면 위의 코드를 수정해보자import tensorflow as tfa = tf.constant([5],dtype=tf.float32)b = tf.constant([10],dtype=tf.float32)c = tf.constant([2],dtype=tf.float32)d = a*b+csess = tf.Session()result = sess.run(d)print resulttf.Session()을 통하여 세션을 생성하고, 이 세션에 그래프 d를 실행하도록 sess.run(d)를 실행한다이 그래프의 실행결과는 리턴값으로 result에 저장이 되고, 출력을 해보면 다음과 같이 정상적으로 52라는 값이 나오는 것을 볼 수 있다.플레이스 홀더 (Placeholder)자아 이제 상수의 개념을 알았으면, 이제는 플레이스 홀더에 대해서 알아보자.y = x * 2 를 그래프를 통해서 실행한다고 하자. 입력값으로는 1,2,3,4,5를 넣고, 출력은 2,4,6,8,10을 기대한다고 하자. 이렇게 여러 입력값을 그래프에서 넣는 경우는 머신러닝에서 y=W*x + b 와 같은 그래프가 있다고 할 때, x는 학습을 위한 데이타가 된다. 즉 지금 살펴보고자 하는 데이타 타입은 학습을 위한 학습용 데이타를 위한 데이타 타입이다.y=x*2를 정의하면 내부적으로 다음과 같은 그래프가 된다.그러면, x에는 값을 1,2,3,4,5를 넣어서 결과값을 그래프를 통해서 계산해 내야한다. 개념적으로 보면 다음과 같다. 이렇게 학습용 데이타를 담는 그릇을 플레이스홀더(placeholder)라고 한다. 플레이스홀더에 대해서 알아보면, 플레이스 홀더의 위의 그래프에서 x 즉 입력값을 저장하는 일종의 통(버킷)이다.tf.placeholder(dtype,shape,name) 으로 정의된다.플레이스 홀더 정의에 사용되는 변수들을 보면dtype : 플레이스홀더에 저장되는 데이타형이다. tf.float32와 같이 실수,정수등의 데이타 타입을 정의한다.shape : 행렬의 차원을 정의한다. shapre=[3,3]으로 정의해주면, 이 플레이스홀더는 3x3 행렬을 저장하게 된다.name : name은 이 플레이스 홀더의 이름을 정의한다. name에 대해서는 나중에 좀 더 자세하게 설명하도록 하겠다.그러면 이 x에 학습용 데이타를 어떻게 넣을 것인가? 이를 피딩(feeding)이라고 한다. 다음 예제를 보자import tensorflow as tfinput_data = [1,2,3,4,5]x = tf.placeholder(dtype=tf.float32)y = x * 2sess = tf.Session()result = sess.run(y,feed_dict={x:input_data})print result처음 input_data=[1,2,3,4,5]으로 정의하고다음으로 x=tf.placeholder(dtype=tf.float32) 를 이용하여, x를 float32 데이타형을 가지는 플레이스 홀더로 정의하다. shape은 편의상 생략하였다.그리고 y=x * 2 로 그래프를 정의하였다.세션이 실행될때, x라는 통에 값을 하나씩 집어 넣는데, (앞에서도 말했듯이 이를 피딩이라고 한다.)sess.run(y,feed_dict={x:input_data}) 와 같이 세션을 통해서 그래프를 실행할 때, feed_dict 변수를 이용해서 플레이스홀더 x에, input_data를 피드하면, 세션에 의해서 그래프가 실행되면서 x는 feed_dict에 의해서 정해진 피드 데이타 [1,2,3,4,5]를 하나씩 읽어서 실행한다.변수형 (Variable)마지막 데이타형은 변수형으로, y=W*x+b 라는 학습용 가설이 있을때, x가 입력데이타 였다면, W와 b는 학습을 통해서 구해야 하는 값이 된다.  이를 변수(Variable)이라고 하는데, 변수형은 Variable 형의 객체로 생성이 된다. tf.Variable.__init__(initial_value=None, trainable=True, collections=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, expected_shape=None, import_scope=None)변수형에 값을 넣는 것은 다음과 같이 한다.var = tf.Variable([1,2,3,4,5], dtype=tf.float32)자 그러면 값을 넣어보고 코드를 실행해보자import tensorflow as tfinput_data = [1,2,3,4,5]x = tf.placeholder(dtype=tf.float32)W = tf.Variable([2],dtype=tf.float32)y = W*xsess = tf.Session()result = sess.run(y,feed_dict={x:input_data})print result우리가 기대하는 결과는 다음과 같다. y=W*x와 같은 그래프를 가지고, x는 [1,2,3,4,5] 값을 피딩하면서, 변수 W에 지정된 2를 곱해서 결과를 내기를 바란다.그렇지만 코드를 실행해보면 다음과 같이 에러가 출력되는 것을 확인할 수 있다.이유는 텐서플로우에서 변수형은 그래프를 실행하기 전에 초기화를 해줘야 그 값이 변수에 지정이 된다. 세션을 초기화 하는 순간 변수 W에 그 값이 지정되는데, 초기화를 하는 방법은 다음과 같이 변수들을 global_variables_initializer() 를 이용해서 초기화 한후, 초기화된 결과를 세션에 전달해 줘야 한다.init = tf.global_variables_initializer()sess.run(init)그러면 초기화를 추가한 코드를 보자import tensorflow as tfinput_data = [1,2,3,4,5]x = tf.placeholder(dtype=tf.float32)W = tf.Variable([2],dtype=tf.float32)y = W*xsess = tf.Session()init = tf.global_variables_initializer()sess.run(init)result = sess.run(y,feed_dict={x:input_data})print result초기화를 수행한 후, 코드를 수행해보면 다음과 같이 우리가 기대했던 결과가 출력됨을 확인할 수 있다. 텐서플로우를 처음 시작할때, Optimizer나 모델등에 대해 이해하는 것도 중요하지만, “데이타를 가지고 학습을 시켜서 적정한 값을 찾는다"" 라는 머신러닝 학습 모델의 특성상, 모델을 그래프로 정의하고, 세션을 만들어서 그래프를 실행하고, 세션이 실행될때 그래프에 동적으로 값을 넣어가면서 (피딩) 실행한 다는 기본 개념을 잘 이해해야, 텐서플로우 프로그래밍을 제대로 시작할 수 있다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//bcho.tistory.com/reaction';window.ReactionReqBody = {    entryId: 1150}공유하기게시글 관리조대협의 블로그 저작자표시 비영리 '빅데이타 & 머신러닝 > 머신러닝' 카테고리의 다른 글텐서플로우 #3-숫자를 인식하는 모델을 만들어보자  (12)2016.12.28텐서플로우 #2 - 행렬과 텐서플로우  (7)2016.12.26딥러닝 - 초보자를 위한 컨볼루셔널 네트워크를 이용한 이미지 인식의 이해  (20)2016.11.30머신러닝의 과학습 / 오버피팅의 개념  (1)2016.11.30딥러닝의 개념과 유례  (3)2016.11.27TagBasic, Constant, data type, Deep learning, google, Graph, Machine Learning, placeholder, session, tensorflow, Tutorial, variable, 강좌, 구글, 그래프, 기초, 딥러닝, 머신러닝, 변수, 상수, 세션, 자료형, 조대협, 초보, 텐서플로우, 튜토리얼, 플레이스홀더'빅데이타 & 머신러닝/머신러닝'의 다른글이전글딥러닝 - 초보자를 위한 컨볼루셔널 네트워크를 이용한 이미지 인식의 이해현재글텐서플로우-#1 자료형의 이해다음글텐서플로우 #2 - 행렬과 텐서플로우관련글텐서플로우 #3-숫자를 인식하는 모델을 만들어보자2016.12.28텐서플로우 #2 - 행렬과 텐서플로우2016.12.26딥러닝 - 초보자를 위한 컨볼루셔널 네트워크를 이용한 이미지 인식의 이해2016.11.30머신러닝의 과학습 / 오버피팅의 개념2016.11.30loadedComments[1150]=true;findFragmentAndHighlight(1150);실리콘밸리에서 살고 있는 평범한 엔지니어 입니다이메일-bwcho75골뱅이지메일 닷컴.아키텍처 디자인, 머신러닝 시스템, 빅데이터 설계, DEVOPS/SRE, 애자일 방법론,쿠버네티스,마이크로서비스, ChatGPT 생성형 AI , CTO 등에 대한 기술 멘토링과 강의 진행합니다. 분류 전체보기  조대협의 소프트웨어 개발  IT 이야기  트렌드  IT와 사람  사는 이야기  골프  책  일정 자료 관리 방법  육아  비지니스  비지니스와 세일즈  스타트업  빅데이타 & 머신러닝  통계학 이론  스트리밍 데이타 처리  머신러닝  R  Zepplin  Google BigQuery  생성형 AI (ChatGPT etc)  Pytorch  클라우드 컴퓨팅 & NoSQL  Data Grid (IMDG)  Identity Management  Apache Httpd  IIS  NginX  NoSQL 일반  RabbitMq  Redis  MongoDB  Hadoop  HBase  Cassandra  CouchBase  Riak  IaaS 클라우드  PaaS 클라우드  SaaS  개인 클라우드  google cloud  Azure  Amazon Web Service  분산컴퓨팅&클라우드  VDI  운영 & Devops  Vert.x & Node.js  도커 & 쿠버네티스  M2M & IOT  아키텍쳐   머신러닝  BI  WEB 2.0  SCA  SOA  Enterprise 2.0  Domain Driven Design  EAI  대용량 아키텍쳐  Security & IDM  모바일  성능과 튜닝  JVM  APM (AP 성능 측정)  자바 성능팁  WAS 튜닝  ALM  애자일  배포(Deployment)  JIRA  에세이  SCM/VCS  Build Automation (빌드..  Test Automation  Build Automation(이클립..  Task Management  프로그래밍  알고리즘  안드로이드  Ruby  JavaScript  Python  Spring & Maven  LIBS  Hibernate(하이버네이트)  프로그래밍팁  MVC  XML 관련  J2EE  JSF & Oracle ADF Fac..  Groovy  Visual Studio  C# & .NET  ASP.NET  Windows Phone7  아두이노  엔터프라이즈 솔루션  Wiki  우분투  포탈  Oracle BPEL  Oracle Service Bus (..  BEA Tuxedo  MS-SQL  SharePoint  BEA WebLogic  빅데이타 Taggoogle,텐서플로우,머신러닝,강좌,Machine Learning,cloud,초보,빅데이타,구글,Kubernetes,튜토리얼,node.js,tensorflow,Tutorial,조대협,클라우드,클라우드 컴퓨팅,딥러닝,쿠버네티스,소개,최근글과 인기글최근글인기글Pytorch - 선형회귀 (Linear Regression)을 통한 코드 구조 이해2024.08.06 16:57Python yield2024.08.06 01:43파이토치 1. 기본 자료형 텐서2024.08.05 16:32클러스터링 #3 - DBSCAN (밀도 기반 클러스터링)2017.10.13 15:11파이썬을 이용한 데이타 시각화 #1 - Matplotlib 기본 그래프 그리기2017.09.23 12:18#18.LangSmith를 이용한 Langchain agent 내부 동작 구조 이해2024.02.03 03:18최근댓글마지막에 설명해 주신 것 같습니다.""이 기능을 사용하면, 클라이언트(모바일)에서 서버로 ⋯ES안녕하세요. 혹시 해당 툴의 서버는 필요 없을까요?rtfrom pinecone import Pineconepc = Pinecone(api⋯Kim_sang_hyeob공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2024/082024/032024/022024/012023/12Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total12,738,990Today : 787Yesterday : 1,385블로그 내 검색관련사이트서버사이드 아키텍트 그룹 DzoneInfoQ마틴파울러 옹Craig Larman 홈페이지강대명님(Redis) 블로그수학공부닷컴(중학교수준)Udacity커니의 안드로이드코드 스쿨랭귀지 튜토리얼Code AcademyCoursera온라인강좌-Udemy데이타 과학 놀이터데이타 관련 튜토리얼 티스토리툴바                    (function () {                         var blogTitle = '조대협의 블로그';                                                (function () {    function isShortContents () {        return window.getSelection().toString().length < 30;    }    function isCommentLink (elementID) {        return elementID === 'commentLinkClipboardInput'    }    function copyWithSource (event) {        if (isShortContents() || isCommentLink(event.target.id)) {            return;        }        var range = window.getSelection().getRangeAt(0);        var contents = range.cloneContents();        var temp = document.createElement('div');        temp.appendChild(contents);        var url = document.location.href;        var decodedUrl = decodeURI(url);        var postfix = ' [' + blogTitle + ':티스토리]';        event.clipboardData.setData('text/plain', temp.innerText + '\n출처: ' + decodedUrl + postfix);        event.clipboardData.setData('text/html', '<pre data-ke-type=""codeblock"">' + temp.innerHTML + '</pre>' + '출처: <a href=""' + url + '"">' + decodedUrl + '</a>' + postfix);        event.preventDefault();    }    document.addEventListener('copy', copyWithSource);})()                    })()hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""81033-1150"",""customProps"":{""userId"":""0"",""blogId"":""81033"",""entryId"":""1150"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""1150"",""entryTitle"":""텐서플로우-#1 자료형의 이해"",""entryType"":""POST"",""categoryName"":""빅데이타 & 머신러닝/머신러닝"",""categoryId"":""555440"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""100320"",""authorNickname"":""Terry Cho"",""blogNmae"":""조대협의 블로그"",""image"":""cfile8.uf@221D7F45584AB42A1F0F4F.png"",""plink"":""/1150"",""tags"":[""Basic"",""Constant"",""data type"",""Deep learning"",""google"",""Graph"",""Machine Learning"",""placeholder"",""session"",""tensorflow"",""Tutorial"",""variable"",""강좌"",""구글"",""그래프"",""기초"",""딥러닝"",""머신러닝"",""변수"",""상수"",""세션"",""자료형"",""조대협"",""초보"",""텐서플로우"",""튜토리얼"",""플레이스홀더""]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
129,https://jpub.tistory.com/603,태그,"도서 소개인공지능, 인간을 유혹하다 제이펍2016. 8. 17. 18:46이 책은 현재 절판입니다. 그간 읽어주신 분들께 감사를 드립니다. 2017년 세종도서 교양부문 우수도서 선정!8개 테마로 읽는 로봇과 소프트웨어의 만남!로봇 사회를 바라보는 과학전문기자와 로봇전문가의 따뜻하면서도 냉정한 통찰! 도서 구매 사이트(가나다순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]  전자책 구매 사이트(가나다순)[교보문고]   [구글북스]   [리디북스]   [알라딘]   [예스이십사]   [인터파크] 출판사 제이펍지은이 김재호, 이경준출판일 2016년 8월 17일페이지 272쪽시리즈 (없음)판  형 신국판변형(152*215*13)제  본 무선(soft cover)정  가 16,800원ISBN 979-11-85890-61-6 (03320)키워드 로봇 / AI / 인공지능 / 머신러닝 / 소프트웨어 / 알파고 / 미래사회분  야 경제경영 / 미래예측 관련 사이트■ (없음) 관련 포스트■ 2016/08/08 - [출간전 책소식] - 인공지능은 우리의 삶을 어떻게 변화시킬까?  관련 시리즈■ (없음) 관련 도서■ 인공지능 1: 현대적 접근방식(제3판)■ 인공지능 2: 현대적 접근방식(제3판)■ 머신러닝 인 액션: 기계 학습 알고리즘으로 데이터 마이닝하기 관련 파일 다운로드■ (없음)   강의 자료(교재로 채택하신 분들은 출판사로 메일을 보내주세요) => jeipubmarketer@gmail.com■ 본문의 그림과 표 샘플 PDF■ 차례, 프롤로그, 베타리더 후기, 1장 '디지털 생명체가 진화한다' 일부인공지능인간을유혹하다_sample.pdf다운로드  정오표 페이지■ http://jpub.tistory.com/616 도서 구매 사이트(가나다순)[강컴]   [교보문고]   [도서11번가]   [반디앤루니스]   [알라딘]   [예스이십사]   [인터파크]  전자책 구매 사이트(가나다순)[교보문고]   [구글북스]   [리디북스]   [알라딘]   [예스이십사]   [인터파크] 출판사 서평8개 테마로 읽는 로봇과 소프트웨어의 만남!로봇 사회를 바라보는 과학전문기자와 로봇전문가의 따뜻하면서도 냉정한 통찰! 이 책은 로봇 사회를 대하는 우리의 자세를 8개의 핵심 키워드로 나누고, 영화, 최신 뉴스, 각계 전문가의 의견을 통해 실감나게 분석한다! ⚫ 진화: 인공지능은 디지털 생명체로 진화하며 인간을 대체할 것이다⚫ 동거: 인간과 로봇이 공생한다. 나는 로봇 애인을 정말 사랑하는 게 아닐까?⚫ 모방: 로봇 공학의 난제를 생체공학에서 찾아낸다. 생체(동물) + 소프트웨어화 = 공학(로봇)⚫ 극복: 로봇의 한계를 넘어서다. 로봇 유인원의 탄생⚫ 위협: 완벽한 로봇은 불가능하며, 인공지능은 나쁜 것만 배운다⚫ 목격: 빗자루를 타고 하늘을 날다. 세상을 바꾸는 로봇 소프트웨어⚫ 유혹: 차가운 로봇과 뜨거운 사랑을 나누다. 로봇과 소프트웨어의 만남 4단계⚫ 습득: 꿈을 꾸며 경험의 도서관을 짓는 로봇 그리고 이 책에는 로봇과 관련한 영화 이야기가 등장한다. 영화는 현재를 반추하고 미래를 상상할 수 있는 좋은 미디어다. 소프트웨어와 로봇과 관련된 영화 이야기들이 책의 내용을 이해하는 데 도움이 될 것이다.  저자 소개김재호서울시립대학교에서 수학을, 서울대학교 대학원에서 철학(윤리학)을 공부하였다. 졸업 후에는 학술기자, 과학기자, 탐사보도 연구원으로 일했다. 〈문화기술과 관동팔경 역사문화의 개발〉, 〈높은 체감실업률과 확산되는 청년실업층의 이중고〉 등의 소논문과 《레이첼 카슨과 침묵의 봄》, 《소프트웨어가 세상을 지배한다》, 《대한민국 소프트웨어 성공 방정식》, 《다시 과학을 생각한다》(공저)를 집필하였다. 《다시 과학을 생각한다》는 한국과학창의재단이 주관하는 ‘2016년 우수과학도서’로 선정되었다. 현재 〈교수신문〉 과학전문기자로 ‘과학 본색’을 연재하고 있으며, 학술 DB 기획위원으로도 일하고 있다. 또한, ‘학술문화연구소’를 운영하며 과학과 기술, 철학, 문화 등에 대해 비평하고 있다. 이경준한국로봇산업협회 전략기획팀 팀장이다. 지난 11년간 로봇산업협회에 재직하면서 국내외 로봇 산업에 대한 인사이트를 꾸준히 연구 및 전파하고 있다. 로봇 기술을 통한 사회적 가치 창출을 사명감으로 삼고 있다. 로봇 IT 융합, 로봇 SW 통합개발환경 등에 참여연구원으로 활동하고 있으며, 로봇 분야 홍보·마케팅을 통한 로봇 문화 확산을 위해서도 노력하고 있다. 2014년부터 서울대 소비트렌드 분석센터와 함께 ‘트렌드 코리아’의 IT 및 로봇 분야 집필진으로 참여하고 있다. 차례1장 진화: 디지털 생명체가 진화한다_1인간보다 더 인간 같은 인공지능 3 기계가 스스로 학습하는 시대가 온다 _ 5 계산 가능성 _ 7 주어진 일 이상을 하는 인공지능 로봇 _ 9 공상과학 영화 속의 인공지능 _ 12 영화로 만나다: 로봇과 행복을 꿈꾸는 인간들 _ 14 사람의 일상을 ‘보는’ 인공지능이 나온다면 _ 16 입력된 사진과 일상생활 연관성 추적 _ 19차세대 인간은 로봇이다 22 로봇이라는 용어가 지닌 의미론 _ 24 로봇 대신 사용되는 이름이 더 구체적 _ 26 로봇이라는 단어가 가진 함의 _ 28 유한한 인간으로서 살아남기 _ 30 인간의 한계를 극복할 차세대 인간의 등장 _ 32 지구와 유사한 행성 찾기 _ 33 차세대 인류의 행방을 찾아서 _ 35더보기2장 동거: 소프트웨어로 작동하는 로봇 애인은 가능할까 _ 39감정을 공유하는 알고리즘 애인의 등장 — 영화 <그녀(Her)>와 소셜 로봇 지보(Jibo) 41 로봇 애인을 정말 사랑하는 것은 아닐까 _ 42또 하나의 새로운 가족, 로봇 — 영화 와 소프트뱅크의 야심작 ‘페퍼’ 46 자식보다 나은 소셜 로봇의 탄생 _ 48 아르바이트로 돈까지 버는 ‘페퍼’ _ 49로봇이 도와주는 행복한 노후 — 영화 〈로봇 앤 프랭크〉와 ‘텔레프레즌스 로봇’ 51 실수하는 로봇을 감싸는 할머니들 _ 52 노인 돌봄 로봇이 각광을 받는 이유 _ 54 3장 모방: 소프트웨어의 로봇화 _ 57동물에서 해답을 찾다 — 생체 공학 59 숲 속을 달리는 ‘아틀라스’ … 내 옆에서 뛴다면 _ 60 동물의 특색을 가미한 로봇이 출현하다 _ 62 로봇 공학은 결국 생물학으로 귀결 _ 65 미래형 물고기 로봇이 실현되다 _ 66구글, 로봇 월드를 꿈꾸다 69 로봇에 꽂힌 래리 페이지, 비전을 갖다 _ 70 기술로 규모의 사업 키워 내는 탁월한 능력자 _ 72 로봇 콘퍼런스에 정기적으로 참여 _ 74 로봇 공학 콘퍼런스 참여의 소중한 어린 시절 _ 75 에릭 슈미트, 인공지능 두려워 말라 _ 78 바둑 천재 이세돌, 알파고에 무릎 꿇다 _ 80 최고의 수를 찾고, 승패를 예측하다 _ 81 인간의 한계와 기계의 무한 능력 _ 83 정부, 지능정보사회 구현 위한 대책 마련 _ 84 한국에서 알파고가 나오기 힘든 이유 _ 86 개발 문화가 변해야 창의성 발현 _ 88 기술 격차·일자리 위협극복…고민에 빠진 한국사회 _ 90 알파고, 결국 구글의 잔치였을까 _ 92 소프트웨어 기업들은 왜 로봇에 주목하는가 _ 94 하드웨어와 소프트웨어가 만나다 _ 95인공지능은 소프트웨어 로봇이다 98 비전 인식에 응용 가능한 ‘알파고’ _ 99 장애 극복의 역할을 하는 ‘인공지능’ _ 100 인류를 지배하는 인공지능? 기우일 뿐이다 _ 102 로봇에서 소프트웨어는 이제 필수다 _ 104 인공지능, 인간의 뇌를 닮아가다 _ 106 더 빨리 더 많이 뉴런의 활동을 기록하라 _ 107 7년마다 두 배로 성장해도 부족해 _ 109 인공지능의 가치는 빅데이터에 있다 _ 111 4장 극복: 로봇의 소프트웨어화 _ 113스스로 판단하는 재난 로봇 만들기 — 로봇 유인원의 탄생 115 후쿠시마 원전 사고에 ‘재난 로봇’이 활약했다면 _ 117 장애물 감지하고 사다리 오르는 로봇 _ 119 두 발·네 발로 걷는 ‘로봇 유인원’ 눈앞에 _ 121로봇 OS 선점을 위한 전쟁의 서막 — 로봇 미들웨어란 무엇인가? 123 오픈 소스로 공개된 ROS, 건강한 생태계 조성 _ 125 개방형 ROS VS 폐쇄형 ROS _ 127휴보의 도전과 가능성 129 신시장으로서 로봇 산업 부상 _ 130 ‘휴보’ 다윗과 골리앗들의 대결 _ 133 5장 위협: 완벽한 소프트웨어와 불완전한 로봇 _ 137총 쏘는 드론의 등장 — 로봇과 AI 법률이 필요한가? 139 완전한 법칙과 인간 보호 VS 완벽한 소프트웨어와 로봇 통제 _ 141 사회적 의미를 부여 받은 로봇 … 새로운 법률 필요 _ 143 점점 모호해지는 인간의 경계 _ 145 로봇에 책임을 묻는 근거는 무엇인가? _ 146로봇 3원칙은 안전한가 — 드론을 제지하라 149 드론을 제지하는 독수리의 활약? _ 150 드론의 안전성과 로봇 3원칙 _ 151 우리 집 앞에 날아다니는 드론, 괜찮을까? _ 152완벽한 소프트웨어로 로봇 제어가 가능할까? 154 나쁜 것만 배운 인공지능 ‘테이’ _ 155 실수하는 로봇과 더 잘 소통해 _ 157 6장 목격: 소프트웨어가 상상하고 로봇이 실현하다 _ 159중앙통제형 소프트웨어 및 클라우드 — 해리포터 퀴디치와 아이로봇 사 161 로봇 공학자들, 하늘을 날게 하다 _ 163 로봇 소프트웨어로 세상을 바꾸자 _ 164 아이로봇의 소프트웨어 기반 클라우드 로봇화 _ 167인간과 교감하며 세상을 바꾸는 로봇 — 인터스텔라 ‘타스(Tars)’ 와 MUSICA 169 우주 최고로 쿨한 막대기 등장 _ 170 인공지능의 미래를 보여 주는 ‘타스’ _ 171 어떻게 하면 인간과 더 잘 교감할까? _ 172모션 캡처와 체감형 오퍼레이팅 소프트웨어 — 슬립 딜러와 리얼 스틸 175 자동화 이전 단계로서 오퍼레이팅 _ 175 로봇 간 전쟁의 서막 ‘로보워’ _ 177 진짜가 나타났다 ‘리얼 스틸’ _ 179당신을 보다 안전하게 할 스마트 치안 — 로보캅과 마이너리티 리포트 181 스마트 치안의 등장과 로보캅의 탄생 _ 182 범죄를 소탕하라 _ 183로봇도 울 수 있다 — 바이센테니얼 맨 185 창의적인 일을 하고 돈까지 버는 로봇 _ 186 억압된 성적 충동, 인간이 되게 하다 _ 187 7장 유혹: 소프트웨어와 로봇 생태계가 열린다 _ 189차가운 기계와 뜨거운 사랑을 나누다 191 경기 침체 현실 도피용 ‘로맨틱 로봇’ _ 192 인간 삶 뒤흔들 로맨틱·에로틱 로봇 _ 195소프트웨어와 로봇의 일자리 위협론 197 와해성 기술로 사라지는 일자리들 _ 198 글쓰기마저 자동화하면 사람이 설자리는 어디일까? _ 199 로봇 저널리즘의 등장으로 일자리가 사라질까? _ 200 정보 수집부터 원고 작성까지 _ 203 사람들이 사라지기 시작한 뉴욕증권거래소 _ 205 인공지능과 공존하는 시대 멀지 않아 … 로봇 패닉 _ 206 로봇에게 내 일자리를 빼앗긴다면 _ 207 로봇에겐 없는 인간만의 능력이란 _ 209 자동화한 사업 구조 ‘플랫폼’ _ 211로봇과 소프트웨어의 만남 4단계 — 결합-통합-융합-통섭 213 가장 강한 로봇을 위한 소프트웨어 _ 214 로봇 소프트웨어 플랫폼을 선점하라 _ 216 위대한 도약은 퀀텀 점프가 될 것이다 _ 218 소프트웨어와 로봇 그리고 그의 적들 _ 220 8장 습득: 꿈을 꾸는 로봇 탄생 _ 225로봇, 경험의 도서관을 짓다 227 무의식과 의식의 경계, 꿈을 꾸는 로봇 _ 228 경험의 도서관을 짓는 로봇 탄생 _ 231 저장된 학습 정보를 주고받는 로봇들 _ 233 유망한 로봇 학습 방법, 딥 러닝 _ 235 증가된 대역폭과 최첨단 클라우드 컴퓨팅 _ 236   window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//jpub.tistory.com/reaction';window.ReactionReqBody = {    entryId: 603}공유하기게시글 관리제이펍의 참 똑똑한 2비트 책 이야기 '도서 소개' 카테고리의 다른 글TCP/IP 쉽게, 더 쉽게:  명쾌한 설명과 풍부한 그림으로 배우는  (0)2016.09.23리눅스 바이블(제9판)  (4)2016.09.13마인크래프트로 배우는 파이썬 프로그래밍  (2)2016.08.11도커: 설치에서 운영까지  (0)2016.07.22그림으로 공부하는 사물인터넷 구조  (0)2016.07.22태그ai, Artificial Intelligence, deep learning, Machine Learning, robot, 김재호, 딥러닝, 로봇, 머신러닝, 미래사회, 소프트웨어, 알파고, 이경준, 인공지능, 제이펍'도서 소개' Related ArticlesTCP/IP 쉽게, 더 쉽게:  명쾌한 설명과 풍부한 그림으로 배우는리눅스 바이블(제9판)마인크래프트로 배우는 파이썬 프로그래밍도커: 설치에서 운영까지Secret댓글달기loadedComments[603]=true;findFragmentAndHighlight(603);"
130,https://prgmti1.tistory.com/,목록전체 글 (57),"본문 바로가기러닝머신 하는 K-공대생카테고리검색하기검색하기Search러닝머신 하는 K-공대생prgmti1 분류 전체보기 (57)  잡담, 일상 (17)  Machine Learning (8)  Project (5)  Problem Solving (19)  BOJ (18)  Algorithms (1)  Computer Vision (1) GuestbookNoticeRecent Posts깨달음""이과생들 발작하는 짤""을 보고 왜 발작하지?대학에 온 후 생각시험기간Recent Comments이게 되네제가 점프해봤는데 됩니다라마지하랑 자자랑하지마라Link«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031Tags구현moreArchives2024/01 (1)2023/10 (1)2023/05 (1)2023/04 (1)2023/02 (4)Today2Total20,009닫기관리 메뉴글쓰기방명록RSS관리목록전체 글 (57)러닝머신 하는 K-공대생깨달음평소와 같이 영상을 보다 [왕초보 엄마의 수학공부]라는 것을 보게 되었다. 영상을 제대로 보지 않았음에도 나는 마음 속 깊이 울리는 어떤 깊은 감정을 느꼈다. 늦은 나이임에도 새로운 것에 도전하고 배워보려는 시도. 그것이 누구나 할 수 있든 아니든 어렵거나 그렇지 않던 본인에게 의미가 있고 가치가 있는 어떤 행동이면 멋있다고 느껴진다. 대학이라는 공간에서 자유로이 내가 원하는 지식을 얻어가고 경험할 수 있는 현재의 나는 행복하다. 내가 해보고자 하는 목표와 과정이 누군가에게 당연하고 어렵지 않은 것이든 나에게 의미가 있는 무언가를 계속 해낼 것이다. 좋은 깨달음의 순간을 공유하고 싶어 이 글을 올린다.카테고리 없음2024. 1. 11. 18:25""이과생들 발작하는 짤""을 보고 왜 발작하지?인터넷 속 이과생들은 이걸 보고 왜 발작할까. 본인의 직관이 통하지 않을 것 같다는 추측만으로 발작하는 것인가? 발작을 하기 위해선 본인에 생각에 대한 논리적인 근거와 확신이 있어야 한다. 나는 직관만으론 확신이 들지 않는 타입이라 오랫만에 나도 발작을 해보고 싶어서 이를 물리적으로 검증해보려고 한다. 누구나 이해할 수 있도록 자세히 기술할 것이고, 이 글을 통해 추상적으로 보이는 문제를 정의하고 분석하는 능력을 키우길 기대한다. 쨋든 위 상황이 가능한지 확인하려면 다음의 상황이 가능한지 확인해보면 된다. 1. 언덕 살짝 옆에서 공을 아래로 던짐 2. 언덕 살짝 옆에서 제자리 위로 점프를 함 3. 점프하고 어느 순간에 충돌함 4. 충돌 이후 다시 상황3 에 도달함 1~4 과정이 가능함을 보이면 3~4 과..잡담, 일상2023. 10. 11. 18:14대학에 온 후 생각23학번으로 들어와 두 달 정도 대학을 다녔다. 처음으로 내가 원하는 과목을 수강신청하고 강의실을 왔다 갔다 하면서 수업을 듣고, 친구들과 놀러 가고, 술도 마시고 동아리에서 계속 인공지능을 공부하고, 예상 밖의 일이지만 잘 맞는 사람과 연애도 하게 되었다. 그냥 별다른 생각 없이 매주 수업 열심히 듣고, 밥 먹고, 공부 좀 하고, 동아리 가서 딥러닝 스터디하고, 여자친구랑 소소하게 만나서 놀고, 친구들이랑 학교에서 하는 세미나나 강연들 보러 다니고 같이 저녁도 먹고 주말엔 과제를 한다. 아직은 첫 학기니 대강대강 살아도 괜찮겠지란 생각에 큰 부담을 못 느끼는 것 같다. 아직 딱히 어려운 전공과목도 없고 과제나 시험, 퀴즈도 어렵지 않고 무난무난해서 큰 공부적인 어려움은 없다. 사람들을 만나는 것도 크게..잡담, 일상2023. 5. 13. 18:03시험기간흐에에ㅔ 고딩도 아닌데 시험공부라니이이 그러던 중 최근 카노의 플라토닉러브를 들었다 카노 목소리가 좋아서 공부하면서 자주 듣는다 https://www.youtube.com/watch?v=ZYN8wEZ3CLs우린 끝까지 갈거야 세상이 멸망해도 절대 포기하지마 이상 대전탑티어공댜생이되고싶은러닝머신하는K공대생이었습니다 그럼 이만(20000)카테고리 없음2023. 4. 5. 00:39Graph-Cut 을 이용한 영상 분할 구현Ⅰ. 글을 시작하며 전에 최적화 분야를 공부하기 위해 ‘영상 이해를 위한 최적화 기법’강의를 듣던 중 영상 분할과 관련된 내용이 있었다. 영상 분할은 이미지를 여러 개의 픽셀 집합으로 나누는 것으로 컴퓨터 비전에서 중요한 주제다. 에너지 함수를 가지고 variational한 방법으로 최적화를 진행하거나 조합적 방법으로 그래프 컷에 기반하여 물체/배경 으로의 영상 분할을 진행하는 아이디어를 얻을 수 있었고 특히 그래프 컷을 활용해 영상 분할을 하는 아이디어가 흥미로웠다. 이에 영상 분할에 대한 최적화 방법들을 정리하고 관련 알고리즘을 학습하며 아이디어를 구체화시켜 밑바닥부터 직접 구현해 실제로 이미지를 주었을 때 영상 분할을 진행할 수 있는 프로젝트를 진행했었다. 나중에 정리해야지 미루고 있었는데 입시가 ..Project2023. 2. 12. 21:12Segment Tree Implementation (Python)정말 심심해져서 최근 교내 대회 문제를 업솔빙하고자 '바벨탑' 문제 를 풀다 세그먼트 트리가 기억이 안나서 다시 복습하고 재귀적 방식과 비재귀적 방식으로 구현해 보았다. 개인적으로 탑다운으로 짠게 직관적이고 레이지나 그 외 여러 확장적 측면에서 편한 것 같은데 Python으로 세그트리 문제들 풀어보면 성능적인 면은 확실히 Bottom-Up 방식이 유리한 것 같다. 1. 재귀적 방식 구현 class SegmentTree: def __init__(self, arr): self.n = len(arr) self.tree = [0] * (4 * self.n) self.build(arr, 1, 0, self.n - 1) def f(self, a, b): return min(a, b) def build(self, a..Problem Solving/Algorithms2023. 2. 12. 06:26[권도현 예술제 출퓸작] 작품명: 🐱모두가 내가 그린 고양이를 보고 비웃어도 좋다. 그래도 고양이는 귀여우니까.카테고리 없음2023. 2. 5. 20:101종 보통 기능시험 정리요즘 너무 뻘글만 올리는 것 같아 운전면허 준비하면서 도움이 될 글도 올려보고자 한다. 물론 내가 다니는 운전면허학원 기준으로 작성이 되었다. 1종 보통: 클러치를 자율자재로 다룰 줄 알아야함. 누룰 때는 꾹 누르고 땔 때는 부드럽게 때기, 왼발 뒷꿈치 땅에 닿지않게.브레이크 쪽에 발을 두지만 누르지 말기.(브레이크 잡을 상황은 긴급 시, T자 들어가기 전, 중간, 나올 때, 신호등 앞, 경사코스 크랙 부분 뿐이다), 힘을 빼고 차분하게 하나하나 클리어 한다는 느낌으로 진행하자. 하루에 틈틈히 시물레이션해보자. 핸들링이 아직 감이 안잡혔다. 3시간 째엔 핸들링 완벽하게 숙지하자. 이거하다 뒤@ㅈ겠어? 란 마인드로 자신감 있게 진행하자. 쪼는 순간 다 꼬임 ㅋ 0. 기본 세팅 둘어가서 클러치 누르기 편한 ..카테고리 없음2023. 2. 3. 21:52고샌애코티 1차 정모 후기 (곧 검열될 수도 있습니다)안녕하세요. 저는 고샌애코티 모임의 주최자 깡태구입니다. 글을 시작하기에 앞서 처음 고샌애코티 단체를 결성하게 된 계기부터 알려드려야겠군요. 고샌애코티 모임의 시작 저는 평소와 같이 ChatGPT와 재밌는 이야기를 주고받으며 즐거운 시간을 보내고 있었습니다. 그러던 중 ChatGPT를 활용한 나무위키 크롤링 및 데이터 분석 결과 세계적인 엘리트들의 공통점을 발견했습니다. 그것은 바로 고양이를 좋아하고 샌즈를 외치며 애니와 코딩을 즐겨한다는 것과 티스토리를 운영했다는 점이었습니다. 이런 엄청난 사실을 알아낸 저는 많은 고민을 하게 되었습니다. 이 사실을 빨리 인스타그램에 올려 전 세계인들에게 알려야 할까. 아니면 국정원에 은밀히 이 정보를 팔아 수십 억의 돈을 벌 것인가. 혹은 내가 나서서 유능한 인재를 ..잡담, 일상2023. 1. 29. 18:07고양이샌즈애니코딩티스토리 모임을 위한 수원역 방탈출 정리먼저 후보군 모집하기 위해 네이버 지도에서 '수원역 방탈출 카페'를 검색 후 괜찮아보이는 세 곳 정도를 수원역에서 가까운 순서대로 대중들의 반응, 가격, 추천 테마, 예약 현황을 정리해보았다. (대중들의 반응은 네이버 지도에서 방문자 리뷰와 블로그 리뷰수를 나타내고, 추천 테마는 친구들이랑 재밌게 문제를 풀면서 탈출하기 위해 난이도 3으로 찾아보았다. 예약 현황은 2023-01-23 23시 기준으로 찾아봤으니 변동사항이 있을 수 있다.) 1. 방탈출 탐정 (http://www.escapecafe.co.kr/) 대중들의 반응: 방문자 리뷰 68, 블로그리뷰 125로 나름 유명한 곳임을 알 수 있다. 가격: 4인 기준 인당 18,000원 추천 테마 - 사라진 피카소, 스토커 예약 현황(2023-01-26) ..잡담, 일상2023. 1. 23. 23:27크리스마스의 기적2052년 크리스마스 이브는 K-과고생 기면중에게 아주 특별한 날이다. 그날 기면중은 봇치 더 락! 12기를 보면서 드디어 봇치와 BTS와 콜라보레이션을 한 장면을 보게 된다. "" 아아닛! 무려 세계적인 프로듀서 Ranky H8이 제작한 트랩비트에 환상적인 봇치의 기타소리가 어울려졌어.."" "" BTS는 허리를 부여잡고 열정적인 춤을 추고 있잖아...? 역시 코리안 비틀즈 답군. "" "" 큭..칙쇼!! 어이 봇치짱 믿고 있었다구! 역시 슈퍼스타가 될 줄 알았어! "" 하지만 그의 행복은 그리 길게 지속되진 않았다. 평소와 같이 버츄얼 스트리머 후라이짱을 보려고 유튜브에 들어갔지만 무슨 일인지 스트리밍은 진행되지 않았기 때문이다. ""후짱..무슨 일이야.. 항상 이 시간대면 스트리밍을 해왔잖아;;"" 그는 후라이짱..잡담, 일상2022. 12. 26. 13:53할 거 추천받습니다입시 끝나고 계속 놀았더니 너무 노잼이네요. 재밌는거 추천받습니다. 대충 생각해본 거는 아래와 같습니다. 이정도 빅재미를 선사할 수 있는 것들이면 환영입니다. 1. 선형대수학 공부 - 길버트 스트랭 or 프리드버그 교재로 연습문제 쭉 풀기 - 강의: https://web.mit.edu/18.06/www/videos.shtml - https://math.mit.edu/~gs/learningfromdata/ 참고 2. 영상기하학 공부 - multiple view geometry 교재로 공부(번역본 or https://edward0im.github.io/mathematics/2020/06/03/multiple-view-geometry1/ ) 3. pytorch 공부 - tensorflow는 편하게 쓸 수 있지..잡담, 일상2022. 12. 7. 11:00Prev12345NextBlog is powered bykakao / Designed byTistory티스토리툴바window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""블로그"",""trackPage"":""블로그홈_보기"",""page"":""블로그홈"",""key"":""4507224"",""customProps"":{""userId"":""0"",""blogId"":""4507224"",""entryId"":""null"",""role"":""guest"",""trackPage"":""블로그홈_보기"",""filterTarget"":false},""entry"":null,""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
131,https://dsbook.tistory.com/334,댓글을 달아 주세요,"추천시스템1 - 추천시스템이란?, 추천 알고리즘의 종류BY 데이터 사이언스딥러닝/추천시스템2021. 7. 28. 15:31     (adsbygoogle = window.adsbygoogle || []).push({});    if(window.ObserveAdsenseUnfilledState !== undefined){ ObserveAdsenseUnfilledState(); }1. An Introduction to Recommender Systems인터넷이 발전됨에 따라 아이템 구매 및 선호에 대한 사용자의 피드백을 얻기 쉬워졌다. 이런 피드백을 바탕으로 과거의 사용자-아이템 간 데이터를 활용해 취향을 고려한 아이템을 추천하는 것이 추천시스템의 기본적 아이디어이다. 추천 알고리즘은 대표적으로 아래와 같이 3가지가 있다.Collaborative Filtering : 협업필터링Content-based Recommender Systems : 컨텐츠 기반 추천시스템Knowledge-based systems : 지식 기반 추천 시스템.1.1 Goals of Recommender Systems추천시스템의 목적을 논하기 전에, 두 가지 추천 문제에 대해 알아보자.1) Prediction version of Problem : Matrix Completion probelm이라고도 하며, 학습 데이터를 통해 유저의 선호도를 정확하게 예측하는 것이 목적(A라는 유저는 1번 상품을 선호할 것이다)2) Ranking version of Problem : 정확한 수치를 예측하는 것이 아닌, 랭킹을 고려해 top-k의 아이템을 선정하는 것이 목적(A라는 유저는 1, 2, 3번 상품 순으로 선호할 것이다)일반적으로 Prediction version of Problem을 푸는 것이 목적이다. 이를 해결해야 Ranking 문제도 해결할 수 있기 때문이다. 하지만 현실적으로 더욱 자연스러운 것을 Ranking 문제이다. 예를 들면 보통 우리가 A, B 중 상품을 고를 때 A와 B를 비교해 상대적으로 더 좋은 것을 사지, A와 B의 점수를 각각 구해서 비교하는 것은 비효율적이기 때문이다.비즈니스적 측면으로 추천시스템의 목적은 아이템 판매량을 높이는 것이기 때문에, 실제 운영적/기술적 측면으로는 아래와 같은 목적이 있다.1) Relevance : 추천된 아이템이 유저에게 관련이 있는가? (명백한 목적이지만 이것만으로 불충분)2) Novelty : 진부한 아이템(예, Sales Top 100)이 아닌 유저가 탐색하지 못한 색다른 아이템을 추천하는가? (어느정도 예상 가능)3) Serendipity : 유저가 이전에 경험해보지 못한 완전 새로운 아이템을 추천하는가? (아예 예상 불가능)4) Diversity : 추천됨 Top-k 아이템에 다양한 아이템이 포함되는가?위와 더불어, 추천시스템을 통해 서비스 이용 만족도, 경험의 개인화를 제공하는 데 유용하다. 또한 추천의 이유(goal)를 같이 제공하는 것이 유용하다.  1.2 Basic Models of Recommender Systems머신러닝에 KNN, SVM 등 여러 모델이 있듯이 추천시스템에도 여러 모델이 있다. 이 챕터에서는 이 모델에 대해 간단히 설명하고자 한다.1) Collaborative Filtering Models(협업 필터링)추천시스템의 주요 Task는 아래와 같은 행렬(유저-아이템)에 빈 부분을 채우는 것이다. 이를 Matrix Completion이라고 부른다. 협업필터링으로 불리는 이 모델은 위 행렬의 빈 부분을 채우기 위해 다수가 협업하는 식으로 해결하는 모델이다. 즉 각 유저, 아이템은 특정 수준의 상관관계를 가진다고 가정한다.예를 들어, A와 B가 유사한 그룹으로 묶인다면 B가 선호하는 아이템을 A가 좋아할 것으로 예측한다. 따라서 A가 구매한 아이템을 제외하고 B가 선호하는 아이템을 A에게 추천한다. 2) Memory-Based methodsMemory-based method는 neighborhood-based collaborative filtering algorithms라고도 불리며 User-based collaborative filtering과 Item-based collaborative filtering으로 구분된다.A. User-based collaborative filtering : 유저 간의 유사도가 높을수록 높은 가중치를 부여하는 방식으로, 특정 유저가 아직 구매하지 않았으나 동질 그룹의 다른 유저가 선호하는 아이템을 추천한다. 일반적으로 특정 A와 유사한 Top K의 유사한 유저들로 동질 그룹으로 구성하여 A가 선호할만한 아이템을 선정한다.B. Item-based collaborative filtering : B라는 아이템에 대한 A 유저의 선호도를 예측하기 위해, B와 가장 유사한 Top K 아이템을 선정하여 Item set을 구성한다. 3.Model-based methods: 모델 기반 방법은 머신러닝이나 데이터마이닝 방법에서 예측 모델의 context를 기반한 방법이다. 모델이 파라미터화되어 있다면, 이 모델의 파라미터는 컨텍스트 내에서 학습된다. 의사결정 나무 베이지안 모델 등이 이 예시에 해당된다. Memory based moethods와 Model-based methods는 비슷한 점이 많다. Types of Ratings추천알고리즘은 tracking ratings에 영향을 많이 받았다. ratings은 이산형이 많고 {-2,-1,0,1,2} or {1,2,3,4,5}처럼 점수를 구간화 해놓았다. 뿐만 아닌 facebook 좋아요와 같은 기능도 ratings에 한 종류라고 볼 수 있다.1.3 Content based recommend systems컨텐츠 기반 추천시스템은 협업 필터링과 다르게, 사용자가 과거에 경험했던 아이템 중 비슷한 아이템을 현재 시점에서 추천하는 것이다. Information Retrieval과 ML의 중간 지점 정도로, 정보를 찾는 과정과 과거 정보를 활용해서 유저의 성향을 배우는 문제라고 볼 수 있다.컨텐츠 기반 추천시스템은 다음과 같은 구조로 생각할 수 있다.데이터 획득 후, 컨텐츠 분석에서 비정형 데이터로부터 관련 있는 정보를 얻는 작업이 필요하다. 예를 들면 feature extraction, vector representation 등의 작업을 수행해야 한다. 그 후 유저가 선호하는 아이템과 취향을 파악하는 유저 프로필 파악이 필요하고 cosine 유사도 등을 이용하여 유사 아이템을 선택한다.ex) 사용자가 떡볶이를 시켜 먹었다고 가정하면, 떡볶이와 관련된 특징(분식, 매운 음식)을 토대로 관련된 특징을 가진 다음음식을 추천하도록 학습한다.1.4 Knowledge based recommend system사용자들의 구매 이력이 적은 경우에 사용한다. 아이템을 추천하기 전에 아이템의 특징과 명시적인 질문을 통해 회득한 사용자 선호도와 추천 범위 등 아이템들에 대한 정보를 고려하여 추천한다.ex) 배달 음식 어플을 처음 사용하면 좋아하는 음식의 종류(한식, 분식), 가격대, 맛(매운, 단짠단짠)과 같은 다양한 데이를 받아서 추천한다.1.5 Hybrid recommend system위에서 언급한 다양한 추천 시스템을 결합하여 만든다. 한 서비스의 단점을 다른 서비스의 장점으로 만든다.ex) 새로운 아이템에 대한 평점이 없으면 추천 성능이 떨어지게 되는 협업 필터링과 아이템의 특징에 대한 정보를 이용할 수 있는 지식 기반 추천 시스템을 결합한다.출처 :1. https://wikidocs.net/487972. https://kr1lib.org/book/3561149/adfc573. http://melonicedlatte.com/datascience/2019/01/26/190736.html4. https://skyeong.net/265728x90반응형(adsbygoogle = window.adsbygoogle || []).push({});window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//dsbook.tistory.com/reaction';window.ReactionReqBody = {    entryId: 334}공유하기게시글 관리데이터 사이언스 사용 설명서 저작자표시 비영리 '딥러닝 > 추천시스템' 카테고리의 다른 글추천시스템 - 모델기반 협업필터링  (0)2021.08.18추천시스템2 - Neighborhood Based Collaborative Filtering  (0)2021.08.03                                //<![CDATA[                                // Created by MissFlash(http://blog.missflash.com)                                var MF_Reference = document.getElementById('MF_Reference');                                MF_Reference.setAttribute(""id"", ""MF_Reference"" + MissFlash_Div_Num);                                MF_Reference.className = ""another_category another_category_color_gray"";                                var ref_source = getElementsByClass(MissFlash_Div_Num,""another_category"");                                if ( ref_source != undefined ) MF_Reference.innerHTML = ref_source;                                MissFlash_Div_Num += 1;                                //]]>                            태그 내용기반 필터링, 지식 기반 필터링, 추천 알고리즘, 추천시스템, 추천시스템 종류, 추천시스템이란?, 컨텐츠 기반 필터링, 하이브리드 필터링, 협업기반 필터링 0댓글을 달아 주세요비공개닉네임*비밀번호*댓글을 남겨주세요TistoryWhaleSkin3.2"">댓글 등록loadedComments[334]=true;findFragmentAndHighlight(334);"
132,https://qkqhxla1.tistory.com/802,'private/memo'의 다른글,"                                                  archives                              홈태그미디어로그위치로그방명록private/memo내가 한 컴퓨터 공부들과 공부 방법, 목표를 정하는 방식, 계기, 취업이야기 등.qkqhxla12016. 12. 13. 13:41자소서 : http://qkqhxla1.tistory.com/797면접 후기 : http://qkqhxla1.tistory.com/799내가 한 공부들과 방법 : http://qkqhxla1.tistory.com/802취업을 위한 알고리즘 공부법 : http://qkqhxla1.tistory.com/990데이터 엔지니어 경력 5년 이직준비 후기 : https://qkqhxla1.tistory.com/1193 개발자로 취업을 준비하시는 분들을 위해 제가 해온 공부들을 자세히 적었습니다. 적고 나니까 취준생분들보다는 컴공으로 진학하는 분들, 뭘 해야 될지 모르는 분들에게 더 도움될 것 같네요. 참고로 공부를 시작하게 된 계기같은것들도 자세히 적었습니다.  1. 공부 시작.전 '컴퓨터 공부' 를 4년 전에(2013년 초) 시작하였습니다.(참고로 전 10학번입니다.) 성적 맞춰서 간 학교에 과라, 처음 대학교들어갔을때는 컴퓨터공학부인데 코딩이나 컴퓨터에 관심도 없이 1학년을 다니고 군대에 갔습니다.(1학년 학점 2.7, c언어 학점 D.) 군대에 있다가 상병때쯤 컴퓨터공학부였던 다른 후임과 해킹에 대해서 이야기를 우연히 나누게 되었죠. 들었는데 멋있어 보였습니다. 그때 느낌이 왔습니다. 아 해킹이 내가 가야 할 길이구나. 뭔가 2학년이니 공부를 시작해야한다는 내면의 압박감과, 하지만 뭘 해야 할지 모르는 시기였는데 일단 흥미를 갖게 되었으니 일단 해보자고 생각했습니다. 군대에서 기본 자료조사를 했고, 병장때부터 슬슬 공부하다 전역후 12년 11월~12월 즈음부터 프로그래밍, 네트워크 등등 공부를 시작하였습니다. 해킹을 목표로 했지만 프로그래밍도 중요하다는걸 그때 알았습니다. c언어로 갤러그나 테트리스를 짤 정도의 실력이 되었지만(지금보면 이것도 별거 아닌데 그땐 이정도면 충분하다고 생각했었습니다...) 졸업전까지 프로그래밍을 꾸준히 하고 싶었습니다. 뭘할까 생각하다가 네이버 지식인에서 c언어 답변자로 활동하기로 마음 먹었습니다. 나름 깊게 생각하고 내린 결정인데 지식인을 하기로 한 이유는... 1) 문제가 마르질 않는다. 책을 사서 공부하면 책을 다 풀면 끝나지만 지식인은 매일 문제가 올라온다.2) 코드 비교가 가능하다. 나말고 다른사람의 답변이 선택된 경우 아무 이유가 없을수도 있지만 대부분 그사람의 더 적절한 함수 사용, 코드 효율, 또는 가독성이 더 좋아서이다. (간단한 학부 수준의 코드라 효율성 등을 따지기에는 많은 무리가 있지만 기초 잡기, 몰랐던 함수로 더 깔끔하게 짜는법 파악. 등에 좋습니다.) 나보다 더 잘하는 사람의 코드를 보고 배울수 있다. 또 내가 못 짜겠는, 애매한 코드의 경우 알림을 설정하여 다른 답변자의 코드를 보고 배울수 있다.3) 짧은 시간에 가능하다. 심심할때 들어가서 풀만한 문제만 빨리 풀면 된다.4) 흥미유발이 가능하다. 내공이나 채택답변 쌓여가는 재미(?)가 있다. 또 열심히 하면 돈도 준다...(활동 열심히 해서 네이버에서 20만원 네이버캐시 받았습니다..) 프로그래밍에서만 1500개이상의 답변이 채택되었습니다.. 지식인 서비스는 확실히 제 기본 프로그래밍 실력에 지대한 역할을 했습니다.5) 지금 와서 느끼는건데 이거 많이 하면 코드 짜는 속도가 엄청나게 빨라집니다... c같은 경우 어떤 함수의 헤더파일이 뭐인지도 자동으로 외우게 되었었고, 에러 분석도 요령이 생겨서 엄청나게 빨라지고, 간단한 로직은 이미 많이 짜봐서 머리로 생각하는거보다 손으로 치는게 훨씬 빠릅니다. 동일한 지식으로 동일한 문제를 풀더라도 코드 짜는 속도가 훨씬 빠릅니다.  다만 문제는 질문의 질이 낮은 경우가 많고, 학교 숙제같은거 해달라는 질문이 많아서 나중엔 스트레스 받습니다. 그러니까 혹시나 하시려면 적절한 질문을 골라서 적절하게 하세요.  2. 해킹과 파이썬 공부.해킹 기본공부를 5개월동안 열심히 하니 어느정도 기본을 끝낼수 있었습니다. 그 이후로 웹 해킹을 공부했었습니다. 리버싱, 시스템 공부 다 해봤는데 눈에 뭔가 결과물이 보이는?(해킹된 웹 페이지가 짜잔 하고 보이는?) 웹해킹이 맞더라고요. 어쨌든 웹 해킹을 2년간 공부했습니다. 웹 해킹시 파이썬이 유용하다해서 파이썬도 13년중순~14년초쯤부터 시작했습니다. 근데 어느순간부터 실력이 는다는 생각이 별로 안 들었습니다. 열심히 한것같은데도요.. 대회에 나가봐도 아웃풋이 없었습니다. 그와 동시에 파이썬으로 프로그래밍하는게 재밌게 느껴졌습니다. 코드가 짧고, 뭔가 구현하기가 되게 쉬웠거든요. 예로 소켓 프로그래밍을 한다고 하면 c는 기본적으로 설정하는 코드만 50줄이 넘지만 파이썬은 5줄 이내로 가능합니다. 그리고 복잡한 형변환... 이 없어요. 어쨌든 파이썬이 재미있어서 웹해킹은 잠시 재쳐두고 프로그래밍을 엄청 했습니다. 중간에 프로그래밍에 대한 흥미가 폭발해서 웹툰 뷰어도 만들고, 몇개월동안 개선도 하고 그랬어요. (결국 이것들은 자소서에 썼습니다.) 그러다 해킹 공부는 멀어지고 파이썬 공부만 하게 됐죠. 재밌으니까요. 나중에 스스로 생각하며 깨달은 점은 해킹을 하려면 창의력?이 어느정도 있어야 하지만 제 자신이 창의력 능력부분에서 극도로 낮다는걸 알게 되었네요.(미술 음악 이런 예체능 항상 최악이었던걸 보면 알수 있었습니다.)  3. 블로그.블로그같은경우는 14년도부터 시작하였습니다. 처음 웹해킹을 할때 문제풀이를 나름대로 hwp파일에 정리해놨는데 보기가 불편했습니다. 그리고 어느순간부터 이정도 지식이면 블로그에 정리할만하겠는데? 라는 생각이 들면서 블로그를 시작했습니다. 근데 블로그 정리가 취업에 신의 한수가 된것같아요. 열심히 공부했는데 증명할수가 없으면 말장 꽝이잖아요. 저같은경우 어느정도 괜찮다 싶은건 다 블로그에 정리해놨는데 이게 정말 좋았던것 같습니다.(앞으로도 계속 할거에요.) 일단 꾸준한게 제 장점인데 꾸준하게 뭔가를 계속 써내려가니 취업시 스펙으로도 써 먹을수 있었습니다.(알고리즘 문제풀이 카테고리라던지.) 블로그를 하면 할수록 대충 어떻게 카테고리를 나눠야하는지, 내가 찾아보기 쉽게 정보를 정리하는 방법이라던지를 배운것 같네요. 티스토리말고 깃헙도 해볼까 했지만 깃헙을 시작하기엔 장벽이 높아서.. 티스토리로 시작하였습니다. (네이버 블로그는 마음에 드는 테마가 없어서 제외)그리고 지금 느끼는 좋은점은.. 알고리즘같은경우 풀어놓은 문제들을 정리해놔서 비슷한 문제를 나중에 볼 경우 다시 소스 참조가 가능하다는 점과(기억이 잘 안나도 빠르게 풀기 가능) 프로그래밍이나 다른 지식들을 공부하면 까먹기 마련인데, 한번 정리해놓으면 다시 기억을 롤백하듯이 공부했던 내용들을 그대로 다시 가져올 수 있다는 점입니다.(아 이런 어려움이 있었지? 아 이거 이렇게 하려면 이렇게 하면 됐었지? 등.) 티스토리가 아니더라도 블로그 정리는 추천드립니다.(근데 사실 귀찮긴 해요.)  3.5 진로 변경해커에서 개발자로 방향을 바꾼건 얼마 되지 않았습니다. 해킹 공부를 2년이상했고, 처음으로 좋아하는 것을 찾았기에 연봉 등 상관없이 해커가 되고 싶었죠. 하지만 시간이 지나 4학년이 되고 취업할때가 되니 생각이 변했습니다. 주변 시선 등도 있고 해서 잘되보고 싶었죠. 보안을 공부하시는 분들은 알겠지만 bob라는 유명한 프로그램이 있습니다. bob교육을 받지 않고 보안을 하면 그닥 성공하지 못할거같다는 인식이 있었습니다.(지극히 제 개인적인 생각입니다. bob가 단순 교육뿐만이 아니라 네트워크도 형성해주는데 이게 중요하다고 생각하거든요.) 1년 휴학을 하고 bob 프로그램을 신청했습니다.(이때가 4기인가? 그랬을거에요.) 경쟁률이 8:1정도로 높다는 소리를 들었기에 모 아니면 도라는 마음가짐을 가지고 있었습니다. 어차피 1년휴학했으니, bob에 붙으면 해커의 길로 가고, 떨어지면 어학연수를 갔다와서 해킹 말고 다른 길도 생각해보자고요. 이때가 해킹실력이 별로 늘지 않는다는걸 절절히 느끼고 있던 때여서 어떻게 보면 마지막 승부수같은 느낌이었습니다. 그런데 떨어졌고, 캐나다로 어학연수를 갔다 왔습니다. bob 프로그램에 떨어진게 다행이었을 정도로 캐나다에서의 어학연수는 성공적이었습니다. 지금도 통역없이 회의 가능하고 영어 뿐만 아니라 캐나다 갔다온게 정말 인생을 바꿔놓았네요. 제 성격적인 본성과 마인드 자체가 변한 느낌입니다. 프로그래밍도 열심히 해 왔으니 개발자도 한번 해보자라는 생각을 가졌습니다. (캐나다에서 어학연수를 하면서 일기도 썼었습니다.) 몇년 공부해온 해커의 길을 포기하는것도 아까웠지만 내 재능으로 이쪽으로 잘되기 힘들다는걸 무의식적으로도 이전부터 알고 있었기 때문에 빠르게 포기했습니다.개발자로도 예상했던거보다 잘 되었으니 bob 결과에 대해서는 지금은 긍정적으로 생각합니다. 그땐 많이 우울했지만요. 사담을 더 적자면 결과발표할때 친구들이랑 술마시고 있었는데 결과 보고 술맛이 뚝 떨어져서 집에 왔었습니다.. 문자가 주말 7시였나? 그때 왔었어요.지금와서 느끼는건데 보안쪽은 새로운 기술을 발견하고 나만 알면 그게 본인의 실력이 되기에, 조금 폐쇄적입니다. 코딩 문제로 알고리즘 문제가 있듯이 해킹 문제가 있는데, 알고리즘 문제에 대해서 해답 찾기는 쉽지만 상대적으로 해킹 문제에 대해서 구글링으로 답 찾기는 어렵습니다. 보안 초보라도 누구나 아는 webhacking.kr같은 문제가 아닌 이상 푼 사람들이 대부분 공유를 안하기 때문이죠. 본인의 실력과 실적이 직접적으로 연결되니 전혀 나쁘다거나 그렇게 생각하지 않습니다. 저도 제가 혼자서 열심히 연구하고 문제풀고 남이 날로 결과만 먹으면 짜증나서 공유는 안했었습니다. 그런데 전반적으로 보안 문화자체가 저와 맞지 않았던것 같아요. 기술공유가 많지 않고, 새로운 방법을 알아내려면 내가 고행해서 찾아내야 하는데 위에 적었듯이 창의력이 부족한 저로써는 잘 맞지 않았던것 같네요. 고행을 할 끈기와 시간은 있었지만 투자하는 시간 대비 아웃풋이 적었습니다.(재능이 별로 없었던것같아요.)저도 제가 풀고나서 구글링했을때 답이 안나오는 일부 문제는 보호처리해놓고 혼자만 봤었지만 개발자로 변경하고 대부분을 공개처리했습니다.4. 알고리즘 공부.알고리즘 공부는 16년 6월쯤 시작했습니다. 어학연수를 캐나다로 갔다와서, 16년 5월즈음에 페북에서 그 유명한 제니퍼소프트에서 인턴을 모집한다는 공고를 봤습니다. 상당히 유명한 회사고, 정규직 전환용 인턴이라길래 해보고 싶었습니다.(나중에 들으니 정규직 전환은 아니라네요.) 인턴을 하려면 코딩시험을 봐야 했고, 봤습니다. 지식인에서 나름 답변도 많이 해주고, c, 파이썬으로 코딩도 이것저것 해봐서 자신이 있는 상태였습니다. 그런데 코딩시험 5문제를 봤는데 5문제 전부 구현은 어떻게 했는데 만족스럽지 못했습니다. 나중에 확인 결과 제대로 푼건 1문제도 없었습니다. 정렬을 직접 구현하는 문제인데 sort함수 써서 제출했으니까 말다했죠.... 당연히 떨어졌고, 나름 충격도 받고 오기도 생겨서 조사좀 하고 종만북을 샀고, 16년 6월부터 어차피 방학이니 밥먹고 알고리즘 이론을 공부하고 문제만 풀었습니다. 여기서 왜 공부를 했냐고 물어보시면 그냥 자존심상해서 잘하고 싶어서 공부했습니다. 알고리즘 공부가 개발자 취업에 요긴하다는것도 모르고 그냥 공부했어요. 그리고 이제 4학년이라 취준을 해야 하긴 하는데 뭘 해야하는지 몰라서 이거라도 열심히 하자 하고 했습니다. 근데 나중에 알고보니 유용했던거죠. 아침 9시에 일어나서 아점먹고 커피먹고 저녁 8시까진 공부만한것같네요. 몇일동안 한문제 잡고 있던 날도 있었습니다. 백준 문제를 풀다보니 랭커의 상징인 랭킹 100등안에 들어보자는 오기도 생겨 닥치는대로 풀었습니다. 그렇게 5개월동안 죽어라 백준 사이트의 문제를 푼 결과 860문제를 풀어서 70등정도까지 올라가봤습니다. 네이버 지식인이나 파이썬에 대해서 베이스가 있었기에 빠른 진전을 보인 것 같습니다. 백준 문제를 풀면서 제니퍼소프트의 코딩문제를 전부 다 발견할수 있어서 제가 풀었던 방법이 전부 다 완전이 틀렸다는걸 깨달을수 있었네요.(그리고 백준에서 코딩 테스트 문제를 많이 찾을수 있다는 사실도 덤으로 알게 되었습니다.) 알고리즘 공부 정리한 카테고리 : http://qkqhxla1.tistory.com/category/algorithm지금 또다시 생각해보면 차라리 제니퍼소프트 인턴에서 떨어진게 다행이었던것 같습니다. 붙었으면 계속 제가 코딩 잘하는줄 알고 기고만장했겠네요.. 그리고(붙었으면) 제니퍼 인턴이 끝난 후 공채로 다른곳 절대 못들어갔겠죠.. 알고리즘을 못하니까. 지금 다시 보니 어떻게 떨어진 것들에 대해서는 개인적으로 제 자신에게 피드백을 잘 줘서 좋은 길로 이끌어 왔었네요.  4.5 막학기 학부생의 취업이야기.전 취업에 있어서는 상당히 운이 좋은 편입니다. 학교를 다니면서, 어학연수하면서 생각을 계속해서 해왔습니다. 나는 어느 정도이고, 어떤게 강점이며, 어떤 전략으로 어떤 기업들을 지원할지요. 다른 글에 댓글로 썼던건데 여기 다시 가져옵니다. 1. 기업의 경우.1) 사기업인가 공기업인가? -> 사기업. 공기업의 정체됨은 답답해서 못 견딤. 현재가 중요해서 정년이 있다는게 큰 메리트로 느껴지지 않음. 인국공같은곳 아닌 이상 평생 한직장 다니기 싫고 연봉에 욕심 있음. 근데 인국공같은곳은 못들어갈것같으니 사기업 목표.2) 사기업 중에서도 모든 대기업을 다 쓸것인가? -> 아니오. 삼성같은곳은 모르겠지만 it가 주가 아닌 대기업(아시아나같은 항공사라던지, 롯데나 한화라던지, 또는 현대 이런 제조업)은 일단 쓰지 않겠습니다. 곰곰히 생각해봤을때 it가 주가 아닌 회사는 성장가능성도 낮고, 이후 이직도 잘 못할것 같아서 단순히 무조건 대기업으로 가고싶지는 않습니다.3) 그럼 구체적으로 어떤 기업 위주로 쓸것인가? -> 내가 하고싶은건 서비스 개발이고 돈도 많이 받으면 좋지만 일이 즐겁다면 돈은 조금 낮아도 괜찮습니다. 1순위는 it 대기업.(네이버, 카카오 등) 1순위 대기업들이 안되면 it 중심 중견기업으로. it중견기업이 안되면 스타트업으로 가겠습니다. 2. 무엇을 해야 하는가?1) 그러면 내가 정한 목표인 it 대기업을 가기 위해서는 무엇을 해야 할까? -> 일반 사기업과 it 기업들의 채용과정 차이를 비교해보면 일반 사기업들은 우리가 독취사같은 카페에서 얻는 그런 성장과정을 적는 자소서나, 인적성, 학교 스펙 등이 중요하지만 it 대기업의 경우에는 자소서는 일반 대기업만큼 중요하지 않음. 코딩테스트라는 큰 관문이 있음. 면접때에도 개발적인 내용을 더 물어봄. 등의 큰 차이가 있음. 생각해서 나온 결론은 나는 전국의 컴퓨터공학부 학부생중에서 알고리즘에 강점이 있는 편이다.(백준에서 상위권 랭킹 가서 이리생각했었습니다.) 하필 내가 지원하려는 it 서비스기업도 알고리즘을 주로 보니 1년동안은 취준을 하면서 내가 가고싶은 기업만 집중해서 자소서를 쓰자. 1년후에도 취업을 못하면 내가생각하는 나 자신이 너무 높은거니 낮춰서 가자. 라고 생각했고 제가생각하기에 높고 괜찮은 기업 공채만 지원했었습니다. 그중에 하나 졸업전에 합격했으니 전략은 성공했습니다.(아직도 생각나는데 통계 기말고사 2시간 전에 최종결과떠서 너무 기분좋게 다찍고나왔습니다.) 지금 생각해보면 알고리즘 문제 왠만한거 다풀고 실력이 절정일때 시기적절하게 지원을 잘해서 코테통과가 생각보다 쉬웠던것 같습니다.  5. 개인적인 의견.s/w개발자를 하려면(또는 취업에 성공하려면) 흥미가 중요한것 같습니다. 저같은경우 4년 전부터 컴퓨터 공부를 하면서 취업을 위해, 공부해야하니까, 라는 이유로 공부한적은 거의 없었던것 같습니다. (알고리즘은 오기로 시작했지만 흥미로 발전했네요.) 전부다 하면 재미있겠는데..? 아니면 해보고 싶다. 라는 의지로 시작하였습니다. 제 컴공관련 친구나 후배들을 만나면 대부분 하는이야기가 뭘 해야될지 모르겠다... 하는데 제가 항상 하는 조언은 이겁니다. 취업은 생각하지 말고 뭘 하면 재밌을지 생각해라. 그리고 그걸 해라. 컴공은 테크트리가 다 웹상에 나와 있고 검색 하루만 하면 뭘 해야 될지 알거다. 취준생처럼 다급한 상황이 아니라면 하면서 이거 하는게 맞는건지 고민하지 마라. 나중에 방향을 바꾸더라도 이전의 공부가 +가 되지 -가 되지는 않는다. 나도 해킹공부가 재밌어서 2년을 했고, 개발로 방향을 바꿨지만 개발에 대한 내 적성을 해킹공부하다 발견했다. 그리고 고민만 하다가는 아무것도 못한다. 라고 말합니다.(1,2학년때는 웹개발자 되고 싶어도 굳이 자바 스프링 이런거에 얽매이지 않아도 돼요! 하고 싶은거 해보세요.) 또 이런 공부들을 하면서 본인의 철학과 생각이 쌓이는데.. 이런게 쌓이면 인성면접은 따로 준비 안하셔도 될정도로 본인의 생각이 쌓입니다.(자소서에 쓸 내용이 늘어나는건 당연합니다.) 완전히 인성적인 질문(팀원간의 불화시 어쩔건가~같은)말고는 대부분의 질문에 본인이 생각하는 철학에 대해 풀어놓아도 좋은 답변이 될 수 있습니다. 어떤 질문을 받아도 자신있게 본인의 생각을 이야기할 수 있습니다. 위에 적은것들은 전부 오픈소스에 기여해라.. 처럼 힘들어보이는 일이 아닙니다. 그냥 열심히 공부만 열심히 하시면 대부분 다 하실수 있는거에요. 그리고... 본인이 공부를 열심히 해오셨으면 대기업 도전해보세요. 단순히 대학이 안좋다고 취준시 대기업은 일단 포기하고 눈낮춰서 시작하는분들이 엄청 많습니다.(대부분 중소 가서 경력쌓고 대기업 이직을 노리시더군요.) 다른 직군은 이해하지만 개발자라는 직종은 대학이 크게 중요한 요소는 아닙니다. 대학교 확인하고 서류부터 광탈하는 경우는 다른 직종보다 드뭅니다. 저도 수도권 대학 출신인데, 저희 학교에도 어릴때 프로그래밍 대회도 준비했을만큼 잘하는 분이 있었는데 대기업은 쓰지도 않는거 보고 많이 놀랐습니다. 저보다도 잘하는게 확실한 그분이 알아서 눈을 낮추더라고요. 대기업 쓰면 갈수 있을텐데 학교가 그닥이어서 애초에 도전도 하지 않는게 안타까웠습니다.열심히 공부해오셨으면 자신감을 가지고 일단 도전해보세요.취업에 도움이 되셨으면 좋겠네요.  +19년 3월 추가.6. 취업해서.저는 위에 적었듯이 파이썬이 저와 맞고 파이썬 개발자를 하고 싶었지만 현실은 알고 있었습니다. 파이썬이라는 언어로 신입을 거의 안 뽑기 때문이죠. 뽑아도 극소수의 스타트업에서 flask나 아니면 데이터 분석, 또는 머신러닝, ai를 위해서 파이썬을 쓰는데 저는 이러한 지식이 아무것도 없었습니다. 그래서 목표를 하고싶은 언어로 할수 있는 일을 하는 회사보다는 가고 싶은 회사를 목표로 잡았죠.(돈 많이 주고 성장성 있고 워라벨 좋아보이는 회사요.) 짧게말해서 it 대기업요. it 대기업이 안되면 차선책은 하고싶은거 할수있는 스타트업이었습니다.지금도 그렇지만 자바 스프링을 가장 많이 쓰기에, 자바 스프링을 메인으로 쓰는 회사 가면 언어를 바꿔봐야겠다고 생각했습니다. 그때도 지금도 적당히 좋은 기업이면서 파이썬을 주로 쓰는곳의 신입으로는 들어가기가 거의 불가능하기 때문이죠. 일단 공고 자체가 적으니.(지금은 요기요였나? 가 있긴 합니다. 공고가 다 파이썬이더군요.) 그런데 여기서 또 운이 따랐는지... 일단 현재 회사에 공채로 합격했습니다. 그리고 한달간 신입교육을 받았는데.. 그 후에 저희가 원하는곳으로 팀을 선택할수가 있더군요??? 오. 갈수 있는 팀 목록에는 보안 팀도 있었습니다. 헐.... 해킹을 포기하고 개발을 하기로 결심하고 개발자로 합격했는데 다시 보안을 갈수 있다니. 엄청나게 고민하다가 결국에는 끝내 개발로 하기로 하고 제가 원하는 팀으로 들어갔습니다. 그리고 제가 들어온 팀은 파이썬을 메인 언어로 씁니다. 취업에 관해서는 노력도 했지만 운도 엄청나게 따랐죠. 누군가 운도 준비된 사람이 잡는다라고 했는데.. 정말 저에게 맞는 말이었습니다.지금은 팀에서 데이터 엔지니어로 일하고 있습니다. 개발자로 일한지 몇년이 지난 지금에는 보안보다는 개발을 선택하길 매우 잘 한것 같아요. 이유는0. 개발은 무언가를 창출하는 일이고 보안은 제한하는 일이다. 대부분의 회사가 무언가를 창출하는게 중요하고(팀 성과 적을때도 개발은 뭐 개발했다 하면 되지만 보안은 매번 고민을 많이 해야할거임.) 보안이 크게 중요해지는건 일반적으로 대기업급인데,(작은 회사에는 보안팀이 없는 경우도 있죠.) 내가 보안을 한다고 가정하면 이직할만한 곳이 많이 없다. 1. 개발 시장이 위에 적은 이유로 보안 시장보다 훨씬 넓다.(제 개인적인 생각인데 개발쪽 시장이 보안쪽의 아마 100배 이상일것같네요.)2. 개발이 수요가 많은만큼 이직도 더 쉽게 되고 연봉올리기도 더 쉽다.(보안쪽에 똑똑한 사람보다 개발쪽의 덜 똑똑한데 연봉 많이 받는 케이스가 상당히 많을겁니다. 기회도 많고요.)3. 가장 좋은 직군은 현재 보기에 백엔드 개발이지만 다른 개발도 나름 수요가 많아서 괜찮다.등입니다. 그래서 혹시나 보안과 개발을 고려하고 있는 분이 있으면 전 개발을 강력 추천합니다. 조금 더 나중에 큰 사건(이직 등)이 생기면 추가로 글을 쓸 예정입니다.window.ReactionButtonType = 'reaction';window.ReactionApiUrl = '//qkqhxla1.tistory.com/reaction';window.ReactionReqBody = {    entryId: 802}공유하기게시글 관리archives저작자표시 비영리 변경금지 'private > memo' 카테고리의 다른 글(기사) 개발자의 평생공부  (2)2018.03.21웹해킹 카테고리 공개....  (2)2017.01.07쿠팡 캐치테스트, 면접 후기.(신입 개발자)  (51)2016.12.11쿠팡 자소서.(신입 개발자)  (0)2016.12.11프로그래머를 위한 이력서 서식  (0)2016.03.13'private/memo'의 다른글이전글쿠팡 캐치테스트, 면접 후기.(신입 개발자)현재글내가 한 컴퓨터 공부들과 공부 방법, 목표를 정하는 방식, 계기, 취업이야기 등.다음글웹해킹 카테고리 공개....관련글(기사) 개발자의 평생공부2018.03.21웹해킹 카테고리 공개....2017.01.07쿠팡 캐치테스트, 면접 후기.(신입 개발자)2016.12.11쿠팡 자소서.(신입 개발자)2016.12.11댓글 42    setInitialEntryComments(802, 1723624591)비밀글등록loadedComments[802]=true;findFragmentAndHighlight(802);프로그래밍 좋아합니다. 자료 퍼가실때는 참조만 적어주세요.. study (973)  setting, git, shell etc (21)  machine learning, image (27)  data engineering (93)  Python (140)  2.7 information (74)  2.7 simple coding(+ c++) (42)  2.7 for fun. (24)  web (27)  back + front (22)  etc (5)  kotlin (0)  algorithm (210)  theory (51)  problem solving (159)  webhacking (180)  sql, sql injection (98)  client (28)  etc (54)  systemhacking (34)  practice (25)  background (9)  private (0)  면접 (0)  memo (56)  Vancouver diary (77)  business trip (10)  normal diary (80)  English (17) Tag최근글과 인기글최근글인기글2023-03-27 월요일2023.03.27 22:022022-12-16 금요일2022.12.16 18:502022-10-13 목요일2022.10.13 23:04데이터 엔지니어 경력 5년 이직준비 후기2022.04.27 12:33취업을 위한 알고리즘 공부법.2019.01.10 11:01json.loads 에러시 위치 찾는 방법 꿀팁2019.12.02 14:06최근댓글네 위에 메일로 보내주세요.qkqhxla1안녕하세요.qkqhxla1@naver.com으로 보내주세요.qkqhxla1안녕하세요.qkqhxla1@naver.com으로 보내주세요.qkqhxla1공지사항페이스북 트위터 플러그인FacebookTwitter(function(d, s, id) {                        var js, fjs = d.getElementsByTagName(s)[0];                        if (d.getElementById(id)) return;                        js = d.createElement(s); js.id = id;                        js.src = '//connect.facebook.net/ko_KR/sdk.js#xfbml=1&version=v3.2&appId=360877073936113&autoLogAppEvents=1';                        fjs.parentNode.insertBefore(js, fjs);                      }(document, 'script', 'facebook-jssdk')); Archives2023/032022/122022/102022/06Calendar«   2024/08   »일월화수목금토    12345678910111213141516171819202122232425262728293031방문자수Total722,589Today : 8Yesterday : 104Copyright © Kakao Corp. All rights reserved.관련사이트Hide지훈현서님 (python developer)백준 온라인 저지 블로그.(매우 유용)티스토리툴바archives구독하기hljs.initHighlightingOnLoad();window.roosevelt_params_queue = window.roosevelt_params_queue || [{channel_id: 'dk', channel_label: '{tistory}'}]window.tiara = {""svcDomain"":""user.tistory.com"",""section"":""글뷰"",""trackPage"":""글뷰_보기"",""page"":""글뷰"",""key"":""1730919-802"",""customProps"":{""userId"":""0"",""blogId"":""1730919"",""entryId"":""802"",""role"":""guest"",""trackPage"":""글뷰_보기"",""filterTarget"":false},""entry"":{""entryId"":""802"",""entryTitle"":""내가 한 컴퓨터 공부들과 공부 방법, 목표를 정하는 방식, 계기, 취업이야기 등."",""entryType"":""POST"",""categoryName"":""private/memo"",""categoryId"":""557080"",""serviceCategoryName"":null,""serviceCategoryId"":null,""author"":""1249158"",""authorNickname"":""qkqhxla1"",""blogNmae"":""archives"",""image"":"""",""plink"":""/802"",""tags"":[]},""kakaoAppKey"":""3e6ddd834b023f24221217e370daed18"",""appUserId"":""null""}"
